{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25 # Eat TensorFlow2 in 30 days // 30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2 English Version: https://jackiexiao.github.io/eat_tensorflow2_in_30_days/english \u4e2d\u6587\u7248\u672c https://jackiexiao.github.io/eat_tensorflow2_in_30_days/chinese \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 Eat Pytorch in 20 days // 20\u5929\u5403\u6389\u90a3\u53eaPytorch \u4e2d\u6587\u7248\u672c: https://jackiexiao.github.io/eat_pytorch_in_20_days/ \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011","title":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25"},{"location":"#how-to-eat-tensorflow2-in-30-days-","text":"Eat TensorFlow2 in 30 days // 30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2 English Version: https://jackiexiao.github.io/eat_tensorflow2_in_30_days/english \u4e2d\u6587\u7248\u672c https://jackiexiao.github.io/eat_tensorflow2_in_30_days/chinese \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 Eat Pytorch in 20 days // 20\u5929\u5403\u6389\u90a3\u53eaPytorch \u4e2d\u6587\u7248\u672c: https://jackiexiao.github.io/eat_pytorch_in_20_days/ \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011","title":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25"},{"location":"chinese/","text":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25 # \u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_tensorflow2_in_30_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 \u300a20\u5929\u5403\u6389\u90a3\u53eaPytorch\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_pytorch_in_20_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 \u4e00\uff0cTensorFlow2 \ud83c\udf4e or Pytorch\ud83d\udd25 # \u5148\u8bf4\u7ed3\u8bba: \u5982\u679c\u662f\u5de5\u7a0b\u5e08\uff0c\u5e94\u8be5\u4f18\u5148\u9009TensorFlow2. \u5982\u679c\u662f\u5b66\u751f\u6216\u8005\u7814\u7a76\u4eba\u5458\uff0c\u5e94\u8be5\u4f18\u5148\u9009\u62e9Pytorch. \u5982\u679c\u65f6\u95f4\u8db3\u591f\uff0c\u6700\u597dTensorFlow2\u548cPytorch\u90fd\u8981\u5b66\u4e60\u638c\u63e1\u3002 \u7406\u7531\u5982\u4e0b\uff1a 1\uff0c \u5728\u5de5\u4e1a\u754c\u6700\u91cd\u8981\u7684\u662f\u6a21\u578b\u843d\u5730\uff0c\u76ee\u524d\u56fd\u5185\u7684\u5927\u90e8\u5206\u4e92\u8054\u7f51\u4f01\u4e1a\u53ea\u652f\u6301TensorFlow\u6a21\u578b\u7684\u5728\u7ebf\u90e8\u7f72\uff0c\u4e0d\u652f\u6301Pytorch\u3002 \u5e76\u4e14\u5de5\u4e1a\u754c\u66f4\u52a0\u6ce8\u91cd\u7684\u662f\u6a21\u578b\u7684\u9ad8\u53ef\u7528\u6027\uff0c\u8bb8\u591a\u65f6\u5019\u4f7f\u7528\u7684\u90fd\u662f\u6210\u719f\u7684\u6a21\u578b\u67b6\u6784\uff0c\u8c03\u8bd5\u9700\u6c42\u5e76\u4e0d\u5927\u3002 2\uff0c \u7814\u7a76\u4eba\u5458\u6700\u91cd\u8981\u7684\u662f\u5feb\u901f\u8fed\u4ee3\u53d1\u8868\u6587\u7ae0\uff0c\u9700\u8981\u5c1d\u8bd5\u4e00\u4e9b\u8f83\u65b0\u7684\u6a21\u578b\u67b6\u6784\u3002\u800cPytorch\u5728\u6613\u7528\u6027\u4e0a\u76f8\u6bd4TensorFlow2\u6709\u4e00\u4e9b\u4f18\u52bf\uff0c\u66f4\u52a0\u65b9\u4fbf\u8c03\u8bd5\u3002 \u5e76\u4e14\u57282019\u5e74\u4ee5\u6765\u5728\u5b66\u672f\u754c\u5360\u9886\u4e86\u5927\u534a\u58c1\u6c5f\u5c71\uff0c\u80fd\u591f\u627e\u5230\u7684\u76f8\u5e94\u6700\u65b0\u7814\u7a76\u6210\u679c\u66f4\u591a\u3002 3\uff0cTensorFlow2\u548cPytorch\u5b9e\u9645\u4e0a\u6574\u4f53\u98ce\u683c\u5df2\u7ecf\u975e\u5e38\u76f8\u4f3c\u4e86\uff0c\u5b66\u4f1a\u4e86\u5176\u4e2d\u4e00\u4e2a\uff0c\u5b66\u4e60\u53e6\u5916\u4e00\u4e2a\u5c06\u6bd4\u8f83\u5bb9\u6613\u3002\u4e24\u79cd\u6846\u67b6\u90fd\u638c\u63e1\u7684\u8bdd\uff0c\u80fd\u591f\u53c2\u8003\u7684\u5f00\u6e90\u6a21\u578b\u6848\u4f8b\u66f4\u591a\uff0c\u5e76\u4e14\u53ef\u4ee5\u65b9\u4fbf\u5730\u5728\u4e24\u79cd\u6846\u67b6\u4e4b\u95f4\u5207\u6362\u3002 \u4e8c\uff0cKeras\ud83c\udf4f and tf.keras \ud83c\udf4e # \u5148\u8bf4\u7ed3\u8bba\uff1a Keras\u5e93\u57282.3.0\u7248\u672c\u540e\u5c06\u4e0d\u518d\u66f4\u65b0\uff0c\u7528\u6237\u5e94\u8be5\u4f7f\u7528tf.keras\u3002 Keras\u53ef\u4ee5\u770b\u6210\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u9ad8\u9636\u63a5\u53e3\u89c4\u8303\uff0c\u5b83\u5e2e\u52a9\u7528\u6237\u4ee5\u66f4\u7b80\u6d01\u7684\u5f62\u5f0f\u5b9a\u4e49\u548c\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u3002 \u4f7f\u7528pip\u5b89\u88c5\u7684Keras\u5e93\u540c\u65f6\u5728tensorflow,theano,CNTK\u7b49\u540e\u7aef\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u8fd9\u79cd\u9ad8\u9636\u63a5\u53e3\u89c4\u8303\u7684\u5b9e\u73b0\u3002 \u800ctf.keras\u662f\u5728TensorFlow\u4e2d\u4ee5TensorFlow\u4f4e\u9636API\u4e3a\u57fa\u7840\u5b9e\u73b0\u7684\u8fd9\u79cd\u9ad8\u9636\u63a5\u53e3\uff0c\u5b83\u662fTensorflow\u7684\u4e00\u4e2a\u5b50\u6a21\u5757\u3002 tf.keras\u7edd\u5927\u90e8\u5206\u529f\u80fd\u548c\u517c\u5bb9\u591a\u79cd\u540e\u7aef\u7684Keras\u5e93\u7528\u6cd5\u5b8c\u5168\u4e00\u6837\uff0c\u4f46\u5e76\u975e\u5168\u90e8\uff0c\u5b83\u548cTensorFlow\u4e4b\u95f4\u7684\u7ed3\u5408\u66f4\u4e3a\u7d27\u5bc6\u3002 \u968f\u7740\u8c37\u6b4c\u5bf9Keras\u7684\u6536\u8d2d\uff0cKeras\u5e932.3.0\u7248\u672c\u540e\u4e5f\u5c06\u4e0d\u518d\u8fdb\u884c\u66f4\u65b0\uff0c\u7528\u6237\u5e94\u5f53\u4f7f\u7528tf.keras\u800c\u4e0d\u662f\u4f7f\u7528pip\u5b89\u88c5\u7684Keras. \u4e09\uff0c\u672c\u4e66\ud83d\udcd6\u9762\u5411\u8bfb\u8005 \ud83d\udc7c # \u672c\u4e66\u5047\u5b9a\u8bfb\u8005\u6709\u4e00\u5b9a\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\uff0c\u4f7f\u7528\u8fc7Keras\u6216\u8005Tensorflow1.0\u6216\u8005Pytorch\u642d\u5efa\u8bad\u7ec3\u8fc7\u6a21\u578b\u3002 \u5bf9\u4e8e\u6ca1\u6709\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u7684\u540c\u5b66\uff0c\u5efa\u8bae\u5728\u5b66\u4e60\u672c\u4e66\u65f6\u540c\u6b65\u53c2\u8003\u5b66\u4e60\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u4e00\u4e66\u3002 \u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u8fd9\u672c\u4e66\u662fKeras\u4e4b\u7236Francois Chollet\u6240\u8457\uff0c\u8be5\u4e66\u5047\u5b9a\u8bfb\u8005\u65e0\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\uff0c\u4ee5Keras\u4e3a\u5de5\u5177\uff0c \u4f7f\u7528\u4e30\u5bcc\u7684\u8303\u4f8b\u793a\u8303\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u8be5\u4e66\u901a\u4fd7\u6613\u61c2\uff0c \u5168\u4e66\u6ca1\u6709\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u6ce8\u91cd\u57f9\u517b\u8bfb\u8005\u7684\u6df1\u5ea6\u5b66\u4e60\u76f4\u89c9\u3002 \u3002 \u56db\uff0c\u672c\u4e66\u5199\u4f5c\u98ce\u683c \ud83c\udf49 # \u672c\u4e66\u662f\u4e00\u672c\u5bf9\u4eba\u7c7b\u7528\u6237\u6781\u5176\u53cb\u5584\u7684TensorFlow2.0\u5165\u95e8\u5de5\u5177\u4e66\uff0c\u4e0d\u523b\u610f\u6076\u5fc3\u8bfb\u8005\u662f\u672c\u4e66\u7684\u5e95\u9650\u8981\u6c42\uff0cDon't let me think\u662f\u672c\u4e66\u7684\u6700\u9ad8\u8ffd\u6c42\u3002 \u672c\u4e66\u4e3b\u8981\u662f\u5728\u53c2\u8003TensorFlow\u5b98\u65b9\u6587\u6863\u548c\u51fd\u6570doc\u6587\u6863\u57fa\u7840\u4e0a\u6574\u7406\u5199\u6210\u7684\u3002 \u4f46\u672c\u4e66\u5728\u7bc7\u7ae0\u7ed3\u6784\u548c\u8303\u4f8b\u9009\u53d6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u6df7\u4e71\u7684\u7bc7\u7ae0\u7ed3\u6784\uff0c\u65e2\u6709\u6559\u7a0b\u53c8\u6709\u6307\u5357\uff0c\u7f3a\u5c11\u6574\u4f53\u7684\u7f16\u6392\u903b\u8f91\u3002 \u672c\u4e66\u6309\u7167\u5185\u5bb9\u96be\u6613\u7a0b\u5ea6\u3001\u8bfb\u8005\u68c0\u7d22\u4e60\u60ef\u548cTensorFlow\u81ea\u8eab\u7684\u5c42\u6b21\u7ed3\u6784\u8bbe\u8ba1\u5185\u5bb9\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u5c42\u6b21\u6e05\u6670\uff0c\u65b9\u4fbf\u6309\u7167\u529f\u80fd\u67e5\u627e\u76f8\u5e94\u8303\u4f8b\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u5197\u957f\u7684\u8303\u4f8b\u4ee3\u7801\uff0c\u672c\u4e66\u5728\u8303\u4f8b\u8bbe\u8ba1\u4e0a\u5c3d\u53ef\u80fd\u7b80\u7ea6\u5316\u548c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u8303\u4f8b\u6613\u8bfb\u6027\u548c\u901a\u7528\u6027\uff0c\u5927\u90e8\u5206\u4ee3\u7801\u7247\u6bb5\u5728\u5b9e\u8df5\u4e2d\u53ef\u5373\u53d6\u5373\u7528\u3002 \u5982\u679c\u8bf4\u901a\u8fc7\u5b66\u4e60TensorFlow\u5b98\u65b9\u6587\u6863\u638c\u63e1TensorFlow2.0\u7684\u96be\u5ea6\u5927\u6982\u662f9\u7684\u8bdd\uff0c\u90a3\u4e48\u901a\u8fc7\u5b66\u4e60\u672c\u4e66\u638c\u63e1TensorFlow2.0\u7684\u96be\u5ea6\u5e94\u8be5\u5927\u6982\u662f3. \u8c28\u4ee5\u4e0b\u56fe\u5bf9\u6bd4\u4e00\u4e0bTensorFlow\u5b98\u65b9\u6559\u7a0b\u4e0e\u672c\u6559\u7a0b\u7684\u5dee\u5f02\u3002 \u4e94\uff0c\u672c\u4e66\u5b66\u4e60\u65b9\u6848 \u23f0 # 1\uff0c\u5b66\u4e60\u8ba1\u5212 \u672c\u4e66\u662f\u4f5c\u8005\u5229\u7528\u5de5\u4f5c\u4e4b\u4f59\u548c\u75ab\u60c5\u653e\u5047\u671f\u95f4\u5927\u69822\u4e2a\u6708\u5199\u6210\u7684\uff0c\u5927\u90e8\u5206\u8bfb\u8005\u5e94\u8be5\u572830\u5929\u53ef\u4ee5\u5b8c\u5168\u5b66\u4f1a\u3002 \u9884\u8ba1\u6bcf\u5929\u82b1\u8d39\u7684\u5b66\u4e60\u65f6\u95f4\u572830\u5206\u949f\u52302\u4e2a\u5c0f\u65f6\u4e4b\u95f4\u3002 \u5f53\u7136\uff0c\u672c\u4e66\u4e5f\u975e\u5e38\u9002\u5408\u4f5c\u4e3aTensorFlow\u7684\u5de5\u5177\u624b\u518c\u5728\u5de5\u7a0b\u843d\u5730\u65f6\u4f5c\u4e3a\u8303\u4f8b\u5e93\u53c2\u8003\u3002 \u70b9\u51fb\u5b66\u4e60\u5185\u5bb9\u84dd\u8272\u6807\u9898\u5373\u53ef\u8fdb\u5165\u8be5\u7ae0\u8282\u3002 \u65e5\u671f \u5b66\u4e60\u5185\u5bb9 \u5185\u5bb9\u96be\u5ea6 \u9884\u8ba1\u5b66\u4e60\u65f6\u95f4 \u66f4\u65b0\u72b6\u6001 [ \u4e00\u3001TensorFlow\u7684\u5efa\u6a21\u6d41\u7a0b ] \u2b50\ufe0f 0hour \u2705 day1 [1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day2 [1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day3 [1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day4 [1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 [ \u4e8c\u3001TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5 ] \u2b50\ufe0f 0hour \u2705 day5 [2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day6 [2-2,\u4e09\u79cd\u8ba1\u7b97\u56fe] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day7 [2-3,\u81ea\u52a8\u5fae\u5206\u673a\u5236] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u4e09\u3001TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784 ] \u2b50\ufe0f 0hour \u2705 day8 [3-1,\u4f4e\u9636API\u793a\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day9 [3-2,\u4e2d\u9636API\u793a\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day10 [3-3,\u9ad8\u9636API\u793a\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u56db\u3001TensorFlow\u7684\u4f4e\u9636API ] \u2b50\ufe0f 0hour \u2705 day11 [4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day12 [4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day13 [4-3,AutoGraph\u7684\u4f7f\u7528\u89c4\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day14 [4-4,AutoGraph\u7684\u673a\u5236\u539f\u7406] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day15 [4-5,AutoGraph\u548ctf.Module] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u4e94\u3001TensorFlow\u7684\u4e2d\u9636API ] \u2b50\ufe0f 0hour \u2705 day16 [5-1,\u6570\u636e\u7ba1\u9053Dataset] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day17 [5-2,\u7279\u5f81\u5217feature_column] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day18 [5-3,\u6fc0\u6d3b\u51fd\u6570activation] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day19 [5-4,\u6a21\u578b\u5c42layers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day20 [5-5,\u635f\u5931\u51fd\u6570losses] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day21 [5-6,\u8bc4\u4f30\u6307\u6807metrics] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day22 [5-7,\u4f18\u5316\u5668optimizers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day23 [5-8,\u56de\u8c03\u51fd\u6570callbacks] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u516d\u3001TensorFlow\u7684\u9ad8\u9636API ] \u2b50\ufe0f 0hour \u2705 day24 [6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day25 [6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day26 [6-3,\u4f7f\u7528\u5355GPU\u8bad\u7ec3\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day27 [6-4,\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day28 [6-5,\u4f7f\u7528TPU\u8bad\u7ec3\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day29 [6-6,\u4f7f\u7528tensorflow-serving\u90e8\u7f72\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day30 [6-7,\u4f7f\u7528spark-scala\u8c03\u7528tensorflow\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 [\u540e\u8bb0\uff1a\u4e00\u4e2a\u5403\u8d27\u548c\u4e00\u9053\u83dc\u7684\u6545\u4e8b] \u2b50\ufe0f 0hour \u2705 2\uff0c\u5b66\u4e60\u73af\u5883 \u672c\u4e66\u5168\u90e8\u6e90\u7801\u5728jupyter\u4e2d\u7f16\u5199\u6d4b\u8bd5\u901a\u8fc7\uff0c\u5efa\u8bae\u901a\u8fc7git\u514b\u9686\u5230\u672c\u5730\uff0c\u5e76\u5728jupyter\u4e2d\u4ea4\u4e92\u5f0f\u8fd0\u884c\u5b66\u4e60\u3002 \u4e3a\u4e86\u76f4\u63a5\u80fd\u591f\u5728jupyter\u4e2d\u6253\u5f00markdown\u6587\u4ef6\uff0c\u5efa\u8bae\u5b89\u88c5jupytext\uff0c\u5c06markdown\u8f6c\u6362\u6210ipynb\u6587\u4ef6\u3002 \u6b64\u5916\uff0c\u672c\u9879\u76ee\u4e5f\u4e0e\u548c\u9cb8\u793e\u533a\u8fbe\u6210\u4e86\u5408\u4f5c\uff0c\u53ef\u4ee5\u5728\u548c\u9cb8\u4e13\u680ffork\u672c\u9879\u76ee\uff0c\u5e76\u76f4\u63a5\u5728\u4e91\u7b14\u8bb0\u672c\u4e0a\u8fd0\u884c\u4ee3\u7801\uff0c\u907f\u514d\u73af\u5883\u914d\u7f6e\u75db\u82e6\u3002 \ud83d\udc33\u548c\u9cb8\u4e13\u680f\u5730\u5740\uff1a https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 #\u514b\u9686\u672c\u4e66\u6e90\u7801\u5230\u672c\u5730,\u4f7f\u7528\u7801\u4e91\u955c\u50cf\u4ed3\u5e93\u56fd\u5185\u4e0b\u8f7d\u901f\u5ea6\u66f4\u5feb #!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5jupytext\uff0c\u4ee5\u4fbf\u80fd\u591f\u5c06\u672c\u4e66\u5404\u7ae0\u8282markdown\u6587\u4ef6\u89c6\u4f5cipynb\u6587\u4ef6\u8fd0\u884c #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5\u6700\u65b0\u7248\u672ctensorflow \u6d4b\u8bd5\u672c\u4e66\u4e2d\u7684\u4ee3\u7801 #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U tensorflow import tensorflow as tf #\u6ce8\uff1a\u672c\u4e66\u5168\u90e8\u4ee3\u7801\u5728tensorflow 2.1\u7248\u672c\u6d4b\u8bd5\u901a\u8fc7 tf . print ( \"tensorflow version:\" , tf . __version__ ) a = tf . constant ( \"hello\" ) b = tf . constant ( \"tensorflow2\" ) c = tf . strings . join ([ a , b ], \" \" ) tf . print ( c ) tensorflow version: 2.1.0 hello tensorflow2 \u516d\uff0c\u9f13\u52b1\u548c\u8054\u7cfb\u4f5c\u8005 \ud83c\udf88\ud83c\udf88 # \u5982\u679c\u672c\u4e66\u5bf9\u4f60\u6709\u6240\u5e2e\u52a9\uff0c\u60f3\u9f13\u52b1\u4e00\u4e0b\u4f5c\u8005\uff0c\u8bb0\u5f97\u7ed9\u672c\u9879\u76ee\u52a0\u4e00\u9897\u661f\u661fstar\u2b50\ufe0f\uff0c\u5e76\u5206\u4eab\u7ed9\u4f60\u7684\u670b\u53cb\u4eec\u5594\ud83d\ude0a! \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25"},{"location":"chinese/#how-to-eat-tensorflow2-in-30-days-","text":"\u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_tensorflow2_in_30_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 \u300a20\u5929\u5403\u6389\u90a3\u53eaPytorch\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_pytorch_in_20_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011","title":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25"},{"location":"chinese/#\u4e00tensorflow2--or-pytorch","text":"\u5148\u8bf4\u7ed3\u8bba: \u5982\u679c\u662f\u5de5\u7a0b\u5e08\uff0c\u5e94\u8be5\u4f18\u5148\u9009TensorFlow2. \u5982\u679c\u662f\u5b66\u751f\u6216\u8005\u7814\u7a76\u4eba\u5458\uff0c\u5e94\u8be5\u4f18\u5148\u9009\u62e9Pytorch. \u5982\u679c\u65f6\u95f4\u8db3\u591f\uff0c\u6700\u597dTensorFlow2\u548cPytorch\u90fd\u8981\u5b66\u4e60\u638c\u63e1\u3002 \u7406\u7531\u5982\u4e0b\uff1a 1\uff0c \u5728\u5de5\u4e1a\u754c\u6700\u91cd\u8981\u7684\u662f\u6a21\u578b\u843d\u5730\uff0c\u76ee\u524d\u56fd\u5185\u7684\u5927\u90e8\u5206\u4e92\u8054\u7f51\u4f01\u4e1a\u53ea\u652f\u6301TensorFlow\u6a21\u578b\u7684\u5728\u7ebf\u90e8\u7f72\uff0c\u4e0d\u652f\u6301Pytorch\u3002 \u5e76\u4e14\u5de5\u4e1a\u754c\u66f4\u52a0\u6ce8\u91cd\u7684\u662f\u6a21\u578b\u7684\u9ad8\u53ef\u7528\u6027\uff0c\u8bb8\u591a\u65f6\u5019\u4f7f\u7528\u7684\u90fd\u662f\u6210\u719f\u7684\u6a21\u578b\u67b6\u6784\uff0c\u8c03\u8bd5\u9700\u6c42\u5e76\u4e0d\u5927\u3002 2\uff0c \u7814\u7a76\u4eba\u5458\u6700\u91cd\u8981\u7684\u662f\u5feb\u901f\u8fed\u4ee3\u53d1\u8868\u6587\u7ae0\uff0c\u9700\u8981\u5c1d\u8bd5\u4e00\u4e9b\u8f83\u65b0\u7684\u6a21\u578b\u67b6\u6784\u3002\u800cPytorch\u5728\u6613\u7528\u6027\u4e0a\u76f8\u6bd4TensorFlow2\u6709\u4e00\u4e9b\u4f18\u52bf\uff0c\u66f4\u52a0\u65b9\u4fbf\u8c03\u8bd5\u3002 \u5e76\u4e14\u57282019\u5e74\u4ee5\u6765\u5728\u5b66\u672f\u754c\u5360\u9886\u4e86\u5927\u534a\u58c1\u6c5f\u5c71\uff0c\u80fd\u591f\u627e\u5230\u7684\u76f8\u5e94\u6700\u65b0\u7814\u7a76\u6210\u679c\u66f4\u591a\u3002 3\uff0cTensorFlow2\u548cPytorch\u5b9e\u9645\u4e0a\u6574\u4f53\u98ce\u683c\u5df2\u7ecf\u975e\u5e38\u76f8\u4f3c\u4e86\uff0c\u5b66\u4f1a\u4e86\u5176\u4e2d\u4e00\u4e2a\uff0c\u5b66\u4e60\u53e6\u5916\u4e00\u4e2a\u5c06\u6bd4\u8f83\u5bb9\u6613\u3002\u4e24\u79cd\u6846\u67b6\u90fd\u638c\u63e1\u7684\u8bdd\uff0c\u80fd\u591f\u53c2\u8003\u7684\u5f00\u6e90\u6a21\u578b\u6848\u4f8b\u66f4\u591a\uff0c\u5e76\u4e14\u53ef\u4ee5\u65b9\u4fbf\u5730\u5728\u4e24\u79cd\u6846\u67b6\u4e4b\u95f4\u5207\u6362\u3002","title":"\u4e00\uff0cTensorFlow2 \ud83c\udf4e or Pytorch\ud83d\udd25"},{"location":"chinese/#\u4e8ckeras-and--tfkeras-","text":"\u5148\u8bf4\u7ed3\u8bba\uff1a Keras\u5e93\u57282.3.0\u7248\u672c\u540e\u5c06\u4e0d\u518d\u66f4\u65b0\uff0c\u7528\u6237\u5e94\u8be5\u4f7f\u7528tf.keras\u3002 Keras\u53ef\u4ee5\u770b\u6210\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u9ad8\u9636\u63a5\u53e3\u89c4\u8303\uff0c\u5b83\u5e2e\u52a9\u7528\u6237\u4ee5\u66f4\u7b80\u6d01\u7684\u5f62\u5f0f\u5b9a\u4e49\u548c\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u3002 \u4f7f\u7528pip\u5b89\u88c5\u7684Keras\u5e93\u540c\u65f6\u5728tensorflow,theano,CNTK\u7b49\u540e\u7aef\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u8fd9\u79cd\u9ad8\u9636\u63a5\u53e3\u89c4\u8303\u7684\u5b9e\u73b0\u3002 \u800ctf.keras\u662f\u5728TensorFlow\u4e2d\u4ee5TensorFlow\u4f4e\u9636API\u4e3a\u57fa\u7840\u5b9e\u73b0\u7684\u8fd9\u79cd\u9ad8\u9636\u63a5\u53e3\uff0c\u5b83\u662fTensorflow\u7684\u4e00\u4e2a\u5b50\u6a21\u5757\u3002 tf.keras\u7edd\u5927\u90e8\u5206\u529f\u80fd\u548c\u517c\u5bb9\u591a\u79cd\u540e\u7aef\u7684Keras\u5e93\u7528\u6cd5\u5b8c\u5168\u4e00\u6837\uff0c\u4f46\u5e76\u975e\u5168\u90e8\uff0c\u5b83\u548cTensorFlow\u4e4b\u95f4\u7684\u7ed3\u5408\u66f4\u4e3a\u7d27\u5bc6\u3002 \u968f\u7740\u8c37\u6b4c\u5bf9Keras\u7684\u6536\u8d2d\uff0cKeras\u5e932.3.0\u7248\u672c\u540e\u4e5f\u5c06\u4e0d\u518d\u8fdb\u884c\u66f4\u65b0\uff0c\u7528\u6237\u5e94\u5f53\u4f7f\u7528tf.keras\u800c\u4e0d\u662f\u4f7f\u7528pip\u5b89\u88c5\u7684Keras.","title":"\u4e8c\uff0cKeras\ud83c\udf4f and  tf.keras \ud83c\udf4e"},{"location":"chinese/#\u4e09\u672c\u4e66\u9762\u5411\u8bfb\u8005-","text":"\u672c\u4e66\u5047\u5b9a\u8bfb\u8005\u6709\u4e00\u5b9a\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\uff0c\u4f7f\u7528\u8fc7Keras\u6216\u8005Tensorflow1.0\u6216\u8005Pytorch\u642d\u5efa\u8bad\u7ec3\u8fc7\u6a21\u578b\u3002 \u5bf9\u4e8e\u6ca1\u6709\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u7684\u540c\u5b66\uff0c\u5efa\u8bae\u5728\u5b66\u4e60\u672c\u4e66\u65f6\u540c\u6b65\u53c2\u8003\u5b66\u4e60\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u4e00\u4e66\u3002 \u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u8fd9\u672c\u4e66\u662fKeras\u4e4b\u7236Francois Chollet\u6240\u8457\uff0c\u8be5\u4e66\u5047\u5b9a\u8bfb\u8005\u65e0\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\uff0c\u4ee5Keras\u4e3a\u5de5\u5177\uff0c \u4f7f\u7528\u4e30\u5bcc\u7684\u8303\u4f8b\u793a\u8303\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u8be5\u4e66\u901a\u4fd7\u6613\u61c2\uff0c \u5168\u4e66\u6ca1\u6709\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u6ce8\u91cd\u57f9\u517b\u8bfb\u8005\u7684\u6df1\u5ea6\u5b66\u4e60\u76f4\u89c9\u3002 \u3002","title":"\u4e09\uff0c\u672c\u4e66\ud83d\udcd6\u9762\u5411\u8bfb\u8005 \ud83d\udc7c"},{"location":"chinese/#\u56db\u672c\u4e66\u5199\u4f5c\u98ce\u683c-","text":"\u672c\u4e66\u662f\u4e00\u672c\u5bf9\u4eba\u7c7b\u7528\u6237\u6781\u5176\u53cb\u5584\u7684TensorFlow2.0\u5165\u95e8\u5de5\u5177\u4e66\uff0c\u4e0d\u523b\u610f\u6076\u5fc3\u8bfb\u8005\u662f\u672c\u4e66\u7684\u5e95\u9650\u8981\u6c42\uff0cDon't let me think\u662f\u672c\u4e66\u7684\u6700\u9ad8\u8ffd\u6c42\u3002 \u672c\u4e66\u4e3b\u8981\u662f\u5728\u53c2\u8003TensorFlow\u5b98\u65b9\u6587\u6863\u548c\u51fd\u6570doc\u6587\u6863\u57fa\u7840\u4e0a\u6574\u7406\u5199\u6210\u7684\u3002 \u4f46\u672c\u4e66\u5728\u7bc7\u7ae0\u7ed3\u6784\u548c\u8303\u4f8b\u9009\u53d6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u6df7\u4e71\u7684\u7bc7\u7ae0\u7ed3\u6784\uff0c\u65e2\u6709\u6559\u7a0b\u53c8\u6709\u6307\u5357\uff0c\u7f3a\u5c11\u6574\u4f53\u7684\u7f16\u6392\u903b\u8f91\u3002 \u672c\u4e66\u6309\u7167\u5185\u5bb9\u96be\u6613\u7a0b\u5ea6\u3001\u8bfb\u8005\u68c0\u7d22\u4e60\u60ef\u548cTensorFlow\u81ea\u8eab\u7684\u5c42\u6b21\u7ed3\u6784\u8bbe\u8ba1\u5185\u5bb9\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u5c42\u6b21\u6e05\u6670\uff0c\u65b9\u4fbf\u6309\u7167\u529f\u80fd\u67e5\u627e\u76f8\u5e94\u8303\u4f8b\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u5197\u957f\u7684\u8303\u4f8b\u4ee3\u7801\uff0c\u672c\u4e66\u5728\u8303\u4f8b\u8bbe\u8ba1\u4e0a\u5c3d\u53ef\u80fd\u7b80\u7ea6\u5316\u548c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u8303\u4f8b\u6613\u8bfb\u6027\u548c\u901a\u7528\u6027\uff0c\u5927\u90e8\u5206\u4ee3\u7801\u7247\u6bb5\u5728\u5b9e\u8df5\u4e2d\u53ef\u5373\u53d6\u5373\u7528\u3002 \u5982\u679c\u8bf4\u901a\u8fc7\u5b66\u4e60TensorFlow\u5b98\u65b9\u6587\u6863\u638c\u63e1TensorFlow2.0\u7684\u96be\u5ea6\u5927\u6982\u662f9\u7684\u8bdd\uff0c\u90a3\u4e48\u901a\u8fc7\u5b66\u4e60\u672c\u4e66\u638c\u63e1TensorFlow2.0\u7684\u96be\u5ea6\u5e94\u8be5\u5927\u6982\u662f3. \u8c28\u4ee5\u4e0b\u56fe\u5bf9\u6bd4\u4e00\u4e0bTensorFlow\u5b98\u65b9\u6559\u7a0b\u4e0e\u672c\u6559\u7a0b\u7684\u5dee\u5f02\u3002","title":"\u56db\uff0c\u672c\u4e66\u5199\u4f5c\u98ce\u683c \ud83c\udf49"},{"location":"chinese/#\u4e94\u672c\u4e66\u5b66\u4e60\u65b9\u6848-","text":"1\uff0c\u5b66\u4e60\u8ba1\u5212 \u672c\u4e66\u662f\u4f5c\u8005\u5229\u7528\u5de5\u4f5c\u4e4b\u4f59\u548c\u75ab\u60c5\u653e\u5047\u671f\u95f4\u5927\u69822\u4e2a\u6708\u5199\u6210\u7684\uff0c\u5927\u90e8\u5206\u8bfb\u8005\u5e94\u8be5\u572830\u5929\u53ef\u4ee5\u5b8c\u5168\u5b66\u4f1a\u3002 \u9884\u8ba1\u6bcf\u5929\u82b1\u8d39\u7684\u5b66\u4e60\u65f6\u95f4\u572830\u5206\u949f\u52302\u4e2a\u5c0f\u65f6\u4e4b\u95f4\u3002 \u5f53\u7136\uff0c\u672c\u4e66\u4e5f\u975e\u5e38\u9002\u5408\u4f5c\u4e3aTensorFlow\u7684\u5de5\u5177\u624b\u518c\u5728\u5de5\u7a0b\u843d\u5730\u65f6\u4f5c\u4e3a\u8303\u4f8b\u5e93\u53c2\u8003\u3002 \u70b9\u51fb\u5b66\u4e60\u5185\u5bb9\u84dd\u8272\u6807\u9898\u5373\u53ef\u8fdb\u5165\u8be5\u7ae0\u8282\u3002 \u65e5\u671f \u5b66\u4e60\u5185\u5bb9 \u5185\u5bb9\u96be\u5ea6 \u9884\u8ba1\u5b66\u4e60\u65f6\u95f4 \u66f4\u65b0\u72b6\u6001 [ \u4e00\u3001TensorFlow\u7684\u5efa\u6a21\u6d41\u7a0b ] \u2b50\ufe0f 0hour \u2705 day1 [1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day2 [1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day3 [1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day4 [1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 [ \u4e8c\u3001TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5 ] \u2b50\ufe0f 0hour \u2705 day5 [2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day6 [2-2,\u4e09\u79cd\u8ba1\u7b97\u56fe] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day7 [2-3,\u81ea\u52a8\u5fae\u5206\u673a\u5236] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u4e09\u3001TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784 ] \u2b50\ufe0f 0hour \u2705 day8 [3-1,\u4f4e\u9636API\u793a\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day9 [3-2,\u4e2d\u9636API\u793a\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day10 [3-3,\u9ad8\u9636API\u793a\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u56db\u3001TensorFlow\u7684\u4f4e\u9636API ] \u2b50\ufe0f 0hour \u2705 day11 [4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day12 [4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day13 [4-3,AutoGraph\u7684\u4f7f\u7528\u89c4\u8303] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day14 [4-4,AutoGraph\u7684\u673a\u5236\u539f\u7406] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day15 [4-5,AutoGraph\u548ctf.Module] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u4e94\u3001TensorFlow\u7684\u4e2d\u9636API ] \u2b50\ufe0f 0hour \u2705 day16 [5-1,\u6570\u636e\u7ba1\u9053Dataset] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day17 [5-2,\u7279\u5f81\u5217feature_column] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day18 [5-3,\u6fc0\u6d3b\u51fd\u6570activation] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day19 [5-4,\u6a21\u578b\u5c42layers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day20 [5-5,\u635f\u5931\u51fd\u6570losses] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day21 [5-6,\u8bc4\u4f30\u6307\u6807metrics] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day22 [5-7,\u4f18\u5316\u5668optimizers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day23 [5-8,\u56de\u8c03\u51fd\u6570callbacks] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ \u516d\u3001TensorFlow\u7684\u9ad8\u9636API ] \u2b50\ufe0f 0hour \u2705 day24 [6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day25 [6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day26 [6-3,\u4f7f\u7528\u5355GPU\u8bad\u7ec3\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day27 [6-4,\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day28 [6-5,\u4f7f\u7528TPU\u8bad\u7ec3\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 day29 [6-6,\u4f7f\u7528tensorflow-serving\u90e8\u7f72\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day30 [6-7,\u4f7f\u7528spark-scala\u8c03\u7528tensorflow\u6a21\u578b] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 [\u540e\u8bb0\uff1a\u4e00\u4e2a\u5403\u8d27\u548c\u4e00\u9053\u83dc\u7684\u6545\u4e8b] \u2b50\ufe0f 0hour \u2705 2\uff0c\u5b66\u4e60\u73af\u5883 \u672c\u4e66\u5168\u90e8\u6e90\u7801\u5728jupyter\u4e2d\u7f16\u5199\u6d4b\u8bd5\u901a\u8fc7\uff0c\u5efa\u8bae\u901a\u8fc7git\u514b\u9686\u5230\u672c\u5730\uff0c\u5e76\u5728jupyter\u4e2d\u4ea4\u4e92\u5f0f\u8fd0\u884c\u5b66\u4e60\u3002 \u4e3a\u4e86\u76f4\u63a5\u80fd\u591f\u5728jupyter\u4e2d\u6253\u5f00markdown\u6587\u4ef6\uff0c\u5efa\u8bae\u5b89\u88c5jupytext\uff0c\u5c06markdown\u8f6c\u6362\u6210ipynb\u6587\u4ef6\u3002 \u6b64\u5916\uff0c\u672c\u9879\u76ee\u4e5f\u4e0e\u548c\u9cb8\u793e\u533a\u8fbe\u6210\u4e86\u5408\u4f5c\uff0c\u53ef\u4ee5\u5728\u548c\u9cb8\u4e13\u680ffork\u672c\u9879\u76ee\uff0c\u5e76\u76f4\u63a5\u5728\u4e91\u7b14\u8bb0\u672c\u4e0a\u8fd0\u884c\u4ee3\u7801\uff0c\u907f\u514d\u73af\u5883\u914d\u7f6e\u75db\u82e6\u3002 \ud83d\udc33\u548c\u9cb8\u4e13\u680f\u5730\u5740\uff1a https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 #\u514b\u9686\u672c\u4e66\u6e90\u7801\u5230\u672c\u5730,\u4f7f\u7528\u7801\u4e91\u955c\u50cf\u4ed3\u5e93\u56fd\u5185\u4e0b\u8f7d\u901f\u5ea6\u66f4\u5feb #!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5jupytext\uff0c\u4ee5\u4fbf\u80fd\u591f\u5c06\u672c\u4e66\u5404\u7ae0\u8282markdown\u6587\u4ef6\u89c6\u4f5cipynb\u6587\u4ef6\u8fd0\u884c #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5\u6700\u65b0\u7248\u672ctensorflow \u6d4b\u8bd5\u672c\u4e66\u4e2d\u7684\u4ee3\u7801 #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U tensorflow import tensorflow as tf #\u6ce8\uff1a\u672c\u4e66\u5168\u90e8\u4ee3\u7801\u5728tensorflow 2.1\u7248\u672c\u6d4b\u8bd5\u901a\u8fc7 tf . print ( \"tensorflow version:\" , tf . __version__ ) a = tf . constant ( \"hello\" ) b = tf . constant ( \"tensorflow2\" ) c = tf . strings . join ([ a , b ], \" \" ) tf . print ( c ) tensorflow version: 2.1.0 hello tensorflow2","title":"\u4e94\uff0c\u672c\u4e66\u5b66\u4e60\u65b9\u6848 \u23f0"},{"location":"chinese/#\u516d\u9f13\u52b1\u548c\u8054\u7cfb\u4f5c\u8005-","text":"\u5982\u679c\u672c\u4e66\u5bf9\u4f60\u6709\u6240\u5e2e\u52a9\uff0c\u60f3\u9f13\u52b1\u4e00\u4e0b\u4f5c\u8005\uff0c\u8bb0\u5f97\u7ed9\u672c\u9879\u76ee\u52a0\u4e00\u9897\u661f\u661fstar\u2b50\ufe0f\uff0c\u5e76\u5206\u4eab\u7ed9\u4f60\u7684\u670b\u53cb\u4eec\u5594\ud83d\ude0a! \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u9f13\u52b1\u548c\u8054\u7cfb\u4f5c\u8005 \ud83c\udf88\ud83c\udf88"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/","text":"\u4e00\u4e2a\u5403\u8d27\u548c\u4e00\u9053\u83dc\u7684\u6545\u4e8b # \u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b\u8fd9\u672c\u4e66\u5df2\u7ecf\u5168\u90e8\u6574\u7406\u5b8c\u7a3f\u3002\u672c\u7bc7\u6587\u7ae0\u7b97\u662f\u8fd9\u672c\u4e66\u7684\u4e00\u4e2a\u540e\u8bb0\u3002 \u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5403\u8d27\u4e0e\u7b97\u6cd5\u7ed3\u7f18\u7684\u6545\u4e8b\uff0c\u5e76\u4ecb\u7ecd\u4e86\u672c\u4e66\u7684\u5199\u4f5c\u8fc7\u7a0b\u3002\u53ef\u4f9b\u611f\u5174\u8da3\u7684\u8bfb\u8005\u4e00\u4e50\u3002 \u5982\u679c\u8bfb\u8005\u65f6\u95f4\u7d27\u8feb\uff0c\u53ef\u76f4\u63a5\u9605\u8bfb\u672c\u6587\u7b2c3\u90e8\u5206\u548c\u7b2c4\u90e8\u5206\uff0c\u4e86\u89e3\u4e66\u7c4d\u5185\u5bb9\u548c\u83b7\u53d6\u65b9\u6cd5\u3002 \u4e00\uff0c\u4e00\u4e2a\u5403\u8d27\u8f6c\u884c\u7b97\u6cd5\u7684\u5fc3\u8def\u5386\u7a0b # 2015\u5e746\u6708\uff0c\u53c8\u662f\u4e00\u4e2a\u6bd5\u4e1a\u5b63\uff0c\u4e00\u4e2a\u5403\u8d27\u4ece\u5317\u4eac\u5403\u996d\u5927\u5b66\u6bd5\u4e1a\u4e86\u3002 \u867d\u7136\u662f\u5403\u996d\u5927\u5b66\u6bd5\u4e1a\uff0c\u4f46\u4ed6\u5b66\u7684\u662f\u7406\u8bba\u7269\u7406\uff0c\u800c\u7406\u8bba\u7269\u7406\u4e0d\u662f\u4e00\u4e2a\u9002\u5408\u627e\u996d\u5403\u7684\u4e13\u4e1a\u3002 \u51e0\u7ecf\u8f97\u8f6c\uff0c\u8fd9\u4e2a\u5403\u8d27\u5728\u91d1\u878d\u884c\u4e1a\u627e\u5230\u4e86\u4e00\u4efd\u91cf\u5316\u7a0b\u5e8f\u5458\u7684\u5de5\u4f5c\uff0c\u867d\u7136\u6536\u5165\u4f4e\u5fae\uff0c\u4f46\u662f\u8fd9\u4e2a\u5403\u8d27\u68a6\u60f3\u6709\u4e00\u5929\u53ef\u4ee5\u627e\u5230\u80fd\u591f\u7a33\u5b9a\u76c8\u5229\u7684\u91cf\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u4ea4\u6613\u8d5a\u94b1\u8ba9\u81ea\u5df1\u80fd\u591f\u6bcf\u5929\u90fd\u6709\u53e3\u597d\u5403\u7684\u3002 \u7136\u800c\uff0c\u8d44\u672c\u5e02\u573a\u6ce2\u8c32\u4e91\u8be1\uff0c\u4ed6\u5c1d\u8bd5\u8fc7\u8bb8\u591a\u4ea4\u6613\u7b56\u7565\uff0c\u5374\u6ca1\u6709\u627e\u5230\u80fd\u591f\u7a33\u5b9a\u8d5a\u94b1\u7684\"\u5723\u676f\"\uff0c\u4f19\u98df\u4e5f\u4e00\u5929\u6bd4\u4e00\u5929\u53d8\u5dee\u4e86\u3002 \u5728\u4e0eK\u7ebf\u7684\u7ea0\u7f20\u4e2d\uff0c\u4ed6\u6162\u6162\u5730\u8ff7\u5931\u4e86\uff0c\u867d\u7136\u4ed6\u77e5\u9053\u6bcf\u6b21\u4e8f\u94b1\u90fd\u662f\u9760\u5b9e\u529b\u8f93\u7684\uff0c\u4f46\u662f\u4ed6\u4e0d\u77e5\u9053\u81ea\u5df1\u6bcf\u6b21\u8d5a\u94b1\u662f\u51ed\u501f\u5b9e\u529b\u8d5a\u7684\u8fd8\u662f\u51ed\u8fd0\u6c14\u8d5a\u7684\u3002\u4ed6\u611f\u5230\u5728\u91d1\u878d\u4ea4\u6613\u8fd9\u4e2a\u884c\u4e1a\u5f88\u96be\u6e05\u6670\u5730\u770b\u5230\u81ea\u5df1\u7684\u8fdb\u6b65\u3002 \u4ed8\u51fa\u4e86\u90a3\u4e48\u591a\u7684\u52aa\u529b\uff0c\u641e\u4e86\u90a3\u4e48\u591a\u6a21\u578b\uff0c\u5199\u4e86\u90a3\u4e48\u591a\u7b56\u7565\uff0c\u81ea\u5df1\u5c31\u771f\u7684\u6709\u6210\u957f\u5417\uff1f\u5728\u6b8b\u9177\u7684\u4ea4\u6613\u4e16\u754c\u91cc\uff0c\u8fd9\u4e9b\u4e1c\u897f\u4e0d\u80fd\u8d5a\u94b1\uff0c\u4e0d\u80fd\u591f\u6539\u5584\u81ea\u5df1\u7684\u4f19\u98df\uff0c\u53c8\u6709\u4ec0\u4e48\u4ef7\u503c\u5462\uff1f \u4f5c\u4e3a\u4e00\u4e2a\u5403\u8d27\uff0c\u4ed6\u65e0\u6cd5\u5fcd\u53d7\u4f19\u98df\u53d8\u5f97\u8d8a\u6765\u8d8a\u5dee\u3002\u4ed6\u51b3\u5b9a\u6362\u4e00\u4e2a\u80fd\u591f\u7a33\u5b9a\u5730\u8ba9\u4f19\u98df\u53d8\u5f97\u66f4\u597d\u7684\u884c\u4e1a\u3002 \u90a3\u4e2a\u65f6\u5019\uff0c\u968f\u7740AlphaGo\u6218\u80dc\u4e16\u754c\u56f4\u68cb\u51a0\u519b\u674e\u4e16\u77f3\u7684\u6545\u4e8b\u5e7f\u4e3a\u4eba\u77e5\uff0c\u5728\u4e92\u8054\u7f51\u9886\u57df\u6709\u4e00\u4e2a\u65b0\u5174\u5c97\u4f4d\u9010\u6e10\u706b\u70ed\uff0c\u90a3\u5c31\u662f\u7b97\u6cd5\u5de5\u7a0b\u5e08\u3002 \u8fd9\u4e2a\u5403\u8d27\u5fc3\u60f3\uff0c\u6211\u4e5f\u662f\u505a\u6a21\u578b\u7684\uff0c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u4e5f\u662f\u505a\u6a21\u578b\u7684\uff0c\u600e\u4e48\u4f19\u98df\u5dee\u522b\u8fd9\u4e48\u5927\uff0c\u4e0d\u884c\u6211\u8981\u8f6c\u884c\u505a\u7b97\u6cd5\u5de5\u7a0b\u5e08\u3002 \u7136\u540e\u5403\u8d27\u5c31\u5f00\u59cb\u51c6\u5907\u4e86\u3002\u5403\u8d27\u6027\u683c\u5185\u5411\uff0c\u4e0d\u64c5\u8a00\u8c08\uff0c\u4ea4\u9645\u5708\u8f83\u5c0f\uff0c\u8eab\u8fb9\u6ca1\u6709\u8ba4\u8bc6\u505a\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u670b\u53cb\u3002 \u4e8e\u662f\u5403\u8d27\u4ece\u4e00\u4e9b\u62db\u8058\u7f51\u7ad9\u4e0a\u6d4f\u89c8\u4e86\u4e00\u4e9b\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u62db\u8058\u4fe1\u606f\uff0c\u53c8\u5728\u77e5\u4e4e\u7b49\u5e73\u53f0\u4e0a\u6d4f\u89c8\u4e86\u4e00\u4e9b\u5173\u4e8e\u8f6c\u884c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u76f8\u5173\u5e16\u5b50\u3002 \u4ed6\u7ed9\u81ea\u5df1\u5236\u5b9a\u4e86\u4e00\u4e2a\u4e3a\u671f\u534a\u5e74\u5de6\u53f3\u7684\u5b66\u4e60\u8ba1\u5212\u3002\u5b66\u4e60\u987a\u5e8f\u5927\u6982\u5982\u4e0b\uff1a 1\uff0cPython\u7f16\u7a0b 2\uff0cNumpy,Pandas,matplotlib\u6570\u636e\u5206\u6790 3\uff0cbeautifulSoup,requests\u7f51\u7edc\u722c\u866b 4\uff0csklearn\u673a\u5668\u5b66\u4e60\uff08\u540c\u6b65\u5b66\u4e60\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\uff0c\u674e\u822a\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300b\uff09 5\uff0ctensorflow\u6df1\u5ea6\u5b66\u4e60\uff08\u540c\u6b65\u5b66\u4e60\u5434\u6069\u8fbe\u7684\u300a\u6df1\u5ea6\u5b66\u4e60\u300b\u89c6\u9891\u8bfe\u7a0b\uff09 \u4ed6\u51b3\u5b9a\u7b2c4\u9636\u6bb5\u5b66\u7684\u5dee\u4e0d\u591a\u5c31\u53bb\u627e\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u3002 \uff08PS\uff1a\u5b9e\u8df5\u8868\u660e\uff0c\u8fd9\u4e2a\u5b66\u4e60\u8ba1\u5212\u7684\u7b2c3\u90e8\u5206\u662f\u53ef\u4ee5\u53bb\u9664\u7684\u3002\u7b97\u6cd5\u5de5\u7a0b\u5e08\u901a\u5e38\u4e0d\u9700\u8981\u638c\u63e1\u722c\u866b\u6280\u672f\uff0c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u8bad\u7ec3\u6a21\u578b\u6240\u9700\u8981\u7684\u6570\u636e\u4e00\u822c\u6765\u81ea\u4e8e\u516c\u53f8\u4e1a\u52a1\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u5e93\u4e2d\u83b7\u53d6\u5373\u53ef\u3002\uff09 \u4e3a\u4e86\u786e\u4fdd\u81ea\u5df1\u80fd\u591f\u771f\u6b63\u5730\u5b66\u4f1a\uff0c\u5e76\u80fd\u591f\u6e05\u6670\u5730\u770b\u5230\u81ea\u5df1\u7684\u6210\u957f\u3002\u8fd9\u4e2a\u5403\u8d27\u51b3\u5b9a\u8981\u8ba9\u81ea\u5df1\u7684\u5b66\u4e60\u7559\u4e0b\u70b9\u75d5\u8ff9\u3002 \u540c\u65f6\uff0c\u4ed6\u53c8\u60f3\uff0c\u80fd\u4e0d\u80fd\u5728\u5b66\u4e60\u7684\u540c\u65f6\u6539\u5584\u4e00\u4e0b\u81ea\u5df1\u7684\u4f19\u98df\u5462\uff1f\u601d\u6765\u60f3\u53bb\uff0c\u6700\u540e\u4ed6\u627e\u5230\u4e86\u4e00\u4e2a\u65b9\u6cd5\uff0c\u90a3\u5c31\u662f\u6bcf\u5b66\u5b8c\u4e00\u4e2a\u90e8\u5206\uff0c\u5c31\u5f55\u5236\u4e00\u4e2a\u89c6\u9891\u8bfe\u7a0b\u62ff\u5230\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u53bb\u5356\u3002\u770b\u80fd\u4e0d\u80fd\u6bcf\u4e2a\u6708\u591a\u4e2a\u4e09\u5757\u4e94\u5757\u7684\uff0c\u4ee5\u4fbf\u6539\u5584\u4e00\u4e0b\u4f19\u98df\u3002 \u4e00\u4e2a\u5403\u8d27\uff0c\u4e00\u65e6\u51b3\u5b9a\u4e3a\u4e86\u6539\u5584\u81ea\u5df1\u7684\u4f19\u98df\u60f3\u8981\u505a\u70b9\u4ec0\u4e48\uff0c\u4ed6\u7684\u610f\u5fd7\u529b\u662f\u60ca\u4eba\u7684\u3002 \u4e8e\u662f\uff0c\u5927\u6982\u6709\u534a\u5e74\u5de6\u53f3\uff0c\u8fd9\u4e2a\u5403\u8d27\u6bcf\u5929\u665a\u4e0a\u548c\u5468\u672b\u7684\u65f6\u95f4\u90fd\u51e0\u4e4e\u82b1\u5728\u4e86\u8fd9\u51e0\u4e2a\u8bfe\u7a0b\u7684\u5b66\u4e60\u548c\u8f93\u51fa\u4e0a\u3002\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u9646\u9646\u7eed\u7eed\u591a\u4e86\u8fd9\u4e2a\u5403\u8d27\u7684\u4ee5\u4e0b5\u95e8\u8bfe\u7a0b\u3002 \u7b2c\u4e00\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u7f16\u7a0bABC\u300b \u5403\u8d27\u672c\u6765\u505a\u91cf\u5316\u4ea4\u6613\u638c\u63e1\u4e86\u4e00\u4e9bPython\u7f16\u7a0b\u57fa\u7840\uff0c\u4f46\u4e0d\u662f\u5f88\u719f\u7ec3\uff0c\u5b66\u4e60\u52a0\u6574\u7406\u8fd9\u4e2a\u8bfe\u7a0b\u5927\u6982\u82b1\u4e86\u534a\u4e2a\u6708\u3002 \u8003\u8651\u5230\u81ea\u8eab\u6c34\u5e73\u6709\u9650\uff0c\u5403\u8d27\u6015\u6ca1\u6709\u4e00\u4e2a\u4eba\u4e70\uff0c\u4e0d\u6562\u5356\u9ad8\u4ef7\uff0c\u56e0\u6b64\u8be5\u8bfe\u7a0b\u6807\u4ef71\u5143\uff0c\u4e0a\u7ebf2\u5e74\u591a\uff0c\u603b\u5171\u5356\u51fa108\u4efd\u3002 \u7b97\u4e0b\u6765\u8fd8\u662f\u4e0d\u9519\u7684\uff0c\u6bcf\u4e2a\u6708\u591a\u4e2a\u4e09\u5757\u94b1\u4f19\u98df\u8d39\u7684\u7406\u60f3\u8fd8\u662f\u57fa\u672c\u5b9e\u73b0\u4e86\u7684\uff0c\u79bb\u4e94\u5757\u94b1\u8fd8\u5dee\u4e00\u4e9b\u3002 \u8be5\u8bfe\u7a0b\u5c3d\u7ba1\u4e70\u7684\u4eba\u4e0d\u591a\uff0c\u8fd8\u662f\u6709\u51e0\u4e2a\u8bc4\u4ef7\u7684\u3002 \u7b2c\u4e8c\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u6570\u636e\u5206\u6790\u300b Python\u6570\u636e\u5206\u6790\u76843\u4e2a\u6807\u51c6\u5957\u4ef6\uff1anumpy,Pandas,matplotlib \u638c\u63e1\u8d77\u6765\u8fd8\u662f\u9700\u8981\u4e0b\u70b9\u529f\u592b\u7684\u3002 \u5403\u8d27\u5b66\u4e60\u8fd9\u51e0\u4e2a\u5e93\u548c\u6574\u7406\u6700\u7ec8\u7684\u8bfe\u7a0b\u5927\u6982\u82b1\u4e86\u4e00\u4e2a\u534a\u6708\u3002\u8003\u8651\u5230\u8fd9\u95e8\u8bfe\u7a0b\u505a\u4e86\u6bd4\u8f83\u4e45\u7684\u65f6\u95f4\uff0c\u540c\u65f6\u5403\u8d27\u611f\u5230\u81ea\u5df1\u7684\u6c34\u5e73\u6709\u4e86\u90a3\u4e48\u4e00\u4e22\u4e22\u8fdb\u6b65\u4e86\uff0cPandas\u73a9\u7684\u57fa\u672c666\u7684\u4e86\uff0c\u5403\u8d27\u51b3\u5b9a\u8fd9\u95e8\u8bfe\u535610\u5757\u94b1\u4e00\u4efd\uff0c\u770b\u770b\u80fd\u4e0d\u80fd\u6bcf\u4e2a\u6708\u591a\u4e2a5\u575710\u5757\u7684\u3002 \u8fd9\u95e8\u8bfe\u7a0b\u4e0a\u7ebf2\u5e74\u591a\uff0c\u603b\u5171\u5356\u51fa\u53bb35\u4efd\u3002\u770b\u6765\u6bcf\u4e2a\u6708\u591a\u4e2a10\u5757\u7684\u76ee\u6807\u4e5f\u662f\u57fa\u672c\u5b9e\u73b0\u4e86\u7684\u3002\u8fd9\u95e8\u8bfe\u7531\u4e8e\u4e70\u7684\u4eba\u975e\u5e38\u5c11\uff0c\u6240\u4ee5\u76ee\u524d\u8fd8\u6ca1\u6709\u6536\u5230\u8fc7\u8bc4\u4ef7\u3002\u5173\u8d77\u95e8\u6765\u8bf4\uff0c\u8fd9\u95e8\u8bfe\u7684\u8d28\u91cf\u53ea\u80fd\u7b97\u662f\u8ba9\u4eba\u4e0d\u5fcd\u5fc3\u7ed9\u5dee\u8bc4\u5427\u3002 \u7b2c\u4e09\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u7f51\u7edc\u722c\u866b\u5165\u95e8\u300b \u7b2c\u56db\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u7f51\u7edc\u722c\u866b\u8fdb\u9636\u300b Python\u7f51\u7edc\u722c\u866b\u7684\u57fa\u7840\u8fd8\u662f\u4e0d\u96be\u7684\uff0c\u4f46\u5982\u679c\u8981\u719f\u7ec3\u638c\u63e1\u5404\u79cd\u53cd\u722c\u7b56\u7565\u7684\u7a81\u7834\u4ee5\u53ca\u5bf9\u52a8\u6001\u7f51\u9875\u7684\u6293\u53d6\u8fd8\u662f\u975e\u5e38\u6709\u6311\u6218\u6027\u7684\uff0c Python\u722c\u866b\u7684\u5b66\u4e60\u4ee5\u53ca\u8fd9\u4e24\u95e8\u8bfe\u7a0b\u7684\u5236\u4f5c\u5927\u6982\u82b1\u8d39\u4e86\u5403\u8d272\u4e2a\u6708\u7684\u65f6\u95f4\u3002 \u5176\u4e2d\u7684\u7f51\u7edc\u722c\u866b\u5165\u95e8\u8bfe\u7a0b\u662f\u514d\u8d39\u8bfe\u7a0b\uff0c\u7f51\u7edc\u722c\u866b\u8fdb\u9636\u8bfe\u7a0b\u552e\u4ef730\u5143\u3002 \u7f51\u7edc\u722c\u866b\u5165\u95e8\u8bfe\u7a0b\u6536\u83b7\u4e86\u4e0d\u5c11\u597d\u8bc4\uff0c\u867d\u7136\u6ca1\u6709\u8d5a\u5230\u4e00\u6bdb\u94b1\uff0c\u4e0d\u80fd\u76f4\u63a5\u6539\u5584\u4f19\u98df\uff0c\u4f46\u5403\u8d27\u770b\u4e86\u8fd9\u4e9b\u597d\u8bc4\uff0c\u611f\u89c9\u6bd4\u5403\u4e86\u871c\u8fd8\u8981\u751c\u3002 \u7b2c\u4e94\u95e8\u8bfe\u7a0b\uff1a\u300asklearn\u673a\u5668\u5b66\u4e60\u300b \u5728\u505a\u8fd9\u95e8\u8bfe\u7a0b\u7684\u65f6\u5019\uff0c\u5403\u8d27\u540c\u6b65\u5b66\u4e60\u4e86\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\u548c\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300b\u7684\u4e00\u4e9b\u7ae0\u8282\u3002\u5305\u62ec\u5b66\u4e60\u548c\u8f93\u51fa\uff0c\u5927\u6982\u82b1\u4e86\u5403\u8d272\u4e2a\u6708\u5de6\u53f3\u65f6\u95f4\u3002 \u6574\u4f53\u4e0a\uff0csklearn\u7684\u57fa\u7840\u4f7f\u7528\u548c\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6982\u5ff5\u7684\u638c\u63e1\u8fd8\u662f\u4e0d\u56f0\u96be\u7684\u3002\u51b3\u7b56\u6811\u548cSVM\u7684\u4e00\u4e9b\u539f\u7406\u53ef\u80fd\u5751\u4f1a\u6bd4\u8f83\u591a\uff0c\u9700\u8981\u82b1\u8d39\u8f83\u591a\u65f6\u95f4\u68b3\u7406\u3002 \u5403\u8d27\u7684\u8fd9\u95e8\u8bfe\u7a0b\u552e\u4ef768\u5143\uff0c\u6574\u4f53\u4e0a\u8bc4\u4ef7\u8f83\u9ad8\uff0c\u8fbe\u52304.7\u9897\u661f\u3002 \u5b9e\u9645\u4e0a\u8fd9\u95e8\u8bfe\u7a0b\u505a\u5230\u4e00\u534a\u7684\u65f6\u5019\uff0c\u5403\u8d27\u51b3\u5b9a\u88f8\u8f9e\uff0c\u56e0\u4e3a\u90a3\u65f6\u5019\u5927\u6982\u662f2018\u5e743\u6708\u4efd\u4e86\uff0c\u662f\u62db\u8058\u7684\u9ec4\u91d1\u65f6\u671f\u3002\u7ecf\u8fc7\u4e86\u534a\u5e74\u591a\u7684\u51c6\u5907\uff0c\u5403\u8d27\u4fe1\u5fc3\u6ee1\u6ee1\uff0c\u611f\u89c9\u5df2\u7ecf\u638c\u63e1\u4e86\u4ecePython\u57fa\u7840\u5230Python\u6570\u636e\u5206\u6790\u5230Python\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6280\u80fd\uff0c\u5e94\u8be5\u80fd\u591f\u6478\u5230\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u673a\u4f1a\u3002 \u5403\u8d27\u5f00\u59cb\u5728Boss\u4e0a\u548c\u62c9\u52fe\u4e0a\u6295\u9012\u7b80\u5386\uff0c\u90a3\u65f6\u5019\u6b63\u662f\u7b97\u6cd5\u5c97\u9700\u6c42most\u706b\u7206\u7684\u65f6\u671f\uff0c\u5403\u8d27\u9646\u9646\u7eed\u7eed\u6536\u5230\u4e86\u4e00\u4e9b\u4e8c\u4e09\u7ebf\u4e92\u8054\u7f51\u516c\u53f8\u7684\u9762\u8bd5\u9080\u7ea6\u3002\u4f46\u9646\u7eed\u9762\u4e86\u597d\u51e0\u573a\uff0c\u5403\u8d27\u53d1\u73b0\u81ea\u5df1\u603b\u662f\u4f1a\u9047\u5230\u4e00\u4e9b\u5982\u624b\u5199\u4e8c\u5206\u67e5\u627e\uff0c\u624b\u5199\u5feb\u6392\u7b97\u6cd5\uff0c\u624b\u5199\u722c\u697c\u68af\u65b9\u6cd5\u8fd9\u6837\u7684\u95ee\u9898\u3002\u62ff\u5230\u8fd9\u4e9b\u95ee\u9898\u540e\u5403\u8d27\u4e00\u8138\u61f5\u903c\uff0c\u5728\u7eb8\u4e0a\u6293\u7834\u8111\u888b\u5199\u4e0b\u4e86\u51e0\u884cimport numpy as np,import pandas as pd \u8fd9\u6837\u7684\u4e1c\u897f\uff0c\u7136\u540e\u9762\u8bd5\u5b98\u5c31\u7b11\u76c8\u76c8\u5730\u8ddf\u5403\u8d27\u8bf4\uff0c\u4f60\u56de\u53bb\u7b49\u901a\u77e5\u5427\u3002 \u4e8e\u662f\uff0c\u5403\u8d27\u4e00\u8fb9\u767d\u5929\u9762\u8bd5\uff0c\u4e00\u8fb9\u665a\u4e0a\u56de\u5bb6\u6574\u7406\u767d\u5929\u9047\u5230\u7684\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u91cd\u70b9\u9488\u5bf9\u4e00\u4e9b\u5e38\u89c1\u7684\u624b\u5199\u4ee3\u7801\u9898\u8fdb\u884c\u4e86\u51c6\u5907\uff0c\u638c\u63e1\u4e86\u4e00\u4e9b\u50cf\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u52a8\u6001\u89c4\u5212\u8fd9\u6837\u57fa\u672c\u7684\u6570\u636e\u7ed3\u6784\u548c\u7b97\u6cd5\u77e5\u8bc6\u3002\u5468\u672b\u7684\u65f6\u5019\uff0c\u518d\u7ee7\u7eed\u5f55\u5236\u300asklearn\u673a\u5668\u5b66\u4e60\u300b\u8fd9\u4e2a\u8bfe\u7a0b\u3002\u8fd9\u6837\u5927\u6982\u6301\u7eed\u4e86\u534a\u4e2a\u591a\u6708\uff0c\u5403\u8d27\u5f00\u59cb\u6536\u5230\u4e00\u4e9boffer. \u5f88\u5feb\uff0c\u5403\u8d27\u8ddf\u4e00\u4e2aoffer\u786e\u8ba4\u4e86\u773c\u795e\uff0c\u6b63\u5f0f\u8f6c\u884c\u6210\u4e3a\u4e86\u4e00\u4e2a\u4e92\u8054\u7f51\u884c\u4e1a\u7684\u642c\u7816\u5de5\uff0c\u4f19\u98df\u76f8\u6bd4\u4ee5\u524d\u6709\u4e86\u8f83\u5927\u7684\u6539\u5584\uff0c\u5403\u8d27\u7684\u5fc3\u91cc\u4e50\u5f00\u4e86\u82b1\u3002 \u5403\u8d27\u540e\u6765\u5728\u5468\u672b\u7684\u65f6\u5019\u4e5f\u628a\u8fd9\u4e9b\u9762\u8bd5\u7684\u7ecf\u9a8c\u603b\u7ed3\u8d77\u6765\uff0c\u653e\u5728\u4e86\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u3002 \u8fd9\u4e2a\u8bfe\u7a0b\u7684\u8bc4\u4ef7\u6bd4\u8f83\u4e24\u7ea7\u5206\u5316\uff0c\u6709\u4eba\u53eb\u597d\uff0c\u4e5f\u6709\u4eba\u5410\u69fd\u8bf4\u6728\u6709\u4ec0\u4e48\u5375\u7528\u3002 \u4e8c\uff0c\u5403\u8d27\u4e3a\u4ec0\u4e48\u8981\u5199\u8fd9\u672c\u4e66\uff1f # \u6210\u4e3a\u4e86\u4e00\u540d\u4e92\u8054\u7f51\u642c\u7816\u5de5\u540e\uff0c\u5403\u8d27\u672c\u60f3\u7740\u5728\u5468\u672b\u65f6\u95f4\uff0c\u628a\u81ea\u5df1\u8f6c\u884c\u4e4b\u524d\u5236\u5b9a\u7684\u5b66\u4e60\u8ba1\u5212\u7684\u7b2c5\u90e8\u5206\uff0c\u5373tensorflow\u6df1\u5ea6\u5b66\u4e60\uff08\u540c\u6b65\u5b66\u4e60\u5434\u6069\u8fbe\u7684\u300a\u6df1\u5ea6\u5b66\u4e60\u300b\u89c6\u9891\u8bfe\u7a0b\uff09\u8fd9\u90e8\u5206\u4ed8\u8bf8\u5b9e\u65bd\u3002 \u4f46\u642c\u7816\u5de5\u4f5c\u975e\u5e38\u8f9b\u82e6\uff0c\u540c\u65f6\u5de5\u4f5c\u8fd8\u9700\u8981\u5403\u8d27\u638c\u63e1\u4e00\u4e9b\u5176\u5b83\u7684\u6280\u80fd\uff0c\u4f8b\u5982linux\u57fa\u672c\u64cd\u4f5c\uff0cgit\u57fa\u672c\u64cd\u4f5c\uff0cHive\u6570\u636e\u5e93\uff0cmapreduce\u7f16\u7a0b\u65b9\u6cd5\uff0cxgboost\u548clightgbm\u5efa\u6a21\u65b9\u6cd5\u7b49\u7b49\u3002 \u5927\u6982\u534a\u5e74\u540e\uff0c\u5403\u8d27\u624d\u611f\u5230\u5df2\u7ecf\u719f\u7ec3\u638c\u63e1\u4e86\u5f53\u65f6\u5de5\u4f5c\u6240\u9700\u8981\u7684\u4e3b\u8981\u6280\u80fd\uff0c\u80fd\u591f\u8f83\u4e3a\u987a\u5229\u5730\u5f00\u53d1\u9879\u76ee\u3002\u5230\u4e86\u5468\u672b\u7684\u65f6\u5019\uff0c\u5403\u8d27\u5f00\u59cb\u4e00\u8fb9\u5728\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u770b\u5434\u6069\u8fbe\u300a\u6df1\u5ea6\u5b66\u4e60\u300b\u89c6\u9891\u8bfe\u7a0b\uff0c\u4e00\u8fb9\u5b66\u4e60\u4f7f\u7528tensorflow. \u5434\u6069\u8fbe\u7684\u8fd9\u4e2a\u7cfb\u5217\u7684\u8bfe\u7a0b\u603b\u4f53\u4e0a\u975e\u5e38\u4e0d\u9519\uff0c\u4f46\u7565\u5fae\u504f\u7406\u8bba\u4e00\u4e9b\uff0c\u8bb2\u4e86\u8f83\u591a\u7684\u6570\u5b66\u7ec6\u8282\uff0c\u5403\u8d27\u5f53\u65f6\u5b66\u7684\u8fd8\u662f\u6709\u4e9b\u5403\u529b\u7684\u3002\u5927\u6982\u7528\u4e86\u534a\u5e74\u7684\u5468\u672b\u65f6\u95f4\uff0c\u624d\u57fa\u672c\u5b66\u4e60\u5b8c\u6210\u4e86\u8fd9\u4e94\u95e8\u8bfe\uff0c\u5e76\u68b3\u7406\u51fa\u6765\u4e865\u7bc7\u5b66\u4e60\u7b14\u8bb0\u3002 \u540e\u6765\u5403\u8d27\u5411\"Python\u4e4b\u7985\"\u516c\u4f17\u53f7\u6295\u7a3f\u4e86\u4e00\u7bc7\u6587\u7ae0\u300a18\u5f0f\u4f18\u96c5\u4f60\u7684Python\u300b\uff0c\u53f7\u4e3b\u5fd7\u519b\u5927\u5927\u5728\u540e\u6765\u505a\u62bd\u5956\u9001\u4e66\u7684\u6d3b\u52a8\u65f6\u5c31\u9001\u4e86\u5403\u8d27\u4e00\u672c\u4e66\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u3002\u8fd9\u672c\u4e66\u76f8\u6bd4\u4e8e\u5434\u6069\u8fbe\u8bfe\u7a0b\u66f4\u52a0\u57fa\u7840\u4e00\u4e9b\uff0c\u8be5\u4e66\u5047\u5b9a\u8bfb\u8005\u65e0\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\uff0c\u4ee5Keras\u4e3a\u5de5\u5177\uff0c\u4f7f\u7528\u4e30\u5bcc\u7684\u8303\u4f8b\u6f14\u793a\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\u3002\u8be5\u4e66\u901a\u4fd7\u6613\u61c2\uff0c\u5168\u4e66\u6ca1\u6709\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u6ce8\u91cd\u57f9\u517b\u8bfb\u8005\u7684\u6df1\u5ea6\u5b66\u4e60\u76f4\u89c9\u3002\u5403\u8d27\u62ff\u6765\u8be5\u4e66\uff0c\u7b80\u76f4\u5982\u83b7\u81f3\u5b9d\uff0c\u4e0d\u5230\u4e24\u4e2a\u5468\u672b\u5c31\u5403\u5b8c\u4e86\uff0c\u5bf9\u6df1\u5ea6\u5b66\u4e60\u5728\u5b9e\u8df5\u5c42\u9762\u6709\u4e86\u66f4\u4e3a\u6e05\u6670\u7684\u8ba4\u8bc6\u3002 \u540c\u65f6\uff0c\u5403\u8d27\u8fd8\u5728\u5b66\u4e60tensorflow1.0\uff0c\u603b\u4f53\u800c\u8a00\u5b66\u5f97\u6bd4\u8f83\u75db\u82e6\uff0c\u5b98\u65b9\u6587\u6863\u8bb2\u7684\u5404\u79cd\u6982\u5ff5\u591a\u800c\u6742\uff0c\u9759\u6001\u56fe\u975e\u5e38\u96be\u4ee5\u8c03\u8bd5\uff0ctf.control_dependencies, tf.while_loop\u8fd9\u4e9b\u4e1c\u897f\u7b80\u76f4\u53cd\u4eba\u7c7b\uff0c\u53c8\u662ftf.estimator, \u53c8\u662ftflearn, \u53c8\u662ftf.keras\uff0c\u8ba9\u4eba\u65e0\u6240\u9002\u4ece\u3002\u5403\u8d27\u82b1\u8d39\u4e86\u975e\u5e38\u591a\u7684\u65f6\u95f4\uff0c\u57fa\u672c\u4e0a\u624d\u628atensorflow1.0\u5e38\u7528\u7684\u4e00\u4e9b\u6982\u5ff5\u548c\u5de5\u5177\u68b3\u7406\u5230\u4e00\u4e2a\u9002\u5408\u4eba\u7c7b\u7406\u89e3\u7684\u7a0b\u5ea6\u3002 \u4f46tensorflow\u4e0d\u4ec1\uff0c\u4ee5\u5403\u8d27\u4e3a\u520d\u72d7\u3002\u5c31\u5728\u5403\u8d27\u5feb\u8981\u6574\u7406\u5b8c\u8fd9\u4e2atensorflow1.0\u6559\u7a0b\u7684\u65f6\u5019\uff0ctensorflow\u5b98\u65b9\u5ba3\u5e03\u5c06\u4e0d\u4e45\u63a8\u51fatensorflow2.0\uff0c\u9ed8\u8ba4\u4f7f\u7528\u52a8\u6001\u56fe\uff0c\u5e76\u5bf9API\u8fdb\u884c\u5927\u5e45\u5ea6\u7684\u8c03\u6574\u3002\u5403\u8d27\u5f53\u65f6\u5fc3\u91cc\u7684\u6ecb\u5473\uff0c\u5c31\u597d\u50cf\u4e00\u4e2a\u7537\u5b69\u5b50\u8ffd\u4e00\u4e2a\u5973\u751f\u8ffd\u4e86\u5927\u534a\u5e74\uff0c\u611f\u89c9\u57fa\u672c\u6478\u6e05\u695a\u4e86\u8fd9\u4e2a\u5973\u751f\u7684\u813e\u6c14\u548c\u4e2a\u6027\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u5973\u751f\u7a81\u7136\u6709\u4e00\u5929\u5bf9\u4ed6\u8bf4\uff1a\"\u4f60\u522b\u8ffd\u4e86\uff0c\u6211\u8981\u53bb\u505a\u53d8\u6027\u624b\u672f\u4e86\uff0c\u53d8\u6210\u4e00\u4e2a\u7537\u5b69\u5b50\u3002\" \u4e8e\u662f\uff0c\u5403\u8d27\u8f6c\u800c\u5f00\u59cb\u5b66\u4e60Spark\uff0c\u6574\u4f53\u800c\u8a00\uff0cSpark\u7684\u5b98\u65b9\u6559\u7a0b\u975e\u5e38\u5b8c\u5584\uff0c\u7f51\u7edc\u4e0a\u4e5f\u6709\u6bd4\u8f83\u597d\u7684\u6559\u7a0b\u8d44\u6e90\u3002\u5403\u8d27\u5b66\u8d77\u6765\u975e\u5e38\u987a\u5229\uff0c\u4e0d\u52302\u4e2a\u6708\uff0c\u5c31\u5b66\u4e60\u5e76\u6574\u7406\u4e86\u4e00\u4efd\u7cfb\u7edf\u7684Spark\u6559\u7a0b\uff0c\u653e\u5728\u4e86github\u4ed3\u5e93\u4e2d\u3002 2019\u5e7410\u67081\u65e5\uff0c\u8fd9\u662f\u4e00\u4e2a\u7279\u522b\u7684\u65e5\u5b50\u3002\u8fd9\u4e00\u5929\u65e2\u662f\u7956\u56fd\u6bcd\u4eb2\u7684\u751f\u65e5\uff0c\u4e5f\u662ftensorflow2.0\u7684\u751f\u65e5\u3002\u5728\u8fd9\u4e00\u5929tensorflow\u5b98\u65b9\u5ba3\u5e03\u53d1\u5e03tensorflow2.0\u7684\u6b63\u5f0f\u7248\u672c\u3002\u5403\u8d27\u77e5\u9053\u8fd9\u4e2a\u6d88\u606f\u540e\u975e\u5e38\u5f00\u5fc3\uff0c\u5c31\u597d\u50cf\u4e00\u4e2a\u82b1\u75f4\u7ec8\u4e8e\u7b49\u5230\u4e86\u82b1\u5f00\u4e00\u6837\u3002\u4f46\u662f\u5403\u8d27\u5f53\u65f6\u6b63\u5728\u505a\u4e00\u4e2a\u4ed6\u642c\u7816\u4ee5\u6765\u9047\u5230\u8fc7\u7684\u6700\u590d\u6742\u7684\u4e00\u4e2aspark\u5927\u6570\u636e\u6316\u6398\u9879\u76ee\uff0c\u5468\u672b\u7684\u65f6\u95f4\u90fd\u6295\u5165\u5230\u8fd9\u4e2a\u9879\u76ee\u7684\u653b\u575a\u4e2d\u53bb\u4e86\u3002\u5403\u8d27\u51b3\u5b9a\u7b49\u8fd9\u4e2a\u9879\u76ee\u57fa\u672c\u5b8c\u6210\u540e\uff0c\u91cd\u65b0\u5b66\u4e60\u5e76\u68b3\u7406\u4e00\u4efdtensorflow2\u7684\u6559\u7a0b\u3002 \u5927\u6982\u57282020\u5e74\u521d\uff0c\u5403\u8d27\u5f00\u59cb\u5b66\u4e60tensorflow2.0\u7684\u5b98\u65b9\u6587\u6863\u3002\u5c3d\u7ba1tensorflow2.0\u5ba3\u79f0\u5df2\u7ecf\u4e3a\u6539\u5584\u7528\u6237\u4f53\u9a8c\u505a\u51fa\u4e86\u5de8\u5927\u7684\u6539\u8fdb\uff0creally easy to use\uff0c\u4f46\u5403\u8d27\u5b66\u5f97\u5e76\u4e0d\u8f7b\u677e\u3002tensorflow2.0\u5b98\u65b9\u6587\u6863\u548ctensorflow1.0\u5b98\u65b9\u6587\u6863\u663e\u7136\u662f\u51fa\u81ea\u540c\u4e00\u6279\u4f5c\u8005\u4e4b\u624b\uff0c\u4ed6\u4eec\u4e00\u5982\u65e2\u5f80\u5730\u79c9\u627f\u7740\u8c37\u6b4cmake things complicated\u7684\u98ce\u683c\u4f20\u7edf\uff0c\u7528\u54c8\u5e0c\u8868\u4e00\u822c\u6df7\u4e71\u7684\u6587\u6863\u7ed3\u6784\u3001\u65e0\u6cd5\u8fd0\u884c\u7684\u8303\u4f8b\u4ee3\u7801\u3001\u590d\u6742\u7684\u51fd\u6570\u5d4c\u5957\u8c03\u7528\u5173\u7cfb\u3001\u968f\u610f\u63d2\u5165\u7684\u4e0d\u5e38\u7528\u7b2c\u4e09\u65b9\u5e93\u7b49\u6280\u5de7\u5c06\u8bfb\u8005\u7684\u61f5\u5708\u7a0b\u5ea6\u9010\u6b65\u63a8\u5411\u9ad8\u6f6e\u3002 \u5728\u5403\u8d27\u770b\u6765\uff0ctensorflow2.0\u5b98\u65b9\u6587\u6863\u6240\u6709\u7684\u95ee\u9898\u53ef\u4ee5\u62bd\u8c61\u4e3a\u4e00\u4e2a\u95ee\u9898\uff1a\u566a\u58f0\u592a\u591a\u3002\u8bfb\u8005\u8981\u4ece\u566a\u58f0\u5982\u6b64\u4e4b\u591a\u7684\u5b98\u65b9\u6559\u7a0b\u4e2d\u63d0\u53d6\u51fa\u4ed6\u60f3\u8981\u7684\u4fe1\u606f\u662f\u975e\u5e38\u7684\u5403\u529b\u7684\u3002\u5982\u679c\u628a\u5b98\u65b9\u6559\u7a0b\u6bd4\u4f5c\u4e00\u76d8\u83dc\uff0c\u90a3\u4e48\u8fd9\u76d8\u83dc\u867d\u7136\u6709\u8bb8\u591a\u8425\u517b\u7269\u8d28\uff0c\u4f46\u4e5f\u6709\u8bb8\u591a\u7684\u6c99\u5b50\uff0c\u4e0d\u5c0f\u5fc3\u54ac\u5230\u4e00\u53e3\u5c31\u784c\u5f97\u614c\uff0c\u751a\u81f3\u4f1a\u89c9\u5f97\u6076\u5fc3\u5f97\u4e0d\u884c\u3002\u5403\u8d27\u51b3\u5b9a\u8981\u505a\u4e00\u76d8\u8425\u517b\u4e30\u5bcc\uff0c\u4e14\u7f8e\u5473\u5b9c\u4eba\u7684\u83dc\u3002 \u5403\u8d27\u5f00\u59cb\u6309\u7167\u4ed6\u60f3\u8c61\u4e2d\u7f8e\u5473\u4f73\u80b4\u7684\u6837\u5b50\u6765\u505a\u8fd9\u76d8\u83dc\u3002\u5468\u672b\u672c\u5e94\u9002\u5408\u53bb\u53c2\u52a0\u6237\u5916\u722c\u5c71\u6d3b\u52a8\uff0c\u4ed6\u5bf9\u7740\u7535\u8111\u5728\u505a\u83dc\u3002\u653e\u5047\u56de\u5bb6\u7684\u706b\u8f66\u4e0a\uff0c\u4ed6\u5bf9\u7740\u7535\u8111\u5728\u505a\u83dc\u3002\u6625\u8282\u5230\u5bb6\u540e\u7531\u4e8e\u75ab\u60c5\u5f71\u54cd\u4e0d\u63d0\u5021\u7a9c\u95e8\uff0c\u4ed6\u53ef\u4ee5\u6709\u66f4\u591a\u65f6\u95f4\u5f00\u5fc3\u5730\u5bf9\u7740\u7535\u8111\u505a\u83dc\u3002\u75ab\u60c5\u5f62\u52bf\u6108\u53d1\u4e25\u5cfb\u4f01\u4e1a\u5ef6\u8fdf\u590d\u5de5\uff0c\u4ed6\u56de\u5230\u5317\u4eac\u4e00\u8fb9\u9694\u79bb\u4e00\u8fb9\u5bf9\u7740\u7535\u8111\u5728\u505a\u83dc\u3002 \u4e09\uff0c\u5403\u8d27\u5199\u7684\u8fd9\u672c\u4e66\u600e\u4e48\u6837\uff1f # \u524d\u540e\u7528\u4e86\u7ea6\u4e24\u4e2a\u6708\uff0c\u5403\u8d27\u7684\u8fd9\u672c\u4e66\u57fa\u672c\u5199\u5b8c\u4e86\u3002\u5403\u8d27\u5fc3\u60f3\uff0c\u8be5\u7ed9\u5b83\u53d6\u4e2a\u4ec0\u4e48\u540d\u5b57\u5462\uff1f \u55ef\uff0c\u6709\u4e86\uff0c\u8fd9\u662f\u4e00\u672c\u53ef\u4ee5\u5e2e\u52a9\u5927\u5bb6\u6539\u5584\u4f19\u98df\u7684\u4e66\u3002\u5927\u6982\u53ef\u4ee5\u8fde\u7eed\u540330\u5929\uff0c\u800c\u4e14\u5e94\u8be5\u5473\u9053\u4e0d\u9519\u3002 \u5c31\u53eb\u4ed6\u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b\u5427\u3002 \u4ece\u8fd9\u672c\u4e66\u7684\u4e66\u540d\u5e94\u8be5\u80fd\u591f\u770b\u51fa\uff0c\u4f5c\u8005\u662f\u4e2a\u5403\u8d27\uff0c\u800c\u4e14\u662f\u4e2a\u5f88\u6709\u6bc5\u529b\u7684\u5403\u8d27\u3002 \u8fd9\u662f\u4e00\u672c\u600e\u4e48\u6837\u7684\u4e66\u5462\uff1f\u8fd9\u662f\u4e00\u672c\u5bf9\u4eba\u7c7b\u7528\u6237\u6781\u5176\u53cb\u5584\u7684TensorFlow2.0\u5165\u95e8\u5de5\u5177\u4e66\u3002 \u4e3a\u4e86\u5c3d\u53ef\u80fd\u964d\u4f4e\u4fe1\u606f\u566a\u58f0\uff0c\u8fd9\u672c\u4e66\u76f8\u6bd4\u5b98\u65b9\u6587\u6863\u5728\u7bc7\u7ae0\u7ed3\u6784\u548c\u8303\u4f8b\u9009\u53d6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u6df7\u4e71\u7684\u7bc7\u7ae0\u7ed3\u6784\uff0c\u65e2\u6709\u6559\u7a0b\u53c8\u6709\u6307\u5357\uff0c\u7f3a\u5c11\u6574\u4f53\u7684\u7f16\u6392\u903b\u8f91\u3002 \u8fd9\u672c\u4e66\u6309\u7167\u5185\u5bb9\u96be\u6613\u7a0b\u5ea6\u3001\u8bfb\u8005\u68c0\u7d22\u4e60\u60ef\u548cTensorFlow\u81ea\u8eab\u7684\u5c42\u6b21\u7ed3\u6784\u8bbe\u8ba1\u5185\u5bb9\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u5c42\u6b21\u6e05\u6670\uff0c\u65b9\u4fbf\u6309\u7167\u529f\u80fd\u67e5\u627e\u76f8\u5e94\u8303\u4f8b\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u5197\u957f\u7684\u8303\u4f8b\u4ee3\u7801\uff0c\u8fd9\u672c\u4e66\u5728\u8303\u4f8b\u8bbe\u8ba1\u4e0a\u5c3d\u53ef\u80fd\u7b80\u7ea6\u5316\u548c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u8303\u4f8b\u6613\u8bfb\u6027\u548c\u901a\u7528\u6027\uff0c\u5927\u90e8\u5206\u4ee3\u7801\u7247\u6bb5\u5728\u5b9e\u8df5\u4e2d\u53ef\u5373\u53d6\u5373\u7528\u3002 \u603b\u4e4b\uff0c\u8fd9\u672c\u4e66\u503e\u6ce8\u4e86\u4e00\u4e2a\u5403\u8d27\u5bf9\u7f8e\u98df\u7684\u5168\u90e8\u5411\u5f80\u548c\u8ffd\u6c42\uff0c\u5982\u679c\u4f60\u975e\u5e38\u559c\u6b22\u7f8e\u98df\uff0c\u5e76\u4e14\u60f3\u8981\u5b66\u4e60TensorFlow2\uff0c\u90a3\u4e48\u8fd9\u672c\u4e66\u4e00\u5b9a\u503c\u5f97\u4f60\u54c1\u5c1d\u54c1\u5c1d\u3002 \u8fd9\u672c\u4e66\u5728github\u4e0a\u7ebf1\u4e2a\u6708\u6765\uff0c\u5f97\u5230\u4e86\u4e0d\u5c11\u5c0f\u4f19\u4f34\u7684\u53cd\u9988\uff0c\u63d0\u4e86\u4e00\u4e9bissues\uff0c\u5403\u8d27\u9488\u5bf9\u76f8\u5173\u95ee\u9898\u8fdb\u884c\u4e86\u4e00\u4e9b\u56de\u7b54\u548c\u5bf9\u9879\u76ee\u505a\u4e86\u6539\u8fdb\u3002 \u540c\u65f6\u8fd9\u4e2a\u9879\u76ee\u4e5f\u83b7\u5f97\u4e86100\u591a\u9897\u661f\u661f\uff0c\u5403\u8d27\u770b\u5728\u773c\u91cc\uff0c\u7f8e\u5728\u5fc3\u91cc\uff0c\u6bcf\u5929\u65e9\u4e0a\u7761\u89c9\u8d77\u6765\u90fd\u4f1a\u53bbgithub\u661f\u7403\u4e0a\u6570\u661f\u661f\u3002 \u56db\uff0c\u5982\u4f55\u83b7\u53d6\u5403\u8d27\u5199\u7684\u8fd9\u672c\u4e66? # \u8fd9\u672c\u4e66\u76ee\u524d\u67094\u79cd\u5f62\u5f0f\u83b7\u53d6\u3002 1\uff0cgitbook\u7535\u5b50\u4e66\u3002\u4ee5\u7f51\u9875\u94fe\u63a5\u5448\u73b0\uff0c\u540c\u65f6\u53ef\u4ee5\u5728\u7535\u8111\u548c\u624b\u673a\u4e0a\u7528\u6d4f\u89c8\u5668\u6253\u5f00\u3002 \u7535\u5b50\u4e66\u94fe\u63a5\uff1a https://lyhue1991.github.io/eat_tensorflow2_in_30_days 2\uff0cgithub\u9879\u76ee\u6e90\u7801\u3002\u5305\u542b\u5168\u90e8\u6570\u636e\u96c6\u548cmd\u683c\u5f0f\u6e90\u7801\uff0c\u53ef\u4ee5\u5728jupyter\u4e0a\u5b89\u88c5jupytext\u540e\u5c06md\u6e90\u7801\u4f5c\u4e3aipynb\u6253\u5f00\u3002 \u9879\u76ee\u94fe\u63a5\uff1a https://github.com/lyhue1991/eat_tensorflow2_in_30_days 3\uff0cpdf\u683c\u5f0f\u7535\u5b50\u4e66\u3002 4\uff0cipynb\u683c\u5f0f\u9879\u76ee\u6e90\u7801\u3002 \u5176\u4e2dgithub\u9879\u76ee\u6e90\u7801\u548cgitbook\u7535\u5b50\u4e66\u5c06\u6301\u7eed\u7ef4\u62a4\uff0c\u540e\u7eed\u53ef\u80fd\u4e5f\u4f1a\u589e\u52a0\u4e00\u4e9b\u65b0\u7684\u8303\u4f8b\u3002pdf\u7248\u672c\u7535\u5b50\u4e66\u548cipynb\u9879\u76ee\u6e90\u7801\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\" Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e \"\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57: tf \u8fdb\u884c\u83b7\u53d6\u3002\u8fd9\u4e24\u79cd\u5f62\u5f0f\u83b7\u53d6\u7684\u300aeat tensorflow2 in 30 days\u300b\u65e0\u6cd5\u4fdd\u8bc1\u66f4\u65b0\u3002 \u9605\u8bfb\u4f53\u9a8c\u4f18\u5148\u63a8\u8350\u4f7f\u7528gitbook\u7535\u5b50\u4e66\uff0c\u5177\u6709\u76ee\u5f55\u67e5\u627e\u548c\u4e0a\u4e0b\u9875\u7ffb\u9875\u529f\u80fd\uff0c\u5b57\u4f53\u5927\u5c0f\u548c\u80cc\u666f\u8272\u53ef\u4ee5\u6839\u636e\u4e2a\u4eba\u559c\u597d\u8fdb\u884c\u8c03\u6574\uff0c\u989c\u503c\u8d85\u9ad8\u3002 \u4e94\uff0c\u9f13\u52b1\u548c\u8054\u7cfb\u8fd9\u4e2a\u5403\u8d27 # \u6700\u540e\uff0c\u60f3\u7ed9\u5927\u5bb6\u8bb2\u4e00\u4e2a\u5403\u8d27\u5c0f\u738b\u5b50\u7684\u6545\u4e8b\u3002 \u5728\u5f88\u4e45\u5f88\u4e45\u4ee5\u524d\uff0c\u6709\u4e00\u4e2a\u5c0f\u738b\u5b50\uff0c\u4f4f\u5728\u4e00\u4e2a\u53ea\u6bd4\u4ed6\u5927\u4e00\u70b9\u70b9\u7684\u661f\u7403\u4e0a\uff0c\u4ed6\uff0c\u60f3\u8981\u4e00\u4e2a\u670b\u53cb\u3002 \u5728\u6628\u5929\u4eca\u5929\u548c\u660e\u5929\uff0c\u6709\u4e00\u4e2a\u5403\u8d27\uff0c\u4f4f\u5728\u4e00\u4e2a\u53ea\u6bd4\u4ed6\u5927\u4e00\u70b9\u70b9\u7684github\u661f\u7403\u4e0a\uff0c\u4ed6\uff0c\u60f3\u8981\u4e00\u9897\u661f\u661f\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e00\u4e2a\u5403\u8d27\u548c\u4e00\u9053\u83dc\u7684\u6545\u4e8b"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/#\u4e00\u4e2a\u5403\u8d27\u548c\u4e00\u9053\u83dc\u7684\u6545\u4e8b","text":"\u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b\u8fd9\u672c\u4e66\u5df2\u7ecf\u5168\u90e8\u6574\u7406\u5b8c\u7a3f\u3002\u672c\u7bc7\u6587\u7ae0\u7b97\u662f\u8fd9\u672c\u4e66\u7684\u4e00\u4e2a\u540e\u8bb0\u3002 \u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5403\u8d27\u4e0e\u7b97\u6cd5\u7ed3\u7f18\u7684\u6545\u4e8b\uff0c\u5e76\u4ecb\u7ecd\u4e86\u672c\u4e66\u7684\u5199\u4f5c\u8fc7\u7a0b\u3002\u53ef\u4f9b\u611f\u5174\u8da3\u7684\u8bfb\u8005\u4e00\u4e50\u3002 \u5982\u679c\u8bfb\u8005\u65f6\u95f4\u7d27\u8feb\uff0c\u53ef\u76f4\u63a5\u9605\u8bfb\u672c\u6587\u7b2c3\u90e8\u5206\u548c\u7b2c4\u90e8\u5206\uff0c\u4e86\u89e3\u4e66\u7c4d\u5185\u5bb9\u548c\u83b7\u53d6\u65b9\u6cd5\u3002","title":"\u4e00\u4e2a\u5403\u8d27\u548c\u4e00\u9053\u83dc\u7684\u6545\u4e8b"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/#\u4e00\u4e00\u4e2a\u5403\u8d27\u8f6c\u884c\u7b97\u6cd5\u7684\u5fc3\u8def\u5386\u7a0b","text":"2015\u5e746\u6708\uff0c\u53c8\u662f\u4e00\u4e2a\u6bd5\u4e1a\u5b63\uff0c\u4e00\u4e2a\u5403\u8d27\u4ece\u5317\u4eac\u5403\u996d\u5927\u5b66\u6bd5\u4e1a\u4e86\u3002 \u867d\u7136\u662f\u5403\u996d\u5927\u5b66\u6bd5\u4e1a\uff0c\u4f46\u4ed6\u5b66\u7684\u662f\u7406\u8bba\u7269\u7406\uff0c\u800c\u7406\u8bba\u7269\u7406\u4e0d\u662f\u4e00\u4e2a\u9002\u5408\u627e\u996d\u5403\u7684\u4e13\u4e1a\u3002 \u51e0\u7ecf\u8f97\u8f6c\uff0c\u8fd9\u4e2a\u5403\u8d27\u5728\u91d1\u878d\u884c\u4e1a\u627e\u5230\u4e86\u4e00\u4efd\u91cf\u5316\u7a0b\u5e8f\u5458\u7684\u5de5\u4f5c\uff0c\u867d\u7136\u6536\u5165\u4f4e\u5fae\uff0c\u4f46\u662f\u8fd9\u4e2a\u5403\u8d27\u68a6\u60f3\u6709\u4e00\u5929\u53ef\u4ee5\u627e\u5230\u80fd\u591f\u7a33\u5b9a\u76c8\u5229\u7684\u91cf\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u4ea4\u6613\u8d5a\u94b1\u8ba9\u81ea\u5df1\u80fd\u591f\u6bcf\u5929\u90fd\u6709\u53e3\u597d\u5403\u7684\u3002 \u7136\u800c\uff0c\u8d44\u672c\u5e02\u573a\u6ce2\u8c32\u4e91\u8be1\uff0c\u4ed6\u5c1d\u8bd5\u8fc7\u8bb8\u591a\u4ea4\u6613\u7b56\u7565\uff0c\u5374\u6ca1\u6709\u627e\u5230\u80fd\u591f\u7a33\u5b9a\u8d5a\u94b1\u7684\"\u5723\u676f\"\uff0c\u4f19\u98df\u4e5f\u4e00\u5929\u6bd4\u4e00\u5929\u53d8\u5dee\u4e86\u3002 \u5728\u4e0eK\u7ebf\u7684\u7ea0\u7f20\u4e2d\uff0c\u4ed6\u6162\u6162\u5730\u8ff7\u5931\u4e86\uff0c\u867d\u7136\u4ed6\u77e5\u9053\u6bcf\u6b21\u4e8f\u94b1\u90fd\u662f\u9760\u5b9e\u529b\u8f93\u7684\uff0c\u4f46\u662f\u4ed6\u4e0d\u77e5\u9053\u81ea\u5df1\u6bcf\u6b21\u8d5a\u94b1\u662f\u51ed\u501f\u5b9e\u529b\u8d5a\u7684\u8fd8\u662f\u51ed\u8fd0\u6c14\u8d5a\u7684\u3002\u4ed6\u611f\u5230\u5728\u91d1\u878d\u4ea4\u6613\u8fd9\u4e2a\u884c\u4e1a\u5f88\u96be\u6e05\u6670\u5730\u770b\u5230\u81ea\u5df1\u7684\u8fdb\u6b65\u3002 \u4ed8\u51fa\u4e86\u90a3\u4e48\u591a\u7684\u52aa\u529b\uff0c\u641e\u4e86\u90a3\u4e48\u591a\u6a21\u578b\uff0c\u5199\u4e86\u90a3\u4e48\u591a\u7b56\u7565\uff0c\u81ea\u5df1\u5c31\u771f\u7684\u6709\u6210\u957f\u5417\uff1f\u5728\u6b8b\u9177\u7684\u4ea4\u6613\u4e16\u754c\u91cc\uff0c\u8fd9\u4e9b\u4e1c\u897f\u4e0d\u80fd\u8d5a\u94b1\uff0c\u4e0d\u80fd\u591f\u6539\u5584\u81ea\u5df1\u7684\u4f19\u98df\uff0c\u53c8\u6709\u4ec0\u4e48\u4ef7\u503c\u5462\uff1f \u4f5c\u4e3a\u4e00\u4e2a\u5403\u8d27\uff0c\u4ed6\u65e0\u6cd5\u5fcd\u53d7\u4f19\u98df\u53d8\u5f97\u8d8a\u6765\u8d8a\u5dee\u3002\u4ed6\u51b3\u5b9a\u6362\u4e00\u4e2a\u80fd\u591f\u7a33\u5b9a\u5730\u8ba9\u4f19\u98df\u53d8\u5f97\u66f4\u597d\u7684\u884c\u4e1a\u3002 \u90a3\u4e2a\u65f6\u5019\uff0c\u968f\u7740AlphaGo\u6218\u80dc\u4e16\u754c\u56f4\u68cb\u51a0\u519b\u674e\u4e16\u77f3\u7684\u6545\u4e8b\u5e7f\u4e3a\u4eba\u77e5\uff0c\u5728\u4e92\u8054\u7f51\u9886\u57df\u6709\u4e00\u4e2a\u65b0\u5174\u5c97\u4f4d\u9010\u6e10\u706b\u70ed\uff0c\u90a3\u5c31\u662f\u7b97\u6cd5\u5de5\u7a0b\u5e08\u3002 \u8fd9\u4e2a\u5403\u8d27\u5fc3\u60f3\uff0c\u6211\u4e5f\u662f\u505a\u6a21\u578b\u7684\uff0c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u4e5f\u662f\u505a\u6a21\u578b\u7684\uff0c\u600e\u4e48\u4f19\u98df\u5dee\u522b\u8fd9\u4e48\u5927\uff0c\u4e0d\u884c\u6211\u8981\u8f6c\u884c\u505a\u7b97\u6cd5\u5de5\u7a0b\u5e08\u3002 \u7136\u540e\u5403\u8d27\u5c31\u5f00\u59cb\u51c6\u5907\u4e86\u3002\u5403\u8d27\u6027\u683c\u5185\u5411\uff0c\u4e0d\u64c5\u8a00\u8c08\uff0c\u4ea4\u9645\u5708\u8f83\u5c0f\uff0c\u8eab\u8fb9\u6ca1\u6709\u8ba4\u8bc6\u505a\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u670b\u53cb\u3002 \u4e8e\u662f\u5403\u8d27\u4ece\u4e00\u4e9b\u62db\u8058\u7f51\u7ad9\u4e0a\u6d4f\u89c8\u4e86\u4e00\u4e9b\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u62db\u8058\u4fe1\u606f\uff0c\u53c8\u5728\u77e5\u4e4e\u7b49\u5e73\u53f0\u4e0a\u6d4f\u89c8\u4e86\u4e00\u4e9b\u5173\u4e8e\u8f6c\u884c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u76f8\u5173\u5e16\u5b50\u3002 \u4ed6\u7ed9\u81ea\u5df1\u5236\u5b9a\u4e86\u4e00\u4e2a\u4e3a\u671f\u534a\u5e74\u5de6\u53f3\u7684\u5b66\u4e60\u8ba1\u5212\u3002\u5b66\u4e60\u987a\u5e8f\u5927\u6982\u5982\u4e0b\uff1a 1\uff0cPython\u7f16\u7a0b 2\uff0cNumpy,Pandas,matplotlib\u6570\u636e\u5206\u6790 3\uff0cbeautifulSoup,requests\u7f51\u7edc\u722c\u866b 4\uff0csklearn\u673a\u5668\u5b66\u4e60\uff08\u540c\u6b65\u5b66\u4e60\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\uff0c\u674e\u822a\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300b\uff09 5\uff0ctensorflow\u6df1\u5ea6\u5b66\u4e60\uff08\u540c\u6b65\u5b66\u4e60\u5434\u6069\u8fbe\u7684\u300a\u6df1\u5ea6\u5b66\u4e60\u300b\u89c6\u9891\u8bfe\u7a0b\uff09 \u4ed6\u51b3\u5b9a\u7b2c4\u9636\u6bb5\u5b66\u7684\u5dee\u4e0d\u591a\u5c31\u53bb\u627e\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u3002 \uff08PS\uff1a\u5b9e\u8df5\u8868\u660e\uff0c\u8fd9\u4e2a\u5b66\u4e60\u8ba1\u5212\u7684\u7b2c3\u90e8\u5206\u662f\u53ef\u4ee5\u53bb\u9664\u7684\u3002\u7b97\u6cd5\u5de5\u7a0b\u5e08\u901a\u5e38\u4e0d\u9700\u8981\u638c\u63e1\u722c\u866b\u6280\u672f\uff0c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u8bad\u7ec3\u6a21\u578b\u6240\u9700\u8981\u7684\u6570\u636e\u4e00\u822c\u6765\u81ea\u4e8e\u516c\u53f8\u4e1a\u52a1\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u5e93\u4e2d\u83b7\u53d6\u5373\u53ef\u3002\uff09 \u4e3a\u4e86\u786e\u4fdd\u81ea\u5df1\u80fd\u591f\u771f\u6b63\u5730\u5b66\u4f1a\uff0c\u5e76\u80fd\u591f\u6e05\u6670\u5730\u770b\u5230\u81ea\u5df1\u7684\u6210\u957f\u3002\u8fd9\u4e2a\u5403\u8d27\u51b3\u5b9a\u8981\u8ba9\u81ea\u5df1\u7684\u5b66\u4e60\u7559\u4e0b\u70b9\u75d5\u8ff9\u3002 \u540c\u65f6\uff0c\u4ed6\u53c8\u60f3\uff0c\u80fd\u4e0d\u80fd\u5728\u5b66\u4e60\u7684\u540c\u65f6\u6539\u5584\u4e00\u4e0b\u81ea\u5df1\u7684\u4f19\u98df\u5462\uff1f\u601d\u6765\u60f3\u53bb\uff0c\u6700\u540e\u4ed6\u627e\u5230\u4e86\u4e00\u4e2a\u65b9\u6cd5\uff0c\u90a3\u5c31\u662f\u6bcf\u5b66\u5b8c\u4e00\u4e2a\u90e8\u5206\uff0c\u5c31\u5f55\u5236\u4e00\u4e2a\u89c6\u9891\u8bfe\u7a0b\u62ff\u5230\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u53bb\u5356\u3002\u770b\u80fd\u4e0d\u80fd\u6bcf\u4e2a\u6708\u591a\u4e2a\u4e09\u5757\u4e94\u5757\u7684\uff0c\u4ee5\u4fbf\u6539\u5584\u4e00\u4e0b\u4f19\u98df\u3002 \u4e00\u4e2a\u5403\u8d27\uff0c\u4e00\u65e6\u51b3\u5b9a\u4e3a\u4e86\u6539\u5584\u81ea\u5df1\u7684\u4f19\u98df\u60f3\u8981\u505a\u70b9\u4ec0\u4e48\uff0c\u4ed6\u7684\u610f\u5fd7\u529b\u662f\u60ca\u4eba\u7684\u3002 \u4e8e\u662f\uff0c\u5927\u6982\u6709\u534a\u5e74\u5de6\u53f3\uff0c\u8fd9\u4e2a\u5403\u8d27\u6bcf\u5929\u665a\u4e0a\u548c\u5468\u672b\u7684\u65f6\u95f4\u90fd\u51e0\u4e4e\u82b1\u5728\u4e86\u8fd9\u51e0\u4e2a\u8bfe\u7a0b\u7684\u5b66\u4e60\u548c\u8f93\u51fa\u4e0a\u3002\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u9646\u9646\u7eed\u7eed\u591a\u4e86\u8fd9\u4e2a\u5403\u8d27\u7684\u4ee5\u4e0b5\u95e8\u8bfe\u7a0b\u3002 \u7b2c\u4e00\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u7f16\u7a0bABC\u300b \u5403\u8d27\u672c\u6765\u505a\u91cf\u5316\u4ea4\u6613\u638c\u63e1\u4e86\u4e00\u4e9bPython\u7f16\u7a0b\u57fa\u7840\uff0c\u4f46\u4e0d\u662f\u5f88\u719f\u7ec3\uff0c\u5b66\u4e60\u52a0\u6574\u7406\u8fd9\u4e2a\u8bfe\u7a0b\u5927\u6982\u82b1\u4e86\u534a\u4e2a\u6708\u3002 \u8003\u8651\u5230\u81ea\u8eab\u6c34\u5e73\u6709\u9650\uff0c\u5403\u8d27\u6015\u6ca1\u6709\u4e00\u4e2a\u4eba\u4e70\uff0c\u4e0d\u6562\u5356\u9ad8\u4ef7\uff0c\u56e0\u6b64\u8be5\u8bfe\u7a0b\u6807\u4ef71\u5143\uff0c\u4e0a\u7ebf2\u5e74\u591a\uff0c\u603b\u5171\u5356\u51fa108\u4efd\u3002 \u7b97\u4e0b\u6765\u8fd8\u662f\u4e0d\u9519\u7684\uff0c\u6bcf\u4e2a\u6708\u591a\u4e2a\u4e09\u5757\u94b1\u4f19\u98df\u8d39\u7684\u7406\u60f3\u8fd8\u662f\u57fa\u672c\u5b9e\u73b0\u4e86\u7684\uff0c\u79bb\u4e94\u5757\u94b1\u8fd8\u5dee\u4e00\u4e9b\u3002 \u8be5\u8bfe\u7a0b\u5c3d\u7ba1\u4e70\u7684\u4eba\u4e0d\u591a\uff0c\u8fd8\u662f\u6709\u51e0\u4e2a\u8bc4\u4ef7\u7684\u3002 \u7b2c\u4e8c\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u6570\u636e\u5206\u6790\u300b Python\u6570\u636e\u5206\u6790\u76843\u4e2a\u6807\u51c6\u5957\u4ef6\uff1anumpy,Pandas,matplotlib \u638c\u63e1\u8d77\u6765\u8fd8\u662f\u9700\u8981\u4e0b\u70b9\u529f\u592b\u7684\u3002 \u5403\u8d27\u5b66\u4e60\u8fd9\u51e0\u4e2a\u5e93\u548c\u6574\u7406\u6700\u7ec8\u7684\u8bfe\u7a0b\u5927\u6982\u82b1\u4e86\u4e00\u4e2a\u534a\u6708\u3002\u8003\u8651\u5230\u8fd9\u95e8\u8bfe\u7a0b\u505a\u4e86\u6bd4\u8f83\u4e45\u7684\u65f6\u95f4\uff0c\u540c\u65f6\u5403\u8d27\u611f\u5230\u81ea\u5df1\u7684\u6c34\u5e73\u6709\u4e86\u90a3\u4e48\u4e00\u4e22\u4e22\u8fdb\u6b65\u4e86\uff0cPandas\u73a9\u7684\u57fa\u672c666\u7684\u4e86\uff0c\u5403\u8d27\u51b3\u5b9a\u8fd9\u95e8\u8bfe\u535610\u5757\u94b1\u4e00\u4efd\uff0c\u770b\u770b\u80fd\u4e0d\u80fd\u6bcf\u4e2a\u6708\u591a\u4e2a5\u575710\u5757\u7684\u3002 \u8fd9\u95e8\u8bfe\u7a0b\u4e0a\u7ebf2\u5e74\u591a\uff0c\u603b\u5171\u5356\u51fa\u53bb35\u4efd\u3002\u770b\u6765\u6bcf\u4e2a\u6708\u591a\u4e2a10\u5757\u7684\u76ee\u6807\u4e5f\u662f\u57fa\u672c\u5b9e\u73b0\u4e86\u7684\u3002\u8fd9\u95e8\u8bfe\u7531\u4e8e\u4e70\u7684\u4eba\u975e\u5e38\u5c11\uff0c\u6240\u4ee5\u76ee\u524d\u8fd8\u6ca1\u6709\u6536\u5230\u8fc7\u8bc4\u4ef7\u3002\u5173\u8d77\u95e8\u6765\u8bf4\uff0c\u8fd9\u95e8\u8bfe\u7684\u8d28\u91cf\u53ea\u80fd\u7b97\u662f\u8ba9\u4eba\u4e0d\u5fcd\u5fc3\u7ed9\u5dee\u8bc4\u5427\u3002 \u7b2c\u4e09\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u7f51\u7edc\u722c\u866b\u5165\u95e8\u300b \u7b2c\u56db\u95e8\u8bfe\u7a0b\uff1a\u300aPython\u7f51\u7edc\u722c\u866b\u8fdb\u9636\u300b Python\u7f51\u7edc\u722c\u866b\u7684\u57fa\u7840\u8fd8\u662f\u4e0d\u96be\u7684\uff0c\u4f46\u5982\u679c\u8981\u719f\u7ec3\u638c\u63e1\u5404\u79cd\u53cd\u722c\u7b56\u7565\u7684\u7a81\u7834\u4ee5\u53ca\u5bf9\u52a8\u6001\u7f51\u9875\u7684\u6293\u53d6\u8fd8\u662f\u975e\u5e38\u6709\u6311\u6218\u6027\u7684\uff0c Python\u722c\u866b\u7684\u5b66\u4e60\u4ee5\u53ca\u8fd9\u4e24\u95e8\u8bfe\u7a0b\u7684\u5236\u4f5c\u5927\u6982\u82b1\u8d39\u4e86\u5403\u8d272\u4e2a\u6708\u7684\u65f6\u95f4\u3002 \u5176\u4e2d\u7684\u7f51\u7edc\u722c\u866b\u5165\u95e8\u8bfe\u7a0b\u662f\u514d\u8d39\u8bfe\u7a0b\uff0c\u7f51\u7edc\u722c\u866b\u8fdb\u9636\u8bfe\u7a0b\u552e\u4ef730\u5143\u3002 \u7f51\u7edc\u722c\u866b\u5165\u95e8\u8bfe\u7a0b\u6536\u83b7\u4e86\u4e0d\u5c11\u597d\u8bc4\uff0c\u867d\u7136\u6ca1\u6709\u8d5a\u5230\u4e00\u6bdb\u94b1\uff0c\u4e0d\u80fd\u76f4\u63a5\u6539\u5584\u4f19\u98df\uff0c\u4f46\u5403\u8d27\u770b\u4e86\u8fd9\u4e9b\u597d\u8bc4\uff0c\u611f\u89c9\u6bd4\u5403\u4e86\u871c\u8fd8\u8981\u751c\u3002 \u7b2c\u4e94\u95e8\u8bfe\u7a0b\uff1a\u300asklearn\u673a\u5668\u5b66\u4e60\u300b \u5728\u505a\u8fd9\u95e8\u8bfe\u7a0b\u7684\u65f6\u5019\uff0c\u5403\u8d27\u540c\u6b65\u5b66\u4e60\u4e86\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\u548c\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300b\u7684\u4e00\u4e9b\u7ae0\u8282\u3002\u5305\u62ec\u5b66\u4e60\u548c\u8f93\u51fa\uff0c\u5927\u6982\u82b1\u4e86\u5403\u8d272\u4e2a\u6708\u5de6\u53f3\u65f6\u95f4\u3002 \u6574\u4f53\u4e0a\uff0csklearn\u7684\u57fa\u7840\u4f7f\u7528\u548c\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6982\u5ff5\u7684\u638c\u63e1\u8fd8\u662f\u4e0d\u56f0\u96be\u7684\u3002\u51b3\u7b56\u6811\u548cSVM\u7684\u4e00\u4e9b\u539f\u7406\u53ef\u80fd\u5751\u4f1a\u6bd4\u8f83\u591a\uff0c\u9700\u8981\u82b1\u8d39\u8f83\u591a\u65f6\u95f4\u68b3\u7406\u3002 \u5403\u8d27\u7684\u8fd9\u95e8\u8bfe\u7a0b\u552e\u4ef768\u5143\uff0c\u6574\u4f53\u4e0a\u8bc4\u4ef7\u8f83\u9ad8\uff0c\u8fbe\u52304.7\u9897\u661f\u3002 \u5b9e\u9645\u4e0a\u8fd9\u95e8\u8bfe\u7a0b\u505a\u5230\u4e00\u534a\u7684\u65f6\u5019\uff0c\u5403\u8d27\u51b3\u5b9a\u88f8\u8f9e\uff0c\u56e0\u4e3a\u90a3\u65f6\u5019\u5927\u6982\u662f2018\u5e743\u6708\u4efd\u4e86\uff0c\u662f\u62db\u8058\u7684\u9ec4\u91d1\u65f6\u671f\u3002\u7ecf\u8fc7\u4e86\u534a\u5e74\u591a\u7684\u51c6\u5907\uff0c\u5403\u8d27\u4fe1\u5fc3\u6ee1\u6ee1\uff0c\u611f\u89c9\u5df2\u7ecf\u638c\u63e1\u4e86\u4ecePython\u57fa\u7840\u5230Python\u6570\u636e\u5206\u6790\u5230Python\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6280\u80fd\uff0c\u5e94\u8be5\u80fd\u591f\u6478\u5230\u7b97\u6cd5\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u673a\u4f1a\u3002 \u5403\u8d27\u5f00\u59cb\u5728Boss\u4e0a\u548c\u62c9\u52fe\u4e0a\u6295\u9012\u7b80\u5386\uff0c\u90a3\u65f6\u5019\u6b63\u662f\u7b97\u6cd5\u5c97\u9700\u6c42most\u706b\u7206\u7684\u65f6\u671f\uff0c\u5403\u8d27\u9646\u9646\u7eed\u7eed\u6536\u5230\u4e86\u4e00\u4e9b\u4e8c\u4e09\u7ebf\u4e92\u8054\u7f51\u516c\u53f8\u7684\u9762\u8bd5\u9080\u7ea6\u3002\u4f46\u9646\u7eed\u9762\u4e86\u597d\u51e0\u573a\uff0c\u5403\u8d27\u53d1\u73b0\u81ea\u5df1\u603b\u662f\u4f1a\u9047\u5230\u4e00\u4e9b\u5982\u624b\u5199\u4e8c\u5206\u67e5\u627e\uff0c\u624b\u5199\u5feb\u6392\u7b97\u6cd5\uff0c\u624b\u5199\u722c\u697c\u68af\u65b9\u6cd5\u8fd9\u6837\u7684\u95ee\u9898\u3002\u62ff\u5230\u8fd9\u4e9b\u95ee\u9898\u540e\u5403\u8d27\u4e00\u8138\u61f5\u903c\uff0c\u5728\u7eb8\u4e0a\u6293\u7834\u8111\u888b\u5199\u4e0b\u4e86\u51e0\u884cimport numpy as np,import pandas as pd \u8fd9\u6837\u7684\u4e1c\u897f\uff0c\u7136\u540e\u9762\u8bd5\u5b98\u5c31\u7b11\u76c8\u76c8\u5730\u8ddf\u5403\u8d27\u8bf4\uff0c\u4f60\u56de\u53bb\u7b49\u901a\u77e5\u5427\u3002 \u4e8e\u662f\uff0c\u5403\u8d27\u4e00\u8fb9\u767d\u5929\u9762\u8bd5\uff0c\u4e00\u8fb9\u665a\u4e0a\u56de\u5bb6\u6574\u7406\u767d\u5929\u9047\u5230\u7684\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u91cd\u70b9\u9488\u5bf9\u4e00\u4e9b\u5e38\u89c1\u7684\u624b\u5199\u4ee3\u7801\u9898\u8fdb\u884c\u4e86\u51c6\u5907\uff0c\u638c\u63e1\u4e86\u4e00\u4e9b\u50cf\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u52a8\u6001\u89c4\u5212\u8fd9\u6837\u57fa\u672c\u7684\u6570\u636e\u7ed3\u6784\u548c\u7b97\u6cd5\u77e5\u8bc6\u3002\u5468\u672b\u7684\u65f6\u5019\uff0c\u518d\u7ee7\u7eed\u5f55\u5236\u300asklearn\u673a\u5668\u5b66\u4e60\u300b\u8fd9\u4e2a\u8bfe\u7a0b\u3002\u8fd9\u6837\u5927\u6982\u6301\u7eed\u4e86\u534a\u4e2a\u591a\u6708\uff0c\u5403\u8d27\u5f00\u59cb\u6536\u5230\u4e00\u4e9boffer. \u5f88\u5feb\uff0c\u5403\u8d27\u8ddf\u4e00\u4e2aoffer\u786e\u8ba4\u4e86\u773c\u795e\uff0c\u6b63\u5f0f\u8f6c\u884c\u6210\u4e3a\u4e86\u4e00\u4e2a\u4e92\u8054\u7f51\u884c\u4e1a\u7684\u642c\u7816\u5de5\uff0c\u4f19\u98df\u76f8\u6bd4\u4ee5\u524d\u6709\u4e86\u8f83\u5927\u7684\u6539\u5584\uff0c\u5403\u8d27\u7684\u5fc3\u91cc\u4e50\u5f00\u4e86\u82b1\u3002 \u5403\u8d27\u540e\u6765\u5728\u5468\u672b\u7684\u65f6\u5019\u4e5f\u628a\u8fd9\u4e9b\u9762\u8bd5\u7684\u7ecf\u9a8c\u603b\u7ed3\u8d77\u6765\uff0c\u653e\u5728\u4e86\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u3002 \u8fd9\u4e2a\u8bfe\u7a0b\u7684\u8bc4\u4ef7\u6bd4\u8f83\u4e24\u7ea7\u5206\u5316\uff0c\u6709\u4eba\u53eb\u597d\uff0c\u4e5f\u6709\u4eba\u5410\u69fd\u8bf4\u6728\u6709\u4ec0\u4e48\u5375\u7528\u3002","title":"\u4e00\uff0c\u4e00\u4e2a\u5403\u8d27\u8f6c\u884c\u7b97\u6cd5\u7684\u5fc3\u8def\u5386\u7a0b"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/#\u4e8c\u5403\u8d27\u4e3a\u4ec0\u4e48\u8981\u5199\u8fd9\u672c\u4e66","text":"\u6210\u4e3a\u4e86\u4e00\u540d\u4e92\u8054\u7f51\u642c\u7816\u5de5\u540e\uff0c\u5403\u8d27\u672c\u60f3\u7740\u5728\u5468\u672b\u65f6\u95f4\uff0c\u628a\u81ea\u5df1\u8f6c\u884c\u4e4b\u524d\u5236\u5b9a\u7684\u5b66\u4e60\u8ba1\u5212\u7684\u7b2c5\u90e8\u5206\uff0c\u5373tensorflow\u6df1\u5ea6\u5b66\u4e60\uff08\u540c\u6b65\u5b66\u4e60\u5434\u6069\u8fbe\u7684\u300a\u6df1\u5ea6\u5b66\u4e60\u300b\u89c6\u9891\u8bfe\u7a0b\uff09\u8fd9\u90e8\u5206\u4ed8\u8bf8\u5b9e\u65bd\u3002 \u4f46\u642c\u7816\u5de5\u4f5c\u975e\u5e38\u8f9b\u82e6\uff0c\u540c\u65f6\u5de5\u4f5c\u8fd8\u9700\u8981\u5403\u8d27\u638c\u63e1\u4e00\u4e9b\u5176\u5b83\u7684\u6280\u80fd\uff0c\u4f8b\u5982linux\u57fa\u672c\u64cd\u4f5c\uff0cgit\u57fa\u672c\u64cd\u4f5c\uff0cHive\u6570\u636e\u5e93\uff0cmapreduce\u7f16\u7a0b\u65b9\u6cd5\uff0cxgboost\u548clightgbm\u5efa\u6a21\u65b9\u6cd5\u7b49\u7b49\u3002 \u5927\u6982\u534a\u5e74\u540e\uff0c\u5403\u8d27\u624d\u611f\u5230\u5df2\u7ecf\u719f\u7ec3\u638c\u63e1\u4e86\u5f53\u65f6\u5de5\u4f5c\u6240\u9700\u8981\u7684\u4e3b\u8981\u6280\u80fd\uff0c\u80fd\u591f\u8f83\u4e3a\u987a\u5229\u5730\u5f00\u53d1\u9879\u76ee\u3002\u5230\u4e86\u5468\u672b\u7684\u65f6\u5019\uff0c\u5403\u8d27\u5f00\u59cb\u4e00\u8fb9\u5728\u7f51\u6613\u4e91\u8bfe\u5802\u4e0a\u770b\u5434\u6069\u8fbe\u300a\u6df1\u5ea6\u5b66\u4e60\u300b\u89c6\u9891\u8bfe\u7a0b\uff0c\u4e00\u8fb9\u5b66\u4e60\u4f7f\u7528tensorflow. \u5434\u6069\u8fbe\u7684\u8fd9\u4e2a\u7cfb\u5217\u7684\u8bfe\u7a0b\u603b\u4f53\u4e0a\u975e\u5e38\u4e0d\u9519\uff0c\u4f46\u7565\u5fae\u504f\u7406\u8bba\u4e00\u4e9b\uff0c\u8bb2\u4e86\u8f83\u591a\u7684\u6570\u5b66\u7ec6\u8282\uff0c\u5403\u8d27\u5f53\u65f6\u5b66\u7684\u8fd8\u662f\u6709\u4e9b\u5403\u529b\u7684\u3002\u5927\u6982\u7528\u4e86\u534a\u5e74\u7684\u5468\u672b\u65f6\u95f4\uff0c\u624d\u57fa\u672c\u5b66\u4e60\u5b8c\u6210\u4e86\u8fd9\u4e94\u95e8\u8bfe\uff0c\u5e76\u68b3\u7406\u51fa\u6765\u4e865\u7bc7\u5b66\u4e60\u7b14\u8bb0\u3002 \u540e\u6765\u5403\u8d27\u5411\"Python\u4e4b\u7985\"\u516c\u4f17\u53f7\u6295\u7a3f\u4e86\u4e00\u7bc7\u6587\u7ae0\u300a18\u5f0f\u4f18\u96c5\u4f60\u7684Python\u300b\uff0c\u53f7\u4e3b\u5fd7\u519b\u5927\u5927\u5728\u540e\u6765\u505a\u62bd\u5956\u9001\u4e66\u7684\u6d3b\u52a8\u65f6\u5c31\u9001\u4e86\u5403\u8d27\u4e00\u672c\u4e66\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u3002\u8fd9\u672c\u4e66\u76f8\u6bd4\u4e8e\u5434\u6069\u8fbe\u8bfe\u7a0b\u66f4\u52a0\u57fa\u7840\u4e00\u4e9b\uff0c\u8be5\u4e66\u5047\u5b9a\u8bfb\u8005\u65e0\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\uff0c\u4ee5Keras\u4e3a\u5de5\u5177\uff0c\u4f7f\u7528\u4e30\u5bcc\u7684\u8303\u4f8b\u6f14\u793a\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\u3002\u8be5\u4e66\u901a\u4fd7\u6613\u61c2\uff0c\u5168\u4e66\u6ca1\u6709\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u6ce8\u91cd\u57f9\u517b\u8bfb\u8005\u7684\u6df1\u5ea6\u5b66\u4e60\u76f4\u89c9\u3002\u5403\u8d27\u62ff\u6765\u8be5\u4e66\uff0c\u7b80\u76f4\u5982\u83b7\u81f3\u5b9d\uff0c\u4e0d\u5230\u4e24\u4e2a\u5468\u672b\u5c31\u5403\u5b8c\u4e86\uff0c\u5bf9\u6df1\u5ea6\u5b66\u4e60\u5728\u5b9e\u8df5\u5c42\u9762\u6709\u4e86\u66f4\u4e3a\u6e05\u6670\u7684\u8ba4\u8bc6\u3002 \u540c\u65f6\uff0c\u5403\u8d27\u8fd8\u5728\u5b66\u4e60tensorflow1.0\uff0c\u603b\u4f53\u800c\u8a00\u5b66\u5f97\u6bd4\u8f83\u75db\u82e6\uff0c\u5b98\u65b9\u6587\u6863\u8bb2\u7684\u5404\u79cd\u6982\u5ff5\u591a\u800c\u6742\uff0c\u9759\u6001\u56fe\u975e\u5e38\u96be\u4ee5\u8c03\u8bd5\uff0ctf.control_dependencies, tf.while_loop\u8fd9\u4e9b\u4e1c\u897f\u7b80\u76f4\u53cd\u4eba\u7c7b\uff0c\u53c8\u662ftf.estimator, \u53c8\u662ftflearn, \u53c8\u662ftf.keras\uff0c\u8ba9\u4eba\u65e0\u6240\u9002\u4ece\u3002\u5403\u8d27\u82b1\u8d39\u4e86\u975e\u5e38\u591a\u7684\u65f6\u95f4\uff0c\u57fa\u672c\u4e0a\u624d\u628atensorflow1.0\u5e38\u7528\u7684\u4e00\u4e9b\u6982\u5ff5\u548c\u5de5\u5177\u68b3\u7406\u5230\u4e00\u4e2a\u9002\u5408\u4eba\u7c7b\u7406\u89e3\u7684\u7a0b\u5ea6\u3002 \u4f46tensorflow\u4e0d\u4ec1\uff0c\u4ee5\u5403\u8d27\u4e3a\u520d\u72d7\u3002\u5c31\u5728\u5403\u8d27\u5feb\u8981\u6574\u7406\u5b8c\u8fd9\u4e2atensorflow1.0\u6559\u7a0b\u7684\u65f6\u5019\uff0ctensorflow\u5b98\u65b9\u5ba3\u5e03\u5c06\u4e0d\u4e45\u63a8\u51fatensorflow2.0\uff0c\u9ed8\u8ba4\u4f7f\u7528\u52a8\u6001\u56fe\uff0c\u5e76\u5bf9API\u8fdb\u884c\u5927\u5e45\u5ea6\u7684\u8c03\u6574\u3002\u5403\u8d27\u5f53\u65f6\u5fc3\u91cc\u7684\u6ecb\u5473\uff0c\u5c31\u597d\u50cf\u4e00\u4e2a\u7537\u5b69\u5b50\u8ffd\u4e00\u4e2a\u5973\u751f\u8ffd\u4e86\u5927\u534a\u5e74\uff0c\u611f\u89c9\u57fa\u672c\u6478\u6e05\u695a\u4e86\u8fd9\u4e2a\u5973\u751f\u7684\u813e\u6c14\u548c\u4e2a\u6027\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u5973\u751f\u7a81\u7136\u6709\u4e00\u5929\u5bf9\u4ed6\u8bf4\uff1a\"\u4f60\u522b\u8ffd\u4e86\uff0c\u6211\u8981\u53bb\u505a\u53d8\u6027\u624b\u672f\u4e86\uff0c\u53d8\u6210\u4e00\u4e2a\u7537\u5b69\u5b50\u3002\" \u4e8e\u662f\uff0c\u5403\u8d27\u8f6c\u800c\u5f00\u59cb\u5b66\u4e60Spark\uff0c\u6574\u4f53\u800c\u8a00\uff0cSpark\u7684\u5b98\u65b9\u6559\u7a0b\u975e\u5e38\u5b8c\u5584\uff0c\u7f51\u7edc\u4e0a\u4e5f\u6709\u6bd4\u8f83\u597d\u7684\u6559\u7a0b\u8d44\u6e90\u3002\u5403\u8d27\u5b66\u8d77\u6765\u975e\u5e38\u987a\u5229\uff0c\u4e0d\u52302\u4e2a\u6708\uff0c\u5c31\u5b66\u4e60\u5e76\u6574\u7406\u4e86\u4e00\u4efd\u7cfb\u7edf\u7684Spark\u6559\u7a0b\uff0c\u653e\u5728\u4e86github\u4ed3\u5e93\u4e2d\u3002 2019\u5e7410\u67081\u65e5\uff0c\u8fd9\u662f\u4e00\u4e2a\u7279\u522b\u7684\u65e5\u5b50\u3002\u8fd9\u4e00\u5929\u65e2\u662f\u7956\u56fd\u6bcd\u4eb2\u7684\u751f\u65e5\uff0c\u4e5f\u662ftensorflow2.0\u7684\u751f\u65e5\u3002\u5728\u8fd9\u4e00\u5929tensorflow\u5b98\u65b9\u5ba3\u5e03\u53d1\u5e03tensorflow2.0\u7684\u6b63\u5f0f\u7248\u672c\u3002\u5403\u8d27\u77e5\u9053\u8fd9\u4e2a\u6d88\u606f\u540e\u975e\u5e38\u5f00\u5fc3\uff0c\u5c31\u597d\u50cf\u4e00\u4e2a\u82b1\u75f4\u7ec8\u4e8e\u7b49\u5230\u4e86\u82b1\u5f00\u4e00\u6837\u3002\u4f46\u662f\u5403\u8d27\u5f53\u65f6\u6b63\u5728\u505a\u4e00\u4e2a\u4ed6\u642c\u7816\u4ee5\u6765\u9047\u5230\u8fc7\u7684\u6700\u590d\u6742\u7684\u4e00\u4e2aspark\u5927\u6570\u636e\u6316\u6398\u9879\u76ee\uff0c\u5468\u672b\u7684\u65f6\u95f4\u90fd\u6295\u5165\u5230\u8fd9\u4e2a\u9879\u76ee\u7684\u653b\u575a\u4e2d\u53bb\u4e86\u3002\u5403\u8d27\u51b3\u5b9a\u7b49\u8fd9\u4e2a\u9879\u76ee\u57fa\u672c\u5b8c\u6210\u540e\uff0c\u91cd\u65b0\u5b66\u4e60\u5e76\u68b3\u7406\u4e00\u4efdtensorflow2\u7684\u6559\u7a0b\u3002 \u5927\u6982\u57282020\u5e74\u521d\uff0c\u5403\u8d27\u5f00\u59cb\u5b66\u4e60tensorflow2.0\u7684\u5b98\u65b9\u6587\u6863\u3002\u5c3d\u7ba1tensorflow2.0\u5ba3\u79f0\u5df2\u7ecf\u4e3a\u6539\u5584\u7528\u6237\u4f53\u9a8c\u505a\u51fa\u4e86\u5de8\u5927\u7684\u6539\u8fdb\uff0creally easy to use\uff0c\u4f46\u5403\u8d27\u5b66\u5f97\u5e76\u4e0d\u8f7b\u677e\u3002tensorflow2.0\u5b98\u65b9\u6587\u6863\u548ctensorflow1.0\u5b98\u65b9\u6587\u6863\u663e\u7136\u662f\u51fa\u81ea\u540c\u4e00\u6279\u4f5c\u8005\u4e4b\u624b\uff0c\u4ed6\u4eec\u4e00\u5982\u65e2\u5f80\u5730\u79c9\u627f\u7740\u8c37\u6b4cmake things complicated\u7684\u98ce\u683c\u4f20\u7edf\uff0c\u7528\u54c8\u5e0c\u8868\u4e00\u822c\u6df7\u4e71\u7684\u6587\u6863\u7ed3\u6784\u3001\u65e0\u6cd5\u8fd0\u884c\u7684\u8303\u4f8b\u4ee3\u7801\u3001\u590d\u6742\u7684\u51fd\u6570\u5d4c\u5957\u8c03\u7528\u5173\u7cfb\u3001\u968f\u610f\u63d2\u5165\u7684\u4e0d\u5e38\u7528\u7b2c\u4e09\u65b9\u5e93\u7b49\u6280\u5de7\u5c06\u8bfb\u8005\u7684\u61f5\u5708\u7a0b\u5ea6\u9010\u6b65\u63a8\u5411\u9ad8\u6f6e\u3002 \u5728\u5403\u8d27\u770b\u6765\uff0ctensorflow2.0\u5b98\u65b9\u6587\u6863\u6240\u6709\u7684\u95ee\u9898\u53ef\u4ee5\u62bd\u8c61\u4e3a\u4e00\u4e2a\u95ee\u9898\uff1a\u566a\u58f0\u592a\u591a\u3002\u8bfb\u8005\u8981\u4ece\u566a\u58f0\u5982\u6b64\u4e4b\u591a\u7684\u5b98\u65b9\u6559\u7a0b\u4e2d\u63d0\u53d6\u51fa\u4ed6\u60f3\u8981\u7684\u4fe1\u606f\u662f\u975e\u5e38\u7684\u5403\u529b\u7684\u3002\u5982\u679c\u628a\u5b98\u65b9\u6559\u7a0b\u6bd4\u4f5c\u4e00\u76d8\u83dc\uff0c\u90a3\u4e48\u8fd9\u76d8\u83dc\u867d\u7136\u6709\u8bb8\u591a\u8425\u517b\u7269\u8d28\uff0c\u4f46\u4e5f\u6709\u8bb8\u591a\u7684\u6c99\u5b50\uff0c\u4e0d\u5c0f\u5fc3\u54ac\u5230\u4e00\u53e3\u5c31\u784c\u5f97\u614c\uff0c\u751a\u81f3\u4f1a\u89c9\u5f97\u6076\u5fc3\u5f97\u4e0d\u884c\u3002\u5403\u8d27\u51b3\u5b9a\u8981\u505a\u4e00\u76d8\u8425\u517b\u4e30\u5bcc\uff0c\u4e14\u7f8e\u5473\u5b9c\u4eba\u7684\u83dc\u3002 \u5403\u8d27\u5f00\u59cb\u6309\u7167\u4ed6\u60f3\u8c61\u4e2d\u7f8e\u5473\u4f73\u80b4\u7684\u6837\u5b50\u6765\u505a\u8fd9\u76d8\u83dc\u3002\u5468\u672b\u672c\u5e94\u9002\u5408\u53bb\u53c2\u52a0\u6237\u5916\u722c\u5c71\u6d3b\u52a8\uff0c\u4ed6\u5bf9\u7740\u7535\u8111\u5728\u505a\u83dc\u3002\u653e\u5047\u56de\u5bb6\u7684\u706b\u8f66\u4e0a\uff0c\u4ed6\u5bf9\u7740\u7535\u8111\u5728\u505a\u83dc\u3002\u6625\u8282\u5230\u5bb6\u540e\u7531\u4e8e\u75ab\u60c5\u5f71\u54cd\u4e0d\u63d0\u5021\u7a9c\u95e8\uff0c\u4ed6\u53ef\u4ee5\u6709\u66f4\u591a\u65f6\u95f4\u5f00\u5fc3\u5730\u5bf9\u7740\u7535\u8111\u505a\u83dc\u3002\u75ab\u60c5\u5f62\u52bf\u6108\u53d1\u4e25\u5cfb\u4f01\u4e1a\u5ef6\u8fdf\u590d\u5de5\uff0c\u4ed6\u56de\u5230\u5317\u4eac\u4e00\u8fb9\u9694\u79bb\u4e00\u8fb9\u5bf9\u7740\u7535\u8111\u5728\u505a\u83dc\u3002","title":"\u4e8c\uff0c\u5403\u8d27\u4e3a\u4ec0\u4e48\u8981\u5199\u8fd9\u672c\u4e66\uff1f"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/#\u4e09\u5403\u8d27\u5199\u7684\u8fd9\u672c\u4e66\u600e\u4e48\u6837","text":"\u524d\u540e\u7528\u4e86\u7ea6\u4e24\u4e2a\u6708\uff0c\u5403\u8d27\u7684\u8fd9\u672c\u4e66\u57fa\u672c\u5199\u5b8c\u4e86\u3002\u5403\u8d27\u5fc3\u60f3\uff0c\u8be5\u7ed9\u5b83\u53d6\u4e2a\u4ec0\u4e48\u540d\u5b57\u5462\uff1f \u55ef\uff0c\u6709\u4e86\uff0c\u8fd9\u662f\u4e00\u672c\u53ef\u4ee5\u5e2e\u52a9\u5927\u5bb6\u6539\u5584\u4f19\u98df\u7684\u4e66\u3002\u5927\u6982\u53ef\u4ee5\u8fde\u7eed\u540330\u5929\uff0c\u800c\u4e14\u5e94\u8be5\u5473\u9053\u4e0d\u9519\u3002 \u5c31\u53eb\u4ed6\u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b\u5427\u3002 \u4ece\u8fd9\u672c\u4e66\u7684\u4e66\u540d\u5e94\u8be5\u80fd\u591f\u770b\u51fa\uff0c\u4f5c\u8005\u662f\u4e2a\u5403\u8d27\uff0c\u800c\u4e14\u662f\u4e2a\u5f88\u6709\u6bc5\u529b\u7684\u5403\u8d27\u3002 \u8fd9\u662f\u4e00\u672c\u600e\u4e48\u6837\u7684\u4e66\u5462\uff1f\u8fd9\u662f\u4e00\u672c\u5bf9\u4eba\u7c7b\u7528\u6237\u6781\u5176\u53cb\u5584\u7684TensorFlow2.0\u5165\u95e8\u5de5\u5177\u4e66\u3002 \u4e3a\u4e86\u5c3d\u53ef\u80fd\u964d\u4f4e\u4fe1\u606f\u566a\u58f0\uff0c\u8fd9\u672c\u4e66\u76f8\u6bd4\u5b98\u65b9\u6587\u6863\u5728\u7bc7\u7ae0\u7ed3\u6784\u548c\u8303\u4f8b\u9009\u53d6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u6df7\u4e71\u7684\u7bc7\u7ae0\u7ed3\u6784\uff0c\u65e2\u6709\u6559\u7a0b\u53c8\u6709\u6307\u5357\uff0c\u7f3a\u5c11\u6574\u4f53\u7684\u7f16\u6392\u903b\u8f91\u3002 \u8fd9\u672c\u4e66\u6309\u7167\u5185\u5bb9\u96be\u6613\u7a0b\u5ea6\u3001\u8bfb\u8005\u68c0\u7d22\u4e60\u60ef\u548cTensorFlow\u81ea\u8eab\u7684\u5c42\u6b21\u7ed3\u6784\u8bbe\u8ba1\u5185\u5bb9\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u5c42\u6b21\u6e05\u6670\uff0c\u65b9\u4fbf\u6309\u7167\u529f\u80fd\u67e5\u627e\u76f8\u5e94\u8303\u4f8b\u3002 \u4e0d\u540c\u4e8e\u5b98\u65b9\u6587\u6863\u5197\u957f\u7684\u8303\u4f8b\u4ee3\u7801\uff0c\u8fd9\u672c\u4e66\u5728\u8303\u4f8b\u8bbe\u8ba1\u4e0a\u5c3d\u53ef\u80fd\u7b80\u7ea6\u5316\u548c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u8303\u4f8b\u6613\u8bfb\u6027\u548c\u901a\u7528\u6027\uff0c\u5927\u90e8\u5206\u4ee3\u7801\u7247\u6bb5\u5728\u5b9e\u8df5\u4e2d\u53ef\u5373\u53d6\u5373\u7528\u3002 \u603b\u4e4b\uff0c\u8fd9\u672c\u4e66\u503e\u6ce8\u4e86\u4e00\u4e2a\u5403\u8d27\u5bf9\u7f8e\u98df\u7684\u5168\u90e8\u5411\u5f80\u548c\u8ffd\u6c42\uff0c\u5982\u679c\u4f60\u975e\u5e38\u559c\u6b22\u7f8e\u98df\uff0c\u5e76\u4e14\u60f3\u8981\u5b66\u4e60TensorFlow2\uff0c\u90a3\u4e48\u8fd9\u672c\u4e66\u4e00\u5b9a\u503c\u5f97\u4f60\u54c1\u5c1d\u54c1\u5c1d\u3002 \u8fd9\u672c\u4e66\u5728github\u4e0a\u7ebf1\u4e2a\u6708\u6765\uff0c\u5f97\u5230\u4e86\u4e0d\u5c11\u5c0f\u4f19\u4f34\u7684\u53cd\u9988\uff0c\u63d0\u4e86\u4e00\u4e9bissues\uff0c\u5403\u8d27\u9488\u5bf9\u76f8\u5173\u95ee\u9898\u8fdb\u884c\u4e86\u4e00\u4e9b\u56de\u7b54\u548c\u5bf9\u9879\u76ee\u505a\u4e86\u6539\u8fdb\u3002 \u540c\u65f6\u8fd9\u4e2a\u9879\u76ee\u4e5f\u83b7\u5f97\u4e86100\u591a\u9897\u661f\u661f\uff0c\u5403\u8d27\u770b\u5728\u773c\u91cc\uff0c\u7f8e\u5728\u5fc3\u91cc\uff0c\u6bcf\u5929\u65e9\u4e0a\u7761\u89c9\u8d77\u6765\u90fd\u4f1a\u53bbgithub\u661f\u7403\u4e0a\u6570\u661f\u661f\u3002","title":"\u4e09\uff0c\u5403\u8d27\u5199\u7684\u8fd9\u672c\u4e66\u600e\u4e48\u6837\uff1f"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/#\u56db\u5982\u4f55\u83b7\u53d6\u5403\u8d27\u5199\u7684\u8fd9\u672c\u4e66","text":"\u8fd9\u672c\u4e66\u76ee\u524d\u67094\u79cd\u5f62\u5f0f\u83b7\u53d6\u3002 1\uff0cgitbook\u7535\u5b50\u4e66\u3002\u4ee5\u7f51\u9875\u94fe\u63a5\u5448\u73b0\uff0c\u540c\u65f6\u53ef\u4ee5\u5728\u7535\u8111\u548c\u624b\u673a\u4e0a\u7528\u6d4f\u89c8\u5668\u6253\u5f00\u3002 \u7535\u5b50\u4e66\u94fe\u63a5\uff1a https://lyhue1991.github.io/eat_tensorflow2_in_30_days 2\uff0cgithub\u9879\u76ee\u6e90\u7801\u3002\u5305\u542b\u5168\u90e8\u6570\u636e\u96c6\u548cmd\u683c\u5f0f\u6e90\u7801\uff0c\u53ef\u4ee5\u5728jupyter\u4e0a\u5b89\u88c5jupytext\u540e\u5c06md\u6e90\u7801\u4f5c\u4e3aipynb\u6253\u5f00\u3002 \u9879\u76ee\u94fe\u63a5\uff1a https://github.com/lyhue1991/eat_tensorflow2_in_30_days 3\uff0cpdf\u683c\u5f0f\u7535\u5b50\u4e66\u3002 4\uff0cipynb\u683c\u5f0f\u9879\u76ee\u6e90\u7801\u3002 \u5176\u4e2dgithub\u9879\u76ee\u6e90\u7801\u548cgitbook\u7535\u5b50\u4e66\u5c06\u6301\u7eed\u7ef4\u62a4\uff0c\u540e\u7eed\u53ef\u80fd\u4e5f\u4f1a\u589e\u52a0\u4e00\u4e9b\u65b0\u7684\u8303\u4f8b\u3002pdf\u7248\u672c\u7535\u5b50\u4e66\u548cipynb\u9879\u76ee\u6e90\u7801\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\" Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e \"\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57: tf \u8fdb\u884c\u83b7\u53d6\u3002\u8fd9\u4e24\u79cd\u5f62\u5f0f\u83b7\u53d6\u7684\u300aeat tensorflow2 in 30 days\u300b\u65e0\u6cd5\u4fdd\u8bc1\u66f4\u65b0\u3002 \u9605\u8bfb\u4f53\u9a8c\u4f18\u5148\u63a8\u8350\u4f7f\u7528gitbook\u7535\u5b50\u4e66\uff0c\u5177\u6709\u76ee\u5f55\u67e5\u627e\u548c\u4e0a\u4e0b\u9875\u7ffb\u9875\u529f\u80fd\uff0c\u5b57\u4f53\u5927\u5c0f\u548c\u80cc\u666f\u8272\u53ef\u4ee5\u6839\u636e\u4e2a\u4eba\u559c\u597d\u8fdb\u884c\u8c03\u6574\uff0c\u989c\u503c\u8d85\u9ad8\u3002","title":"\u56db\uff0c\u5982\u4f55\u83b7\u53d6\u5403\u8d27\u5199\u7684\u8fd9\u672c\u4e66?"},{"location":"chinese/%E5%90%8E%E8%AE%B0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%90%83%E8%B4%A7%E5%92%8C%E4%B8%80%E9%81%93%E8%8F%9C%E7%9A%84%E6%95%85%E4%BA%8B/#\u4e94\u9f13\u52b1\u548c\u8054\u7cfb\u8fd9\u4e2a\u5403\u8d27","text":"\u6700\u540e\uff0c\u60f3\u7ed9\u5927\u5bb6\u8bb2\u4e00\u4e2a\u5403\u8d27\u5c0f\u738b\u5b50\u7684\u6545\u4e8b\u3002 \u5728\u5f88\u4e45\u5f88\u4e45\u4ee5\u524d\uff0c\u6709\u4e00\u4e2a\u5c0f\u738b\u5b50\uff0c\u4f4f\u5728\u4e00\u4e2a\u53ea\u6bd4\u4ed6\u5927\u4e00\u70b9\u70b9\u7684\u661f\u7403\u4e0a\uff0c\u4ed6\uff0c\u60f3\u8981\u4e00\u4e2a\u670b\u53cb\u3002 \u5728\u6628\u5929\u4eca\u5929\u548c\u660e\u5929\uff0c\u6709\u4e00\u4e2a\u5403\u8d27\uff0c\u4f4f\u5728\u4e00\u4e2a\u53ea\u6bd4\u4ed6\u5927\u4e00\u70b9\u70b9\u7684github\u661f\u7403\u4e0a\uff0c\u4ed6\uff0c\u60f3\u8981\u4e00\u9897\u661f\u661f\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\uff0c\u9f13\u52b1\u548c\u8054\u7cfb\u8fd9\u4e2a\u5403\u8d27"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/","text":"\u4e00\u3001TensorFlow\u7684\u5efa\u6a21\u6d41\u7a0b # \u5c3d\u7ba1TensorFlow\u8bbe\u8ba1\u4e0a\u8db3\u591f\u7075\u6d3b\uff0c\u53ef\u4ee5\u7528\u4e8e\u8fdb\u884c\u5404\u79cd\u590d\u6742\u7684\u6570\u503c\u8ba1\u7b97\u3002 \u4f46\u901a\u5e38\u4eba\u4eec\u4f7f\u7528TensorFlow\u6765\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5c24\u5176\u5e38\u7528\u4e8e\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002 \u4ece\u539f\u7406\u4e0a\u8bf4\u53ef\u4ee5\u4f7f\u7528\u5f20\u91cf\u6784\u5efa\u8ba1\u7b97\u56fe\u6765\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u673a\u5236\u8bad\u7ec3\u6a21\u578b\u3002 \u4f46\u4e3a\u7b80\u6d01\u8d77\u89c1\uff0c\u4e00\u822c\u63a8\u8350\u4f7f\u7528TensorFlow\u7684\u9ad8\u5c42\u6b21keras\u63a5\u53e3\u6765\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u7f51\u6a21\u578b\u3002 \u4f7f\u7528TensorFlow\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u4e00\u822c\u6d41\u7a0b\u5305\u62ec\uff1a 1\uff0c\u51c6\u5907\u6570\u636e 2\uff0c\u5b9a\u4e49\u6a21\u578b 3\uff0c\u8bad\u7ec3\u6a21\u578b 4\uff0c\u8bc4\u4f30\u6a21\u578b 5\uff0c\u4f7f\u7528\u6a21\u578b 6\uff0c\u4fdd\u5b58\u6a21\u578b\u3002 \u5bf9\u65b0\u624b\u6765\u8bf4\uff0c\u5176\u4e2d\u6700\u56f0\u96be\u7684\u90e8\u5206\u5b9e\u9645\u4e0a\u662f\u51c6\u5907\u6570\u636e\u8fc7\u7a0b\u3002 \u6211\u4eec\u5728\u5b9e\u8df5\u4e2d\u901a\u5e38\u4f1a\u9047\u5230\u7684\u6570\u636e\u7c7b\u578b\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\uff0c\u56fe\u7247\u6570\u636e\uff0c\u6587\u672c\u6570\u636e\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u6211\u4eec\u5c06\u5206\u522b\u4ee5titanic\u751f\u5b58\u9884\u6d4b\u95ee\u9898\uff0ccifar2\u56fe\u7247\u5206\u7c7b\u95ee\u9898\uff0cimdb\u7535\u5f71\u8bc4\u8bba\u5206\u7c7b\u95ee\u9898\uff0c\u56fd\u5185\u65b0\u51a0\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u9884\u6d4b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a\u5e94\u7528tensorflow\u5bf9\u8fd9\u56db\u7c7b\u6570\u636e\u7684\u5efa\u6a21\u65b9\u6cd5\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e00\u3001TensorFlow\u7684\u5efa\u6a21\u6d41\u7a0b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/#\u4e00tensorflow\u7684\u5efa\u6a21\u6d41\u7a0b","text":"\u5c3d\u7ba1TensorFlow\u8bbe\u8ba1\u4e0a\u8db3\u591f\u7075\u6d3b\uff0c\u53ef\u4ee5\u7528\u4e8e\u8fdb\u884c\u5404\u79cd\u590d\u6742\u7684\u6570\u503c\u8ba1\u7b97\u3002 \u4f46\u901a\u5e38\u4eba\u4eec\u4f7f\u7528TensorFlow\u6765\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5c24\u5176\u5e38\u7528\u4e8e\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002 \u4ece\u539f\u7406\u4e0a\u8bf4\u53ef\u4ee5\u4f7f\u7528\u5f20\u91cf\u6784\u5efa\u8ba1\u7b97\u56fe\u6765\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u673a\u5236\u8bad\u7ec3\u6a21\u578b\u3002 \u4f46\u4e3a\u7b80\u6d01\u8d77\u89c1\uff0c\u4e00\u822c\u63a8\u8350\u4f7f\u7528TensorFlow\u7684\u9ad8\u5c42\u6b21keras\u63a5\u53e3\u6765\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u7f51\u6a21\u578b\u3002 \u4f7f\u7528TensorFlow\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u4e00\u822c\u6d41\u7a0b\u5305\u62ec\uff1a 1\uff0c\u51c6\u5907\u6570\u636e 2\uff0c\u5b9a\u4e49\u6a21\u578b 3\uff0c\u8bad\u7ec3\u6a21\u578b 4\uff0c\u8bc4\u4f30\u6a21\u578b 5\uff0c\u4f7f\u7528\u6a21\u578b 6\uff0c\u4fdd\u5b58\u6a21\u578b\u3002 \u5bf9\u65b0\u624b\u6765\u8bf4\uff0c\u5176\u4e2d\u6700\u56f0\u96be\u7684\u90e8\u5206\u5b9e\u9645\u4e0a\u662f\u51c6\u5907\u6570\u636e\u8fc7\u7a0b\u3002 \u6211\u4eec\u5728\u5b9e\u8df5\u4e2d\u901a\u5e38\u4f1a\u9047\u5230\u7684\u6570\u636e\u7c7b\u578b\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\uff0c\u56fe\u7247\u6570\u636e\uff0c\u6587\u672c\u6570\u636e\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u6211\u4eec\u5c06\u5206\u522b\u4ee5titanic\u751f\u5b58\u9884\u6d4b\u95ee\u9898\uff0ccifar2\u56fe\u7247\u5206\u7c7b\u95ee\u9898\uff0cimdb\u7535\u5f71\u8bc4\u8bba\u5206\u7c7b\u95ee\u9898\uff0c\u56fd\u5185\u65b0\u51a0\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u9884\u6d4b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a\u5e94\u7528tensorflow\u5bf9\u8fd9\u56db\u7c7b\u6570\u636e\u7684\u5efa\u6a21\u65b9\u6cd5\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e00\u3001TensorFlow\u7684\u5efa\u6a21\u6d41\u7a0b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # \u4e00\uff0c\u51c6\u5907\u6570\u636e # titanic\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u4e58\u5ba2\u4fe1\u606f\u9884\u6d4b\u4ed6\u4eec\u5728Titanic\u53f7\u649e\u51fb\u51b0\u5c71\u6c89\u6ca1\u540e\u80fd\u5426\u751f\u5b58\u3002 \u7ed3\u6784\u5316\u6570\u636e\u4e00\u822c\u4f1a\u4f7f\u7528Pandas\u4e2d\u7684DataFrame\u8fdb\u884c\u9884\u5904\u7406\u3002 import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers dftrain_raw = pd . read_csv ( '../../data/titanic/train.csv' ) dftest_raw = pd . read_csv ( '../../data/titanic/test.csv' ) dftrain_raw . head ( 10 ) \u5b57\u6bb5\u8bf4\u660e\uff1a Survived:0\u4ee3\u8868\u6b7b\u4ea1\uff0c1\u4ee3\u8868\u5b58\u6d3b\u3010y\u6807\u7b7e\u3011 Pclass:\u4e58\u5ba2\u6240\u6301\u7968\u7c7b\uff0c\u6709\u4e09\u79cd\u503c(1,2,3) \u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\u3011 Name:\u4e58\u5ba2\u59d3\u540d \u3010\u820d\u53bb\u3011 Sex:\u4e58\u5ba2\u6027\u522b \u3010\u8f6c\u6362\u6210bool\u7279\u5f81\u3011 Age:\u4e58\u5ba2\u5e74\u9f84(\u6709\u7f3a\u5931) \u3010\u6570\u503c\u7279\u5f81\uff0c\u6dfb\u52a0\u201c\u5e74\u9f84\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 SibSp:\u4e58\u5ba2\u5144\u5f1f\u59d0\u59b9/\u914d\u5076\u7684\u4e2a\u6570(\u6574\u6570\u503c) \u3010\u6570\u503c\u7279\u5f81\u3011 Parch:\u4e58\u5ba2\u7236\u6bcd/\u5b69\u5b50\u7684\u4e2a\u6570(\u6574\u6570\u503c)\u3010\u6570\u503c\u7279\u5f81\u3011 Ticket:\u7968\u53f7(\u5b57\u7b26\u4e32)\u3010\u820d\u53bb\u3011 Fare:\u4e58\u5ba2\u6240\u6301\u7968\u7684\u4ef7\u683c(\u6d6e\u70b9\u6570\uff0c0-500\u4e0d\u7b49) \u3010\u6570\u503c\u7279\u5f81\u3011 Cabin:\u4e58\u5ba2\u6240\u5728\u8239\u8231(\u6709\u7f3a\u5931) \u3010\u6dfb\u52a0\u201c\u6240\u5728\u8239\u8231\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 Embarked:\u4e58\u5ba2\u767b\u8239\u6e2f\u53e3:S\u3001C\u3001Q(\u6709\u7f3a\u5931)\u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\uff0c\u56db\u7ef4\u5ea6 S,C,Q,nan\u3011 \u5229\u7528Pandas\u7684\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790EDA\uff08Exploratory Data Analysis\uff09\u3002 label\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Survived' ] . value_counts () . plot ( kind = 'bar' , figsize = ( 12 , 8 ), fontsize = 15 , rot = 0 ) ax . set_ylabel ( 'Counts' , fontsize = 15 ) ax . set_xlabel ( 'Survived' , fontsize = 15 ) plt . show () \u5e74\u9f84\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Age' ] . plot ( kind = 'hist' , bins = 20 , color = 'purple' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . set_ylabel ( 'Frequency' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u5e74\u9f84\u548clabel\u7684\u76f8\u5173\u6027 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw . query ( 'Survived == 0' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) dftrain_raw . query ( 'Survived == 1' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . legend ([ 'Survived==0' , 'Survived==1' ], fontsize = 12 ) ax . set_ylabel ( 'Density' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u4e0b\u9762\u4e3a\u6b63\u5f0f\u7684\u6570\u636e\u9884\u5904\u7406 def preprocessing ( dfdata ): dfresult = pd . DataFrame () #Pclass dfPclass = pd . get_dummies ( dfdata [ 'Pclass' ]) dfPclass . columns = [ 'Pclass_' + str ( x ) for x in dfPclass . columns ] dfresult = pd . concat ([ dfresult , dfPclass ], axis = 1 ) #Sex dfSex = pd . get_dummies ( dfdata [ 'Sex' ]) dfresult = pd . concat ([ dfresult , dfSex ], axis = 1 ) #Age dfresult [ 'Age' ] = dfdata [ 'Age' ] . fillna ( 0 ) dfresult [ 'Age_null' ] = pd . isna ( dfdata [ 'Age' ]) . astype ( 'int32' ) #SibSp,Parch,Fare dfresult [ 'SibSp' ] = dfdata [ 'SibSp' ] dfresult [ 'Parch' ] = dfdata [ 'Parch' ] dfresult [ 'Fare' ] = dfdata [ 'Fare' ] #Carbin dfresult [ 'Cabin_null' ] = pd . isna ( dfdata [ 'Cabin' ]) . astype ( 'int32' ) #Embarked dfEmbarked = pd . get_dummies ( dfdata [ 'Embarked' ], dummy_na = True ) dfEmbarked . columns = [ 'Embarked_' + str ( x ) for x in dfEmbarked . columns ] dfresult = pd . concat ([ dfresult , dfEmbarked ], axis = 1 ) return ( dfresult ) x_train = preprocessing ( dftrain_raw ) y_train = dftrain_raw [ 'Survived' ] . values x_test = preprocessing ( dftest_raw ) y_test = dftest_raw [ 'Survived' ] . values print ( \"x_train.shape =\" , x_train . shape ) print ( \"x_test.shape =\" , x_test . shape ) x_train.shape = (712, 15) x_test.shape = (179, 15) \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u6700\u7b80\u5355\u7684Sequential\uff0c\u6309\u5c42\u987a\u5e8f\u6a21\u578b\u3002 tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 20 , activation = 'relu' , input_shape = ( 15 ,))) model . add ( layers . Dense ( 10 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 20) 320 _________________________________________________________________ dense_1 (Dense) (None, 10) 210 _________________________________________________________________ dense_2 (Dense) (None, 1) 11 ================================================================= Total params: 541 Trainable params: 541 Non-trainable params: 0 _________________________________________________________________ \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # \u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u9009\u62e9\u6700\u5e38\u7528\u4e5f\u6700\u7b80\u5355\u7684\u5185\u7f6efit\u65b9\u6cd5\u3002 # \u4e8c\u5206\u7c7b\u95ee\u9898\u9009\u62e9\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ]) history = model . fit ( x_train , y_train , batch_size = 64 , epochs = 30 , validation_split = 0.2 #\u5206\u5272\u4e00\u90e8\u5206\u8bad\u7ec3\u6570\u636e\u7528\u4e8e\u9a8c\u8bc1 ) Train on 569 samples, validate on 143 samples Epoch 1/30 569/569 [==============================] - 1s 2ms/sample - loss: 3.5841 - AUC: 0.4079 - val_loss: 3.4429 - val_AUC: 0.4129 Epoch 2/30 569/569 [==============================] - 0s 102us/sample - loss: 2.6093 - AUC: 0.3967 - val_loss: 2.4886 - val_AUC: 0.4139 Epoch 3/30 569/569 [==============================] - 0s 68us/sample - loss: 1.8375 - AUC: 0.4003 - val_loss: 1.7383 - val_AUC: 0.4223 Epoch 4/30 569/569 [==============================] - 0s 83us/sample - loss: 1.2545 - AUC: 0.4390 - val_loss: 1.1936 - val_AUC: 0.4765 Epoch 5/30 569/569 [==============================] - ETA: 0s - loss: 1.4435 - AUC: 0.375 - 0s 90us/sample - loss: 0.9141 - AUC: 0.5192 - val_loss: 0.8274 - val_AUC: 0.5584 Epoch 6/30 569/569 [==============================] - 0s 110us/sample - loss: 0.7052 - AUC: 0.6290 - val_loss: 0.6596 - val_AUC: 0.6880 Epoch 7/30 569/569 [==============================] - 0s 90us/sample - loss: 0.6410 - AUC: 0.7086 - val_loss: 0.6519 - val_AUC: 0.6845 Epoch 8/30 569/569 [==============================] - 0s 93us/sample - loss: 0.6246 - AUC: 0.7080 - val_loss: 0.6480 - val_AUC: 0.6846 Epoch 9/30 569/569 [==============================] - 0s 73us/sample - loss: 0.6088 - AUC: 0.7113 - val_loss: 0.6497 - val_AUC: 0.6838 Epoch 10/30 569/569 [==============================] - 0s 79us/sample - loss: 0.6051 - AUC: 0.7117 - val_loss: 0.6454 - val_AUC: 0.6873 Epoch 11/30 569/569 [==============================] - 0s 96us/sample - loss: 0.5972 - AUC: 0.7218 - val_loss: 0.6369 - val_AUC: 0.6888 Epoch 12/30 569/569 [==============================] - 0s 92us/sample - loss: 0.5918 - AUC: 0.7294 - val_loss: 0.6330 - val_AUC: 0.6908 Epoch 13/30 569/569 [==============================] - 0s 75us/sample - loss: 0.5864 - AUC: 0.7363 - val_loss: 0.6281 - val_AUC: 0.6948 Epoch 14/30 569/569 [==============================] - 0s 104us/sample - loss: 0.5832 - AUC: 0.7426 - val_loss: 0.6240 - val_AUC: 0.7030 Epoch 15/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5777 - AUC: 0.7507 - val_loss: 0.6200 - val_AUC: 0.7066 Epoch 16/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5726 - AUC: 0.7569 - val_loss: 0.6155 - val_AUC: 0.7132 Epoch 17/30 569/569 [==============================] - 0s 99us/sample - loss: 0.5674 - AUC: 0.7643 - val_loss: 0.6070 - val_AUC: 0.7255 Epoch 18/30 569/569 [==============================] - 0s 97us/sample - loss: 0.5631 - AUC: 0.7721 - val_loss: 0.6061 - val_AUC: 0.7305 Epoch 19/30 569/569 [==============================] - 0s 73us/sample - loss: 0.5580 - AUC: 0.7792 - val_loss: 0.6027 - val_AUC: 0.7332 Epoch 20/30 569/569 [==============================] - 0s 85us/sample - loss: 0.5533 - AUC: 0.7861 - val_loss: 0.5997 - val_AUC: 0.7366 Epoch 21/30 569/569 [==============================] - 0s 87us/sample - loss: 0.5497 - AUC: 0.7926 - val_loss: 0.5961 - val_AUC: 0.7433 Epoch 22/30 569/569 [==============================] - 0s 101us/sample - loss: 0.5454 - AUC: 0.7987 - val_loss: 0.5943 - val_AUC: 0.7438 Epoch 23/30 569/569 [==============================] - 0s 100us/sample - loss: 0.5398 - AUC: 0.8057 - val_loss: 0.5926 - val_AUC: 0.7492 Epoch 24/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5328 - AUC: 0.8122 - val_loss: 0.5912 - val_AUC: 0.7493 Epoch 25/30 569/569 [==============================] - 0s 86us/sample - loss: 0.5283 - AUC: 0.8147 - val_loss: 0.5902 - val_AUC: 0.7509 Epoch 26/30 569/569 [==============================] - 0s 67us/sample - loss: 0.5246 - AUC: 0.8196 - val_loss: 0.5845 - val_AUC: 0.7552 Epoch 27/30 569/569 [==============================] - 0s 72us/sample - loss: 0.5205 - AUC: 0.8271 - val_loss: 0.5837 - val_AUC: 0.7584 Epoch 28/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5144 - AUC: 0.8302 - val_loss: 0.5848 - val_AUC: 0.7561 Epoch 29/30 569/569 [==============================] - 0s 77us/sample - loss: 0.5099 - AUC: 0.8326 - val_loss: 0.5809 - val_AUC: 0.7583 Epoch 30/30 569/569 [==============================] - 0s 80us/sample - loss: 0.5071 - AUC: 0.8349 - val_loss: 0.5816 - val_AUC: 0.7605 \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # \u6211\u4eec\u9996\u5148\u8bc4\u4f30\u4e00\u4e0b\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\u3002 % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"AUC\" ) \u6211\u4eec\u518d\u770b\u4e00\u4e0b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6548\u679c. model . evaluate ( x = x_test , y = y_test ) [0.5191367897907448, 0.8122605] \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # #\u9884\u6d4b\u6982\u7387 model . predict ( x_test [ 0 : 10 ]) #model(tf.constant(x_test[0:10].values,dtype = tf.float32)) #\u7b49\u4ef7\u5199\u6cd5 array([[0.26501188], [0.40970832], [0.44285864], [0.78408605], [0.47650957], [0.43849158], [0.27426785], [0.5962582 ], [0.59476686], [0.17882936]], dtype=float32) #\u9884\u6d4b\u7c7b\u522b model . predict_classes ( x_test [ 0 : 10 ]) array([[0], [0], [0], [1], [0], [0], [0], [1], [1], [0]], dtype=int32) \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u53ef\u4ee5\u4f7f\u7528Keras\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u3002\u524d\u8005\u4ec5\u4ec5\u9002\u5408\u4f7f\u7528Python\u73af\u5883\u6062\u590d\u6a21\u578b\uff0c\u540e\u8005\u5219\u53ef\u4ee5\u8de8\u5e73\u53f0\u8fdb\u884c\u6a21\u578b\u90e8\u7f72\u3002 \u63a8\u8350\u4f7f\u7528\u540e\u4e00\u79cd\u65b9\u5f0f\u8fdb\u884c\u4fdd\u5b58\u3002 1\uff0cKeras\u65b9\u5f0f\u4fdd\u5b58 # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u53ca\u6743\u91cd model . save ( '../../data/keras_model.h5' ) del model #\u5220\u9664\u73b0\u6709\u6a21\u578b # identical to the previous one model = models . load_model ( '../../data/keras_model.h5' ) model . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784 json_str = model . to_json () # \u6062\u590d\u6a21\u578b\u7ed3\u6784 model_json = models . model_from_json ( json_str ) #\u4fdd\u5b58\u6a21\u578b\u6743\u91cd model . save_weights ( '../../data/keras_model_weight.h5' ) # \u6062\u590d\u6a21\u578b\u7ed3\u6784 model_json = models . model_from_json ( json_str ) model_json . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ] ) # \u52a0\u8f7d\u6743\u91cd model_json . load_weights ( '../../data/keras_model_weight.h5' ) model_json . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] 2\uff0cTensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58 # \u4fdd\u5b58\u6743\u91cd\uff0c\u8be5\u65b9\u5f0f\u4ec5\u4ec5\u4fdd\u5b58\u6743\u91cd\u5f20\u91cf model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u4e0e\u6a21\u578b\u53c2\u6570\u5230\u6587\u4ef6,\u8be5\u65b9\u5f0f\u4fdd\u5b58\u7684\u6a21\u578b\u5177\u6709\u8de8\u5e73\u53f0\u6027\u4fbf\u4e8e\u90e8\u7f72 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( x_test , y_test ) [0.5191365896656527, 0.8122605] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-1\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"","title":"1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"titanic\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u4e58\u5ba2\u4fe1\u606f\u9884\u6d4b\u4ed6\u4eec\u5728Titanic\u53f7\u649e\u51fb\u51b0\u5c71\u6c89\u6ca1\u540e\u80fd\u5426\u751f\u5b58\u3002 \u7ed3\u6784\u5316\u6570\u636e\u4e00\u822c\u4f1a\u4f7f\u7528Pandas\u4e2d\u7684DataFrame\u8fdb\u884c\u9884\u5904\u7406\u3002 import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers dftrain_raw = pd . read_csv ( '../../data/titanic/train.csv' ) dftest_raw = pd . read_csv ( '../../data/titanic/test.csv' ) dftrain_raw . head ( 10 ) \u5b57\u6bb5\u8bf4\u660e\uff1a Survived:0\u4ee3\u8868\u6b7b\u4ea1\uff0c1\u4ee3\u8868\u5b58\u6d3b\u3010y\u6807\u7b7e\u3011 Pclass:\u4e58\u5ba2\u6240\u6301\u7968\u7c7b\uff0c\u6709\u4e09\u79cd\u503c(1,2,3) \u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\u3011 Name:\u4e58\u5ba2\u59d3\u540d \u3010\u820d\u53bb\u3011 Sex:\u4e58\u5ba2\u6027\u522b \u3010\u8f6c\u6362\u6210bool\u7279\u5f81\u3011 Age:\u4e58\u5ba2\u5e74\u9f84(\u6709\u7f3a\u5931) \u3010\u6570\u503c\u7279\u5f81\uff0c\u6dfb\u52a0\u201c\u5e74\u9f84\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 SibSp:\u4e58\u5ba2\u5144\u5f1f\u59d0\u59b9/\u914d\u5076\u7684\u4e2a\u6570(\u6574\u6570\u503c) \u3010\u6570\u503c\u7279\u5f81\u3011 Parch:\u4e58\u5ba2\u7236\u6bcd/\u5b69\u5b50\u7684\u4e2a\u6570(\u6574\u6570\u503c)\u3010\u6570\u503c\u7279\u5f81\u3011 Ticket:\u7968\u53f7(\u5b57\u7b26\u4e32)\u3010\u820d\u53bb\u3011 Fare:\u4e58\u5ba2\u6240\u6301\u7968\u7684\u4ef7\u683c(\u6d6e\u70b9\u6570\uff0c0-500\u4e0d\u7b49) \u3010\u6570\u503c\u7279\u5f81\u3011 Cabin:\u4e58\u5ba2\u6240\u5728\u8239\u8231(\u6709\u7f3a\u5931) \u3010\u6dfb\u52a0\u201c\u6240\u5728\u8239\u8231\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 Embarked:\u4e58\u5ba2\u767b\u8239\u6e2f\u53e3:S\u3001C\u3001Q(\u6709\u7f3a\u5931)\u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\uff0c\u56db\u7ef4\u5ea6 S,C,Q,nan\u3011 \u5229\u7528Pandas\u7684\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790EDA\uff08Exploratory Data Analysis\uff09\u3002 label\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Survived' ] . value_counts () . plot ( kind = 'bar' , figsize = ( 12 , 8 ), fontsize = 15 , rot = 0 ) ax . set_ylabel ( 'Counts' , fontsize = 15 ) ax . set_xlabel ( 'Survived' , fontsize = 15 ) plt . show () \u5e74\u9f84\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Age' ] . plot ( kind = 'hist' , bins = 20 , color = 'purple' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . set_ylabel ( 'Frequency' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u5e74\u9f84\u548clabel\u7684\u76f8\u5173\u6027 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw . query ( 'Survived == 0' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) dftrain_raw . query ( 'Survived == 1' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . legend ([ 'Survived==0' , 'Survived==1' ], fontsize = 12 ) ax . set_ylabel ( 'Density' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u4e0b\u9762\u4e3a\u6b63\u5f0f\u7684\u6570\u636e\u9884\u5904\u7406 def preprocessing ( dfdata ): dfresult = pd . DataFrame () #Pclass dfPclass = pd . get_dummies ( dfdata [ 'Pclass' ]) dfPclass . columns = [ 'Pclass_' + str ( x ) for x in dfPclass . columns ] dfresult = pd . concat ([ dfresult , dfPclass ], axis = 1 ) #Sex dfSex = pd . get_dummies ( dfdata [ 'Sex' ]) dfresult = pd . concat ([ dfresult , dfSex ], axis = 1 ) #Age dfresult [ 'Age' ] = dfdata [ 'Age' ] . fillna ( 0 ) dfresult [ 'Age_null' ] = pd . isna ( dfdata [ 'Age' ]) . astype ( 'int32' ) #SibSp,Parch,Fare dfresult [ 'SibSp' ] = dfdata [ 'SibSp' ] dfresult [ 'Parch' ] = dfdata [ 'Parch' ] dfresult [ 'Fare' ] = dfdata [ 'Fare' ] #Carbin dfresult [ 'Cabin_null' ] = pd . isna ( dfdata [ 'Cabin' ]) . astype ( 'int32' ) #Embarked dfEmbarked = pd . get_dummies ( dfdata [ 'Embarked' ], dummy_na = True ) dfEmbarked . columns = [ 'Embarked_' + str ( x ) for x in dfEmbarked . columns ] dfresult = pd . concat ([ dfresult , dfEmbarked ], axis = 1 ) return ( dfresult ) x_train = preprocessing ( dftrain_raw ) y_train = dftrain_raw [ 'Survived' ] . values x_test = preprocessing ( dftest_raw ) y_test = dftest_raw [ 'Survived' ] . values print ( \"x_train.shape =\" , x_train . shape ) print ( \"x_test.shape =\" , x_test . shape ) x_train.shape = (712, 15) x_test.shape = (179, 15)","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u6700\u7b80\u5355\u7684Sequential\uff0c\u6309\u5c42\u987a\u5e8f\u6a21\u578b\u3002 tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 20 , activation = 'relu' , input_shape = ( 15 ,))) model . add ( layers . Dense ( 10 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 20) 320 _________________________________________________________________ dense_1 (Dense) (None, 10) 210 _________________________________________________________________ dense_2 (Dense) (None, 1) 11 ================================================================= Total params: 541 Trainable params: 541 Non-trainable params: 0 _________________________________________________________________","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"\u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u9009\u62e9\u6700\u5e38\u7528\u4e5f\u6700\u7b80\u5355\u7684\u5185\u7f6efit\u65b9\u6cd5\u3002 # \u4e8c\u5206\u7c7b\u95ee\u9898\u9009\u62e9\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ]) history = model . fit ( x_train , y_train , batch_size = 64 , epochs = 30 , validation_split = 0.2 #\u5206\u5272\u4e00\u90e8\u5206\u8bad\u7ec3\u6570\u636e\u7528\u4e8e\u9a8c\u8bc1 ) Train on 569 samples, validate on 143 samples Epoch 1/30 569/569 [==============================] - 1s 2ms/sample - loss: 3.5841 - AUC: 0.4079 - val_loss: 3.4429 - val_AUC: 0.4129 Epoch 2/30 569/569 [==============================] - 0s 102us/sample - loss: 2.6093 - AUC: 0.3967 - val_loss: 2.4886 - val_AUC: 0.4139 Epoch 3/30 569/569 [==============================] - 0s 68us/sample - loss: 1.8375 - AUC: 0.4003 - val_loss: 1.7383 - val_AUC: 0.4223 Epoch 4/30 569/569 [==============================] - 0s 83us/sample - loss: 1.2545 - AUC: 0.4390 - val_loss: 1.1936 - val_AUC: 0.4765 Epoch 5/30 569/569 [==============================] - ETA: 0s - loss: 1.4435 - AUC: 0.375 - 0s 90us/sample - loss: 0.9141 - AUC: 0.5192 - val_loss: 0.8274 - val_AUC: 0.5584 Epoch 6/30 569/569 [==============================] - 0s 110us/sample - loss: 0.7052 - AUC: 0.6290 - val_loss: 0.6596 - val_AUC: 0.6880 Epoch 7/30 569/569 [==============================] - 0s 90us/sample - loss: 0.6410 - AUC: 0.7086 - val_loss: 0.6519 - val_AUC: 0.6845 Epoch 8/30 569/569 [==============================] - 0s 93us/sample - loss: 0.6246 - AUC: 0.7080 - val_loss: 0.6480 - val_AUC: 0.6846 Epoch 9/30 569/569 [==============================] - 0s 73us/sample - loss: 0.6088 - AUC: 0.7113 - val_loss: 0.6497 - val_AUC: 0.6838 Epoch 10/30 569/569 [==============================] - 0s 79us/sample - loss: 0.6051 - AUC: 0.7117 - val_loss: 0.6454 - val_AUC: 0.6873 Epoch 11/30 569/569 [==============================] - 0s 96us/sample - loss: 0.5972 - AUC: 0.7218 - val_loss: 0.6369 - val_AUC: 0.6888 Epoch 12/30 569/569 [==============================] - 0s 92us/sample - loss: 0.5918 - AUC: 0.7294 - val_loss: 0.6330 - val_AUC: 0.6908 Epoch 13/30 569/569 [==============================] - 0s 75us/sample - loss: 0.5864 - AUC: 0.7363 - val_loss: 0.6281 - val_AUC: 0.6948 Epoch 14/30 569/569 [==============================] - 0s 104us/sample - loss: 0.5832 - AUC: 0.7426 - val_loss: 0.6240 - val_AUC: 0.7030 Epoch 15/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5777 - AUC: 0.7507 - val_loss: 0.6200 - val_AUC: 0.7066 Epoch 16/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5726 - AUC: 0.7569 - val_loss: 0.6155 - val_AUC: 0.7132 Epoch 17/30 569/569 [==============================] - 0s 99us/sample - loss: 0.5674 - AUC: 0.7643 - val_loss: 0.6070 - val_AUC: 0.7255 Epoch 18/30 569/569 [==============================] - 0s 97us/sample - loss: 0.5631 - AUC: 0.7721 - val_loss: 0.6061 - val_AUC: 0.7305 Epoch 19/30 569/569 [==============================] - 0s 73us/sample - loss: 0.5580 - AUC: 0.7792 - val_loss: 0.6027 - val_AUC: 0.7332 Epoch 20/30 569/569 [==============================] - 0s 85us/sample - loss: 0.5533 - AUC: 0.7861 - val_loss: 0.5997 - val_AUC: 0.7366 Epoch 21/30 569/569 [==============================] - 0s 87us/sample - loss: 0.5497 - AUC: 0.7926 - val_loss: 0.5961 - val_AUC: 0.7433 Epoch 22/30 569/569 [==============================] - 0s 101us/sample - loss: 0.5454 - AUC: 0.7987 - val_loss: 0.5943 - val_AUC: 0.7438 Epoch 23/30 569/569 [==============================] - 0s 100us/sample - loss: 0.5398 - AUC: 0.8057 - val_loss: 0.5926 - val_AUC: 0.7492 Epoch 24/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5328 - AUC: 0.8122 - val_loss: 0.5912 - val_AUC: 0.7493 Epoch 25/30 569/569 [==============================] - 0s 86us/sample - loss: 0.5283 - AUC: 0.8147 - val_loss: 0.5902 - val_AUC: 0.7509 Epoch 26/30 569/569 [==============================] - 0s 67us/sample - loss: 0.5246 - AUC: 0.8196 - val_loss: 0.5845 - val_AUC: 0.7552 Epoch 27/30 569/569 [==============================] - 0s 72us/sample - loss: 0.5205 - AUC: 0.8271 - val_loss: 0.5837 - val_AUC: 0.7584 Epoch 28/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5144 - AUC: 0.8302 - val_loss: 0.5848 - val_AUC: 0.7561 Epoch 29/30 569/569 [==============================] - 0s 77us/sample - loss: 0.5099 - AUC: 0.8326 - val_loss: 0.5809 - val_AUC: 0.7583 Epoch 30/30 569/569 [==============================] - 0s 80us/sample - loss: 0.5071 - AUC: 0.8349 - val_loss: 0.5816 - val_AUC: 0.7605","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"\u6211\u4eec\u9996\u5148\u8bc4\u4f30\u4e00\u4e0b\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\u3002 % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"AUC\" ) \u6211\u4eec\u518d\u770b\u4e00\u4e0b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6548\u679c. model . evaluate ( x = x_test , y = y_test ) [0.5191367897907448, 0.8122605]","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"#\u9884\u6d4b\u6982\u7387 model . predict ( x_test [ 0 : 10 ]) #model(tf.constant(x_test[0:10].values,dtype = tf.float32)) #\u7b49\u4ef7\u5199\u6cd5 array([[0.26501188], [0.40970832], [0.44285864], [0.78408605], [0.47650957], [0.43849158], [0.27426785], [0.5962582 ], [0.59476686], [0.17882936]], dtype=float32) #\u9884\u6d4b\u7c7b\u522b model . predict_classes ( x_test [ 0 : 10 ]) array([[0], [0], [0], [1], [0], [0], [0], [1], [1], [0]], dtype=int32)","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u53ef\u4ee5\u4f7f\u7528Keras\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u3002\u524d\u8005\u4ec5\u4ec5\u9002\u5408\u4f7f\u7528Python\u73af\u5883\u6062\u590d\u6a21\u578b\uff0c\u540e\u8005\u5219\u53ef\u4ee5\u8de8\u5e73\u53f0\u8fdb\u884c\u6a21\u578b\u90e8\u7f72\u3002 \u63a8\u8350\u4f7f\u7528\u540e\u4e00\u79cd\u65b9\u5f0f\u8fdb\u884c\u4fdd\u5b58\u3002 1\uff0cKeras\u65b9\u5f0f\u4fdd\u5b58 # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u53ca\u6743\u91cd model . save ( '../../data/keras_model.h5' ) del model #\u5220\u9664\u73b0\u6709\u6a21\u578b # identical to the previous one model = models . load_model ( '../../data/keras_model.h5' ) model . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784 json_str = model . to_json () # \u6062\u590d\u6a21\u578b\u7ed3\u6784 model_json = models . model_from_json ( json_str ) #\u4fdd\u5b58\u6a21\u578b\u6743\u91cd model . save_weights ( '../../data/keras_model_weight.h5' ) # \u6062\u590d\u6a21\u578b\u7ed3\u6784 model_json = models . model_from_json ( json_str ) model_json . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ] ) # \u52a0\u8f7d\u6743\u91cd model_json . load_weights ( '../../data/keras_model_weight.h5' ) model_json . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] 2\uff0cTensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58 # \u4fdd\u5b58\u6743\u91cd\uff0c\u8be5\u65b9\u5f0f\u4ec5\u4ec5\u4fdd\u5b58\u6743\u91cd\u5f20\u91cf model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u4e0e\u6a21\u578b\u53c2\u6570\u5230\u6587\u4ef6,\u8be5\u65b9\u5f0f\u4fdd\u5b58\u7684\u6a21\u578b\u5177\u6709\u8de8\u5e73\u53f0\u6027\u4fbf\u4e8e\u90e8\u7f72 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( x_test , y_test ) [0.5191365896656527, 0.8122605] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # \u4e00\uff0c\u51c6\u5907\u6570\u636e # cifar2\u6570\u636e\u96c6\u4e3acifar10\u6570\u636e\u96c6\u7684\u5b50\u96c6\uff0c\u53ea\u5305\u62ec\u524d\u4e24\u79cd\u7c7b\u522bairplane\u548cautomobile\u3002 \u8bad\u7ec3\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54045000\u5f20\uff0c\u6d4b\u8bd5\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54041000\u5f20\u3002 cifar2\u4efb\u52a1\u7684\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u6765\u5bf9\u98de\u673aairplane\u548c\u673a\u52a8\u8f66automobile\u4e24\u79cd\u56fe\u7247\u8fdb\u884c\u5206\u7c7b\u3002 \u6211\u4eec\u51c6\u5907\u7684Cifar2\u6570\u636e\u96c6\u7684\u6587\u4ef6\u7ed3\u6784\u5982\u4e0b\u6240\u793a\u3002 \u5728tensorflow\u4e2d\u51c6\u5907\u56fe\u7247\u6570\u636e\u7684\u5e38\u7528\u65b9\u6848\u6709\u4e24\u79cd\uff0c\u7b2c\u4e00\u79cd\u662f\u4f7f\u7528tf.keras\u4e2d\u7684ImageDataGenerator\u5de5\u5177\u6784\u5efa\u56fe\u7247\u6570\u636e\u751f\u6210\u5668\u3002 \u7b2c\u4e8c\u79cd\u662f\u4f7f\u7528tf.data.Dataset\u642d\u914dtf.image\u4e2d\u7684\u4e00\u4e9b\u56fe\u7247\u5904\u7406\u65b9\u6cd5\u6784\u5efa\u6570\u636e\u7ba1\u9053\u3002 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u66f4\u4e3a\u7b80\u5355\uff0c\u5176\u4f7f\u7528\u8303\u4f8b\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u6587\u7ae0\u3002 https://zhuanlan.zhihu.com/p/67466552 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662fTensorFlow\u7684\u539f\u751f\u65b9\u6cd5\uff0c\u66f4\u52a0\u7075\u6d3b\uff0c\u4f7f\u7528\u5f97\u5f53\u7684\u8bdd\u4e5f\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002 \u6211\u4eec\u6b64\u5904\u4ecb\u7ecd\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u3002 import tensorflow as tf from tensorflow.keras import datasets , layers , models BATCH_SIZE = 100 def load_image ( img_path , size = ( 32 , 32 )): label = tf . constant ( 1 , tf . int8 ) if tf . strings . regex_full_match ( img_path , \".*automobile.*\" ) \\ else tf . constant ( 0 , tf . int8 ) img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , size ) / 255.0 return ( img , label ) #\u4f7f\u7528\u5e76\u884c\u5316\u9884\u5904\u7406num_parallel_calls \u548c\u9884\u5b58\u6570\u636eprefetch\u6765\u63d0\u5347\u6027\u80fd ds_train = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . Dataset . list_files ( \"../../data/cifar2/test/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i ,( img , label ) in enumerate ( ds_train . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () for x , y in ds_train . take ( 1 ): print ( x . shape , y . shape ) (100, 32, 32, 3) (100,) \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u6a21\u578b\u3002 tf . keras . backend . clear_session () #\u6e05\u7a7a\u4f1a\u8bdd inputs = layers . Input ( shape = ( 32 , 32 , 3 )) x = layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ))( inputs ) x = layers . MaxPool2D ()( x ) x = layers . Conv2D ( 64 , kernel_size = ( 5 , 5 ))( x ) x = layers . MaxPool2D ()( x ) x = layers . Dropout ( rate = 0.1 )( x ) x = layers . Flatten ()( x ) x = layers . Dense ( 32 , activation = 'relu' )( x ) outputs = layers . Dense ( 1 , activation = 'sigmoid' )( x ) model = models . Model ( inputs = inputs , outputs = outputs ) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 32, 32, 3)] 0 _________________________________________________________________ conv2d (Conv2D) (None, 30, 30, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 15, 15, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 11, 11, 64) 51264 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ dropout (Dropout) (None, 5, 5, 64) 0 _________________________________________________________________ flatten (Flatten) (None, 1600) 0 _________________________________________________________________ dense (Dense) (None, 32) 51232 _________________________________________________________________ dense_1 (Dense) (None, 1) 33 ================================================================= Total params: 103,425 Trainable params: 103,425 Non-trainable params: 0 _________________________________________________________________ \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # \u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u9009\u62e9\u6700\u5e38\u7528\u4e5f\u6700\u7b80\u5355\u7684\u5185\u7f6efit\u65b9\u6cd5\u3002 import datetime import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## \u5728 Python3 \u4e0b\u5efa\u8bae\u4f7f\u7528 pathlib \u4fee\u6b63\u5404\u64cd\u4f5c\u7cfb\u7edf\u7684\u8def\u5f84 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ), loss = tf . keras . losses . binary_crossentropy , metrics = [ \"accuracy\" ] ) history = model . fit ( ds_train , epochs = 10 , validation_data = ds_test , callbacks = [ tensorboard_callback ], workers = 4 ) Train for 100 steps, validate for 20 steps Epoch 1/10 100/100 [==============================] - 16s 156ms/step - loss: 0.4830 - accuracy: 0.7697 - val_loss: 0.3396 - val_accuracy: 0.8475 Epoch 2/10 100/100 [==============================] - 14s 142ms/step - loss: 0.3437 - accuracy: 0.8469 - val_loss: 0.2997 - val_accuracy: 0.8680 Epoch 3/10 100/100 [==============================] - 13s 131ms/step - loss: 0.2871 - accuracy: 0.8777 - val_loss: 0.2390 - val_accuracy: 0.9015 Epoch 4/10 100/100 [==============================] - 12s 117ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.2005 - val_accuracy: 0.9195 Epoch 5/10 100/100 [==============================] - 13s 130ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9180 Epoch 6/10 100/100 [==============================] - 14s 136ms/step - loss: 0.1737 - accuracy: 0.9323 - val_loss: 0.1723 - val_accuracy: 0.9275 Epoch 7/10 100/100 [==============================] - 14s 139ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1670 - val_accuracy: 0.9310 Epoch 8/10 100/100 [==============================] - 13s 134ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9340 Epoch 9/10 100/100 [==============================] - 14s 137ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1581 - val_accuracy: 0.9340 Epoch 10/10 100/100 [==============================] - 14s 142ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9345 \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # % load_ext tensorboard #%tensorboard --logdir ../../data/keras_model from tensorboard import notebook notebook . list () #\u5728tensorboard\u4e2d\u67e5\u770b\u6a21\u578b notebook . start ( \"--logdir ../../data/keras_model\" ) import pandas as pd dfhistory = pd . DataFrame ( history . history ) dfhistory . index = range ( 1 , len ( dfhistory ) + 1 ) dfhistory . index . name = 'epoch' dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"accuracy\" ) #\u53ef\u4ee5\u4f7f\u7528evaluate\u5bf9\u6570\u636e\u8fdb\u884c\u8bc4\u4f30 val_loss , val_accuracy = model . evaluate ( ds_test , workers = 4 ) print ( val_loss , val_accuracy ) 0.16139143370091916 0.9345 \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # \u53ef\u4ee5\u4f7f\u7528model.predict(ds_test)\u8fdb\u884c\u9884\u6d4b\u3002 \u4e5f\u53ef\u4ee5\u4f7f\u7528model.predict_on_batch(x_test)\u5bf9\u4e00\u4e2a\u6279\u91cf\u8fdb\u884c\u9884\u6d4b\u3002 model . predict ( ds_test ) array([[9.9996173e-01], [9.5104784e-01], [2.8648047e-04], ..., [1.1484033e-03], [3.5589080e-02], [9.8537153e-01]], dtype=float32) for x , y in ds_test . take ( 1 ): print ( model . predict_on_batch ( x [ 0 : 20 ])) tf.Tensor( [[3.8065155e-05] [8.8236779e-01] [9.1433197e-01] [9.9921846e-01] [6.4052093e-01] [4.9970779e-03] [2.6735585e-04] [9.9842811e-01] [7.9198682e-01] [7.4823302e-01] [8.7208226e-03] [9.3951421e-03] [9.9790359e-01] [9.9998581e-01] [2.1642199e-05] [1.7915063e-02] [2.5839690e-02] [9.7538447e-01] [9.7393811e-01] [9.7333014e-01]], shape=(20, 1), dtype=float32) \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u63a8\u8350\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u3002 # \u4fdd\u5b58\u6743\u91cd\uff0c\u8be5\u65b9\u5f0f\u4ec5\u4ec5\u4fdd\u5b58\u6743\u91cd\u5f20\u91cf model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u4e0e\u6a21\u578b\u53c2\u6570\u5230\u6587\u4ef6,\u8be5\u65b9\u5f0f\u4fdd\u5b58\u7684\u6a21\u578b\u5177\u6709\u8de8\u5e73\u53f0\u6027\u4fbf\u4e8e\u90e8\u7f72 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( ds_test ) [0.16139124035835267, 0.9345] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-2\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"","title":"1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"cifar2\u6570\u636e\u96c6\u4e3acifar10\u6570\u636e\u96c6\u7684\u5b50\u96c6\uff0c\u53ea\u5305\u62ec\u524d\u4e24\u79cd\u7c7b\u522bairplane\u548cautomobile\u3002 \u8bad\u7ec3\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54045000\u5f20\uff0c\u6d4b\u8bd5\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54041000\u5f20\u3002 cifar2\u4efb\u52a1\u7684\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u6765\u5bf9\u98de\u673aairplane\u548c\u673a\u52a8\u8f66automobile\u4e24\u79cd\u56fe\u7247\u8fdb\u884c\u5206\u7c7b\u3002 \u6211\u4eec\u51c6\u5907\u7684Cifar2\u6570\u636e\u96c6\u7684\u6587\u4ef6\u7ed3\u6784\u5982\u4e0b\u6240\u793a\u3002 \u5728tensorflow\u4e2d\u51c6\u5907\u56fe\u7247\u6570\u636e\u7684\u5e38\u7528\u65b9\u6848\u6709\u4e24\u79cd\uff0c\u7b2c\u4e00\u79cd\u662f\u4f7f\u7528tf.keras\u4e2d\u7684ImageDataGenerator\u5de5\u5177\u6784\u5efa\u56fe\u7247\u6570\u636e\u751f\u6210\u5668\u3002 \u7b2c\u4e8c\u79cd\u662f\u4f7f\u7528tf.data.Dataset\u642d\u914dtf.image\u4e2d\u7684\u4e00\u4e9b\u56fe\u7247\u5904\u7406\u65b9\u6cd5\u6784\u5efa\u6570\u636e\u7ba1\u9053\u3002 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u66f4\u4e3a\u7b80\u5355\uff0c\u5176\u4f7f\u7528\u8303\u4f8b\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u6587\u7ae0\u3002 https://zhuanlan.zhihu.com/p/67466552 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662fTensorFlow\u7684\u539f\u751f\u65b9\u6cd5\uff0c\u66f4\u52a0\u7075\u6d3b\uff0c\u4f7f\u7528\u5f97\u5f53\u7684\u8bdd\u4e5f\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002 \u6211\u4eec\u6b64\u5904\u4ecb\u7ecd\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u3002 import tensorflow as tf from tensorflow.keras import datasets , layers , models BATCH_SIZE = 100 def load_image ( img_path , size = ( 32 , 32 )): label = tf . constant ( 1 , tf . int8 ) if tf . strings . regex_full_match ( img_path , \".*automobile.*\" ) \\ else tf . constant ( 0 , tf . int8 ) img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , size ) / 255.0 return ( img , label ) #\u4f7f\u7528\u5e76\u884c\u5316\u9884\u5904\u7406num_parallel_calls \u548c\u9884\u5b58\u6570\u636eprefetch\u6765\u63d0\u5347\u6027\u80fd ds_train = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . Dataset . list_files ( \"../../data/cifar2/test/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i ,( img , label ) in enumerate ( ds_train . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () for x , y in ds_train . take ( 1 ): print ( x . shape , y . shape ) (100, 32, 32, 3) (100,)","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u6a21\u578b\u3002 tf . keras . backend . clear_session () #\u6e05\u7a7a\u4f1a\u8bdd inputs = layers . Input ( shape = ( 32 , 32 , 3 )) x = layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ))( inputs ) x = layers . MaxPool2D ()( x ) x = layers . Conv2D ( 64 , kernel_size = ( 5 , 5 ))( x ) x = layers . MaxPool2D ()( x ) x = layers . Dropout ( rate = 0.1 )( x ) x = layers . Flatten ()( x ) x = layers . Dense ( 32 , activation = 'relu' )( x ) outputs = layers . Dense ( 1 , activation = 'sigmoid' )( x ) model = models . Model ( inputs = inputs , outputs = outputs ) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 32, 32, 3)] 0 _________________________________________________________________ conv2d (Conv2D) (None, 30, 30, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 15, 15, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 11, 11, 64) 51264 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ dropout (Dropout) (None, 5, 5, 64) 0 _________________________________________________________________ flatten (Flatten) (None, 1600) 0 _________________________________________________________________ dense (Dense) (None, 32) 51232 _________________________________________________________________ dense_1 (Dense) (None, 1) 33 ================================================================= Total params: 103,425 Trainable params: 103,425 Non-trainable params: 0 _________________________________________________________________","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"\u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u9009\u62e9\u6700\u5e38\u7528\u4e5f\u6700\u7b80\u5355\u7684\u5185\u7f6efit\u65b9\u6cd5\u3002 import datetime import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## \u5728 Python3 \u4e0b\u5efa\u8bae\u4f7f\u7528 pathlib \u4fee\u6b63\u5404\u64cd\u4f5c\u7cfb\u7edf\u7684\u8def\u5f84 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ), loss = tf . keras . losses . binary_crossentropy , metrics = [ \"accuracy\" ] ) history = model . fit ( ds_train , epochs = 10 , validation_data = ds_test , callbacks = [ tensorboard_callback ], workers = 4 ) Train for 100 steps, validate for 20 steps Epoch 1/10 100/100 [==============================] - 16s 156ms/step - loss: 0.4830 - accuracy: 0.7697 - val_loss: 0.3396 - val_accuracy: 0.8475 Epoch 2/10 100/100 [==============================] - 14s 142ms/step - loss: 0.3437 - accuracy: 0.8469 - val_loss: 0.2997 - val_accuracy: 0.8680 Epoch 3/10 100/100 [==============================] - 13s 131ms/step - loss: 0.2871 - accuracy: 0.8777 - val_loss: 0.2390 - val_accuracy: 0.9015 Epoch 4/10 100/100 [==============================] - 12s 117ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.2005 - val_accuracy: 0.9195 Epoch 5/10 100/100 [==============================] - 13s 130ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9180 Epoch 6/10 100/100 [==============================] - 14s 136ms/step - loss: 0.1737 - accuracy: 0.9323 - val_loss: 0.1723 - val_accuracy: 0.9275 Epoch 7/10 100/100 [==============================] - 14s 139ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1670 - val_accuracy: 0.9310 Epoch 8/10 100/100 [==============================] - 13s 134ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9340 Epoch 9/10 100/100 [==============================] - 14s 137ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1581 - val_accuracy: 0.9340 Epoch 10/10 100/100 [==============================] - 14s 142ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9345","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"% load_ext tensorboard #%tensorboard --logdir ../../data/keras_model from tensorboard import notebook notebook . list () #\u5728tensorboard\u4e2d\u67e5\u770b\u6a21\u578b notebook . start ( \"--logdir ../../data/keras_model\" ) import pandas as pd dfhistory = pd . DataFrame ( history . history ) dfhistory . index = range ( 1 , len ( dfhistory ) + 1 ) dfhistory . index . name = 'epoch' dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"accuracy\" ) #\u53ef\u4ee5\u4f7f\u7528evaluate\u5bf9\u6570\u636e\u8fdb\u884c\u8bc4\u4f30 val_loss , val_accuracy = model . evaluate ( ds_test , workers = 4 ) print ( val_loss , val_accuracy ) 0.16139143370091916 0.9345","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"\u53ef\u4ee5\u4f7f\u7528model.predict(ds_test)\u8fdb\u884c\u9884\u6d4b\u3002 \u4e5f\u53ef\u4ee5\u4f7f\u7528model.predict_on_batch(x_test)\u5bf9\u4e00\u4e2a\u6279\u91cf\u8fdb\u884c\u9884\u6d4b\u3002 model . predict ( ds_test ) array([[9.9996173e-01], [9.5104784e-01], [2.8648047e-04], ..., [1.1484033e-03], [3.5589080e-02], [9.8537153e-01]], dtype=float32) for x , y in ds_test . take ( 1 ): print ( model . predict_on_batch ( x [ 0 : 20 ])) tf.Tensor( [[3.8065155e-05] [8.8236779e-01] [9.1433197e-01] [9.9921846e-01] [6.4052093e-01] [4.9970779e-03] [2.6735585e-04] [9.9842811e-01] [7.9198682e-01] [7.4823302e-01] [8.7208226e-03] [9.3951421e-03] [9.9790359e-01] [9.9998581e-01] [2.1642199e-05] [1.7915063e-02] [2.5839690e-02] [9.7538447e-01] [9.7393811e-01] [9.7333014e-01]], shape=(20, 1), dtype=float32)","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u63a8\u8350\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u3002 # \u4fdd\u5b58\u6743\u91cd\uff0c\u8be5\u65b9\u5f0f\u4ec5\u4ec5\u4fdd\u5b58\u6743\u91cd\u5f20\u91cf model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # \u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u4e0e\u6a21\u578b\u53c2\u6570\u5230\u6587\u4ef6,\u8be5\u65b9\u5f0f\u4fdd\u5b58\u7684\u6a21\u578b\u5177\u6709\u8de8\u5e73\u53f0\u6027\u4fbf\u4e8e\u90e8\u7f72 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( ds_test ) [0.16139124035835267, 0.9345] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # \u4e00\uff0c\u51c6\u5907\u6570\u636e # imdb\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u7535\u5f71\u8bc4\u8bba\u7684\u6587\u672c\u5185\u5bb9\u9884\u6d4b\u8bc4\u8bba\u7684\u60c5\u611f\u6807\u7b7e\u3002 \u8bad\u7ec3\u96c6\u670920000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u6d4b\u8bd5\u96c6\u67095000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u5176\u4e2d\u6b63\u9762\u8bc4\u8bba\u548c\u8d1f\u9762\u8bc4\u8bba\u90fd\u5404\u5360\u4e00\u534a\u3002 \u6587\u672c\u6570\u636e\u9884\u5904\u7406\u8f83\u4e3a\u7e41\u7410\uff0c\u5305\u62ec\u4e2d\u6587\u5207\u8bcd\uff08\u672c\u793a\u4f8b\u4e0d\u6d89\u53ca\uff09\uff0c\u6784\u5efa\u8bcd\u5178\uff0c\u7f16\u7801\u8f6c\u6362\uff0c\u5e8f\u5217\u586b\u5145\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 \u5728tensorflow\u4e2d\u5b8c\u6210\u6587\u672c\u6570\u636e\u9884\u5904\u7406\u7684\u5e38\u7528\u65b9\u6848\u6709\u4e24\u79cd\uff0c\u7b2c\u4e00\u79cd\u662f\u5229\u7528tf.keras.preprocessing\u4e2d\u7684Tokenizer\u8bcd\u5178\u6784\u5efa\u5de5\u5177\u548ctf.keras.utils.Sequence\u6784\u5efa\u6587\u672c\u6570\u636e\u751f\u6210\u5668\u7ba1\u9053\u3002 \u7b2c\u4e8c\u79cd\u662f\u4f7f\u7528tf.data.Dataset\u642d\u914d.keras.layers.experimental.preprocessing.TextVectorization\u9884\u5904\u7406\u5c42\u3002 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u8f83\u4e3a\u590d\u6742\uff0c\u5176\u4f7f\u7528\u8303\u4f8b\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u6587\u7ae0\u3002 https://zhuanlan.zhihu.com/p/67697840 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u4e3aTensorFlow\u539f\u751f\u65b9\u5f0f\uff0c\u76f8\u5bf9\u4e5f\u66f4\u52a0\u7b80\u5355\u4e00\u4e9b\u3002 \u6211\u4eec\u6b64\u5904\u4ecb\u7ecd\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u3002 import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , preprocessing , optimizers , losses , metrics from tensorflow.keras.layers.experimental.preprocessing import TextVectorization import re , string train_data_path = \"../../data/imdb/train.csv\" test_data_path = \"../../data/imdb/test.csv\" MAX_WORDS = 10000 # \u4ec5\u8003\u8651\u6700\u9ad8\u9891\u768410000\u4e2a\u8bcd MAX_LEN = 200 # \u6bcf\u4e2a\u6837\u672c\u4fdd\u7559200\u4e2a\u8bcd\u7684\u957f\u5ea6 BATCH_SIZE = 20 #\u6784\u5efa\u7ba1\u9053 def split_line ( line ): arr = tf . strings . split ( line , \" \\t \" ) label = tf . expand_dims ( tf . cast ( tf . strings . to_number ( arr [ 0 ]), tf . int32 ), axis = 0 ) text = tf . expand_dims ( arr [ 1 ], axis = 0 ) return ( text , label ) ds_train_raw = tf . data . TextLineDataset ( filenames = [ train_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test_raw = tf . data . TextLineDataset ( filenames = [ test_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) #\u6784\u5efa\u8bcd\u5178 def clean_text ( text ): lowercase = tf . strings . lower ( text ) stripped_html = tf . strings . regex_replace ( lowercase , '<br />' , ' ' ) cleaned_punctuation = tf . strings . regex_replace ( stripped_html , '[ %s ]' % re . escape ( string . punctuation ), '' ) return cleaned_punctuation vectorize_layer = TextVectorization ( standardize = clean_text , split = 'whitespace' , max_tokens = MAX_WORDS - 1 , #\u6709\u4e00\u4e2a\u7559\u7ed9\u5360\u4f4d\u7b26 output_mode = 'int' , output_sequence_length = MAX_LEN ) ds_text = ds_train_raw . map ( lambda text , label : text ) vectorize_layer . adapt ( ds_text ) print ( vectorize_layer . get_vocabulary ()[ 0 : 100 ]) #\u5355\u8bcd\u7f16\u7801 ds_train = ds_train_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = ds_test_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) [b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters'] \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 # \u6f14\u793a\u81ea\u5b9a\u4e49\u6a21\u578b\u8303\u4f8b\uff0c\u5b9e\u9645\u4e0a\u5e94\u8be5\u4f18\u5148\u4f7f\u7528Sequential\u6216\u8005\u51fd\u6570\u5f0fAPI tf . keras . backend . clear_session () class CnnModel ( models . Model ): def __init__ ( self ): super ( CnnModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN ) self . conv_1 = layers . Conv1D ( 16 , kernel_size = 5 , name = \"conv_1\" , activation = \"relu\" ) self . pool_1 = layers . MaxPool1D ( name = \"pool_1\" ) self . conv_2 = layers . Conv1D ( 128 , kernel_size = 2 , name = \"conv_2\" , activation = \"relu\" ) self . pool_2 = layers . MaxPool1D ( name = \"pool_2\" ) self . flatten = layers . Flatten () self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( CnnModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . conv_1 ( x ) x = self . pool_1 ( x ) x = self . conv_2 ( x ) x = self . pool_2 ( x ) x = self . flatten ( x ) x = self . dense ( x ) return ( x ) # \u7528\u4e8e\u663e\u793aOutput Shape def summary ( self ): x_input = layers . Input ( shape = MAX_LEN ) output = self . call ( x_input ) model = tf . keras . Model ( inputs = x_input , outputs = output ) model . summary () model = CnnModel () model . build ( input_shape = ( None , MAX_LEN )) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 200)] 0 _________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 _________________________________________________________________ conv_1 (Conv1D) (None, 196, 16) 576 _________________________________________________________________ pool_1 (MaxPooling1D) (None, 98, 16) 0 _________________________________________________________________ conv_2 (Conv1D) (None, 97, 128) 4224 _________________________________________________________________ pool_2 (MaxPooling1D) (None, 48, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6144) 0 _________________________________________________________________ dense (Dense) (None, 1) 6145 ================================================================= Total params: 80,945 Trainable params: 80,945 Non-trainable params: 0 _________________________________________________________________ \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # \u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u901a\u8fc7\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u8bad\u7ec3\u6a21\u578b\u3002 #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) optimizer = optimizers . Nadam () loss_func = losses . BinaryCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features , training = False ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) #\u6b64\u5904logs\u6a21\u677f\u9700\u8981\u6839\u636emetric\u5177\u4f53\u60c5\u51b5\u4fee\u6539 logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , epochs = 6 ) ================================================================================13:54:08 Epoch=1,Loss:0.442317516,Accuracy:0.7695,Valid Loss:0.323672801,Valid Accuracy:0.8614 ================================================================================13:54:20 Epoch=2,Loss:0.245737702,Accuracy:0.90215,Valid Loss:0.356488883,Valid Accuracy:0.8554 ================================================================================13:54:32 Epoch=3,Loss:0.17360799,Accuracy:0.93455,Valid Loss:0.361132562,Valid Accuracy:0.8674 ================================================================================13:54:44 Epoch=4,Loss:0.113476314,Accuracy:0.95975,Valid Loss:0.483677238,Valid Accuracy:0.856 ================================================================================13:54:57 Epoch=5,Loss:0.0698405355,Accuracy:0.9768,Valid Loss:0.607856631,Valid Accuracy:0.857 ================================================================================13:55:15 Epoch=6,Loss:0.0366807655,Accuracy:0.98825,Valid Loss:0.745884955,Valid Accuracy:0.854 \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # \u901a\u8fc7\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u8bad\u7ec3\u7684\u6a21\u578b\u6ca1\u6709\u7ecf\u8fc7\u7f16\u8bd1\uff0c\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528model.evaluate(ds_valid)\u65b9\u6cd5 def evaluate_model ( model , ds_valid ): for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Valid Loss: {} ,Valid Accuracy: {} ' tf . print ( tf . strings . format ( logs ,( valid_loss . result (), valid_metric . result ()))) valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () evaluate_model ( model , ds_test ) Valid Loss:0.745884418,Valid Accuracy:0.854 \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # \u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u65b9\u6cd5: model.predict(ds_test) model(x_test) model.call(x_test) model.predict_on_batch(x_test) \u63a8\u8350\u4f18\u5148\u4f7f\u7528model.predict(ds_test)\u65b9\u6cd5\uff0c\u65e2\u53ef\u4ee5\u5bf9Dataset\uff0c\u4e5f\u53ef\u4ee5\u5bf9Tensor\u4f7f\u7528\u3002 model . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) for x_test , _ in ds_test . take ( 1 ): print ( model ( x_test )) #\u4ee5\u4e0b\u65b9\u6cd5\u7b49\u4ef7\uff1a #print(model.call(x_test)) #print(model.predict_on_batch(x_test)) tf.Tensor( [[7.8648227e-01] [9.9999011e-01] [9.9944776e-01] [3.7153201e-09] [9.4462049e-01] [2.3522753e-04] [1.2044354e-04] [9.3752089e-07] [9.9996352e-01] [9.3435925e-01] [9.8746723e-01] [9.9908626e-01] [4.1563155e-08] [4.1808244e-03] [8.0184749e-05] [8.3910513e-01] [3.5167937e-05] [7.2113985e-01] [4.5228912e-03] [9.9942589e-01]], shape=(20, 1), dtype=float32) \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u63a8\u8350\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u3002 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-3\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"","title":"1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"imdb\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u7535\u5f71\u8bc4\u8bba\u7684\u6587\u672c\u5185\u5bb9\u9884\u6d4b\u8bc4\u8bba\u7684\u60c5\u611f\u6807\u7b7e\u3002 \u8bad\u7ec3\u96c6\u670920000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u6d4b\u8bd5\u96c6\u67095000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u5176\u4e2d\u6b63\u9762\u8bc4\u8bba\u548c\u8d1f\u9762\u8bc4\u8bba\u90fd\u5404\u5360\u4e00\u534a\u3002 \u6587\u672c\u6570\u636e\u9884\u5904\u7406\u8f83\u4e3a\u7e41\u7410\uff0c\u5305\u62ec\u4e2d\u6587\u5207\u8bcd\uff08\u672c\u793a\u4f8b\u4e0d\u6d89\u53ca\uff09\uff0c\u6784\u5efa\u8bcd\u5178\uff0c\u7f16\u7801\u8f6c\u6362\uff0c\u5e8f\u5217\u586b\u5145\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 \u5728tensorflow\u4e2d\u5b8c\u6210\u6587\u672c\u6570\u636e\u9884\u5904\u7406\u7684\u5e38\u7528\u65b9\u6848\u6709\u4e24\u79cd\uff0c\u7b2c\u4e00\u79cd\u662f\u5229\u7528tf.keras.preprocessing\u4e2d\u7684Tokenizer\u8bcd\u5178\u6784\u5efa\u5de5\u5177\u548ctf.keras.utils.Sequence\u6784\u5efa\u6587\u672c\u6570\u636e\u751f\u6210\u5668\u7ba1\u9053\u3002 \u7b2c\u4e8c\u79cd\u662f\u4f7f\u7528tf.data.Dataset\u642d\u914d.keras.layers.experimental.preprocessing.TextVectorization\u9884\u5904\u7406\u5c42\u3002 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u8f83\u4e3a\u590d\u6742\uff0c\u5176\u4f7f\u7528\u8303\u4f8b\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u6587\u7ae0\u3002 https://zhuanlan.zhihu.com/p/67697840 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u4e3aTensorFlow\u539f\u751f\u65b9\u5f0f\uff0c\u76f8\u5bf9\u4e5f\u66f4\u52a0\u7b80\u5355\u4e00\u4e9b\u3002 \u6211\u4eec\u6b64\u5904\u4ecb\u7ecd\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u3002 import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , preprocessing , optimizers , losses , metrics from tensorflow.keras.layers.experimental.preprocessing import TextVectorization import re , string train_data_path = \"../../data/imdb/train.csv\" test_data_path = \"../../data/imdb/test.csv\" MAX_WORDS = 10000 # \u4ec5\u8003\u8651\u6700\u9ad8\u9891\u768410000\u4e2a\u8bcd MAX_LEN = 200 # \u6bcf\u4e2a\u6837\u672c\u4fdd\u7559200\u4e2a\u8bcd\u7684\u957f\u5ea6 BATCH_SIZE = 20 #\u6784\u5efa\u7ba1\u9053 def split_line ( line ): arr = tf . strings . split ( line , \" \\t \" ) label = tf . expand_dims ( tf . cast ( tf . strings . to_number ( arr [ 0 ]), tf . int32 ), axis = 0 ) text = tf . expand_dims ( arr [ 1 ], axis = 0 ) return ( text , label ) ds_train_raw = tf . data . TextLineDataset ( filenames = [ train_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test_raw = tf . data . TextLineDataset ( filenames = [ test_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) #\u6784\u5efa\u8bcd\u5178 def clean_text ( text ): lowercase = tf . strings . lower ( text ) stripped_html = tf . strings . regex_replace ( lowercase , '<br />' , ' ' ) cleaned_punctuation = tf . strings . regex_replace ( stripped_html , '[ %s ]' % re . escape ( string . punctuation ), '' ) return cleaned_punctuation vectorize_layer = TextVectorization ( standardize = clean_text , split = 'whitespace' , max_tokens = MAX_WORDS - 1 , #\u6709\u4e00\u4e2a\u7559\u7ed9\u5360\u4f4d\u7b26 output_mode = 'int' , output_sequence_length = MAX_LEN ) ds_text = ds_train_raw . map ( lambda text , label : text ) vectorize_layer . adapt ( ds_text ) print ( vectorize_layer . get_vocabulary ()[ 0 : 100 ]) #\u5355\u8bcd\u7f16\u7801 ds_train = ds_train_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = ds_test_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) [b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters']","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 # \u6f14\u793a\u81ea\u5b9a\u4e49\u6a21\u578b\u8303\u4f8b\uff0c\u5b9e\u9645\u4e0a\u5e94\u8be5\u4f18\u5148\u4f7f\u7528Sequential\u6216\u8005\u51fd\u6570\u5f0fAPI tf . keras . backend . clear_session () class CnnModel ( models . Model ): def __init__ ( self ): super ( CnnModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN ) self . conv_1 = layers . Conv1D ( 16 , kernel_size = 5 , name = \"conv_1\" , activation = \"relu\" ) self . pool_1 = layers . MaxPool1D ( name = \"pool_1\" ) self . conv_2 = layers . Conv1D ( 128 , kernel_size = 2 , name = \"conv_2\" , activation = \"relu\" ) self . pool_2 = layers . MaxPool1D ( name = \"pool_2\" ) self . flatten = layers . Flatten () self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( CnnModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . conv_1 ( x ) x = self . pool_1 ( x ) x = self . conv_2 ( x ) x = self . pool_2 ( x ) x = self . flatten ( x ) x = self . dense ( x ) return ( x ) # \u7528\u4e8e\u663e\u793aOutput Shape def summary ( self ): x_input = layers . Input ( shape = MAX_LEN ) output = self . call ( x_input ) model = tf . keras . Model ( inputs = x_input , outputs = output ) model . summary () model = CnnModel () model . build ( input_shape = ( None , MAX_LEN )) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 200)] 0 _________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 _________________________________________________________________ conv_1 (Conv1D) (None, 196, 16) 576 _________________________________________________________________ pool_1 (MaxPooling1D) (None, 98, 16) 0 _________________________________________________________________ conv_2 (Conv1D) (None, 97, 128) 4224 _________________________________________________________________ pool_2 (MaxPooling1D) (None, 48, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6144) 0 _________________________________________________________________ dense (Dense) (None, 1) 6145 ================================================================= Total params: 80,945 Trainable params: 80,945 Non-trainable params: 0 _________________________________________________________________","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"\u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u901a\u8fc7\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u8bad\u7ec3\u6a21\u578b\u3002 #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) optimizer = optimizers . Nadam () loss_func = losses . BinaryCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features , training = False ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) #\u6b64\u5904logs\u6a21\u677f\u9700\u8981\u6839\u636emetric\u5177\u4f53\u60c5\u51b5\u4fee\u6539 logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , epochs = 6 ) ================================================================================13:54:08 Epoch=1,Loss:0.442317516,Accuracy:0.7695,Valid Loss:0.323672801,Valid Accuracy:0.8614 ================================================================================13:54:20 Epoch=2,Loss:0.245737702,Accuracy:0.90215,Valid Loss:0.356488883,Valid Accuracy:0.8554 ================================================================================13:54:32 Epoch=3,Loss:0.17360799,Accuracy:0.93455,Valid Loss:0.361132562,Valid Accuracy:0.8674 ================================================================================13:54:44 Epoch=4,Loss:0.113476314,Accuracy:0.95975,Valid Loss:0.483677238,Valid Accuracy:0.856 ================================================================================13:54:57 Epoch=5,Loss:0.0698405355,Accuracy:0.9768,Valid Loss:0.607856631,Valid Accuracy:0.857 ================================================================================13:55:15 Epoch=6,Loss:0.0366807655,Accuracy:0.98825,Valid Loss:0.745884955,Valid Accuracy:0.854","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"\u901a\u8fc7\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u8bad\u7ec3\u7684\u6a21\u578b\u6ca1\u6709\u7ecf\u8fc7\u7f16\u8bd1\uff0c\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528model.evaluate(ds_valid)\u65b9\u6cd5 def evaluate_model ( model , ds_valid ): for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Valid Loss: {} ,Valid Accuracy: {} ' tf . print ( tf . strings . format ( logs ,( valid_loss . result (), valid_metric . result ()))) valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () evaluate_model ( model , ds_test ) Valid Loss:0.745884418,Valid Accuracy:0.854","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u65b9\u6cd5: model.predict(ds_test) model(x_test) model.call(x_test) model.predict_on_batch(x_test) \u63a8\u8350\u4f18\u5148\u4f7f\u7528model.predict(ds_test)\u65b9\u6cd5\uff0c\u65e2\u53ef\u4ee5\u5bf9Dataset\uff0c\u4e5f\u53ef\u4ee5\u5bf9Tensor\u4f7f\u7528\u3002 model . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) for x_test , _ in ds_test . take ( 1 ): print ( model ( x_test )) #\u4ee5\u4e0b\u65b9\u6cd5\u7b49\u4ef7\uff1a #print(model.call(x_test)) #print(model.predict_on_batch(x_test)) tf.Tensor( [[7.8648227e-01] [9.9999011e-01] [9.9944776e-01] [3.7153201e-09] [9.4462049e-01] [2.3522753e-04] [1.2044354e-04] [9.3752089e-07] [9.9996352e-01] [9.3435925e-01] [9.8746723e-01] [9.9908626e-01] [4.1563155e-08] [4.1808244e-03] [8.0184749e-05] [8.3910513e-01] [3.5167937e-05] [7.2113985e-01] [4.5228912e-03] [9.9942589e-01]], shape=(20, 1), dtype=float32)","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u63a8\u8350\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u3002 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # \u56fd\u5185\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u4ece\u53d1\u73b0\u81f3\u4eca\u5df2\u7ecf\u6301\u7eed3\u4e2a\u591a\u6708\u4e86\uff0c\u8fd9\u573a\u8d77\u6e90\u4e8e\u5403\u91ce\u5473\u7684\u707e\u96be\u7ed9\u5927\u5bb6\u7684\u751f\u6d3b\u9020\u6210\u4e86\u8bf8\u591a\u65b9\u9762\u7684\u5f71\u54cd\u3002 \u6709\u7684\u540c\u5b66\u662f\u6536\u5165\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u611f\u60c5\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u5fc3\u7406\u4e0a\u7684\uff0c\u8fd8\u6709\u7684\u540c\u5b66\u662f\u4f53\u91cd\u4e0a\u7684\u3002 \u90a3\u4e48\u56fd\u5185\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u4f55\u65f6\u7ed3\u675f\u5462\uff1f\u4ec0\u4e48\u65f6\u5019\u6211\u4eec\u624d\u53ef\u4ee5\u91cd\u83b7\u81ea\u7531\u5462\uff1f \u672c\u7bc7\u6587\u7ae0\u5c06\u5229\u7528TensorFlow2.0\u5efa\u7acb\u65f6\u95f4\u5e8f\u5217RNN\u6a21\u578b\uff0c\u5bf9\u56fd\u5185\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u8fdb\u884c\u9884\u6d4b\u3002 \u4e00\uff0c\u51c6\u5907\u6570\u636e # \u672c\u6587\u7684\u6570\u636e\u96c6\u53d6\u81eatushare\uff0c\u83b7\u53d6\u8be5\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u53c2\u8003\u4e86\u4ee5\u4e0b\u6587\u7ae0\u3002 \u300a https://zhuanlan.zhihu.com/p/109556102 \u300b import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , callbacks % matplotlib inline % config InlineBackend . figure_format = 'svg' df = pd . read_csv ( \"../../data/covid-19.csv\" , sep = \" \\t \" ) df . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdata = df . set_index ( \"date\" ) dfdiff = dfdata . diff ( periods = 1 ) . dropna () dfdiff = dfdiff . reset_index ( \"date\" ) dfdiff . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdiff = dfdiff . drop ( \"date\" , axis = 1 ) . astype ( \"float32\" ) #\u7528\u67d0\u65e5\u524d8\u5929\u7a97\u53e3\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u9884\u6d4b\u8be5\u65e5\u6570\u636e WINDOW_SIZE = 8 def batch_dataset ( dataset ): dataset_batched = dataset . batch ( WINDOW_SIZE , drop_remainder = True ) return dataset_batched ds_data = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values , dtype = tf . float32 )) \\ . window ( WINDOW_SIZE , shift = 1 ) . flat_map ( batch_dataset ) ds_label = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values [ WINDOW_SIZE :], dtype = tf . float32 )) #\u6570\u636e\u8f83\u5c0f\uff0c\u53ef\u4ee5\u5c06\u5168\u90e8\u8bad\u7ec3\u6570\u636e\u653e\u5165\u5230\u4e00\u4e2abatch\u4e2d\uff0c\u63d0\u5347\u6027\u80fd ds_train = tf . data . Dataset . zip (( ds_data , ds_label )) . batch ( 38 ) . cache () \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\u3002 #\u8003\u8651\u5230\u65b0\u589e\u786e\u8bca\uff0c\u65b0\u589e\u6cbb\u6108\uff0c\u65b0\u589e\u6b7b\u4ea1\u4eba\u6570\u6570\u636e\u4e0d\u53ef\u80fd\u5c0f\u4e8e0\uff0c\u8bbe\u8ba1\u5982\u4e0b\u7ed3\u6784 class Block ( layers . Layer ): def __init__ ( self , ** kwargs ): super ( Block , self ) . __init__ ( ** kwargs ) def call ( self , x_input , x ): x_out = tf . maximum (( 1 + x ) * x_input [:, - 1 ,:], 0.0 ) return x_out def get_config ( self ): config = super ( Block , self ) . get_config () return config tf . keras . backend . clear_session () x_input = layers . Input ( shape = ( None , 3 ), dtype = tf . float32 ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x_input ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , input_shape = ( None , 3 ))( x ) x = layers . Dense ( 3 )( x ) #\u8003\u8651\u5230\u65b0\u589e\u786e\u8bca\uff0c\u65b0\u589e\u6cbb\u6108\uff0c\u65b0\u589e\u6b7b\u4ea1\u4eba\u6570\u6570\u636e\u4e0d\u53ef\u80fd\u5c0f\u4e8e0\uff0c\u8bbe\u8ba1\u5982\u4e0b\u7ed3\u6784 #x = tf.maximum((1+x)*x_input[:,-1,:],0.0) x = Block ()( x_input , x ) model = models . Model ( inputs = [ x_input ], outputs = [ x ]) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, None, 3)] 0 _________________________________________________________________ lstm (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_1 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_2 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_3 (LSTM) (None, 3) 84 _________________________________________________________________ dense (Dense) (None, 3) 12 _________________________________________________________________ block (Block) (None, 3) 0 ================================================================= Total params: 348 Trainable params: 348 Non-trainable params: 0 _________________________________________________________________ \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # \u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u9009\u62e9\u6700\u5e38\u7528\u4e5f\u6700\u7b80\u5355\u7684\u5185\u7f6efit\u65b9\u6cd5\u3002 \u6ce8\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8c03\u8bd5\u8f83\u4e3a\u56f0\u96be\uff0c\u9700\u8981\u8bbe\u7f6e\u591a\u4e2a\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u591a\u6b21\u5c1d\u8bd5\uff0c\u4ee5\u53d6\u5f97\u8f83\u597d\u7684\u6548\u679c\u3002 #\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u8003\u8651\u5e73\u65b9\u5dee\u548c\u9884\u6d4b\u76ee\u6807\u7684\u6bd4\u503c class MSPE ( losses . Loss ): def call ( self , y_true , y_pred ): err_percent = ( y_true - y_pred ) ** 2 / ( tf . maximum ( y_true ** 2 , 1e-7 )) mean_err_percent = tf . reduce_mean ( err_percent ) return mean_err_percent def get_config ( self ): config = super ( MSPE , self ) . get_config () return config import os import datetime optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.01 ) model . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## \u5728 Python3 \u4e0b\u5efa\u8bae\u4f7f\u7528 pathlib \u4fee\u6b63\u5404\u64cd\u4f5c\u7cfb\u7edf\u7684\u8def\u5f84 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tb_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) #\u5982\u679closs\u5728100\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5b66\u4e60\u7387\u51cf\u534a\u3002 lr_callback = tf . keras . callbacks . ReduceLROnPlateau ( monitor = \"loss\" , factor = 0.5 , patience = 100 ) #\u5f53loss\u5728200\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002 stop_callback = tf . keras . callbacks . EarlyStopping ( monitor = \"loss\" , patience = 200 ) callbacks_list = [ tb_callback , lr_callback , stop_callback ] history = model . fit ( ds_train , epochs = 500 , callbacks = callbacks_list ) Epoch 371/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1184 Epoch 372/500 1/1 [==============================] - 0s 64ms/step - loss: 0.1177 Epoch 373/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1169 Epoch 374/500 1/1 [==============================] - 0s 50ms/step - loss: 0.1161 Epoch 375/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1154 Epoch 376/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1147 Epoch 377/500 1/1 [==============================] - 0s 62ms/step - loss: 0.1140 Epoch 378/500 1/1 [==============================] - 0s 93ms/step - loss: 0.1133 Epoch 379/500 1/1 [==============================] - 0s 85ms/step - loss: 0.1126 Epoch 380/500 1/1 [==============================] - 0s 68ms/step - loss: 0.1119 Epoch 381/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1113 Epoch 382/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1107 Epoch 383/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1100 Epoch 384/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1094 Epoch 385/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1088 Epoch 386/500 1/1 [==============================] - 0s 74ms/step - loss: 0.1082 Epoch 387/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1077 Epoch 388/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1071 Epoch 389/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1066 Epoch 390/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1060 Epoch 391/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1055 Epoch 392/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1050 Epoch 393/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1045 Epoch 394/500 1/1 [==============================] - 0s 65ms/step - loss: 0.1040 Epoch 395/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1035 Epoch 396/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1031 Epoch 397/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1026 Epoch 398/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1022 Epoch 399/500 1/1 [==============================] - 0s 57ms/step - loss: 0.1017 Epoch 400/500 1/1 [==============================] - 0s 63ms/step - loss: 0.1013 Epoch 401/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1009 Epoch 402/500 1/1 [==============================] - 0s 53ms/step - loss: 0.1005 Epoch 403/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1001 Epoch 404/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0997 Epoch 405/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0993 Epoch 406/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0990 Epoch 407/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0986 Epoch 408/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0982 Epoch 409/500 1/1 [==============================] - 0s 67ms/step - loss: 0.0979 Epoch 410/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0976 Epoch 411/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0972 Epoch 412/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0969 Epoch 413/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0966 Epoch 414/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0963 Epoch 415/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0960 Epoch 416/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0957 Epoch 417/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0954 Epoch 418/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0951 Epoch 419/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0948 Epoch 420/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0946 Epoch 421/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0943 Epoch 422/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0941 Epoch 423/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0938 Epoch 424/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0936 Epoch 425/500 1/1 [==============================] - 0s 100ms/step - loss: 0.0933 Epoch 426/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0931 Epoch 427/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0929 Epoch 428/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0926 Epoch 429/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0924 Epoch 430/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0922 Epoch 431/500 1/1 [==============================] - 0s 75ms/step - loss: 0.0920 Epoch 432/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0918 Epoch 433/500 1/1 [==============================] - 0s 77ms/step - loss: 0.0916 Epoch 434/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0914 Epoch 435/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0912 Epoch 436/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0911 Epoch 437/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0909 Epoch 438/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0907 Epoch 439/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0905 Epoch 440/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0904 Epoch 441/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0902 Epoch 442/500 1/1 [==============================] - 0s 73ms/step - loss: 0.0901 Epoch 443/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0899 Epoch 444/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0898 Epoch 445/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0896 Epoch 446/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0895 Epoch 447/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0893 Epoch 448/500 1/1 [==============================] - 0s 64ms/step - loss: 0.0892 Epoch 449/500 1/1 [==============================] - 0s 70ms/step - loss: 0.0891 Epoch 450/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0889 Epoch 451/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0888 Epoch 452/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0887 Epoch 453/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0886 Epoch 454/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0885 Epoch 455/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0883 Epoch 456/500 1/1 [==============================] - 0s 71ms/step - loss: 0.0882 Epoch 457/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0881 Epoch 458/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0880 Epoch 459/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 460/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0878 Epoch 461/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0878 Epoch 462/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 463/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0879 Epoch 464/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0888 Epoch 465/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0875 Epoch 466/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0873 Epoch 467/500 1/1 [==============================] - 0s 49ms/step - loss: 0.0872 Epoch 468/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0872 Epoch 469/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 470/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 471/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0870 Epoch 472/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0871 Epoch 473/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0869 Epoch 474/500 1/1 [==============================] - 0s 61ms/step - loss: 0.0870 Epoch 475/500 1/1 [==============================] - 0s 47ms/step - loss: 0.0868 Epoch 476/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0868 Epoch 477/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0866 Epoch 478/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0867 Epoch 479/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0865 Epoch 480/500 1/1 [==============================] - 0s 65ms/step - loss: 0.0866 Epoch 481/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0864 Epoch 482/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0865 Epoch 483/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0863 Epoch 484/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0864 Epoch 485/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0862 Epoch 486/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0863 Epoch 487/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0861 Epoch 488/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0862 Epoch 489/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0860 Epoch 490/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0861 Epoch 491/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 492/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 493/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 494/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 495/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0858 Epoch 496/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0859 Epoch 497/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0857 Epoch 498/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0858 Epoch 499/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0857 Epoch 500/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0858 \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # \u8bc4\u4f30\u6a21\u578b\u4e00\u822c\u8981\u8bbe\u7f6e\u9a8c\u8bc1\u96c6\u6216\u8005\u6d4b\u8bd5\u96c6\uff0c\u7531\u4e8e\u6b64\u4f8b\u6570\u636e\u8f83\u5c11\uff0c\u6211\u4eec\u4ec5\u4ec5\u53ef\u89c6\u5316\u635f\u5931\u51fd\u6570\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8fed\u4ee3\u60c5\u51b5\u3002 % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . title ( 'Training ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric ]) plt . show () plot_metric ( history , \"loss\" ) \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # \u6b64\u5904\u6211\u4eec\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\uff0c\u5373 \u65b0\u589e\u786e\u8bca\u75c5\u4f8b\u4e3a0 \u7684\u65f6\u95f4\u3002 #\u4f7f\u7528dfresult\u8bb0\u5f55\u73b0\u6709\u6570\u636e\u4ee5\u53ca\u6b64\u540e\u9884\u6d4b\u7684\u75ab\u60c5\u6570\u636e dfresult = dfdiff [[ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ]] . copy () dfresult . tail () #\u9884\u6d4b\u6b64\u540e100\u5929\u7684\u65b0\u589e\u8d70\u52bf,\u5c06\u5176\u7ed3\u679c\u6dfb\u52a0\u5230dfresult\u4e2d for i in range ( 100 ): arr_predict = model . predict ( tf . constant ( tf . expand_dims ( dfresult . values [ - 38 :,:], axis = 0 ))) dfpredict = pd . DataFrame ( tf . cast ( tf . floor ( arr_predict ), tf . float32 ) . numpy (), columns = dfresult . columns ) dfresult = dfresult . append ( dfpredict , ignore_index = True ) dfresult . query ( \"confirmed_num==0\" ) . head () # \u7b2c55\u5929\u5f00\u59cb\u65b0\u589e\u786e\u8bca\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f10\u5929\u540e\uff0c\u5373\u9884\u8ba13\u670820\u65e5\u65b0\u589e\u786e\u8bca\u964d\u4e3a0 # \u6ce8\uff1a\u8be5\u9884\u6d4b\u504f\u4e50\u89c2 dfresult . query ( \"cured_num==0\" ) . head () # \u7b2c164\u5929\u5f00\u59cb\u65b0\u589e\u6cbb\u6108\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f\u5927\u69824\u4e2a\u6708\u540e\uff0c\u53737\u670810\u65e5\u5de6\u53f3\u5168\u90e8\u6cbb\u6108\u3002 # \u6ce8: \u8be5\u9884\u6d4b\u504f\u60b2\u89c2\uff0c\u5e76\u4e14\u5b58\u5728\u95ee\u9898\uff0c\u5982\u679c\u5c06\u6bcf\u5929\u65b0\u589e\u6cbb\u6108\u4eba\u6570\u52a0\u8d77\u6765\uff0c\u5c06\u8d85\u8fc7\u7d2f\u8ba1\u786e\u8bca\u4eba\u6570\u3002 dfresult . query ( \"dead_num==0\" ) . head () # \u7b2c60\u5929\u5f00\u59cb\uff0c\u65b0\u589e\u6b7b\u4ea1\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f\u5927\u698215\u5929\u540e\uff0c\u537320200325 # \u8be5\u9884\u6d4b\u8f83\u4e3a\u5408\u7406 \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u63a8\u8350\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u3002 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' , compile = False ) optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ) model_loaded . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) model_loaded . predict ( ds_train ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"\u56fd\u5185\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u4ece\u53d1\u73b0\u81f3\u4eca\u5df2\u7ecf\u6301\u7eed3\u4e2a\u591a\u6708\u4e86\uff0c\u8fd9\u573a\u8d77\u6e90\u4e8e\u5403\u91ce\u5473\u7684\u707e\u96be\u7ed9\u5927\u5bb6\u7684\u751f\u6d3b\u9020\u6210\u4e86\u8bf8\u591a\u65b9\u9762\u7684\u5f71\u54cd\u3002 \u6709\u7684\u540c\u5b66\u662f\u6536\u5165\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u611f\u60c5\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u5fc3\u7406\u4e0a\u7684\uff0c\u8fd8\u6709\u7684\u540c\u5b66\u662f\u4f53\u91cd\u4e0a\u7684\u3002 \u90a3\u4e48\u56fd\u5185\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u4f55\u65f6\u7ed3\u675f\u5462\uff1f\u4ec0\u4e48\u65f6\u5019\u6211\u4eec\u624d\u53ef\u4ee5\u91cd\u83b7\u81ea\u7531\u5462\uff1f \u672c\u7bc7\u6587\u7ae0\u5c06\u5229\u7528TensorFlow2.0\u5efa\u7acb\u65f6\u95f4\u5e8f\u5217RNN\u6a21\u578b\uff0c\u5bf9\u56fd\u5185\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u8fdb\u884c\u9884\u6d4b\u3002","title":"1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"\u672c\u6587\u7684\u6570\u636e\u96c6\u53d6\u81eatushare\uff0c\u83b7\u53d6\u8be5\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u53c2\u8003\u4e86\u4ee5\u4e0b\u6587\u7ae0\u3002 \u300a https://zhuanlan.zhihu.com/p/109556102 \u300b import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , callbacks % matplotlib inline % config InlineBackend . figure_format = 'svg' df = pd . read_csv ( \"../../data/covid-19.csv\" , sep = \" \\t \" ) df . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdata = df . set_index ( \"date\" ) dfdiff = dfdata . diff ( periods = 1 ) . dropna () dfdiff = dfdiff . reset_index ( \"date\" ) dfdiff . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdiff = dfdiff . drop ( \"date\" , axis = 1 ) . astype ( \"float32\" ) #\u7528\u67d0\u65e5\u524d8\u5929\u7a97\u53e3\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u9884\u6d4b\u8be5\u65e5\u6570\u636e WINDOW_SIZE = 8 def batch_dataset ( dataset ): dataset_batched = dataset . batch ( WINDOW_SIZE , drop_remainder = True ) return dataset_batched ds_data = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values , dtype = tf . float32 )) \\ . window ( WINDOW_SIZE , shift = 1 ) . flat_map ( batch_dataset ) ds_label = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values [ WINDOW_SIZE :], dtype = tf . float32 )) #\u6570\u636e\u8f83\u5c0f\uff0c\u53ef\u4ee5\u5c06\u5168\u90e8\u8bad\u7ec3\u6570\u636e\u653e\u5165\u5230\u4e00\u4e2abatch\u4e2d\uff0c\u63d0\u5347\u6027\u80fd ds_train = tf . data . Dataset . zip (( ds_data , ds_label )) . batch ( 38 ) . cache ()","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\u3002 #\u8003\u8651\u5230\u65b0\u589e\u786e\u8bca\uff0c\u65b0\u589e\u6cbb\u6108\uff0c\u65b0\u589e\u6b7b\u4ea1\u4eba\u6570\u6570\u636e\u4e0d\u53ef\u80fd\u5c0f\u4e8e0\uff0c\u8bbe\u8ba1\u5982\u4e0b\u7ed3\u6784 class Block ( layers . Layer ): def __init__ ( self , ** kwargs ): super ( Block , self ) . __init__ ( ** kwargs ) def call ( self , x_input , x ): x_out = tf . maximum (( 1 + x ) * x_input [:, - 1 ,:], 0.0 ) return x_out def get_config ( self ): config = super ( Block , self ) . get_config () return config tf . keras . backend . clear_session () x_input = layers . Input ( shape = ( None , 3 ), dtype = tf . float32 ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x_input ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , input_shape = ( None , 3 ))( x ) x = layers . Dense ( 3 )( x ) #\u8003\u8651\u5230\u65b0\u589e\u786e\u8bca\uff0c\u65b0\u589e\u6cbb\u6108\uff0c\u65b0\u589e\u6b7b\u4ea1\u4eba\u6570\u6570\u636e\u4e0d\u53ef\u80fd\u5c0f\u4e8e0\uff0c\u8bbe\u8ba1\u5982\u4e0b\u7ed3\u6784 #x = tf.maximum((1+x)*x_input[:,-1,:],0.0) x = Block ()( x_input , x ) model = models . Model ( inputs = [ x_input ], outputs = [ x ]) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, None, 3)] 0 _________________________________________________________________ lstm (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_1 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_2 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_3 (LSTM) (None, 3) 84 _________________________________________________________________ dense (Dense) (None, 3) 12 _________________________________________________________________ block (Block) (None, 3) 0 ================================================================= Total params: 348 Trainable params: 348 Non-trainable params: 0 _________________________________________________________________","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"\u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u67093\u79cd\u65b9\u6cd5\uff0c\u5185\u7f6efit\u65b9\u6cd5\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5\uff0c\u4ee5\u53ca\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002\u6b64\u5904\u6211\u4eec\u9009\u62e9\u6700\u5e38\u7528\u4e5f\u6700\u7b80\u5355\u7684\u5185\u7f6efit\u65b9\u6cd5\u3002 \u6ce8\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8c03\u8bd5\u8f83\u4e3a\u56f0\u96be\uff0c\u9700\u8981\u8bbe\u7f6e\u591a\u4e2a\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u591a\u6b21\u5c1d\u8bd5\uff0c\u4ee5\u53d6\u5f97\u8f83\u597d\u7684\u6548\u679c\u3002 #\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u8003\u8651\u5e73\u65b9\u5dee\u548c\u9884\u6d4b\u76ee\u6807\u7684\u6bd4\u503c class MSPE ( losses . Loss ): def call ( self , y_true , y_pred ): err_percent = ( y_true - y_pred ) ** 2 / ( tf . maximum ( y_true ** 2 , 1e-7 )) mean_err_percent = tf . reduce_mean ( err_percent ) return mean_err_percent def get_config ( self ): config = super ( MSPE , self ) . get_config () return config import os import datetime optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.01 ) model . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## \u5728 Python3 \u4e0b\u5efa\u8bae\u4f7f\u7528 pathlib \u4fee\u6b63\u5404\u64cd\u4f5c\u7cfb\u7edf\u7684\u8def\u5f84 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tb_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) #\u5982\u679closs\u5728100\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5b66\u4e60\u7387\u51cf\u534a\u3002 lr_callback = tf . keras . callbacks . ReduceLROnPlateau ( monitor = \"loss\" , factor = 0.5 , patience = 100 ) #\u5f53loss\u5728200\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002 stop_callback = tf . keras . callbacks . EarlyStopping ( monitor = \"loss\" , patience = 200 ) callbacks_list = [ tb_callback , lr_callback , stop_callback ] history = model . fit ( ds_train , epochs = 500 , callbacks = callbacks_list ) Epoch 371/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1184 Epoch 372/500 1/1 [==============================] - 0s 64ms/step - loss: 0.1177 Epoch 373/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1169 Epoch 374/500 1/1 [==============================] - 0s 50ms/step - loss: 0.1161 Epoch 375/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1154 Epoch 376/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1147 Epoch 377/500 1/1 [==============================] - 0s 62ms/step - loss: 0.1140 Epoch 378/500 1/1 [==============================] - 0s 93ms/step - loss: 0.1133 Epoch 379/500 1/1 [==============================] - 0s 85ms/step - loss: 0.1126 Epoch 380/500 1/1 [==============================] - 0s 68ms/step - loss: 0.1119 Epoch 381/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1113 Epoch 382/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1107 Epoch 383/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1100 Epoch 384/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1094 Epoch 385/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1088 Epoch 386/500 1/1 [==============================] - 0s 74ms/step - loss: 0.1082 Epoch 387/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1077 Epoch 388/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1071 Epoch 389/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1066 Epoch 390/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1060 Epoch 391/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1055 Epoch 392/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1050 Epoch 393/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1045 Epoch 394/500 1/1 [==============================] - 0s 65ms/step - loss: 0.1040 Epoch 395/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1035 Epoch 396/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1031 Epoch 397/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1026 Epoch 398/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1022 Epoch 399/500 1/1 [==============================] - 0s 57ms/step - loss: 0.1017 Epoch 400/500 1/1 [==============================] - 0s 63ms/step - loss: 0.1013 Epoch 401/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1009 Epoch 402/500 1/1 [==============================] - 0s 53ms/step - loss: 0.1005 Epoch 403/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1001 Epoch 404/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0997 Epoch 405/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0993 Epoch 406/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0990 Epoch 407/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0986 Epoch 408/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0982 Epoch 409/500 1/1 [==============================] - 0s 67ms/step - loss: 0.0979 Epoch 410/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0976 Epoch 411/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0972 Epoch 412/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0969 Epoch 413/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0966 Epoch 414/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0963 Epoch 415/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0960 Epoch 416/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0957 Epoch 417/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0954 Epoch 418/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0951 Epoch 419/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0948 Epoch 420/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0946 Epoch 421/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0943 Epoch 422/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0941 Epoch 423/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0938 Epoch 424/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0936 Epoch 425/500 1/1 [==============================] - 0s 100ms/step - loss: 0.0933 Epoch 426/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0931 Epoch 427/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0929 Epoch 428/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0926 Epoch 429/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0924 Epoch 430/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0922 Epoch 431/500 1/1 [==============================] - 0s 75ms/step - loss: 0.0920 Epoch 432/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0918 Epoch 433/500 1/1 [==============================] - 0s 77ms/step - loss: 0.0916 Epoch 434/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0914 Epoch 435/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0912 Epoch 436/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0911 Epoch 437/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0909 Epoch 438/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0907 Epoch 439/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0905 Epoch 440/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0904 Epoch 441/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0902 Epoch 442/500 1/1 [==============================] - 0s 73ms/step - loss: 0.0901 Epoch 443/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0899 Epoch 444/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0898 Epoch 445/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0896 Epoch 446/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0895 Epoch 447/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0893 Epoch 448/500 1/1 [==============================] - 0s 64ms/step - loss: 0.0892 Epoch 449/500 1/1 [==============================] - 0s 70ms/step - loss: 0.0891 Epoch 450/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0889 Epoch 451/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0888 Epoch 452/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0887 Epoch 453/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0886 Epoch 454/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0885 Epoch 455/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0883 Epoch 456/500 1/1 [==============================] - 0s 71ms/step - loss: 0.0882 Epoch 457/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0881 Epoch 458/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0880 Epoch 459/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 460/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0878 Epoch 461/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0878 Epoch 462/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 463/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0879 Epoch 464/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0888 Epoch 465/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0875 Epoch 466/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0873 Epoch 467/500 1/1 [==============================] - 0s 49ms/step - loss: 0.0872 Epoch 468/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0872 Epoch 469/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 470/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 471/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0870 Epoch 472/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0871 Epoch 473/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0869 Epoch 474/500 1/1 [==============================] - 0s 61ms/step - loss: 0.0870 Epoch 475/500 1/1 [==============================] - 0s 47ms/step - loss: 0.0868 Epoch 476/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0868 Epoch 477/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0866 Epoch 478/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0867 Epoch 479/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0865 Epoch 480/500 1/1 [==============================] - 0s 65ms/step - loss: 0.0866 Epoch 481/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0864 Epoch 482/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0865 Epoch 483/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0863 Epoch 484/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0864 Epoch 485/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0862 Epoch 486/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0863 Epoch 487/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0861 Epoch 488/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0862 Epoch 489/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0860 Epoch 490/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0861 Epoch 491/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 492/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 493/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 494/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 495/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0858 Epoch 496/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0859 Epoch 497/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0857 Epoch 498/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0858 Epoch 499/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0857 Epoch 500/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0858","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"\u8bc4\u4f30\u6a21\u578b\u4e00\u822c\u8981\u8bbe\u7f6e\u9a8c\u8bc1\u96c6\u6216\u8005\u6d4b\u8bd5\u96c6\uff0c\u7531\u4e8e\u6b64\u4f8b\u6570\u636e\u8f83\u5c11\uff0c\u6211\u4eec\u4ec5\u4ec5\u53ef\u89c6\u5316\u635f\u5931\u51fd\u6570\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8fed\u4ee3\u60c5\u51b5\u3002 % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . title ( 'Training ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric ]) plt . show () plot_metric ( history , \"loss\" )","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"\u6b64\u5904\u6211\u4eec\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\uff0c\u5373 \u65b0\u589e\u786e\u8bca\u75c5\u4f8b\u4e3a0 \u7684\u65f6\u95f4\u3002 #\u4f7f\u7528dfresult\u8bb0\u5f55\u73b0\u6709\u6570\u636e\u4ee5\u53ca\u6b64\u540e\u9884\u6d4b\u7684\u75ab\u60c5\u6570\u636e dfresult = dfdiff [[ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ]] . copy () dfresult . tail () #\u9884\u6d4b\u6b64\u540e100\u5929\u7684\u65b0\u589e\u8d70\u52bf,\u5c06\u5176\u7ed3\u679c\u6dfb\u52a0\u5230dfresult\u4e2d for i in range ( 100 ): arr_predict = model . predict ( tf . constant ( tf . expand_dims ( dfresult . values [ - 38 :,:], axis = 0 ))) dfpredict = pd . DataFrame ( tf . cast ( tf . floor ( arr_predict ), tf . float32 ) . numpy (), columns = dfresult . columns ) dfresult = dfresult . append ( dfpredict , ignore_index = True ) dfresult . query ( \"confirmed_num==0\" ) . head () # \u7b2c55\u5929\u5f00\u59cb\u65b0\u589e\u786e\u8bca\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f10\u5929\u540e\uff0c\u5373\u9884\u8ba13\u670820\u65e5\u65b0\u589e\u786e\u8bca\u964d\u4e3a0 # \u6ce8\uff1a\u8be5\u9884\u6d4b\u504f\u4e50\u89c2 dfresult . query ( \"cured_num==0\" ) . head () # \u7b2c164\u5929\u5f00\u59cb\u65b0\u589e\u6cbb\u6108\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f\u5927\u69824\u4e2a\u6708\u540e\uff0c\u53737\u670810\u65e5\u5de6\u53f3\u5168\u90e8\u6cbb\u6108\u3002 # \u6ce8: \u8be5\u9884\u6d4b\u504f\u60b2\u89c2\uff0c\u5e76\u4e14\u5b58\u5728\u95ee\u9898\uff0c\u5982\u679c\u5c06\u6bcf\u5929\u65b0\u589e\u6cbb\u6108\u4eba\u6570\u52a0\u8d77\u6765\uff0c\u5c06\u8d85\u8fc7\u7d2f\u8ba1\u786e\u8bca\u4eba\u6570\u3002 dfresult . query ( \"dead_num==0\" ) . head () # \u7b2c60\u5929\u5f00\u59cb\uff0c\u65b0\u589e\u6b7b\u4ea1\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f\u5927\u698215\u5929\u540e\uff0c\u537320200325 # \u8be5\u9884\u6d4b\u8f83\u4e3a\u5408\u7406","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"chinese/1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u63a8\u8350\u4f7f\u7528TensorFlow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u3002 model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' , compile = False ) optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ) model_loaded . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) model_loaded . predict ( ds_train ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/","text":"\u4e8c\u3001TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5 # TensorFlow\u2122 \u662f\u4e00\u4e2a\u91c7\u7528 \u6570\u636e\u6d41\u56fe \uff08data flow graphs\uff09\uff0c\u7528\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u5f00\u6e90\u8f6f\u4ef6\u5e93\u3002\u8282\u70b9\uff08Nodes\uff09\u5728\u56fe\u4e2d\u8868\u793a\u6570\u5b66\u64cd\u4f5c\uff0c\u56fe\u4e2d\u7684\u7ebf\uff08edges\uff09\u5219\u8868\u793a\u5728\u8282\u70b9\u95f4\u76f8\u4e92\u8054\u7cfb\u7684\u591a\u7ef4\u6570\u636e\u6570\u7ec4\uff0c\u5373\u5f20\u91cf\uff08tensor\uff09\u3002\u5b83\u7075\u6d3b\u7684\u67b6\u6784\u8ba9\u4f60\u53ef\u4ee5**\u5728\u591a\u79cd\u5e73\u53f0\u4e0a\u5c55\u5f00\u8ba1\u7b97**\uff0c\u4f8b\u5982\u53f0\u5f0f\u8ba1\u7b97\u673a\u4e2d\u7684\u4e00\u4e2a\u6216\u591a\u4e2aCPU\uff08\u6216GPU\uff09\uff0c\u670d\u52a1\u5668\uff0c\u79fb\u52a8\u8bbe\u5907\u7b49\u7b49\u3002TensorFlow \u6700\u521d\u7531Google\u5927\u8111\u5c0f\u7ec4\uff08\u96b6\u5c5e\u4e8eGoogle\u673a\u5668\u667a\u80fd\u7814\u7a76\u673a\u6784\uff09\u7684\u7814\u7a76\u5458\u548c\u5de5\u7a0b\u5e08\u4eec\u5f00\u53d1\u51fa\u6765\uff0c \u7528\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc**\u65b9\u9762\u7684\u7814\u7a76\uff0c\u4f46\u8fd9\u4e2a\u7cfb\u7edf\u7684\u901a\u7528\u6027\u4f7f\u5176\u4e5f\u53ef**\u5e7f\u6cdb\u7528\u4e8e\u5176\u4ed6\u8ba1\u7b97\u9886\u57df \u3002 TensorFlow\u7684\u4e3b\u8981\u4f18\u70b9\uff1a \u7075\u6d3b\u6027\uff1a\u652f\u6301\u5e95\u5c42\u6570\u503c\u8ba1\u7b97\uff0cC++\u81ea\u5b9a\u4e49\u64cd\u4f5c\u7b26 \u53ef\u79fb\u690d\u6027\uff1a\u4ece\u670d\u52a1\u5668\u5230PC\u5230\u624b\u673a\uff0c\u4eceCPU\u5230GPU\u5230TPU \u5206\u5e03\u5f0f\u8ba1\u7b97\uff1a\u5206\u5e03\u5f0f\u5e76\u884c\u8ba1\u7b97\uff0c\u53ef\u6307\u5b9a\u64cd\u4f5c\u7b26\u5bf9\u5e94\u8ba1\u7b97\u8bbe\u5907 \u4fd7\u8bdd\u8bf4\uff0c\u4e07\u4e08\u9ad8\u697c\u5e73\u5730\u8d77\uff0cTensorFlow\u8fd9\u5ea7\u5927\u53a6\u4e5f\u6709\u5b83\u7684\u5730\u57fa\u3002 Tensorflow\u5e95\u5c42\u6700\u6838\u5fc3\u7684\u6982\u5ff5\u662f\u5f20\u91cf\uff0c\u8ba1\u7b97\u56fe\u4ee5\u53ca\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\u3001TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/#\u4e8ctensorflow\u7684\u6838\u5fc3\u6982\u5ff5","text":"TensorFlow\u2122 \u662f\u4e00\u4e2a\u91c7\u7528 \u6570\u636e\u6d41\u56fe \uff08data flow graphs\uff09\uff0c\u7528\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u5f00\u6e90\u8f6f\u4ef6\u5e93\u3002\u8282\u70b9\uff08Nodes\uff09\u5728\u56fe\u4e2d\u8868\u793a\u6570\u5b66\u64cd\u4f5c\uff0c\u56fe\u4e2d\u7684\u7ebf\uff08edges\uff09\u5219\u8868\u793a\u5728\u8282\u70b9\u95f4\u76f8\u4e92\u8054\u7cfb\u7684\u591a\u7ef4\u6570\u636e\u6570\u7ec4\uff0c\u5373\u5f20\u91cf\uff08tensor\uff09\u3002\u5b83\u7075\u6d3b\u7684\u67b6\u6784\u8ba9\u4f60\u53ef\u4ee5**\u5728\u591a\u79cd\u5e73\u53f0\u4e0a\u5c55\u5f00\u8ba1\u7b97**\uff0c\u4f8b\u5982\u53f0\u5f0f\u8ba1\u7b97\u673a\u4e2d\u7684\u4e00\u4e2a\u6216\u591a\u4e2aCPU\uff08\u6216GPU\uff09\uff0c\u670d\u52a1\u5668\uff0c\u79fb\u52a8\u8bbe\u5907\u7b49\u7b49\u3002TensorFlow \u6700\u521d\u7531Google\u5927\u8111\u5c0f\u7ec4\uff08\u96b6\u5c5e\u4e8eGoogle\u673a\u5668\u667a\u80fd\u7814\u7a76\u673a\u6784\uff09\u7684\u7814\u7a76\u5458\u548c\u5de5\u7a0b\u5e08\u4eec\u5f00\u53d1\u51fa\u6765\uff0c \u7528\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc**\u65b9\u9762\u7684\u7814\u7a76\uff0c\u4f46\u8fd9\u4e2a\u7cfb\u7edf\u7684\u901a\u7528\u6027\u4f7f\u5176\u4e5f\u53ef**\u5e7f\u6cdb\u7528\u4e8e\u5176\u4ed6\u8ba1\u7b97\u9886\u57df \u3002 TensorFlow\u7684\u4e3b\u8981\u4f18\u70b9\uff1a \u7075\u6d3b\u6027\uff1a\u652f\u6301\u5e95\u5c42\u6570\u503c\u8ba1\u7b97\uff0cC++\u81ea\u5b9a\u4e49\u64cd\u4f5c\u7b26 \u53ef\u79fb\u690d\u6027\uff1a\u4ece\u670d\u52a1\u5668\u5230PC\u5230\u624b\u673a\uff0c\u4eceCPU\u5230GPU\u5230TPU \u5206\u5e03\u5f0f\u8ba1\u7b97\uff1a\u5206\u5e03\u5f0f\u5e76\u884c\u8ba1\u7b97\uff0c\u53ef\u6307\u5b9a\u64cd\u4f5c\u7b26\u5bf9\u5e94\u8ba1\u7b97\u8bbe\u5907 \u4fd7\u8bdd\u8bf4\uff0c\u4e07\u4e08\u9ad8\u697c\u5e73\u5730\u8d77\uff0cTensorFlow\u8fd9\u5ea7\u5927\u53a6\u4e5f\u6709\u5b83\u7684\u5730\u57fa\u3002 Tensorflow\u5e95\u5c42\u6700\u6838\u5fc3\u7684\u6982\u5ff5\u662f\u5f20\u91cf\uff0c\u8ba1\u7b97\u56fe\u4ee5\u53ca\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\u3001TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","text":"2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784 # \u7a0b\u5e8f = \u6570\u636e\u7ed3\u6784+\u7b97\u6cd5\u3002 TensorFlow\u7a0b\u5e8f = \u5f20\u91cf\u6570\u636e\u7ed3\u6784 + \u8ba1\u7b97\u56fe\u7b97\u6cd5\u8bed\u8a00 \u5f20\u91cf\u548c\u8ba1\u7b97\u56fe\u662f TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5\u3002 Tensorflow\u7684\u57fa\u672c\u6570\u636e\u7ed3\u6784\u662f\u5f20\u91cfTensor\u3002\u5f20\u91cf\u5373\u591a\u7ef4\u6570\u7ec4\u3002Tensorflow\u7684\u5f20\u91cf\u548cnumpy\u4e2d\u7684array\u5f88\u7c7b\u4f3c\u3002 \u4ece\u884c\u4e3a\u7279\u6027\u6765\u770b\uff0c\u6709\u4e24\u79cd\u7c7b\u578b\u7684\u5f20\u91cf\uff0c\u5e38\u91cfconstant\u548c\u53d8\u91cfVariable. \u5e38\u91cf\u7684\u503c\u5728\u8ba1\u7b97\u56fe\u4e2d\u4e0d\u53ef\u4ee5\u88ab\u91cd\u65b0\u8d4b\u503c\uff0c\u53d8\u91cf\u53ef\u4ee5\u5728\u8ba1\u7b97\u56fe\u4e2d\u7528assign\u7b49\u7b97\u5b50\u91cd\u65b0\u8d4b\u503c\u3002 \u4e00\uff0c\u5e38\u91cf\u5f20\u91cf # \u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u548cnumpy.array\u57fa\u672c\u4e00\u4e00\u5bf9\u5e94\u3002 import numpy as np import tensorflow as tf i = tf . constant ( 1 ) # tf.int32 \u7c7b\u578b\u5e38\u91cf l = tf . constant ( 1 , dtype = tf . int64 ) # tf.int64 \u7c7b\u578b\u5e38\u91cf f = tf . constant ( 1.23 ) #tf.float32 \u7c7b\u578b\u5e38\u91cf d = tf . constant ( 3.14 , dtype = tf . double ) # tf.double \u7c7b\u578b\u5e38\u91cf s = tf . constant ( \"hello world\" ) # tf.string\u7c7b\u578b\u5e38\u91cf b = tf . constant ( True ) #tf.bool\u7c7b\u578b\u5e38\u91cf print ( tf . int64 == np . int64 ) print ( tf . bool == np . bool ) print ( tf . double == np . float64 ) print ( tf . string == np . unicode ) # tf.string\u7c7b\u578b\u548cnp.unicode\u7c7b\u578b\u4e0d\u7b49\u4ef7 True True True False \u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u53ef\u4ee5\u7528\u4e0d\u540c\u7ef4\u5ea6(rank)\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 \u6807\u91cf\u4e3a0\u7ef4\u5f20\u91cf\uff0c\u5411\u91cf\u4e3a1\u7ef4\u5f20\u91cf\uff0c\u77e9\u9635\u4e3a2\u7ef4\u5f20\u91cf\u3002 \u5f69\u8272\u56fe\u50cf\u6709rgb\u4e09\u4e2a\u901a\u9053\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a3\u7ef4\u5f20\u91cf\u3002 \u89c6\u9891\u8fd8\u6709\u65f6\u95f4\u7ef4\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a4\u7ef4\u5f20\u91cf\u3002 \u53ef\u4ee5\u7b80\u5355\u5730\u603b\u7ed3\u4e3a\uff1a\u6709\u51e0\u5c42\u4e2d\u62ec\u53f7\uff0c\u5c31\u662f\u591a\u5c11\u7ef4\u7684\u5f20\u91cf\u3002 scalar = tf . constant ( True ) #\u6807\u91cf\uff0c0\u7ef4\u5f20\u91cf print ( tf . rank ( scalar )) print ( scalar . numpy () . ndim ) # tf.rank\u7684\u4f5c\u7528\u548cnumpy\u7684ndim\u65b9\u6cd5\u76f8\u540c tf.Tensor(0, shape=(), dtype=int32) 0 vector = tf . constant ([ 1.0 , 2.0 , 3.0 , 4.0 ]) #\u5411\u91cf\uff0c1\u7ef4\u5f20\u91cf print ( tf . rank ( vector )) print ( np . ndim ( vector . numpy ())) tf.Tensor(1, shape=(), dtype=int32) 1 matrix = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) #\u77e9\u9635, 2\u7ef4\u5f20\u91cf print ( tf . rank ( matrix ) . numpy ()) print ( np . ndim ( matrix )) 2 2 tensor3 = tf . constant ([[[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]],[[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]]) # 3\u7ef4\u5f20\u91cf print ( tensor3 ) print ( tf . rank ( tensor3 )) tf.Tensor( [[[1. 2.] [3. 4.]] [[5. 6.] [7. 8.]]], shape=(2, 2, 2), dtype=float32) tf.Tensor(3, shape=(), dtype=int32) tensor4 = tf . constant ([[[[ 1.0 , 1.0 ],[ 2.0 , 2.0 ]],[[ 3.0 , 3.0 ],[ 4.0 , 4.0 ]]], [[[ 5.0 , 5.0 ],[ 6.0 , 6.0 ]],[[ 7.0 , 7.0 ],[ 8.0 , 8.0 ]]]]) # 4\u7ef4\u5f20\u91cf print ( tensor4 ) print ( tf . rank ( tensor4 )) tf.Tensor( [[[[1. 1.] [2. 2.]] [[3. 3.] [4. 4.]]] [[[5. 5.] [6. 6.]] [[7. 7.] [8. 8.]]]], shape=(2, 2, 2, 2), dtype=float32) tf.Tensor(4, shape=(), dtype=int32) \u53ef\u4ee5\u7528tf.cast\u6539\u53d8\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u3002 \u53ef\u4ee5\u7528numpy\u65b9\u6cd5\u5c06tensorflow\u4e2d\u7684\u5f20\u91cf\u8f6c\u5316\u6210numpy\u4e2d\u7684\u5f20\u91cf\u3002 \u53ef\u4ee5\u7528shape\u65b9\u6cd5\u67e5\u770b\u5f20\u91cf\u7684\u5c3a\u5bf8\u3002 h = tf . constant ([ 123 , 456 ], dtype = tf . int32 ) f = tf . cast ( h , tf . float32 ) print ( h . dtype , f . dtype ) <dtype: 'int32'> <dtype: 'float32'> y = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) print ( y . numpy ()) #\u8f6c\u6362\u6210np.array print ( y . shape ) [[1. 2.] [3. 4.]] (2, 2) u = tf . constant ( u \"\u4f60\u597d \u4e16\u754c\" ) print ( u . numpy ()) print ( u . numpy () . decode ( \"utf-8\" )) b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xe4\\xb8\\x96\\xe7\\x95\\x8c' \u4f60\u597d \u4e16\u754c \u4e8c\uff0c\u53d8\u91cf\u5f20\u91cf # \u6a21\u578b\u4e2d\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\u4e00\u822c\u88ab\u8bbe\u7f6e\u6210\u53d8\u91cf\u3002 # \u5e38\u91cf\u503c\u4e0d\u53ef\u4ee5\u6539\u53d8\uff0c\u5e38\u91cf\u7684\u91cd\u65b0\u8d4b\u503c\u76f8\u5f53\u4e8e\u521b\u9020\u65b0\u7684\u5185\u5b58\u7a7a\u95f4 c = tf . constant ([ 1.0 , 2.0 ]) print ( c ) print ( id ( c )) c = c + tf . constant ([ 1.0 , 1.0 ]) print ( c ) print ( id ( c )) tf.Tensor([1. 2.], shape=(2,), dtype=float32) 5276289568 tf.Tensor([2. 3.], shape=(2,), dtype=float32) 5276290240 # \u53d8\u91cf\u7684\u503c\u53ef\u4ee5\u6539\u53d8\uff0c\u53ef\u4ee5\u901a\u8fc7assign, assign_add\u7b49\u65b9\u6cd5\u7ed9\u53d8\u91cf\u91cd\u65b0\u8d4b\u503c v = tf . Variable ([ 1.0 , 2.0 ], name = \"v\" ) print ( v ) print ( id ( v )) v . assign_add ([ 1.0 , 1.0 ]) print ( v ) print ( id ( v )) <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)> 5276259888 <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)> 5276259888 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#2-1\u5f20\u91cf\u6570\u636e\u7ed3\u6784","text":"\u7a0b\u5e8f = \u6570\u636e\u7ed3\u6784+\u7b97\u6cd5\u3002 TensorFlow\u7a0b\u5e8f = \u5f20\u91cf\u6570\u636e\u7ed3\u6784 + \u8ba1\u7b97\u56fe\u7b97\u6cd5\u8bed\u8a00 \u5f20\u91cf\u548c\u8ba1\u7b97\u56fe\u662f TensorFlow\u7684\u6838\u5fc3\u6982\u5ff5\u3002 Tensorflow\u7684\u57fa\u672c\u6570\u636e\u7ed3\u6784\u662f\u5f20\u91cfTensor\u3002\u5f20\u91cf\u5373\u591a\u7ef4\u6570\u7ec4\u3002Tensorflow\u7684\u5f20\u91cf\u548cnumpy\u4e2d\u7684array\u5f88\u7c7b\u4f3c\u3002 \u4ece\u884c\u4e3a\u7279\u6027\u6765\u770b\uff0c\u6709\u4e24\u79cd\u7c7b\u578b\u7684\u5f20\u91cf\uff0c\u5e38\u91cfconstant\u548c\u53d8\u91cfVariable. \u5e38\u91cf\u7684\u503c\u5728\u8ba1\u7b97\u56fe\u4e2d\u4e0d\u53ef\u4ee5\u88ab\u91cd\u65b0\u8d4b\u503c\uff0c\u53d8\u91cf\u53ef\u4ee5\u5728\u8ba1\u7b97\u56fe\u4e2d\u7528assign\u7b49\u7b97\u5b50\u91cd\u65b0\u8d4b\u503c\u3002","title":"2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#\u4e00\u5e38\u91cf\u5f20\u91cf","text":"\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u548cnumpy.array\u57fa\u672c\u4e00\u4e00\u5bf9\u5e94\u3002 import numpy as np import tensorflow as tf i = tf . constant ( 1 ) # tf.int32 \u7c7b\u578b\u5e38\u91cf l = tf . constant ( 1 , dtype = tf . int64 ) # tf.int64 \u7c7b\u578b\u5e38\u91cf f = tf . constant ( 1.23 ) #tf.float32 \u7c7b\u578b\u5e38\u91cf d = tf . constant ( 3.14 , dtype = tf . double ) # tf.double \u7c7b\u578b\u5e38\u91cf s = tf . constant ( \"hello world\" ) # tf.string\u7c7b\u578b\u5e38\u91cf b = tf . constant ( True ) #tf.bool\u7c7b\u578b\u5e38\u91cf print ( tf . int64 == np . int64 ) print ( tf . bool == np . bool ) print ( tf . double == np . float64 ) print ( tf . string == np . unicode ) # tf.string\u7c7b\u578b\u548cnp.unicode\u7c7b\u578b\u4e0d\u7b49\u4ef7 True True True False \u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u53ef\u4ee5\u7528\u4e0d\u540c\u7ef4\u5ea6(rank)\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 \u6807\u91cf\u4e3a0\u7ef4\u5f20\u91cf\uff0c\u5411\u91cf\u4e3a1\u7ef4\u5f20\u91cf\uff0c\u77e9\u9635\u4e3a2\u7ef4\u5f20\u91cf\u3002 \u5f69\u8272\u56fe\u50cf\u6709rgb\u4e09\u4e2a\u901a\u9053\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a3\u7ef4\u5f20\u91cf\u3002 \u89c6\u9891\u8fd8\u6709\u65f6\u95f4\u7ef4\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a4\u7ef4\u5f20\u91cf\u3002 \u53ef\u4ee5\u7b80\u5355\u5730\u603b\u7ed3\u4e3a\uff1a\u6709\u51e0\u5c42\u4e2d\u62ec\u53f7\uff0c\u5c31\u662f\u591a\u5c11\u7ef4\u7684\u5f20\u91cf\u3002 scalar = tf . constant ( True ) #\u6807\u91cf\uff0c0\u7ef4\u5f20\u91cf print ( tf . rank ( scalar )) print ( scalar . numpy () . ndim ) # tf.rank\u7684\u4f5c\u7528\u548cnumpy\u7684ndim\u65b9\u6cd5\u76f8\u540c tf.Tensor(0, shape=(), dtype=int32) 0 vector = tf . constant ([ 1.0 , 2.0 , 3.0 , 4.0 ]) #\u5411\u91cf\uff0c1\u7ef4\u5f20\u91cf print ( tf . rank ( vector )) print ( np . ndim ( vector . numpy ())) tf.Tensor(1, shape=(), dtype=int32) 1 matrix = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) #\u77e9\u9635, 2\u7ef4\u5f20\u91cf print ( tf . rank ( matrix ) . numpy ()) print ( np . ndim ( matrix )) 2 2 tensor3 = tf . constant ([[[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]],[[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]]) # 3\u7ef4\u5f20\u91cf print ( tensor3 ) print ( tf . rank ( tensor3 )) tf.Tensor( [[[1. 2.] [3. 4.]] [[5. 6.] [7. 8.]]], shape=(2, 2, 2), dtype=float32) tf.Tensor(3, shape=(), dtype=int32) tensor4 = tf . constant ([[[[ 1.0 , 1.0 ],[ 2.0 , 2.0 ]],[[ 3.0 , 3.0 ],[ 4.0 , 4.0 ]]], [[[ 5.0 , 5.0 ],[ 6.0 , 6.0 ]],[[ 7.0 , 7.0 ],[ 8.0 , 8.0 ]]]]) # 4\u7ef4\u5f20\u91cf print ( tensor4 ) print ( tf . rank ( tensor4 )) tf.Tensor( [[[[1. 1.] [2. 2.]] [[3. 3.] [4. 4.]]] [[[5. 5.] [6. 6.]] [[7. 7.] [8. 8.]]]], shape=(2, 2, 2, 2), dtype=float32) tf.Tensor(4, shape=(), dtype=int32) \u53ef\u4ee5\u7528tf.cast\u6539\u53d8\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u3002 \u53ef\u4ee5\u7528numpy\u65b9\u6cd5\u5c06tensorflow\u4e2d\u7684\u5f20\u91cf\u8f6c\u5316\u6210numpy\u4e2d\u7684\u5f20\u91cf\u3002 \u53ef\u4ee5\u7528shape\u65b9\u6cd5\u67e5\u770b\u5f20\u91cf\u7684\u5c3a\u5bf8\u3002 h = tf . constant ([ 123 , 456 ], dtype = tf . int32 ) f = tf . cast ( h , tf . float32 ) print ( h . dtype , f . dtype ) <dtype: 'int32'> <dtype: 'float32'> y = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) print ( y . numpy ()) #\u8f6c\u6362\u6210np.array print ( y . shape ) [[1. 2.] [3. 4.]] (2, 2) u = tf . constant ( u \"\u4f60\u597d \u4e16\u754c\" ) print ( u . numpy ()) print ( u . numpy () . decode ( \"utf-8\" )) b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xe4\\xb8\\x96\\xe7\\x95\\x8c' \u4f60\u597d \u4e16\u754c","title":"\u4e00\uff0c\u5e38\u91cf\u5f20\u91cf"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#\u4e8c\u53d8\u91cf\u5f20\u91cf","text":"\u6a21\u578b\u4e2d\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\u4e00\u822c\u88ab\u8bbe\u7f6e\u6210\u53d8\u91cf\u3002 # \u5e38\u91cf\u503c\u4e0d\u53ef\u4ee5\u6539\u53d8\uff0c\u5e38\u91cf\u7684\u91cd\u65b0\u8d4b\u503c\u76f8\u5f53\u4e8e\u521b\u9020\u65b0\u7684\u5185\u5b58\u7a7a\u95f4 c = tf . constant ([ 1.0 , 2.0 ]) print ( c ) print ( id ( c )) c = c + tf . constant ([ 1.0 , 1.0 ]) print ( c ) print ( id ( c )) tf.Tensor([1. 2.], shape=(2,), dtype=float32) 5276289568 tf.Tensor([2. 3.], shape=(2,), dtype=float32) 5276290240 # \u53d8\u91cf\u7684\u503c\u53ef\u4ee5\u6539\u53d8\uff0c\u53ef\u4ee5\u901a\u8fc7assign, assign_add\u7b49\u65b9\u6cd5\u7ed9\u53d8\u91cf\u91cd\u65b0\u8d4b\u503c v = tf . Variable ([ 1.0 , 2.0 ], name = \"v\" ) print ( v ) print ( id ( v )) v . assign_add ([ 1.0 , 1.0 ]) print ( v ) print ( id ( v )) <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)> 5276259888 <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)> 5276259888 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u53d8\u91cf\u5f20\u91cf"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E4%B8%89%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE/","text":"2-2,\u4e09\u79cd\u8ba1\u7b97\u56fe # \u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph. \u5728TensorFlow1.0\u65f6\u4ee3\uff0c\u91c7\u7528\u7684\u662f\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u9700\u8981\u5148\u4f7f\u7528TensorFlow\u7684\u5404\u79cd\u7b97\u5b50\u521b\u5efa\u8ba1\u7b97\u56fe\uff0c\u7136\u540e\u518d\u5f00\u542f\u4e00\u4e2a\u4f1a\u8bddSession\uff0c\u663e\u5f0f\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u800c\u5728TensorFlow2.0\u65f6\u4ee3\uff0c\u91c7\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u5373\u6bcf\u4f7f\u7528\u4e00\u4e2a\u7b97\u5b50\u540e\uff0c\u8be5\u7b97\u5b50\u4f1a\u88ab\u52a8\u6001\u52a0\u5165\u5230\u9690\u542b\u7684\u9ed8\u8ba4\u8ba1\u7b97\u56fe\u4e2d\u7acb\u5373\u6267\u884c\u5f97\u5230\u7ed3\u679c\uff0c\u800c\u65e0\u9700\u5f00\u542fSession\u3002 \u4f7f\u7528\u52a8\u6001\u8ba1\u7b97\u56fe\u5373Eager Excution\u7684\u597d\u5904\u662f\u65b9\u4fbf\u8c03\u8bd5\u7a0b\u5e8f\uff0c\u5b83\u4f1a\u8ba9TensorFlow\u4ee3\u7801\u7684\u8868\u73b0\u548cPython\u539f\u751f\u4ee3\u7801\u7684\u8868\u73b0\u4e00\u6837\uff0c\u5199\u8d77\u6765\u5c31\u50cf\u5199numpy\u4e00\u6837\uff0c\u5404\u79cd\u65e5\u5fd7\u6253\u5370\uff0c\u63a7\u5236\u6d41\u5168\u90e8\u90fd\u662f\u53ef\u4ee5\u4f7f\u7528\u7684\u3002 \u4f7f\u7528\u52a8\u6001\u8ba1\u7b97\u56fe\u7684\u7f3a\u70b9\u662f\u8fd0\u884c\u6548\u7387\u76f8\u5bf9\u4f1a\u4f4e\u4e00\u4e9b\u3002\u56e0\u4e3a\u4f7f\u7528\u52a8\u6001\u56fe\u4f1a\u6709\u8bb8\u591a\u6b21Python\u8fdb\u7a0b\u548cTensorFlow\u7684C++\u8fdb\u7a0b\u4e4b\u95f4\u7684\u901a\u4fe1\u3002\u800c\u9759\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u5b8c\u6210\u4e4b\u540e\u51e0\u4e4e\u5168\u90e8\u5728TensorFlow\u5185\u6838\u4e0a\u4f7f\u7528C++\u4ee3\u7801\u6267\u884c\uff0c\u6548\u7387\u66f4\u9ad8\u3002\u6b64\u5916\u9759\u6001\u56fe\u4f1a\u5bf9\u8ba1\u7b97\u6b65\u9aa4\u8fdb\u884c\u4e00\u5b9a\u7684\u4f18\u5316\uff0c\u526a\u53bb\u548c\u7ed3\u679c\u65e0\u5173\u7684\u8ba1\u7b97\u6b65\u9aa4\u3002 \u5982\u679c\u9700\u8981\u5728TensorFlow2.0\u4e2d\u4f7f\u7528\u9759\u6001\u56fe\uff0c\u53ef\u4ee5\u4f7f\u7528@tf.function\u88c5\u9970\u5668\u5c06\u666e\u901aPython\u51fd\u6570\u8f6c\u6362\u6210\u5bf9\u5e94\u7684TensorFlow\u8ba1\u7b97\u56fe\u6784\u5efa\u4ee3\u7801\u3002\u8fd0\u884c\u8be5\u51fd\u6570\u5c31\u76f8\u5f53\u4e8e\u5728TensorFlow1.0\u4e2d\u7528Session\u6267\u884c\u4ee3\u7801\u3002\u4f7f\u7528tf.function\u6784\u5efa\u9759\u6001\u56fe\u7684\u65b9\u5f0f\u53eb\u505a Autograph. \u4e00\uff0c\u8ba1\u7b97\u56fe\u7b80\u4ecb # \u8ba1\u7b97\u56fe\u7531\u8282\u70b9(nodes)\u548c\u7ebf(edges)\u7ec4\u6210\u3002 \u8282\u70b9\u8868\u793a\u64cd\u4f5c\u7b26Operator\uff0c\u6216\u8005\u79f0\u4e4b\u4e3a\u7b97\u5b50\uff0c\u7ebf\u8868\u793a\u8ba1\u7b97\u95f4\u7684\u4f9d\u8d56\u3002 \u5b9e\u7ebf\u8868\u793a\u6709\u6570\u636e\u4f20\u9012\u4f9d\u8d56\uff0c\u4f20\u9012\u7684\u6570\u636e\u5373\u5f20\u91cf\u3002 \u865a\u7ebf\u901a\u5e38\u53ef\u4ee5\u8868\u793a\u63a7\u5236\u4f9d\u8d56\uff0c\u5373\u6267\u884c\u5148\u540e\u987a\u5e8f\u3002 \u4e8c\uff0c\u9759\u6001\u8ba1\u7b97\u56fe # \u5728TensorFlow1.0\u4e2d\uff0c\u4f7f\u7528\u9759\u6001\u8ba1\u7b97\u56fe\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e8c\u6b65\u5728\u4f1a\u8bdd\u4e2d\u6267\u884c\u8ba1\u7b97\u56fe\u3002 TensorFlow 1.0\u9759\u6001\u8ba1\u7b97\u56fe\u8303\u4f8b import tensorflow as tf #\u5b9a\u4e49\u8ba1\u7b97\u56fe g = tf . Graph () with g . as_default (): #placeholder\u4e3a\u5360\u4f4d\u7b26\uff0c\u6267\u884c\u4f1a\u8bdd\u65f6\u5019\u6307\u5b9a\u586b\u5145\u5bf9\u8c61 x = tf . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . string_join ([ x , y ], name = 'join' , separator = ' ' ) #\u6267\u884c\u8ba1\u7b97\u56fe with tf . Session ( graph = g ) as sess : print ( sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" })) TensorFlow2.0 \u6000\u65e7\u7248\u9759\u6001\u8ba1\u7b97\u56fe TensorFlow2.0\u4e3a\u4e86\u786e\u4fdd\u5bf9\u8001\u7248\u672ctensorflow\u9879\u76ee\u7684\u517c\u5bb9\u6027\uff0c\u5728tf.compat.v1\u5b50\u6a21\u5757\u4e2d\u4fdd\u7559\u4e86\u5bf9TensorFlow1.0\u90a3\u79cd\u9759\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u98ce\u683c\u7684\u652f\u6301\u3002 \u53ef\u79f0\u4e4b\u4e3a\u6000\u65e7\u7248\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u5df2\u7ecf\u4e0d\u63a8\u8350\u4f7f\u7528\u4e86\u3002 import tensorflow as tf g = tf . compat . v1 . Graph () with g . as_default (): x = tf . compat . v1 . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . compat . v1 . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . strings . join ([ x , y ], name = \"join\" , separator = \" \" ) with tf . compat . v1 . Session ( graph = g ) as sess : # fetches\u7684\u7ed3\u679c\u975e\u5e38\u50cf\u4e00\u4e2a\u51fd\u6570\u7684\u8fd4\u56de\u503c\uff0c\u800cfeed_dict\u4e2d\u7684\u5360\u4f4d\u7b26\u76f8\u5f53\u4e8e\u51fd\u6570\u7684\u53c2\u6570\u5e8f\u5217\u3002 result = sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" }) print ( result ) b'hello world' \u4e09\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe # \u5728TensorFlow2.0\u4e2d\uff0c\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph. \u5728TensorFlow1.0\u4e2d\uff0c\u4f7f\u7528\u9759\u6001\u8ba1\u7b97\u56fe\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e8c\u6b65\u5728\u4f1a\u8bdd\u4e2d\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u5df2\u7ecf\u4e0d\u533a\u5206\u8ba1\u7b97\u56fe\u7684\u5b9a\u4e49\u548c\u6267\u884c\u4e86\uff0c\u800c\u662f\u5b9a\u4e49\u540e\u7acb\u5373\u6267\u884c\u3002\u56e0\u6b64\u79f0\u4e4b\u4e3a Eager Excution. Eager\u8fd9\u4e2a\u82f1\u6587\u5355\u8bcd\u7684\u539f\u610f\u662f\"\u8feb\u4e0d\u53ca\u5f85\u7684\"\uff0c\u4e5f\u5c31\u662f\u7acb\u5373\u6267\u884c\u7684\u610f\u601d\u3002 # \u52a8\u6001\u8ba1\u7b97\u56fe\u5728\u6bcf\u4e2a\u7b97\u5b50\u5904\u90fd\u8fdb\u884c\u6784\u5efa\uff0c\u6784\u5efa\u540e\u7acb\u5373\u6267\u884c x = tf . constant ( \"hello\" ) y = tf . constant ( \"world\" ) z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) hello world # \u53ef\u4ee5\u5c06\u52a8\u6001\u8ba1\u7b97\u56fe\u4ee3\u7801\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5173\u7cfb\u5c01\u88c5\u6210\u51fd\u6570 def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string) \u56db\uff0cTensorFlow2.0\u7684Autograph # \u52a8\u6001\u8ba1\u7b97\u56fe\u8fd0\u884c\u6548\u7387\u76f8\u5bf9\u8f83\u4f4e\u3002 \u53ef\u4ee5\u7528@tf.function\u88c5\u9970\u5668\u5c06\u666e\u901aPython\u51fd\u6570\u8f6c\u6362\u6210\u548cTensorFlow1.0\u5bf9\u5e94\u7684\u9759\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u4ee3\u7801\u3002 \u5728TensorFlow1.0\u4e2d\uff0c\u4f7f\u7528\u8ba1\u7b97\u56fe\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e8c\u6b65\u5728\u4f1a\u8bdd\u4e2d\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u5728TensorFlow2.0\u4e2d\uff0c\u5982\u679c\u91c7\u7528Autograph\u7684\u65b9\u5f0f\u4f7f\u7528\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\u53d8\u6210\u4e86\u5b9a\u4e49\u51fd\u6570\uff0c\u7b2c\u4e8c\u6b65\u6267\u884c\u8ba1\u7b97\u56fe\u53d8\u6210\u4e86\u8c03\u7528\u51fd\u6570\u3002 \u4e0d\u9700\u8981\u4f7f\u7528\u4f1a\u8bdd\u4e86\uff0c\u4e00\u4e9b\u90fd\u50cf\u539f\u59cb\u7684Python\u8bed\u6cd5\u4e00\u6837\u81ea\u7136\u3002 \u5b9e\u8df5\u4e2d\uff0c\u6211\u4eec\u4e00\u822c\u4f1a\u5148\u7528\u52a8\u6001\u8ba1\u7b97\u56fe\u8c03\u8bd5\u4ee3\u7801\uff0c\u7136\u540e\u5728\u9700\u8981\u63d0\u9ad8\u6027\u80fd\u7684\u7684\u5730\u65b9\u5229\u7528@tf.function\u5207\u6362\u6210Autograph\u83b7\u5f97\u66f4\u9ad8\u7684\u6548\u7387\u3002 \u5f53\u7136\uff0c@tf.function\u7684\u4f7f\u7528\u9700\u8981\u9075\u5faa\u4e00\u5b9a\u7684\u89c4\u8303\uff0c\u6211\u4eec\u540e\u9762\u7ae0\u8282\u5c06\u91cd\u70b9\u4ecb\u7ecd\u3002 import tensorflow as tf # \u4f7f\u7528autograph\u6784\u5efa\u9759\u6001\u56fe @tf . function def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string) import datetime # \u521b\u5efa\u65e5\u5fd7 import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## \u5728 Python3 \u4e0b\u5efa\u8bae\u4f7f\u7528 pathlib \u4fee\u6b63\u5404\u64cd\u4f5c\u7cfb\u7edf\u7684\u8def\u5f84 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) writer = tf . summary . create_file_writer ( logdir ) #\u5f00\u542fautograph\u8ddf\u8e2a tf . summary . trace_on ( graph = True , profiler = True ) #\u6267\u884cautograph result = strjoin ( \"hello\" , \"world\" ) #\u5c06\u8ba1\u7b97\u56fe\u4fe1\u606f\u5199\u5165\u65e5\u5fd7 with writer . as_default (): tf . summary . trace_export ( name = \"autograph\" , step = 0 , profiler_outdir = logdir ) #\u542f\u52a8 tensorboard\u5728jupyter\u4e2d\u7684\u9b54\u6cd5\u547d\u4ee4 % load_ext tensorboard #\u542f\u52a8tensorboard % tensorboard -- logdir ../../ data / autograph / \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"2-2,\u4e09\u79cd\u8ba1\u7b97\u56fe"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E4%B8%89%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE/#2-2\u4e09\u79cd\u8ba1\u7b97\u56fe","text":"\u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph. \u5728TensorFlow1.0\u65f6\u4ee3\uff0c\u91c7\u7528\u7684\u662f\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u9700\u8981\u5148\u4f7f\u7528TensorFlow\u7684\u5404\u79cd\u7b97\u5b50\u521b\u5efa\u8ba1\u7b97\u56fe\uff0c\u7136\u540e\u518d\u5f00\u542f\u4e00\u4e2a\u4f1a\u8bddSession\uff0c\u663e\u5f0f\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u800c\u5728TensorFlow2.0\u65f6\u4ee3\uff0c\u91c7\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u5373\u6bcf\u4f7f\u7528\u4e00\u4e2a\u7b97\u5b50\u540e\uff0c\u8be5\u7b97\u5b50\u4f1a\u88ab\u52a8\u6001\u52a0\u5165\u5230\u9690\u542b\u7684\u9ed8\u8ba4\u8ba1\u7b97\u56fe\u4e2d\u7acb\u5373\u6267\u884c\u5f97\u5230\u7ed3\u679c\uff0c\u800c\u65e0\u9700\u5f00\u542fSession\u3002 \u4f7f\u7528\u52a8\u6001\u8ba1\u7b97\u56fe\u5373Eager Excution\u7684\u597d\u5904\u662f\u65b9\u4fbf\u8c03\u8bd5\u7a0b\u5e8f\uff0c\u5b83\u4f1a\u8ba9TensorFlow\u4ee3\u7801\u7684\u8868\u73b0\u548cPython\u539f\u751f\u4ee3\u7801\u7684\u8868\u73b0\u4e00\u6837\uff0c\u5199\u8d77\u6765\u5c31\u50cf\u5199numpy\u4e00\u6837\uff0c\u5404\u79cd\u65e5\u5fd7\u6253\u5370\uff0c\u63a7\u5236\u6d41\u5168\u90e8\u90fd\u662f\u53ef\u4ee5\u4f7f\u7528\u7684\u3002 \u4f7f\u7528\u52a8\u6001\u8ba1\u7b97\u56fe\u7684\u7f3a\u70b9\u662f\u8fd0\u884c\u6548\u7387\u76f8\u5bf9\u4f1a\u4f4e\u4e00\u4e9b\u3002\u56e0\u4e3a\u4f7f\u7528\u52a8\u6001\u56fe\u4f1a\u6709\u8bb8\u591a\u6b21Python\u8fdb\u7a0b\u548cTensorFlow\u7684C++\u8fdb\u7a0b\u4e4b\u95f4\u7684\u901a\u4fe1\u3002\u800c\u9759\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u5b8c\u6210\u4e4b\u540e\u51e0\u4e4e\u5168\u90e8\u5728TensorFlow\u5185\u6838\u4e0a\u4f7f\u7528C++\u4ee3\u7801\u6267\u884c\uff0c\u6548\u7387\u66f4\u9ad8\u3002\u6b64\u5916\u9759\u6001\u56fe\u4f1a\u5bf9\u8ba1\u7b97\u6b65\u9aa4\u8fdb\u884c\u4e00\u5b9a\u7684\u4f18\u5316\uff0c\u526a\u53bb\u548c\u7ed3\u679c\u65e0\u5173\u7684\u8ba1\u7b97\u6b65\u9aa4\u3002 \u5982\u679c\u9700\u8981\u5728TensorFlow2.0\u4e2d\u4f7f\u7528\u9759\u6001\u56fe\uff0c\u53ef\u4ee5\u4f7f\u7528@tf.function\u88c5\u9970\u5668\u5c06\u666e\u901aPython\u51fd\u6570\u8f6c\u6362\u6210\u5bf9\u5e94\u7684TensorFlow\u8ba1\u7b97\u56fe\u6784\u5efa\u4ee3\u7801\u3002\u8fd0\u884c\u8be5\u51fd\u6570\u5c31\u76f8\u5f53\u4e8e\u5728TensorFlow1.0\u4e2d\u7528Session\u6267\u884c\u4ee3\u7801\u3002\u4f7f\u7528tf.function\u6784\u5efa\u9759\u6001\u56fe\u7684\u65b9\u5f0f\u53eb\u505a Autograph.","title":"2-2,\u4e09\u79cd\u8ba1\u7b97\u56fe"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E4%B8%89%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e00\u8ba1\u7b97\u56fe\u7b80\u4ecb","text":"\u8ba1\u7b97\u56fe\u7531\u8282\u70b9(nodes)\u548c\u7ebf(edges)\u7ec4\u6210\u3002 \u8282\u70b9\u8868\u793a\u64cd\u4f5c\u7b26Operator\uff0c\u6216\u8005\u79f0\u4e4b\u4e3a\u7b97\u5b50\uff0c\u7ebf\u8868\u793a\u8ba1\u7b97\u95f4\u7684\u4f9d\u8d56\u3002 \u5b9e\u7ebf\u8868\u793a\u6709\u6570\u636e\u4f20\u9012\u4f9d\u8d56\uff0c\u4f20\u9012\u7684\u6570\u636e\u5373\u5f20\u91cf\u3002 \u865a\u7ebf\u901a\u5e38\u53ef\u4ee5\u8868\u793a\u63a7\u5236\u4f9d\u8d56\uff0c\u5373\u6267\u884c\u5148\u540e\u987a\u5e8f\u3002","title":"\u4e00\uff0c\u8ba1\u7b97\u56fe\u7b80\u4ecb"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E4%B8%89%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e8c\u9759\u6001\u8ba1\u7b97\u56fe","text":"\u5728TensorFlow1.0\u4e2d\uff0c\u4f7f\u7528\u9759\u6001\u8ba1\u7b97\u56fe\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e8c\u6b65\u5728\u4f1a\u8bdd\u4e2d\u6267\u884c\u8ba1\u7b97\u56fe\u3002 TensorFlow 1.0\u9759\u6001\u8ba1\u7b97\u56fe\u8303\u4f8b import tensorflow as tf #\u5b9a\u4e49\u8ba1\u7b97\u56fe g = tf . Graph () with g . as_default (): #placeholder\u4e3a\u5360\u4f4d\u7b26\uff0c\u6267\u884c\u4f1a\u8bdd\u65f6\u5019\u6307\u5b9a\u586b\u5145\u5bf9\u8c61 x = tf . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . string_join ([ x , y ], name = 'join' , separator = ' ' ) #\u6267\u884c\u8ba1\u7b97\u56fe with tf . Session ( graph = g ) as sess : print ( sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" })) TensorFlow2.0 \u6000\u65e7\u7248\u9759\u6001\u8ba1\u7b97\u56fe TensorFlow2.0\u4e3a\u4e86\u786e\u4fdd\u5bf9\u8001\u7248\u672ctensorflow\u9879\u76ee\u7684\u517c\u5bb9\u6027\uff0c\u5728tf.compat.v1\u5b50\u6a21\u5757\u4e2d\u4fdd\u7559\u4e86\u5bf9TensorFlow1.0\u90a3\u79cd\u9759\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u98ce\u683c\u7684\u652f\u6301\u3002 \u53ef\u79f0\u4e4b\u4e3a\u6000\u65e7\u7248\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u5df2\u7ecf\u4e0d\u63a8\u8350\u4f7f\u7528\u4e86\u3002 import tensorflow as tf g = tf . compat . v1 . Graph () with g . as_default (): x = tf . compat . v1 . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . compat . v1 . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . strings . join ([ x , y ], name = \"join\" , separator = \" \" ) with tf . compat . v1 . Session ( graph = g ) as sess : # fetches\u7684\u7ed3\u679c\u975e\u5e38\u50cf\u4e00\u4e2a\u51fd\u6570\u7684\u8fd4\u56de\u503c\uff0c\u800cfeed_dict\u4e2d\u7684\u5360\u4f4d\u7b26\u76f8\u5f53\u4e8e\u51fd\u6570\u7684\u53c2\u6570\u5e8f\u5217\u3002 result = sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" }) print ( result ) b'hello world'","title":"\u4e8c\uff0c\u9759\u6001\u8ba1\u7b97\u56fe"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E4%B8%89%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e09\u52a8\u6001\u8ba1\u7b97\u56fe","text":"\u5728TensorFlow2.0\u4e2d\uff0c\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph. \u5728TensorFlow1.0\u4e2d\uff0c\u4f7f\u7528\u9759\u6001\u8ba1\u7b97\u56fe\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e8c\u6b65\u5728\u4f1a\u8bdd\u4e2d\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u5df2\u7ecf\u4e0d\u533a\u5206\u8ba1\u7b97\u56fe\u7684\u5b9a\u4e49\u548c\u6267\u884c\u4e86\uff0c\u800c\u662f\u5b9a\u4e49\u540e\u7acb\u5373\u6267\u884c\u3002\u56e0\u6b64\u79f0\u4e4b\u4e3a Eager Excution. Eager\u8fd9\u4e2a\u82f1\u6587\u5355\u8bcd\u7684\u539f\u610f\u662f\"\u8feb\u4e0d\u53ca\u5f85\u7684\"\uff0c\u4e5f\u5c31\u662f\u7acb\u5373\u6267\u884c\u7684\u610f\u601d\u3002 # \u52a8\u6001\u8ba1\u7b97\u56fe\u5728\u6bcf\u4e2a\u7b97\u5b50\u5904\u90fd\u8fdb\u884c\u6784\u5efa\uff0c\u6784\u5efa\u540e\u7acb\u5373\u6267\u884c x = tf . constant ( \"hello\" ) y = tf . constant ( \"world\" ) z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) hello world # \u53ef\u4ee5\u5c06\u52a8\u6001\u8ba1\u7b97\u56fe\u4ee3\u7801\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5173\u7cfb\u5c01\u88c5\u6210\u51fd\u6570 def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string)","title":"\u4e09\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E4%B8%89%E7%A7%8D%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u56dbtensorflow20\u7684autograph","text":"\u52a8\u6001\u8ba1\u7b97\u56fe\u8fd0\u884c\u6548\u7387\u76f8\u5bf9\u8f83\u4f4e\u3002 \u53ef\u4ee5\u7528@tf.function\u88c5\u9970\u5668\u5c06\u666e\u901aPython\u51fd\u6570\u8f6c\u6362\u6210\u548cTensorFlow1.0\u5bf9\u5e94\u7684\u9759\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u4ee3\u7801\u3002 \u5728TensorFlow1.0\u4e2d\uff0c\u4f7f\u7528\u8ba1\u7b97\u56fe\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e8c\u6b65\u5728\u4f1a\u8bdd\u4e2d\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u5728TensorFlow2.0\u4e2d\uff0c\u5982\u679c\u91c7\u7528Autograph\u7684\u65b9\u5f0f\u4f7f\u7528\u8ba1\u7b97\u56fe\uff0c\u7b2c\u4e00\u6b65\u5b9a\u4e49\u8ba1\u7b97\u56fe\u53d8\u6210\u4e86\u5b9a\u4e49\u51fd\u6570\uff0c\u7b2c\u4e8c\u6b65\u6267\u884c\u8ba1\u7b97\u56fe\u53d8\u6210\u4e86\u8c03\u7528\u51fd\u6570\u3002 \u4e0d\u9700\u8981\u4f7f\u7528\u4f1a\u8bdd\u4e86\uff0c\u4e00\u4e9b\u90fd\u50cf\u539f\u59cb\u7684Python\u8bed\u6cd5\u4e00\u6837\u81ea\u7136\u3002 \u5b9e\u8df5\u4e2d\uff0c\u6211\u4eec\u4e00\u822c\u4f1a\u5148\u7528\u52a8\u6001\u8ba1\u7b97\u56fe\u8c03\u8bd5\u4ee3\u7801\uff0c\u7136\u540e\u5728\u9700\u8981\u63d0\u9ad8\u6027\u80fd\u7684\u7684\u5730\u65b9\u5229\u7528@tf.function\u5207\u6362\u6210Autograph\u83b7\u5f97\u66f4\u9ad8\u7684\u6548\u7387\u3002 \u5f53\u7136\uff0c@tf.function\u7684\u4f7f\u7528\u9700\u8981\u9075\u5faa\u4e00\u5b9a\u7684\u89c4\u8303\uff0c\u6211\u4eec\u540e\u9762\u7ae0\u8282\u5c06\u91cd\u70b9\u4ecb\u7ecd\u3002 import tensorflow as tf # \u4f7f\u7528autograph\u6784\u5efa\u9759\u6001\u56fe @tf . function def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string) import datetime # \u521b\u5efa\u65e5\u5fd7 import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## \u5728 Python3 \u4e0b\u5efa\u8bae\u4f7f\u7528 pathlib \u4fee\u6b63\u5404\u64cd\u4f5c\u7cfb\u7edf\u7684\u8def\u5f84 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) writer = tf . summary . create_file_writer ( logdir ) #\u5f00\u542fautograph\u8ddf\u8e2a tf . summary . trace_on ( graph = True , profiler = True ) #\u6267\u884cautograph result = strjoin ( \"hello\" , \"world\" ) #\u5c06\u8ba1\u7b97\u56fe\u4fe1\u606f\u5199\u5165\u65e5\u5fd7 with writer . as_default (): tf . summary . trace_export ( name = \"autograph\" , step = 0 , profiler_outdir = logdir ) #\u542f\u52a8 tensorboard\u5728jupyter\u4e2d\u7684\u9b54\u6cd5\u547d\u4ee4 % load_ext tensorboard #\u542f\u52a8tensorboard % tensorboard -- logdir ../../ data / autograph / \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0cTensorFlow2.0\u7684Autograph"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/","text":"2-3,\u81ea\u52a8\u5fae\u5206\u673a\u5236 # \u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u4f9d\u8d56\u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6\u6765\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0c\u6c42\u68af\u5ea6\u8fc7\u7a0b\u901a\u5e38\u662f\u4e00\u4ef6\u975e\u5e38\u590d\u6742\u800c\u5bb9\u6613\u51fa\u9519\u7684\u4e8b\u60c5\u3002 \u800c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u81ea\u52a8\u5730\u5b8c\u6210\u8fd9\u79cd\u6c42\u68af\u5ea6\u8fd0\u7b97\u3002 Tensorflow\u4e00\u822c\u4f7f\u7528\u68af\u5ea6\u78c1\u5e26tf.GradientTape\u6765\u8bb0\u5f55\u6b63\u5411\u8fd0\u7b97\u8fc7\u7a0b\uff0c\u7136\u540e\u53cd\u64ad\u78c1\u5e26\u81ea\u52a8\u5f97\u5230\u68af\u5ea6\u503c\u3002 \u8fd9\u79cd\u5229\u7528tf.GradientTape\u6c42\u5fae\u5206\u7684\u65b9\u6cd5\u53eb\u505aTensorflow\u7684\u81ea\u52a8\u5fae\u5206\u673a\u5236\u3002 \u4e00\uff0c\u5229\u7528\u68af\u5ea6\u78c1\u5e26\u6c42\u5bfc\u6570 # import tensorflow as tf import numpy as np # f(x) = a*x**2 + b*x + c\u7684\u5bfc\u6570 x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) print ( dy_dx ) tf.Tensor(-2.0, shape=(), dtype=float32) # \u5bf9\u5e38\u91cf\u5f20\u91cf\u4e5f\u53ef\u4ee5\u6c42\u5bfc\uff0c\u9700\u8981\u589e\u52a0watch with tf . GradientTape () as tape : tape . watch ([ a , b , c ]) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx , dy_da , dy_db , dy_dc = tape . gradient ( y ,[ x , a , b , c ]) print ( dy_da ) print ( dy_dc ) tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32) # \u53ef\u4ee5\u6c42\u4e8c\u9636\u5bfc\u6570 with tf . GradientTape () as tape2 : with tf . GradientTape () as tape1 : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape1 . gradient ( y , x ) dy2_dx2 = tape2 . gradient ( dy_dx , x ) print ( dy2_dx2 ) tf.Tensor(2.0, shape=(), dtype=float32) # \u53ef\u4ee5\u5728autograph\u4e2d\u4f7f\u7528 @tf . function def f ( x ): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) # \u81ea\u53d8\u91cf\u8f6c\u6362\u6210tf.float32 x = tf . cast ( x , tf . float32 ) with tf . GradientTape () as tape : tape . watch ( x ) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) return (( dy_dx , y )) tf . print ( f ( tf . constant ( 0.0 ))) tf . print ( f ( tf . constant ( 1.0 ))) (-2, 1) (0, 0) \u4e8c\uff0c\u5229\u7528\u68af\u5ea6\u78c1\u5e26\u548c\u4f18\u5316\u5668\u6c42\u6700\u5c0f\u503c # # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) tf . print ( \"y =\" , y , \"; x =\" , x ) y = 0 ; x = 0.999998569 # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.minimize # optimizer.minimize\u76f8\u5f53\u4e8e\u5148\u7528tape\u6c42gradient,\u518dapply_gradient x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) #\u6ce8\u610ff()\u65e0\u53c2\u6570 def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): optimizer . minimize ( f ,[ x ]) tf . print ( \"y =\" , f (), \"; x =\" , x ) y = 0 ; x = 0.999998569 # \u5728autograph\u4e2d\u5b8c\u6210\u6700\u5c0f\u503c\u6c42\u89e3 # \u4f7f\u7528optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) for _ in tf . range ( 1000 ): #\u6ce8\u610fautograph\u65f6\u4f7f\u7528tf.range(1000)\u800c\u4e0d\u662frange(1000) with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( minimizef ()) tf . print ( x ) 0 0.999998569 # \u5728autograph\u4e2d\u5b8c\u6210\u6700\u5c0f\u503c\u6c42\u89e3 # \u4f7f\u7528optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) return ( f ()) tf . print ( train ( 1000 )) tf . print ( x ) 0 0.999998569 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"2-3,\u81ea\u52a8\u5fae\u5206\u673a\u5236"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#2-3\u81ea\u52a8\u5fae\u5206\u673a\u5236","text":"\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u4f9d\u8d56\u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6\u6765\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0c\u6c42\u68af\u5ea6\u8fc7\u7a0b\u901a\u5e38\u662f\u4e00\u4ef6\u975e\u5e38\u590d\u6742\u800c\u5bb9\u6613\u51fa\u9519\u7684\u4e8b\u60c5\u3002 \u800c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u81ea\u52a8\u5730\u5b8c\u6210\u8fd9\u79cd\u6c42\u68af\u5ea6\u8fd0\u7b97\u3002 Tensorflow\u4e00\u822c\u4f7f\u7528\u68af\u5ea6\u78c1\u5e26tf.GradientTape\u6765\u8bb0\u5f55\u6b63\u5411\u8fd0\u7b97\u8fc7\u7a0b\uff0c\u7136\u540e\u53cd\u64ad\u78c1\u5e26\u81ea\u52a8\u5f97\u5230\u68af\u5ea6\u503c\u3002 \u8fd9\u79cd\u5229\u7528tf.GradientTape\u6c42\u5fae\u5206\u7684\u65b9\u6cd5\u53eb\u505aTensorflow\u7684\u81ea\u52a8\u5fae\u5206\u673a\u5236\u3002","title":"2-3,\u81ea\u52a8\u5fae\u5206\u673a\u5236"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#\u4e00\u5229\u7528\u68af\u5ea6\u78c1\u5e26\u6c42\u5bfc\u6570","text":"import tensorflow as tf import numpy as np # f(x) = a*x**2 + b*x + c\u7684\u5bfc\u6570 x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) print ( dy_dx ) tf.Tensor(-2.0, shape=(), dtype=float32) # \u5bf9\u5e38\u91cf\u5f20\u91cf\u4e5f\u53ef\u4ee5\u6c42\u5bfc\uff0c\u9700\u8981\u589e\u52a0watch with tf . GradientTape () as tape : tape . watch ([ a , b , c ]) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx , dy_da , dy_db , dy_dc = tape . gradient ( y ,[ x , a , b , c ]) print ( dy_da ) print ( dy_dc ) tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32) # \u53ef\u4ee5\u6c42\u4e8c\u9636\u5bfc\u6570 with tf . GradientTape () as tape2 : with tf . GradientTape () as tape1 : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape1 . gradient ( y , x ) dy2_dx2 = tape2 . gradient ( dy_dx , x ) print ( dy2_dx2 ) tf.Tensor(2.0, shape=(), dtype=float32) # \u53ef\u4ee5\u5728autograph\u4e2d\u4f7f\u7528 @tf . function def f ( x ): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) # \u81ea\u53d8\u91cf\u8f6c\u6362\u6210tf.float32 x = tf . cast ( x , tf . float32 ) with tf . GradientTape () as tape : tape . watch ( x ) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) return (( dy_dx , y )) tf . print ( f ( tf . constant ( 0.0 ))) tf . print ( f ( tf . constant ( 1.0 ))) (-2, 1) (0, 0)","title":"\u4e00\uff0c\u5229\u7528\u68af\u5ea6\u78c1\u5e26\u6c42\u5bfc\u6570"},{"location":"chinese/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#\u4e8c\u5229\u7528\u68af\u5ea6\u78c1\u5e26\u548c\u4f18\u5316\u5668\u6c42\u6700\u5c0f\u503c","text":"# \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) tf . print ( \"y =\" , y , \"; x =\" , x ) y = 0 ; x = 0.999998569 # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.minimize # optimizer.minimize\u76f8\u5f53\u4e8e\u5148\u7528tape\u6c42gradient,\u518dapply_gradient x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) #\u6ce8\u610ff()\u65e0\u53c2\u6570 def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): optimizer . minimize ( f ,[ x ]) tf . print ( \"y =\" , f (), \"; x =\" , x ) y = 0 ; x = 0.999998569 # \u5728autograph\u4e2d\u5b8c\u6210\u6700\u5c0f\u503c\u6c42\u89e3 # \u4f7f\u7528optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) for _ in tf . range ( 1000 ): #\u6ce8\u610fautograph\u65f6\u4f7f\u7528tf.range(1000)\u800c\u4e0d\u662frange(1000) with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( minimizef ()) tf . print ( x ) 0 0.999998569 # \u5728autograph\u4e2d\u5b8c\u6210\u6700\u5c0f\u503c\u6c42\u89e3 # \u4f7f\u7528optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) return ( f ()) tf . print ( train ( 1000 )) tf . print ( x ) 0 0.999998569 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u5229\u7528\u68af\u5ea6\u78c1\u5e26\u548c\u4f18\u5316\u5668\u6c42\u6700\u5c0f\u503c"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/","text":"\u4e09\u3001TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784 # \u672c\u7ae0\u6211\u4eec\u4ecb\u7ecdTensorFlow\u4e2d5\u4e2a\u4e0d\u540c\u7684\u5c42\u6b21\u7ed3\u6784\uff1a\u5373\u786c\u4ef6\u5c42\uff0c\u5185\u6838\u5c42\uff0c\u4f4e\u9636API\uff0c\u4e2d\u9636API\uff0c\u9ad8\u9636API\u3002\u5e76\u4ee5\u7ebf\u6027\u56de\u5f52\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u4e3a\u4f8b\uff0c\u76f4\u89c2\u5bf9\u6bd4\u5c55\u793a\u5728\u4e0d\u540c\u5c42\u7ea7\u5b9e\u73b0\u6a21\u578b\u7684\u7279\u70b9\u3002 TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784\u4ece\u4f4e\u5230\u9ad8\u53ef\u4ee5\u5206\u6210\u5982\u4e0b\u4e94\u5c42\u3002 \u6700\u5e95\u5c42\u4e3a\u786c\u4ef6\u5c42\uff0cTensorFlow\u652f\u6301CPU\u3001GPU\u6216TPU\u52a0\u5165\u8ba1\u7b97\u8d44\u6e90\u6c60\u3002 \u7b2c\u4e8c\u5c42\u4e3aC++\u5b9e\u73b0\u7684\u5185\u6838\uff0ckernel\u53ef\u4ee5\u8de8\u5e73\u53f0\u5206\u5e03\u8fd0\u884c\u3002 \u7b2c\u4e09\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u64cd\u4f5c\u7b26\uff0c\u63d0\u4f9b\u4e86\u5c01\u88c5C++\u5185\u6838\u7684\u4f4e\u7ea7API\u6307\u4ee4\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u5f20\u91cf\u64cd\u4f5c\u7b97\u5b50\u3001\u8ba1\u7b97\u56fe\u3001\u81ea\u52a8\u5fae\u5206. \u5982tf.Variable,tf.constant,tf.function,tf.GradientTape,tf.nn.softmax... \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e09\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u7b2c\u56db\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u7ec4\u4ef6\uff0c\u5bf9\u4f4e\u7ea7API\u8fdb\u884c\u4e86\u51fd\u6570\u5c01\u88c5\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\uff0c\u7279\u5f81\u5217\u7b49\u7b49\u3002 \u5982tf.keras.layers,tf.keras.losses,tf.keras.metrics,tf.keras.optimizers,tf.data.DataSet,tf.feature_column... \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u56db\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u7b2c\u4e94\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u6210\u54c1\uff0c\u4e00\u822c\u4e3a\u6309\u7167OOP\u65b9\u5f0f\u5c01\u88c5\u7684\u9ad8\u7ea7API\uff0c\u4e3b\u8981\u4e3atf.keras.models\u63d0\u4f9b\u7684\u6a21\u578b\u7684\u7c7b\u63a5\u53e3\u3002 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e94\u5c42API\u5c31\u662f\u6a21\u578b\u672c\u8eab\uff0c\u5373\u3010\u6a21\u578b\u4e4b\u5c4b\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\u3001TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/#\u4e09tensorflow\u7684\u5c42\u6b21\u7ed3\u6784","text":"\u672c\u7ae0\u6211\u4eec\u4ecb\u7ecdTensorFlow\u4e2d5\u4e2a\u4e0d\u540c\u7684\u5c42\u6b21\u7ed3\u6784\uff1a\u5373\u786c\u4ef6\u5c42\uff0c\u5185\u6838\u5c42\uff0c\u4f4e\u9636API\uff0c\u4e2d\u9636API\uff0c\u9ad8\u9636API\u3002\u5e76\u4ee5\u7ebf\u6027\u56de\u5f52\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u4e3a\u4f8b\uff0c\u76f4\u89c2\u5bf9\u6bd4\u5c55\u793a\u5728\u4e0d\u540c\u5c42\u7ea7\u5b9e\u73b0\u6a21\u578b\u7684\u7279\u70b9\u3002 TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784\u4ece\u4f4e\u5230\u9ad8\u53ef\u4ee5\u5206\u6210\u5982\u4e0b\u4e94\u5c42\u3002 \u6700\u5e95\u5c42\u4e3a\u786c\u4ef6\u5c42\uff0cTensorFlow\u652f\u6301CPU\u3001GPU\u6216TPU\u52a0\u5165\u8ba1\u7b97\u8d44\u6e90\u6c60\u3002 \u7b2c\u4e8c\u5c42\u4e3aC++\u5b9e\u73b0\u7684\u5185\u6838\uff0ckernel\u53ef\u4ee5\u8de8\u5e73\u53f0\u5206\u5e03\u8fd0\u884c\u3002 \u7b2c\u4e09\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u64cd\u4f5c\u7b26\uff0c\u63d0\u4f9b\u4e86\u5c01\u88c5C++\u5185\u6838\u7684\u4f4e\u7ea7API\u6307\u4ee4\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u5f20\u91cf\u64cd\u4f5c\u7b97\u5b50\u3001\u8ba1\u7b97\u56fe\u3001\u81ea\u52a8\u5fae\u5206. \u5982tf.Variable,tf.constant,tf.function,tf.GradientTape,tf.nn.softmax... \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e09\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u7b2c\u56db\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u7ec4\u4ef6\uff0c\u5bf9\u4f4e\u7ea7API\u8fdb\u884c\u4e86\u51fd\u6570\u5c01\u88c5\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\uff0c\u7279\u5f81\u5217\u7b49\u7b49\u3002 \u5982tf.keras.layers,tf.keras.losses,tf.keras.metrics,tf.keras.optimizers,tf.data.DataSet,tf.feature_column... \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u56db\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u7b2c\u4e94\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u6210\u54c1\uff0c\u4e00\u822c\u4e3a\u6309\u7167OOP\u65b9\u5f0f\u5c01\u88c5\u7684\u9ad8\u7ea7API\uff0c\u4e3b\u8981\u4e3atf.keras.models\u63d0\u4f9b\u7684\u6a21\u578b\u7684\u7c7b\u63a5\u53e3\u3002 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e94\u5c42API\u5c31\u662f\u6a21\u578b\u672c\u8eab\uff0c\u5373\u3010\u6a21\u578b\u4e4b\u5c4b\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\u3001TensorFlow\u7684\u5c42\u6b21\u7ed3\u6784"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/","text":"3-1,\u4f4e\u9636API\u793a\u8303 # \u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528TensorFlow\u7684\u4f4e\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 \u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) \u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 2.6161194 0.11071014] [ 9.79207 -0.70180416] [ 9.792343 6.9149055 ] [-2.4186516 -9.375019 ] [ 9.83749 -3.4637213 ] [ 7.3953056 4.374569 ] [-0.14686584 -0.28063297] [ 0.49001217 -9.739792 ]], shape=(8, 2), dtype=float32) tf.Tensor( [[ 9.334667 ] [22.058844 ] [ 3.0695205] [26.736238 ] [35.292133 ] [ 4.2943544] [ 1.6713585] [34.826904 ]], shape=(8, 1), dtype=float32) 2\uff0c\u5b9a\u4e49\u6a21\u578b w = tf . Variable ( tf . random . normal ( w0 . shape )) b = tf . Variable ( tf . zeros_like ( b0 , dtype = tf . float32 )) # \u5b9a\u4e49\u6a21\u578b class LinearRegression : #\u6b63\u5411\u4f20\u64ad def __call__ ( self , x ): return x @w + b # \u635f\u5931\u51fd\u6570 def loss_func ( self , y_true , y_pred ): return tf . reduce_mean (( y_true - y_pred ) ** 2 / 2 ) model = LinearRegression () 3\uff0c\u8bad\u7ec3\u6a21\u578b # \u4f7f\u7528\u52a8\u6001\u56fe\u8c03\u8bd5 def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss # \u6d4b\u8bd5train_step\u6548\u679c batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) train_step ( model , features , labels ) <tf.Tensor: shape=(), dtype=float32, numpy=211.09982> def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:35:56 epoch = 50 loss = 1.78806472 w = [[1.97554708] [-2.97719598]] b = [[2.60692883]] ================================================================================16:36:00 epoch = 100 loss = 2.64588404 w = [[1.97319281] [-2.97810626]] b = [[2.95525956]] ================================================================================16:36:04 epoch = 150 loss = 1.42576694 w = [[1.96466208] [-2.98337793]] b = [[3.00264144]] ================================================================================16:36:08 epoch = 200 loss = 1.68992615 w = [[1.97718477] [-2.983814]] b = [[3.01013041]] ##\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:36:35 epoch = 50 loss = 0.894210339 w = [[1.96927285] [-2.98914337]] b = [[3.00987792]] ================================================================================16:36:36 epoch = 100 loss = 1.58621466 w = [[1.97566223] [-2.98550248]] b = [[3.00998402]] ================================================================================16:36:37 epoch = 150 loss = 2.2695992 w = [[1.96664226] [-2.99248481]] b = [[3.01028705]] ================================================================================16:36:38 epoch = 200 loss = 1.90848124 w = [[1.98000824] [-2.98888135]] b = [[3.01085401]] # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () \u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 0.03732629 3.5783494 ] [ 0.542919 5.035079 ] [ 5.860281 -2.4476354 ] [ 0.63657564 3.194231 ] [-3.5072308 2.5578873 ] [-2.4109735 -3.6621518 ] [ 4.0975413 -2.4172943 ] [ 1.9393908 -6.782317 ] [-4.7453732 -0.5176727 ] [-1.4057113 -7.9775257 ]], shape=(10, 2), dtype=float32) tf.Tensor( [[1.] [1.] [0.] [1.] [1.] [1.] [1.] [0.] [1.] [0.]], shape=(10, 1), dtype=float32) 2\uff0c\u5b9a\u4e49\u6a21\u578b \u6b64\u5904\u8303\u4f8b\u6211\u4eec\u5229\u7528tf.Module\u6765\u7ec4\u7ec7\u6a21\u578b\u53d8\u91cf\uff0c\u5173\u4e8etf.Module\u7684\u8f83\u8be6\u7ec6\u4ecb\u7ecd\u53c2\u8003\u672c\u4e66\u7b2c\u56db\u7ae0\u6700\u540e\u4e00\u8282: Autograph\u548ctf.Module\u3002 class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . w1 = tf . Variable ( tf . random . truncated_normal ([ 2 , 4 ]), dtype = tf . float32 ) self . b1 = tf . Variable ( tf . zeros ([ 1 , 4 ]), dtype = tf . float32 ) self . w2 = tf . Variable ( tf . random . truncated_normal ([ 4 , 8 ]), dtype = tf . float32 ) self . b2 = tf . Variable ( tf . zeros ([ 1 , 8 ]), dtype = tf . float32 ) self . w3 = tf . Variable ( tf . random . truncated_normal ([ 8 , 1 ]), dtype = tf . float32 ) self . b3 = tf . Variable ( tf . zeros ([ 1 , 1 ]), dtype = tf . float32 ) # \u6b63\u5411\u4f20\u64ad @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = tf . nn . relu ( x @self . w1 + self . b1 ) x = tf . nn . relu ( x @self . w2 + self . b2 ) y = tf . nn . sigmoid ( x @self . w3 + self . b3 ) return y # \u635f\u5931\u51fd\u6570(\u4e8c\u5143\u4ea4\u53c9\u71b5) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def loss_func ( self , y_true , y_pred ): #\u5c06\u9884\u6d4b\u503c\u9650\u5236\u5728 1e-7 \u4ee5\u4e0a, 1 - 1e-7 \u4ee5\u4e0b\uff0c\u907f\u514dlog(0)\u9519\u8bef eps = 1e-7 y_pred = tf . clip_by_value ( y_pred , eps , 1.0 - eps ) bce = - y_true * tf . math . log ( y_pred ) - ( 1 - y_true ) * tf . math . log ( 1 - y_pred ) return tf . reduce_mean ( bce ) # \u8bc4\u4f30\u6307\u6807(\u51c6\u786e\u7387) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def metric_func ( self , y_true , y_pred ): y_pred = tf . where ( y_pred > 0.5 , tf . ones_like ( y_pred , dtype = tf . float32 ), tf . zeros_like ( y_pred , dtype = tf . float32 )) acc = tf . reduce_mean ( 1 - tf . abs ( y_true - y_pred )) return acc model = DNNModel () # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) predictions = model ( features ) loss = model . loss_func ( labels , predictions ) metric = model . metric_func ( labels , predictions ) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.76568353 init metric 0.6 print ( len ( model . trainable_variables )) 6 3\uff0c\u8bad\u7ec3\u6a21\u578b ##\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 grads = tape . gradient ( loss , model . trainable_variables ) # \u6267\u884c\u68af\u5ea6\u4e0b\u964d for p , dloss_dp in zip ( model . trainable_variables , grads ): p . assign ( p - 0.001 * dloss_dp ) # \u8ba1\u7b97\u8bc4\u4f30\u6307\u6807 metric = model . metric_func ( labels , predictions ) return loss , metric def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 100 ): loss , metric = train_step ( model , features , labels ) if epoch % 100 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 600 ) ================================================================================16:47:35 epoch = 100 loss = 0.567795336 accuracy = 0.71 ================================================================================16:47:39 epoch = 200 loss = 0.50955683 accuracy = 0.77 ================================================================================16:47:43 epoch = 300 loss = 0.421476126 accuracy = 0.84 ================================================================================16:47:47 epoch = 400 loss = 0.330618203 accuracy = 0.9 ================================================================================16:47:51 epoch = 500 loss = 0.308296859 accuracy = 0.89 ================================================================================16:47:55 epoch = 600 loss = 0.279367268 accuracy = 0.96 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"3-1,\u4f4e\u9636API\u793a\u8303"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/#3-1\u4f4e\u9636api\u793a\u8303","text":"\u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528TensorFlow\u7684\u4f4e\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 \u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"3-1,\u4f4e\u9636API\u793a\u8303"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e00\u7ebf\u6027\u56de\u5f52\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 2.6161194 0.11071014] [ 9.79207 -0.70180416] [ 9.792343 6.9149055 ] [-2.4186516 -9.375019 ] [ 9.83749 -3.4637213 ] [ 7.3953056 4.374569 ] [-0.14686584 -0.28063297] [ 0.49001217 -9.739792 ]], shape=(8, 2), dtype=float32) tf.Tensor( [[ 9.334667 ] [22.058844 ] [ 3.0695205] [26.736238 ] [35.292133 ] [ 4.2943544] [ 1.6713585] [34.826904 ]], shape=(8, 1), dtype=float32) 2\uff0c\u5b9a\u4e49\u6a21\u578b w = tf . Variable ( tf . random . normal ( w0 . shape )) b = tf . Variable ( tf . zeros_like ( b0 , dtype = tf . float32 )) # \u5b9a\u4e49\u6a21\u578b class LinearRegression : #\u6b63\u5411\u4f20\u64ad def __call__ ( self , x ): return x @w + b # \u635f\u5931\u51fd\u6570 def loss_func ( self , y_true , y_pred ): return tf . reduce_mean (( y_true - y_pred ) ** 2 / 2 ) model = LinearRegression () 3\uff0c\u8bad\u7ec3\u6a21\u578b # \u4f7f\u7528\u52a8\u6001\u56fe\u8c03\u8bd5 def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss # \u6d4b\u8bd5train_step\u6548\u679c batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) train_step ( model , features , labels ) <tf.Tensor: shape=(), dtype=float32, numpy=211.09982> def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:35:56 epoch = 50 loss = 1.78806472 w = [[1.97554708] [-2.97719598]] b = [[2.60692883]] ================================================================================16:36:00 epoch = 100 loss = 2.64588404 w = [[1.97319281] [-2.97810626]] b = [[2.95525956]] ================================================================================16:36:04 epoch = 150 loss = 1.42576694 w = [[1.96466208] [-2.98337793]] b = [[3.00264144]] ================================================================================16:36:08 epoch = 200 loss = 1.68992615 w = [[1.97718477] [-2.983814]] b = [[3.01013041]] ##\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:36:35 epoch = 50 loss = 0.894210339 w = [[1.96927285] [-2.98914337]] b = [[3.00987792]] ================================================================================16:36:36 epoch = 100 loss = 1.58621466 w = [[1.97566223] [-2.98550248]] b = [[3.00998402]] ================================================================================16:36:37 epoch = 150 loss = 2.2695992 w = [[1.96664226] [-2.99248481]] b = [[3.01028705]] ================================================================================16:36:38 epoch = 200 loss = 1.90848124 w = [[1.98000824] [-2.98888135]] b = [[3.01085401]] # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"\u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e8cdnn\u4e8c\u5206\u7c7b\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 0.03732629 3.5783494 ] [ 0.542919 5.035079 ] [ 5.860281 -2.4476354 ] [ 0.63657564 3.194231 ] [-3.5072308 2.5578873 ] [-2.4109735 -3.6621518 ] [ 4.0975413 -2.4172943 ] [ 1.9393908 -6.782317 ] [-4.7453732 -0.5176727 ] [-1.4057113 -7.9775257 ]], shape=(10, 2), dtype=float32) tf.Tensor( [[1.] [1.] [0.] [1.] [1.] [1.] [1.] [0.] [1.] [0.]], shape=(10, 1), dtype=float32) 2\uff0c\u5b9a\u4e49\u6a21\u578b \u6b64\u5904\u8303\u4f8b\u6211\u4eec\u5229\u7528tf.Module\u6765\u7ec4\u7ec7\u6a21\u578b\u53d8\u91cf\uff0c\u5173\u4e8etf.Module\u7684\u8f83\u8be6\u7ec6\u4ecb\u7ecd\u53c2\u8003\u672c\u4e66\u7b2c\u56db\u7ae0\u6700\u540e\u4e00\u8282: Autograph\u548ctf.Module\u3002 class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . w1 = tf . Variable ( tf . random . truncated_normal ([ 2 , 4 ]), dtype = tf . float32 ) self . b1 = tf . Variable ( tf . zeros ([ 1 , 4 ]), dtype = tf . float32 ) self . w2 = tf . Variable ( tf . random . truncated_normal ([ 4 , 8 ]), dtype = tf . float32 ) self . b2 = tf . Variable ( tf . zeros ([ 1 , 8 ]), dtype = tf . float32 ) self . w3 = tf . Variable ( tf . random . truncated_normal ([ 8 , 1 ]), dtype = tf . float32 ) self . b3 = tf . Variable ( tf . zeros ([ 1 , 1 ]), dtype = tf . float32 ) # \u6b63\u5411\u4f20\u64ad @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = tf . nn . relu ( x @self . w1 + self . b1 ) x = tf . nn . relu ( x @self . w2 + self . b2 ) y = tf . nn . sigmoid ( x @self . w3 + self . b3 ) return y # \u635f\u5931\u51fd\u6570(\u4e8c\u5143\u4ea4\u53c9\u71b5) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def loss_func ( self , y_true , y_pred ): #\u5c06\u9884\u6d4b\u503c\u9650\u5236\u5728 1e-7 \u4ee5\u4e0a, 1 - 1e-7 \u4ee5\u4e0b\uff0c\u907f\u514dlog(0)\u9519\u8bef eps = 1e-7 y_pred = tf . clip_by_value ( y_pred , eps , 1.0 - eps ) bce = - y_true * tf . math . log ( y_pred ) - ( 1 - y_true ) * tf . math . log ( 1 - y_pred ) return tf . reduce_mean ( bce ) # \u8bc4\u4f30\u6307\u6807(\u51c6\u786e\u7387) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def metric_func ( self , y_true , y_pred ): y_pred = tf . where ( y_pred > 0.5 , tf . ones_like ( y_pred , dtype = tf . float32 ), tf . zeros_like ( y_pred , dtype = tf . float32 )) acc = tf . reduce_mean ( 1 - tf . abs ( y_true - y_pred )) return acc model = DNNModel () # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) predictions = model ( features ) loss = model . loss_func ( labels , predictions ) metric = model . metric_func ( labels , predictions ) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.76568353 init metric 0.6 print ( len ( model . trainable_variables )) 6 3\uff0c\u8bad\u7ec3\u6a21\u578b ##\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 grads = tape . gradient ( loss , model . trainable_variables ) # \u6267\u884c\u68af\u5ea6\u4e0b\u964d for p , dloss_dp in zip ( model . trainable_variables , grads ): p . assign ( p - 0.001 * dloss_dp ) # \u8ba1\u7b97\u8bc4\u4f30\u6307\u6807 metric = model . metric_func ( labels , predictions ) return loss , metric def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 100 ): loss , metric = train_step ( model , features , labels ) if epoch % 100 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 600 ) ================================================================================16:47:35 epoch = 100 loss = 0.567795336 accuracy = 0.71 ================================================================================16:47:39 epoch = 200 loss = 0.50955683 accuracy = 0.77 ================================================================================16:47:43 epoch = 300 loss = 0.421476126 accuracy = 0.84 ================================================================================16:47:47 epoch = 400 loss = 0.330618203 accuracy = 0.9 ================================================================================16:47:51 epoch = 500 loss = 0.308296859 accuracy = 0.89 ================================================================================16:47:55 epoch = 600 loss = 0.279367268 accuracy = 0.96 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/","text":"3-2,\u4e2d\u9636API\u793a\u8303 # \u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528TensorFlow\u7684\u4e2d\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 TensorFlow\u7684\u4e2d\u9636API\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\uff0c\u7279\u5f81\u5217\u7b49\u7b49\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) \u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 100 ) . batch ( 10 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) 2\uff0c\u5b9a\u4e49\u6a21\u578b model = layers . Dense ( units = 1 ) model . build ( input_shape = ( 2 ,)) #\u7528build\u65b9\u6cd5\u521b\u5efavariables model . loss_func = losses . mean_squared_error model . optimizer = optimizers . SGD ( learning_rate = 0.001 ) 3\uff0c\u8bad\u7ec3\u6a21\u578b #\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . variables ) model . optimizer . apply_gradients ( zip ( grads , model . variables )) return loss # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss = tf . constant ( 0.0 ) for features , labels in ds : loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , model . variables [ 0 ]) tf . print ( \"b =\" , model . variables [ 1 ]) train_model ( model , epochs = 200 ) ================================================================================17:01:48 epoch = 50 loss = 2.56481647 w = [[1.99355531] [-2.99061537]] b = [3.09484935] ================================================================================17:01:51 epoch = 100 loss = 5.96198225 w = [[1.98028314] [-2.96975136]] b = [3.09501529] ================================================================================17:01:54 epoch = 150 loss = 4.79625702 w = [[2.00056171] [-2.98774862]] b = [3.09567738] ================================================================================17:01:58 epoch = 200 loss = 8.26704407 w = [[2.00282311] [-2.99300027]] b = [3.09406662] # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () \u4e8c\uff0c DNN\u4e8c\u5206\u7c7b\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 4000 ) . batch ( 100 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) 2, \u5b9a\u4e49\u6a21\u578b class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . dense1 = layers . Dense ( 4 , activation = \"relu\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" ) # \u6b63\u5411\u4f20\u64ad @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . loss_func = losses . binary_crossentropy model . metric_func = metrics . binary_accuracy model . optimizer = optimizers . Adam ( learning_rate = 0.001 ) # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 ( features , labels ) = next ( ds . as_numpy_iterator ()) predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.13653195 init metric 0.5 3\uff0c\u8bad\u7ec3\u6a21\u578b #\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . trainable_variables ) model . optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) return loss , metric # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) (<tf.Tensor: shape=(), dtype=float32, numpy=1.2033114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.47>) def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss , metric = tf . constant ( 0.0 ), tf . constant ( 0.0 ) for features , labels in ds : loss , metric = train_step ( model , features , labels ) if epoch % 10 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 60 ) ================================================================================17:07:36 epoch = 10 loss = 0.556449413 accuracy = 0.79 ================================================================================17:07:38 epoch = 20 loss = 0.439187407 accuracy = 0.86 ================================================================================17:07:40 epoch = 30 loss = 0.259921253 accuracy = 0.95 ================================================================================17:07:42 epoch = 40 loss = 0.244920313 accuracy = 0.9 ================================================================================17:07:43 epoch = 50 loss = 0.19839409 accuracy = 0.92 ================================================================================17:07:45 epoch = 60 loss = 0.126151696 accuracy = 0.95 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"3-2,\u4e2d\u9636API\u793a\u8303"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/#3-2\u4e2d\u9636api\u793a\u8303","text":"\u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528TensorFlow\u7684\u4e2d\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 TensorFlow\u7684\u4e2d\u9636API\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\uff0c\u7279\u5f81\u5217\u7b49\u7b49\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"3-2,\u4e2d\u9636API\u793a\u8303"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e00\u7ebf\u6027\u56de\u5f52\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 100 ) . batch ( 10 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) 2\uff0c\u5b9a\u4e49\u6a21\u578b model = layers . Dense ( units = 1 ) model . build ( input_shape = ( 2 ,)) #\u7528build\u65b9\u6cd5\u521b\u5efavariables model . loss_func = losses . mean_squared_error model . optimizer = optimizers . SGD ( learning_rate = 0.001 ) 3\uff0c\u8bad\u7ec3\u6a21\u578b #\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . variables ) model . optimizer . apply_gradients ( zip ( grads , model . variables )) return loss # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss = tf . constant ( 0.0 ) for features , labels in ds : loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , model . variables [ 0 ]) tf . print ( \"b =\" , model . variables [ 1 ]) train_model ( model , epochs = 200 ) ================================================================================17:01:48 epoch = 50 loss = 2.56481647 w = [[1.99355531] [-2.99061537]] b = [3.09484935] ================================================================================17:01:51 epoch = 100 loss = 5.96198225 w = [[1.98028314] [-2.96975136]] b = [3.09501529] ================================================================================17:01:54 epoch = 150 loss = 4.79625702 w = [[2.00056171] [-2.98774862]] b = [3.09567738] ================================================================================17:01:58 epoch = 200 loss = 8.26704407 w = [[2.00282311] [-2.99300027]] b = [3.09406662] # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"\u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e8c-dnn\u4e8c\u5206\u7c7b\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 4000 ) . batch ( 100 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) 2, \u5b9a\u4e49\u6a21\u578b class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . dense1 = layers . Dense ( 4 , activation = \"relu\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" ) # \u6b63\u5411\u4f20\u64ad @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . loss_func = losses . binary_crossentropy model . metric_func = metrics . binary_accuracy model . optimizer = optimizers . Adam ( learning_rate = 0.001 ) # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 ( features , labels ) = next ( ds . as_numpy_iterator ()) predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.13653195 init metric 0.5 3\uff0c\u8bad\u7ec3\u6a21\u578b #\u4f7f\u7528autograph\u673a\u5236\u8f6c\u6362\u6210\u9759\u6001\u56fe\u52a0\u901f @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . trainable_variables ) model . optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) return loss , metric # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) (<tf.Tensor: shape=(), dtype=float32, numpy=1.2033114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.47>) def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss , metric = tf . constant ( 0.0 ), tf . constant ( 0.0 ) for features , labels in ds : loss , metric = train_step ( model , features , labels ) if epoch % 10 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 60 ) ================================================================================17:07:36 epoch = 10 loss = 0.556449413 accuracy = 0.79 ================================================================================17:07:38 epoch = 20 loss = 0.439187407 accuracy = 0.86 ================================================================================17:07:40 epoch = 30 loss = 0.259921253 accuracy = 0.95 ================================================================================17:07:42 epoch = 40 loss = 0.244920313 accuracy = 0.9 ================================================================================17:07:43 epoch = 50 loss = 0.19839409 accuracy = 0.92 ================================================================================17:07:45 epoch = 60 loss = 0.126151696 accuracy = 0.95 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c DNN\u4e8c\u5206\u7c7b\u6a21\u578b"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/","text":"3-3,\u9ad8\u9636API\u793a\u8303 # \u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528TensorFlow\u7684\u9ad8\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 TensorFlow\u7684\u9ad8\u9636API\u4e3b\u8981\u4e3atf.keras.models\u63d0\u4f9b\u7684\u6a21\u578b\u7684\u7c7b\u63a5\u53e3\u3002 \u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u5206\u522b\u6f14\u793a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\u4ee5\u53ca\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) \u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b # \u6b64\u8303\u4f8b\u6211\u4eec\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u5185\u7f6emodel.fit\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3010\u9762\u5411\u65b0\u624b\u3011\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , optimizers #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 2\uff0c\u5b9a\u4e49\u6a21\u578b tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 1 , input_shape = ( 2 ,))) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 3\uff0c\u8bad\u7ec3\u6a21\u578b ### \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 model . compile ( optimizer = \"adam\" , loss = \"mse\" , metrics = [ \"mae\" ]) model . fit ( X , Y , batch_size = 10 , epochs = 200 ) tf . print ( \"w = \" , model . layers [ 0 ] . kernel ) tf . print ( \"b = \" , model . layers [ 0 ] . bias ) Epoch 197/200 400/400 [==============================] - 0s 190us/sample - loss: 4.3977 - mae: 1.7129 Epoch 198/200 400/400 [==============================] - 0s 172us/sample - loss: 4.3918 - mae: 1.7117 Epoch 199/200 400/400 [==============================] - 0s 134us/sample - loss: 4.3861 - mae: 1.7106 Epoch 200/200 400/400 [==============================] - 0s 166us/sample - loss: 4.3786 - mae: 1.7092 w = [[1.99339032] [-3.00866461]] b = [2.67018795] # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () \u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b # \u6b64\u8303\u4f8b\u6211\u4eec\u4f7f\u7528\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3010\u9762\u5411\u4e13\u5bb6\u3011 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 n = n_positive + n_negative #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) #\u6837\u672c\u6d17\u724c data = tf . concat ([ X , Y ], axis = 1 ) data = tf . random . shuffle ( data ) X = data [:,: 2 ] Y = data [:, 2 :] #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds_train = tf . data . Dataset . from_tensor_slices (( X [ 0 : n * 3 // 4 ,:], Y [ 0 : n * 3 // 4 ,:])) \\ . shuffle ( buffer_size = 1000 ) . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () ds_valid = tf . data . Dataset . from_tensor_slices (( X [ n * 3 // 4 :,:], Y [ n * 3 // 4 :,:])) \\ . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () 2\uff0c\u5b9a\u4e49\u6a21\u578b tf . keras . backend . clear_session () class DNNModel ( models . Model ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () def build ( self , input_shape ): self . dense1 = layers . Dense ( 4 , activation = \"relu\" , name = \"dense1\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" , name = \"dense2\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" , name = \"dense3\" ) super ( DNNModel , self ) . build ( input_shape ) # \u6b63\u5411\u4f20\u64ad @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def call ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . build ( input_shape = ( None , 2 )) model . summary () Model: \"dnn_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense1 (Dense) multiple 12 _________________________________________________________________ dense2 (Dense) multiple 40 _________________________________________________________________ dense3 (Dense) multiple 9 ================================================================= Total params: 61 Trainable params: 61 Non-trainable params: 0 _________________________________________________________________ 3\uff0c\u8bad\u7ec3\u6a21\u578b ### \u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af optimizer = optimizers . Adam ( learning_rate = 0.01 ) loss_func = tf . keras . losses . BinaryCrossentropy () train_loss = tf . keras . metrics . Mean ( name = 'train_loss' ) train_metric = tf . keras . metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = tf . keras . metrics . Mean ( name = 'valid_loss' ) valid_metric = tf . keras . metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = loss_func ( labels , predictions ) grads = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 100 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_valid , 1000 ) ================================================================================17:35:02 Epoch=100,Loss:0.194088802,Accuracy:0.923064,Valid Loss:0.215538561,Valid Accuracy:0.904368 ================================================================================17:35:22 Epoch=200,Loss:0.151239693,Accuracy:0.93768847,Valid Loss:0.181166962,Valid Accuracy:0.920664132 ================================================================================17:35:43 Epoch=300,Loss:0.134556711,Accuracy:0.944247484,Valid Loss:0.171530813,Valid Accuracy:0.926396072 ================================================================================17:36:04 Epoch=400,Loss:0.125722557,Accuracy:0.949172914,Valid Loss:0.16731061,Valid Accuracy:0.929318547 ================================================================================17:36:24 Epoch=500,Loss:0.120216407,Accuracy:0.952525079,Valid Loss:0.164817035,Valid Accuracy:0.931044817 ================================================================================17:36:44 Epoch=600,Loss:0.116434008,Accuracy:0.954830289,Valid Loss:0.163089141,Valid Accuracy:0.932202339 ================================================================================17:37:05 Epoch=700,Loss:0.113658346,Accuracy:0.956433,Valid Loss:0.161804497,Valid Accuracy:0.933092058 ================================================================================17:37:25 Epoch=800,Loss:0.111522928,Accuracy:0.957467675,Valid Loss:0.160796657,Valid Accuracy:0.93379426 ================================================================================17:37:46 Epoch=900,Loss:0.109816991,Accuracy:0.958205402,Valid Loss:0.159987748,Valid Accuracy:0.934343576 ================================================================================17:38:06 Epoch=1000,Loss:0.10841465,Accuracy:0.958805501,Valid Loss:0.159325734,Valid Accuracy:0.934785843 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"3-3,\u9ad8\u9636API\u793a\u8303"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/#3-3\u9ad8\u9636api\u793a\u8303","text":"\u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528TensorFlow\u7684\u9ad8\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 TensorFlow\u7684\u9ad8\u9636API\u4e3b\u8981\u4e3atf.keras.models\u63d0\u4f9b\u7684\u6a21\u578b\u7684\u7c7b\u63a5\u53e3\u3002 \u4f7f\u7528Keras\u63a5\u53e3\u6709\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u6b64\u5904\u5206\u522b\u6f14\u793a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\u4ee5\u53ca\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"3-3,\u9ad8\u9636API\u793a\u8303"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e00\u7ebf\u6027\u56de\u5f52\u6a21\u578b","text":"\u6b64\u8303\u4f8b\u6211\u4eec\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u5185\u7f6emodel.fit\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3010\u9762\u5411\u65b0\u624b\u3011\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , optimizers #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 2\uff0c\u5b9a\u4e49\u6a21\u578b tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 1 , input_shape = ( 2 ,))) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 3\uff0c\u8bad\u7ec3\u6a21\u578b ### \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 model . compile ( optimizer = \"adam\" , loss = \"mse\" , metrics = [ \"mae\" ]) model . fit ( X , Y , batch_size = 10 , epochs = 200 ) tf . print ( \"w = \" , model . layers [ 0 ] . kernel ) tf . print ( \"b = \" , model . layers [ 0 ] . bias ) Epoch 197/200 400/400 [==============================] - 0s 190us/sample - loss: 4.3977 - mae: 1.7129 Epoch 198/200 400/400 [==============================] - 0s 172us/sample - loss: 4.3918 - mae: 1.7117 Epoch 199/200 400/400 [==============================] - 0s 134us/sample - loss: 4.3861 - mae: 1.7106 Epoch 200/200 400/400 [==============================] - 0s 166us/sample - loss: 4.3786 - mae: 1.7092 w = [[1.99339032] [-3.00866461]] b = [2.67018795] # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"\u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b"},{"location":"chinese/3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e8cdnn\u4e8c\u5206\u7c7b\u6a21\u578b","text":"\u6b64\u8303\u4f8b\u6211\u4eec\u4f7f\u7528\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3010\u9762\u5411\u4e13\u5bb6\u3011 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 n = n_positive + n_negative #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) #\u6837\u672c\u6d17\u724c data = tf . concat ([ X , Y ], axis = 1 ) data = tf . random . shuffle ( data ) X = data [:,: 2 ] Y = data [:, 2 :] #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds_train = tf . data . Dataset . from_tensor_slices (( X [ 0 : n * 3 // 4 ,:], Y [ 0 : n * 3 // 4 ,:])) \\ . shuffle ( buffer_size = 1000 ) . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () ds_valid = tf . data . Dataset . from_tensor_slices (( X [ n * 3 // 4 :,:], Y [ n * 3 // 4 :,:])) \\ . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () 2\uff0c\u5b9a\u4e49\u6a21\u578b tf . keras . backend . clear_session () class DNNModel ( models . Model ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () def build ( self , input_shape ): self . dense1 = layers . Dense ( 4 , activation = \"relu\" , name = \"dense1\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" , name = \"dense2\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" , name = \"dense3\" ) super ( DNNModel , self ) . build ( input_shape ) # \u6b63\u5411\u4f20\u64ad @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def call ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . build ( input_shape = ( None , 2 )) model . summary () Model: \"dnn_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense1 (Dense) multiple 12 _________________________________________________________________ dense2 (Dense) multiple 40 _________________________________________________________________ dense3 (Dense) multiple 9 ================================================================= Total params: 61 Trainable params: 61 Non-trainable params: 0 _________________________________________________________________ 3\uff0c\u8bad\u7ec3\u6a21\u578b ### \u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af optimizer = optimizers . Adam ( learning_rate = 0.01 ) loss_func = tf . keras . losses . BinaryCrossentropy () train_loss = tf . keras . metrics . Mean ( name = 'train_loss' ) train_metric = tf . keras . metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = tf . keras . metrics . Mean ( name = 'valid_loss' ) valid_metric = tf . keras . metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = loss_func ( labels , predictions ) grads = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 100 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_valid , 1000 ) ================================================================================17:35:02 Epoch=100,Loss:0.194088802,Accuracy:0.923064,Valid Loss:0.215538561,Valid Accuracy:0.904368 ================================================================================17:35:22 Epoch=200,Loss:0.151239693,Accuracy:0.93768847,Valid Loss:0.181166962,Valid Accuracy:0.920664132 ================================================================================17:35:43 Epoch=300,Loss:0.134556711,Accuracy:0.944247484,Valid Loss:0.171530813,Valid Accuracy:0.926396072 ================================================================================17:36:04 Epoch=400,Loss:0.125722557,Accuracy:0.949172914,Valid Loss:0.16731061,Valid Accuracy:0.929318547 ================================================================================17:36:24 Epoch=500,Loss:0.120216407,Accuracy:0.952525079,Valid Loss:0.164817035,Valid Accuracy:0.931044817 ================================================================================17:36:44 Epoch=600,Loss:0.116434008,Accuracy:0.954830289,Valid Loss:0.163089141,Valid Accuracy:0.932202339 ================================================================================17:37:05 Epoch=700,Loss:0.113658346,Accuracy:0.956433,Valid Loss:0.161804497,Valid Accuracy:0.933092058 ================================================================================17:37:25 Epoch=800,Loss:0.111522928,Accuracy:0.957467675,Valid Loss:0.160796657,Valid Accuracy:0.93379426 ================================================================================17:37:46 Epoch=900,Loss:0.109816991,Accuracy:0.958205402,Valid Loss:0.159987748,Valid Accuracy:0.934343576 ================================================================================17:38:06 Epoch=1000,Loss:0.10841465,Accuracy:0.958805501,Valid Loss:0.159325734,Valid Accuracy:0.934785843 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/","text":"\u56db\u3001TensorFlow\u7684\u4f4e\u9636API # TensorFlow\u7684\u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4f4e\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u5728\u4f4e\u9636API\u5c42\u6b21\u4e0a\uff0c\u53ef\u4ee5\u628aTensorFlow\u5f53\u505a\u4e00\u4e2a\u589e\u5f3a\u7248\u7684numpy\u6765\u4f7f\u7528\u3002 TensorFlow\u63d0\u4f9b\u7684\u65b9\u6cd5\u6bd4numpy\u66f4\u5168\u9762\uff0c\u8fd0\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528GPU\u8fdb\u884c\u52a0\u901f\u3002 \u524d\u9762\u51e0\u7ae0\u6211\u4eec\u5bf9\u4f4e\u9636API\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u6574\u4f53\u7684\u8ba4\u8bc6\uff0c\u672c\u7ae0\u6211\u4eec\u5c06\u91cd\u70b9\u8be6\u7ec6\u4ecb\u7ecd\u5f20\u91cf\u64cd\u4f5c\u548cAutograph\u8ba1\u7b97\u56fe\u3002 \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 Autograph\u8ba1\u7b97\u56fe\u6211\u4eec\u5c06\u4ecb\u7ecd\u4f7f\u7528Autograph\u7684\u89c4\u8303\u5efa\u8bae\uff0cAutograph\u7684\u673a\u5236\u539f\u7406\uff0cAutograph\u548ctf.Module. \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\u3001TensorFlow\u7684\u4f4e\u9636API"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/#\u56dbtensorflow\u7684\u4f4e\u9636api","text":"TensorFlow\u7684\u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4f4e\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u5728\u4f4e\u9636API\u5c42\u6b21\u4e0a\uff0c\u53ef\u4ee5\u628aTensorFlow\u5f53\u505a\u4e00\u4e2a\u589e\u5f3a\u7248\u7684numpy\u6765\u4f7f\u7528\u3002 TensorFlow\u63d0\u4f9b\u7684\u65b9\u6cd5\u6bd4numpy\u66f4\u5168\u9762\uff0c\u8fd0\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528GPU\u8fdb\u884c\u52a0\u901f\u3002 \u524d\u9762\u51e0\u7ae0\u6211\u4eec\u5bf9\u4f4e\u9636API\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u6574\u4f53\u7684\u8ba4\u8bc6\uff0c\u672c\u7ae0\u6211\u4eec\u5c06\u91cd\u70b9\u8be6\u7ec6\u4ecb\u7ecd\u5f20\u91cf\u64cd\u4f5c\u548cAutograph\u8ba1\u7b97\u56fe\u3002 \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 Autograph\u8ba1\u7b97\u56fe\u6211\u4eec\u5c06\u4ecb\u7ecd\u4f7f\u7528Autograph\u7684\u89c4\u8303\u5efa\u8bae\uff0cAutograph\u7684\u673a\u5236\u539f\u7406\uff0cAutograph\u548ctf.Module. \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\u3001TensorFlow\u7684\u4f4e\u9636API"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/","text":"4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c # \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u3002 \u4e00\uff0c\u521b\u5efa\u5f20\u91cf # \u5f20\u91cf\u521b\u5efa\u7684\u8bb8\u591a\u65b9\u6cd5\u548cnumpy\u4e2d\u521b\u5efaarray\u7684\u65b9\u6cd5\u5f88\u50cf\u3002 import tensorflow as tf import numpy as np a = tf . constant ([ 1 , 2 , 3 ], dtype = tf . float32 ) tf . print ( a ) [1 2 3] b = tf . range ( 1 , 10 , delta = 2 ) tf . print ( b ) [1 3 5 7 9] c = tf . linspace ( 0.0 , 2 * 3.14 , 100 ) tf . print ( c ) [0 0.0634343475 0.126868695 ... 6.15313148 6.21656609 6.28] d = tf . zeros ([ 3 , 3 ]) tf . print ( d ) [[0 0 0] [0 0 0] [0 0 0]] a = tf . ones ([ 3 , 3 ]) b = tf . zeros_like ( a , dtype = tf . float32 ) tf . print ( a ) tf . print ( b ) [[1 1 1] [1 1 1] [1 1 1]] [[0 0 0] [0 0 0] [0 0 0]] b = tf . fill ([ 3 , 2 ], 5 ) tf . print ( b ) [[5 5] [5 5] [5 5]] #\u5747\u5300\u5206\u5e03\u968f\u673a tf . random . set_seed ( 1.0 ) a = tf . random . uniform ([ 5 ], minval = 0 , maxval = 10 ) tf . print ( a ) [1.65130854 9.01481247 6.30974197 4.34546089 2.9193902] #\u6b63\u6001\u5206\u5e03\u968f\u673a b = tf . random . normal ([ 3 , 3 ], mean = 0.0 , stddev = 1.0 ) tf . print ( b ) [[0.403087884 -1.0880208 -0.0630953535] [1.33655667 0.711760104 -0.489286453] [-0.764221311 -1.03724861 -1.25193381]] #\u6b63\u6001\u5206\u5e03\u968f\u673a\uff0c\u5254\u96642\u500d\u65b9\u5dee\u4ee5\u5916\u6570\u636e\u91cd\u65b0\u751f\u6210 c = tf . random . truncated_normal (( 5 , 5 ), mean = 0.0 , stddev = 1.0 , dtype = tf . float32 ) tf . print ( c ) [[-0.457012236 -0.406867266 0.728577733 -0.892977774 -0.369404584] [0.323488563 1.19383323 0.888299048 1.25985599 -1.95951891] [-0.202244401 0.294496894 -0.468728036 1.29494202 1.48142183] [0.0810953453 1.63843894 0.556645 0.977199793 -1.17777884] [1.67368948 0.0647980496 -0.705142677 -0.281972528 0.126546144]] # \u7279\u6b8a\u77e9\u9635 I = tf . eye ( 3 , 3 ) #\u5355\u4f4d\u77e9\u9635 tf . print ( I ) tf . print ( \" \" ) t = tf . linalg . diag ([ 1 , 2 , 3 ]) #\u5bf9\u89d2\u9635 tf . print ( t ) [[1 0 0] [0 1 0] [0 0 1]] [[1 0 0] [0 2 0] [0 0 3]] \u4e8c \uff0c\u7d22\u5f15\u5207\u7247 # \u5f20\u91cf\u7684\u7d22\u5f15\u5207\u7247\u65b9\u5f0f\u548cnumpy\u51e0\u4e4e\u662f\u4e00\u6837\u7684\u3002\u5207\u7247\u65f6\u652f\u6301\u7f3a\u7701\u53c2\u6570\u548c\u7701\u7565\u53f7\u3002 \u5bf9\u4e8etf.Variable,\u53ef\u4ee5\u901a\u8fc7\u7d22\u5f15\u548c\u5207\u7247\u5bf9\u90e8\u5206\u5143\u7d20\u8fdb\u884c\u4fee\u6539\u3002 \u5bf9\u4e8e\u63d0\u53d6\u5f20\u91cf\u7684\u8fde\u7eed\u5b50\u533a\u57df\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528tf.slice. \u6b64\u5916\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528tf.gather,tf.gather_nd,tf.boolean_mask\u3002 tf.boolean_mask\u529f\u80fd\u6700\u4e3a\u5f3a\u5927\uff0c\u5b83\u53ef\u4ee5\u5b9e\u73b0tf.gather,tf.gather_nd\u7684\u529f\u80fd\uff0c\u5e76\u4e14tf.boolean_mask\u8fd8\u53ef\u4ee5\u5b9e\u73b0\u5e03\u5c14\u7d22\u5f15\u3002 \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u67d0\u4e9b\u5143\u7d20\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528tf.where\uff0ctf.scatter_nd\u3002 tf . random . set_seed ( 3 ) t = tf . random . uniform ([ 5 , 5 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( t ) [[4 7 4 2 9] [9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2] [3 7 0 0 3]] #\u7b2c0\u884c tf . print ( t [ 0 ]) [4 7 4 2 9] #\u5012\u6570\u7b2c\u4e00\u884c tf . print ( t [ - 1 ]) [3 7 0 0 3] #\u7b2c1\u884c\u7b2c3\u5217 tf . print ( t [ 1 , 3 ]) tf . print ( t [ 1 ][ 3 ]) 4 4 #\u7b2c1\u884c\u81f3\u7b2c3\u884c tf . print ( t [ 1 : 4 ,:]) tf . print ( tf . slice ( t ,[ 1 , 0 ],[ 3 , 5 ])) #tf.slice(input,begin_vector,size_vector) [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] #\u7b2c1\u884c\u81f3\u6700\u540e\u4e00\u884c\uff0c\u7b2c0\u5217\u5230\u6700\u540e\u4e00\u5217\u6bcf\u9694\u4e24\u5217\u53d6\u4e00\u5217 tf . print ( t [ 1 : 4 ,: 4 : 2 ]) [[9 2] [7 7] [9 9]] #\u5bf9\u53d8\u91cf\u6765\u8bf4\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u548c\u5207\u7247\u4fee\u6539\u90e8\u5206\u5143\u7d20 x = tf . Variable ([[ 1 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) x [ 1 ,:] . assign ( tf . constant ([ 0.0 , 0.0 ])) tf . print ( x ) [[1 2] [0 0]] a = tf . random . uniform ([ 3 , 3 , 3 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( a ) [[[7 3 9] [9 0 7] [9 6 7]] [[1 3 3] [0 8 1] [3 1 0]] [[4 0 6] [6 2 2] [7 9 5]]] #\u7701\u7565\u53f7\u53ef\u4ee5\u8868\u793a\u591a\u4e2a\u5192\u53f7 tf . print ( a [ ... , 1 ]) [[3 0 6] [3 8 1] [0 2 9]] \u4ee5\u4e0a\u5207\u7247\u65b9\u5f0f\u76f8\u5bf9\u89c4\u5219\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528tf.gather,tf.gather_nd,tf.boolean_mask\u3002 \u8003\u8651\u73ed\u7ea7\u6210\u7ee9\u518c\u7684\u4f8b\u5b50\uff0c\u67094\u4e2a\u73ed\u7ea7\uff0c\u6bcf\u4e2a\u73ed\u7ea710\u4e2a\u5b66\u751f\uff0c\u6bcf\u4e2a\u5b66\u751f7\u95e8\u79d1\u76ee\u6210\u7ee9\u3002\u53ef\u4ee5\u7528\u4e00\u4e2a4\u00d710\u00d77\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 scores = tf . random . uniform (( 4 , 10 , 7 ), minval = 0 , maxval = 100 , dtype = tf . int32 ) tf . print ( scores ) [[[52 82 66 ... 17 86 14] [8 36 94 ... 13 78 41] [77 53 51 ... 22 91 56] ... [11 19 26 ... 89 86 68] [60 72 0 ... 11 26 15] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [83 36 31 ... 75 38 85] [54 26 67 ... 60 68 98] ... [20 5 18 ... 32 45 3] [72 52 81 ... 88 41 20] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [78 71 54 ... 43 98 81] [21 66 53 ... 97 75 77] ... [6 74 3 ... 53 65 43] [98 36 72 ... 33 36 81] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [35 8 82 ... 11 59 97] [44 6 99 ... 81 60 27] ... [76 26 35 ... 51 8 17] [33 52 53 ... 78 37 31] [71 27 44 ... 0 52 16]]] #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 p = tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u7b2c1\u95e8\u8bfe\u7a0b\uff0c\u7b2c3\u95e8\u8bfe\u7a0b\uff0c\u7b2c6\u95e8\u8bfe\u7a0b\u6210\u7ee9 q = tf . gather ( tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ),[ 1 , 3 , 6 ], axis = 2 ) tf . print ( q ) [[[82 55 14] [80 46 96] [99 58 74]] [[73 48 81] [10 38 92] [21 86 90]] [[80 57 60] [12 34 25] [78 71 21]] [[57 75 3] [41 47 13] [27 96 16]]] # \u62bd\u53d6\u7b2c0\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c2\u4e2a\u73ed\u7ea7\u7684\u7b2c4\u4e2a\u5b66\u751f\uff0c\u7b2c3\u4e2a\u73ed\u7ea7\u7684\u7b2c6\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 #indices\u7684\u957f\u5ea6\u4e3a\u91c7\u6837\u6837\u672c\u7684\u4e2a\u6570\uff0c\u6bcf\u4e2a\u5143\u7d20\u4e3a\u91c7\u6837\u4f4d\u7f6e\u7684\u5750\u6807 s = tf . gather_nd ( scores , indices = [( 0 , 0 ),( 2 , 4 ),( 3 , 6 )]) s <tf.Tensor: shape=(3, 7), dtype=int32, numpy= array([[52, 82, 66, 55, 17, 86, 14], [99, 94, 46, 70, 1, 63, 41], [46, 83, 70, 80, 90, 85, 17]], dtype=int32)> \u4ee5\u4e0atf.gather\u548ctf.gather_nd\u7684\u529f\u80fd\u4e5f\u53ef\u4ee5\u7528tf.boolean_mask\u6765\u5b9e\u73b0\u3002 #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 p = tf . boolean_mask ( scores ,[ True , False , False , False , False , True , False , False , False , True ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] #\u62bd\u53d6\u7b2c0\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c2\u4e2a\u73ed\u7ea7\u7684\u7b2c4\u4e2a\u5b66\u751f\uff0c\u7b2c3\u4e2a\u73ed\u7ea7\u7684\u7b2c6\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 s = tf . boolean_mask ( scores , [[ True , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , True , False , False , False , False , False ], [ False , False , False , False , False , False , True , False , False , False ]]) tf . print ( s ) [[52 82 66 ... 17 86 14] [99 94 46 ... 1 63 41] [46 83 70 ... 90 85 17]] #\u5229\u7528tf.boolean_mask\u53ef\u4ee5\u5b9e\u73b0\u5e03\u5c14\u7d22\u5f15 #\u627e\u5230\u77e9\u9635\u4e2d\u5c0f\u4e8e0\u7684\u5143\u7d20 c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) tf . print ( c , \" \\n \" ) tf . print ( tf . boolean_mask ( c , c < 0 ), \" \\n \" ) tf . print ( c [ c < 0 ]) #\u5e03\u5c14\u7d22\u5f15\uff0c\u4e3aboolean_mask\u7684\u8bed\u6cd5\u7cd6\u5f62\u5f0f [[-1 1 -1] [2 2 -2] [3 -3 3]] [-1 -1 -2 -3] [-1 -1 -2 -3] \u4ee5\u4e0a\u8fd9\u4e9b\u65b9\u6cd5\u4ec5\u80fd\u63d0\u53d6\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\uff0c\u4f46\u4e0d\u80fd\u66f4\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\u3002 \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528tf.where\u548ctf.scatter_nd\u3002 tf.where\u53ef\u4ee5\u7406\u89e3\u4e3aif\u7684\u5f20\u91cf\u7248\u672c\uff0c\u6b64\u5916\u5b83\u8fd8\u53ef\u4ee5\u7528\u4e8e\u627e\u5230\u6ee1\u8db3\u6761\u4ef6\u7684\u6240\u6709\u5143\u7d20\u7684\u4f4d\u7f6e\u5750\u6807\u3002 tf.scatter_nd\u7684\u4f5c\u7528\u548ctf.gather_nd\u6709\u4e9b\u76f8\u53cd\uff0ctf.gather_nd\u7528\u4e8e\u6536\u96c6\u5f20\u91cf\u7684\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5143\u7d20\uff0c \u800ctf.scatter_nd\u53ef\u4ee5\u5c06\u67d0\u4e9b\u503c\u63d2\u5165\u5230\u4e00\u4e2a\u7ed9\u5b9ashape\u7684\u51680\u7684\u5f20\u91cf\u7684\u6307\u5b9a\u4f4d\u7f6e\u5904\u3002 #\u627e\u5230\u5f20\u91cf\u4e2d\u5c0f\u4e8e0\u7684\u5143\u7d20,\u5c06\u5176\u6362\u6210np.nan\u5f97\u5230\u65b0\u7684\u5f20\u91cf #tf.where\u548cnp.where\u4f5c\u7528\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3aif\u7684\u5f20\u91cf\u7248\u672c c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) d = tf . where ( c < 0 , tf . fill ( c . shape , np . nan ), c ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[nan, 1., nan], [ 2., 2., nan], [ 3., nan, 3.]], dtype=float32)> #\u5982\u679cwhere\u53ea\u6709\u4e00\u4e2a\u53c2\u6570\uff0c\u5c06\u8fd4\u56de\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684\u4f4d\u7f6e\u5750\u6807 indices = tf . where ( c < 0 ) indices <tf.Tensor: shape=(4, 2), dtype=int64, numpy= array([[0, 0], [0, 2], [1, 2], [2, 1]])> #\u5c06\u5f20\u91cf\u7684\u7b2c[0,0]\u548c[2,1]\u4e24\u4e2a\u4f4d\u7f6e\u5143\u7d20\u66ff\u6362\u4e3a0\u5f97\u5230\u65b0\u7684\u5f20\u91cf d = c - tf . scatter_nd ([[ 0 , 0 ],[ 2 , 1 ]],[ c [ 0 , 0 ], c [ 2 , 1 ]], c . shape ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[ 0., 1., -1.], [ 2., 2., -2.], [ 3., 0., 3.]], dtype=float32)> #scatter_nd\u7684\u4f5c\u7528\u548cgather_nd\u6709\u4e9b\u76f8\u53cd #\u53ef\u4ee5\u5c06\u67d0\u4e9b\u503c\u63d2\u5165\u5230\u4e00\u4e2a\u7ed9\u5b9ashape\u7684\u51680\u7684\u5f20\u91cf\u7684\u6307\u5b9a\u4f4d\u7f6e\u5904\u3002 indices = tf . where ( c < 0 ) tf . scatter_nd ( indices , tf . gather_nd ( c , indices ), c . shape ) <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[-1., 0., -1.], [ 0., 0., -2.], [ 0., -3., 0.]], dtype=float32)> \u4e09\uff0c\u7ef4\u5ea6\u53d8\u6362 # \u7ef4\u5ea6\u53d8\u6362\u76f8\u5173\u51fd\u6570\u4e3b\u8981\u6709 tf.reshape, tf.squeeze, tf.expand_dims, tf.transpose. tf.reshape \u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\u3002 tf.squeeze \u53ef\u4ee5\u51cf\u5c11\u7ef4\u5ea6\u3002 tf.expand_dims \u53ef\u4ee5\u589e\u52a0\u7ef4\u5ea6\u3002 tf.transpose \u53ef\u4ee5\u4ea4\u6362\u7ef4\u5ea6\u3002 tf.reshape\u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\uff0c\u4f46\u662f\u5176\u672c\u8d28\u4e0a\u4e0d\u4f1a\u6539\u53d8\u5f20\u91cf\u5143\u7d20\u7684\u5b58\u50a8\u987a\u5e8f\uff0c\u6240\u4ee5\uff0c\u8be5\u64cd\u4f5c\u5b9e\u9645\u4e0a\u975e\u5e38\u8fc5\u901f\uff0c\u5e76\u4e14\u662f\u53ef\u9006\u7684\u3002 a = tf . random . uniform ( shape = [ 1 , 3 , 3 , 2 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) tf . print ( a ) TensorShape([1, 3, 3, 2]) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] # \u6539\u6210 \uff083,6\uff09\u5f62\u72b6\u7684\u5f20\u91cf b = tf . reshape ( a ,[ 3 , 6 ]) tf . print ( b . shape ) tf . print ( b ) TensorShape([3, 6]) [[135 178 26 116 29 224] [179 219 153 209 111 215] [39 7 138 129 59 205]] # \u6539\u56de\u6210 [1,3,3,2] \u5f62\u72b6\u7684\u5f20\u91cf c = tf . reshape ( b ,[ 1 , 3 , 3 , 2 ]) tf . print ( c ) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] \u5982\u679c\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\uff0c\u5229\u7528tf.squeeze\u53ef\u4ee5\u6d88\u9664\u8fd9\u4e2a\u7ef4\u5ea6\u3002 \u548ctf.reshape\u76f8\u4f3c\uff0c\u5b83\u672c\u8d28\u4e0a\u4e0d\u4f1a\u6539\u53d8\u5f20\u91cf\u5143\u7d20\u7684\u5b58\u50a8\u987a\u5e8f\u3002 \u5f20\u91cf\u7684\u5404\u4e2a\u5143\u7d20\u5728\u5185\u5b58\u4e2d\u662f\u7ebf\u6027\u5b58\u50a8\u7684\uff0c\u5176\u4e00\u822c\u89c4\u5f8b\u662f\uff0c\u540c\u4e00\u5c42\u7ea7\u4e2d\u7684\u76f8\u90bb\u5143\u7d20\u7684\u7269\u7406\u5730\u5740\u4e5f\u76f8\u90bb\u3002 s = tf . squeeze ( a ) tf . print ( s . shape ) tf . print ( s ) TensorShape([3, 3, 2]) [[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]] d = tf . expand_dims ( s , axis = 0 ) #\u5728\u7b2c0\u7ef4\u63d2\u5165\u957f\u5ea6\u4e3a1\u7684\u4e00\u4e2a\u7ef4\u5ea6 d <tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy= array([[[[135, 178], [ 26, 116], [ 29, 224]], [[179, 219], [153, 209], [111, 215]], [[ 39, 7], [138, 129], [ 59, 205]]]], dtype=int32)> tf.transpose\u53ef\u4ee5\u4ea4\u6362\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u4e0etf.reshape\u4e0d\u540c\uff0c\u5b83\u4f1a\u6539\u53d8\u5f20\u91cf\u5143\u7d20\u7684\u5b58\u50a8\u987a\u5e8f\u3002 tf.transpose\u5e38\u7528\u4e8e\u56fe\u7247\u5b58\u50a8\u683c\u5f0f\u7684\u53d8\u6362\u4e0a\u3002 # Batch,Height,Width,Channel a = tf . random . uniform ( shape = [ 100 , 600 , 600 , 4 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) # \u8f6c\u6362\u6210 Channel,Height,Width,Batch s = tf . transpose ( a , perm = [ 3 , 1 , 2 , 0 ]) tf . print ( s . shape ) TensorShape([100, 600, 600, 4]) TensorShape([4, 600, 600, 100]) \u56db\uff0c\u5408\u5e76\u5206\u5272 # \u548cnumpy\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u7528tf.concat\u548ctf.stack\u65b9\u6cd5\u5bf9\u591a\u4e2a\u5f20\u91cf\u8fdb\u884c\u5408\u5e76\uff0c\u53ef\u4ee5\u7528tf.split\u65b9\u6cd5\u628a\u4e00\u4e2a\u5f20\u91cf\u5206\u5272\u6210\u591a\u4e2a\u5f20\u91cf\u3002 tf.concat\u548ctf.stack\u6709\u7565\u5fae\u7684\u533a\u522b\uff0ctf.concat\u662f\u8fde\u63a5\uff0c\u4e0d\u4f1a\u589e\u52a0\u7ef4\u5ea6\uff0c\u800ctf.stack\u662f\u5806\u53e0\uff0c\u4f1a\u589e\u52a0\u7ef4\u5ea6\u3002 a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) tf . concat ([ a , b , c ], axis = 0 ) <tf.Tensor: shape=(6, 2), dtype=float32, numpy= array([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]], dtype=float32)> tf . concat ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 6), dtype=float32, numpy= array([[ 1., 2., 5., 6., 9., 10.], [ 3., 4., 7., 8., 11., 12.]], dtype=float32)> tf . stack ([ a , b , c ]) <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 3., 4.]], [[ 5., 6.], [ 7., 8.]], [[ 9., 10.], [11., 12.]]], dtype=float32)> tf . stack ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 5., 6.], [ 9., 10.]], [[ 3., 4.], [ 7., 8.], [11., 12.]]], dtype=float32)> a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) c = tf . concat ([ a , b , c ], axis = 0 ) tf.split\u662ftf.concat\u7684\u9006\u8fd0\u7b97\uff0c\u53ef\u4ee5\u6307\u5b9a\u5206\u5272\u4efd\u6570\u5e73\u5747\u5206\u5272\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9a\u6bcf\u4efd\u7684\u8bb0\u5f55\u6570\u91cf\u8fdb\u884c\u5206\u5272\u3002 #tf.split(value,num_or_size_splits,axis) tf . split ( c , 3 , axis = 0 ) #\u6307\u5b9a\u5206\u5272\u4efd\u6570\uff0c\u5e73\u5747\u5206\u5272 [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] tf . split ( c ,[ 2 , 2 , 2 ], axis = 0 ) #\u6307\u5b9a\u6bcf\u4efd\u7684\u8bb0\u5f55\u6570\u91cf [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#4-1\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c","text":"\u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u3002","title":"4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u4e00\u521b\u5efa\u5f20\u91cf","text":"\u5f20\u91cf\u521b\u5efa\u7684\u8bb8\u591a\u65b9\u6cd5\u548cnumpy\u4e2d\u521b\u5efaarray\u7684\u65b9\u6cd5\u5f88\u50cf\u3002 import tensorflow as tf import numpy as np a = tf . constant ([ 1 , 2 , 3 ], dtype = tf . float32 ) tf . print ( a ) [1 2 3] b = tf . range ( 1 , 10 , delta = 2 ) tf . print ( b ) [1 3 5 7 9] c = tf . linspace ( 0.0 , 2 * 3.14 , 100 ) tf . print ( c ) [0 0.0634343475 0.126868695 ... 6.15313148 6.21656609 6.28] d = tf . zeros ([ 3 , 3 ]) tf . print ( d ) [[0 0 0] [0 0 0] [0 0 0]] a = tf . ones ([ 3 , 3 ]) b = tf . zeros_like ( a , dtype = tf . float32 ) tf . print ( a ) tf . print ( b ) [[1 1 1] [1 1 1] [1 1 1]] [[0 0 0] [0 0 0] [0 0 0]] b = tf . fill ([ 3 , 2 ], 5 ) tf . print ( b ) [[5 5] [5 5] [5 5]] #\u5747\u5300\u5206\u5e03\u968f\u673a tf . random . set_seed ( 1.0 ) a = tf . random . uniform ([ 5 ], minval = 0 , maxval = 10 ) tf . print ( a ) [1.65130854 9.01481247 6.30974197 4.34546089 2.9193902] #\u6b63\u6001\u5206\u5e03\u968f\u673a b = tf . random . normal ([ 3 , 3 ], mean = 0.0 , stddev = 1.0 ) tf . print ( b ) [[0.403087884 -1.0880208 -0.0630953535] [1.33655667 0.711760104 -0.489286453] [-0.764221311 -1.03724861 -1.25193381]] #\u6b63\u6001\u5206\u5e03\u968f\u673a\uff0c\u5254\u96642\u500d\u65b9\u5dee\u4ee5\u5916\u6570\u636e\u91cd\u65b0\u751f\u6210 c = tf . random . truncated_normal (( 5 , 5 ), mean = 0.0 , stddev = 1.0 , dtype = tf . float32 ) tf . print ( c ) [[-0.457012236 -0.406867266 0.728577733 -0.892977774 -0.369404584] [0.323488563 1.19383323 0.888299048 1.25985599 -1.95951891] [-0.202244401 0.294496894 -0.468728036 1.29494202 1.48142183] [0.0810953453 1.63843894 0.556645 0.977199793 -1.17777884] [1.67368948 0.0647980496 -0.705142677 -0.281972528 0.126546144]] # \u7279\u6b8a\u77e9\u9635 I = tf . eye ( 3 , 3 ) #\u5355\u4f4d\u77e9\u9635 tf . print ( I ) tf . print ( \" \" ) t = tf . linalg . diag ([ 1 , 2 , 3 ]) #\u5bf9\u89d2\u9635 tf . print ( t ) [[1 0 0] [0 1 0] [0 0 1]] [[1 0 0] [0 2 0] [0 0 3]]","title":"\u4e00\uff0c\u521b\u5efa\u5f20\u91cf"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u4e8c-\u7d22\u5f15\u5207\u7247","text":"\u5f20\u91cf\u7684\u7d22\u5f15\u5207\u7247\u65b9\u5f0f\u548cnumpy\u51e0\u4e4e\u662f\u4e00\u6837\u7684\u3002\u5207\u7247\u65f6\u652f\u6301\u7f3a\u7701\u53c2\u6570\u548c\u7701\u7565\u53f7\u3002 \u5bf9\u4e8etf.Variable,\u53ef\u4ee5\u901a\u8fc7\u7d22\u5f15\u548c\u5207\u7247\u5bf9\u90e8\u5206\u5143\u7d20\u8fdb\u884c\u4fee\u6539\u3002 \u5bf9\u4e8e\u63d0\u53d6\u5f20\u91cf\u7684\u8fde\u7eed\u5b50\u533a\u57df\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528tf.slice. \u6b64\u5916\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528tf.gather,tf.gather_nd,tf.boolean_mask\u3002 tf.boolean_mask\u529f\u80fd\u6700\u4e3a\u5f3a\u5927\uff0c\u5b83\u53ef\u4ee5\u5b9e\u73b0tf.gather,tf.gather_nd\u7684\u529f\u80fd\uff0c\u5e76\u4e14tf.boolean_mask\u8fd8\u53ef\u4ee5\u5b9e\u73b0\u5e03\u5c14\u7d22\u5f15\u3002 \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u67d0\u4e9b\u5143\u7d20\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528tf.where\uff0ctf.scatter_nd\u3002 tf . random . set_seed ( 3 ) t = tf . random . uniform ([ 5 , 5 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( t ) [[4 7 4 2 9] [9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2] [3 7 0 0 3]] #\u7b2c0\u884c tf . print ( t [ 0 ]) [4 7 4 2 9] #\u5012\u6570\u7b2c\u4e00\u884c tf . print ( t [ - 1 ]) [3 7 0 0 3] #\u7b2c1\u884c\u7b2c3\u5217 tf . print ( t [ 1 , 3 ]) tf . print ( t [ 1 ][ 3 ]) 4 4 #\u7b2c1\u884c\u81f3\u7b2c3\u884c tf . print ( t [ 1 : 4 ,:]) tf . print ( tf . slice ( t ,[ 1 , 0 ],[ 3 , 5 ])) #tf.slice(input,begin_vector,size_vector) [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] #\u7b2c1\u884c\u81f3\u6700\u540e\u4e00\u884c\uff0c\u7b2c0\u5217\u5230\u6700\u540e\u4e00\u5217\u6bcf\u9694\u4e24\u5217\u53d6\u4e00\u5217 tf . print ( t [ 1 : 4 ,: 4 : 2 ]) [[9 2] [7 7] [9 9]] #\u5bf9\u53d8\u91cf\u6765\u8bf4\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u548c\u5207\u7247\u4fee\u6539\u90e8\u5206\u5143\u7d20 x = tf . Variable ([[ 1 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) x [ 1 ,:] . assign ( tf . constant ([ 0.0 , 0.0 ])) tf . print ( x ) [[1 2] [0 0]] a = tf . random . uniform ([ 3 , 3 , 3 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( a ) [[[7 3 9] [9 0 7] [9 6 7]] [[1 3 3] [0 8 1] [3 1 0]] [[4 0 6] [6 2 2] [7 9 5]]] #\u7701\u7565\u53f7\u53ef\u4ee5\u8868\u793a\u591a\u4e2a\u5192\u53f7 tf . print ( a [ ... , 1 ]) [[3 0 6] [3 8 1] [0 2 9]] \u4ee5\u4e0a\u5207\u7247\u65b9\u5f0f\u76f8\u5bf9\u89c4\u5219\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528tf.gather,tf.gather_nd,tf.boolean_mask\u3002 \u8003\u8651\u73ed\u7ea7\u6210\u7ee9\u518c\u7684\u4f8b\u5b50\uff0c\u67094\u4e2a\u73ed\u7ea7\uff0c\u6bcf\u4e2a\u73ed\u7ea710\u4e2a\u5b66\u751f\uff0c\u6bcf\u4e2a\u5b66\u751f7\u95e8\u79d1\u76ee\u6210\u7ee9\u3002\u53ef\u4ee5\u7528\u4e00\u4e2a4\u00d710\u00d77\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 scores = tf . random . uniform (( 4 , 10 , 7 ), minval = 0 , maxval = 100 , dtype = tf . int32 ) tf . print ( scores ) [[[52 82 66 ... 17 86 14] [8 36 94 ... 13 78 41] [77 53 51 ... 22 91 56] ... [11 19 26 ... 89 86 68] [60 72 0 ... 11 26 15] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [83 36 31 ... 75 38 85] [54 26 67 ... 60 68 98] ... [20 5 18 ... 32 45 3] [72 52 81 ... 88 41 20] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [78 71 54 ... 43 98 81] [21 66 53 ... 97 75 77] ... [6 74 3 ... 53 65 43] [98 36 72 ... 33 36 81] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [35 8 82 ... 11 59 97] [44 6 99 ... 81 60 27] ... [76 26 35 ... 51 8 17] [33 52 53 ... 78 37 31] [71 27 44 ... 0 52 16]]] #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 p = tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u7b2c1\u95e8\u8bfe\u7a0b\uff0c\u7b2c3\u95e8\u8bfe\u7a0b\uff0c\u7b2c6\u95e8\u8bfe\u7a0b\u6210\u7ee9 q = tf . gather ( tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ),[ 1 , 3 , 6 ], axis = 2 ) tf . print ( q ) [[[82 55 14] [80 46 96] [99 58 74]] [[73 48 81] [10 38 92] [21 86 90]] [[80 57 60] [12 34 25] [78 71 21]] [[57 75 3] [41 47 13] [27 96 16]]] # \u62bd\u53d6\u7b2c0\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c2\u4e2a\u73ed\u7ea7\u7684\u7b2c4\u4e2a\u5b66\u751f\uff0c\u7b2c3\u4e2a\u73ed\u7ea7\u7684\u7b2c6\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 #indices\u7684\u957f\u5ea6\u4e3a\u91c7\u6837\u6837\u672c\u7684\u4e2a\u6570\uff0c\u6bcf\u4e2a\u5143\u7d20\u4e3a\u91c7\u6837\u4f4d\u7f6e\u7684\u5750\u6807 s = tf . gather_nd ( scores , indices = [( 0 , 0 ),( 2 , 4 ),( 3 , 6 )]) s <tf.Tensor: shape=(3, 7), dtype=int32, numpy= array([[52, 82, 66, 55, 17, 86, 14], [99, 94, 46, 70, 1, 63, 41], [46, 83, 70, 80, 90, 85, 17]], dtype=int32)> \u4ee5\u4e0atf.gather\u548ctf.gather_nd\u7684\u529f\u80fd\u4e5f\u53ef\u4ee5\u7528tf.boolean_mask\u6765\u5b9e\u73b0\u3002 #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 p = tf . boolean_mask ( scores ,[ True , False , False , False , False , True , False , False , False , True ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] #\u62bd\u53d6\u7b2c0\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c2\u4e2a\u73ed\u7ea7\u7684\u7b2c4\u4e2a\u5b66\u751f\uff0c\u7b2c3\u4e2a\u73ed\u7ea7\u7684\u7b2c6\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 s = tf . boolean_mask ( scores , [[ True , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , True , False , False , False , False , False ], [ False , False , False , False , False , False , True , False , False , False ]]) tf . print ( s ) [[52 82 66 ... 17 86 14] [99 94 46 ... 1 63 41] [46 83 70 ... 90 85 17]] #\u5229\u7528tf.boolean_mask\u53ef\u4ee5\u5b9e\u73b0\u5e03\u5c14\u7d22\u5f15 #\u627e\u5230\u77e9\u9635\u4e2d\u5c0f\u4e8e0\u7684\u5143\u7d20 c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) tf . print ( c , \" \\n \" ) tf . print ( tf . boolean_mask ( c , c < 0 ), \" \\n \" ) tf . print ( c [ c < 0 ]) #\u5e03\u5c14\u7d22\u5f15\uff0c\u4e3aboolean_mask\u7684\u8bed\u6cd5\u7cd6\u5f62\u5f0f [[-1 1 -1] [2 2 -2] [3 -3 3]] [-1 -1 -2 -3] [-1 -1 -2 -3] \u4ee5\u4e0a\u8fd9\u4e9b\u65b9\u6cd5\u4ec5\u80fd\u63d0\u53d6\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\uff0c\u4f46\u4e0d\u80fd\u66f4\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\u3002 \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528tf.where\u548ctf.scatter_nd\u3002 tf.where\u53ef\u4ee5\u7406\u89e3\u4e3aif\u7684\u5f20\u91cf\u7248\u672c\uff0c\u6b64\u5916\u5b83\u8fd8\u53ef\u4ee5\u7528\u4e8e\u627e\u5230\u6ee1\u8db3\u6761\u4ef6\u7684\u6240\u6709\u5143\u7d20\u7684\u4f4d\u7f6e\u5750\u6807\u3002 tf.scatter_nd\u7684\u4f5c\u7528\u548ctf.gather_nd\u6709\u4e9b\u76f8\u53cd\uff0ctf.gather_nd\u7528\u4e8e\u6536\u96c6\u5f20\u91cf\u7684\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5143\u7d20\uff0c \u800ctf.scatter_nd\u53ef\u4ee5\u5c06\u67d0\u4e9b\u503c\u63d2\u5165\u5230\u4e00\u4e2a\u7ed9\u5b9ashape\u7684\u51680\u7684\u5f20\u91cf\u7684\u6307\u5b9a\u4f4d\u7f6e\u5904\u3002 #\u627e\u5230\u5f20\u91cf\u4e2d\u5c0f\u4e8e0\u7684\u5143\u7d20,\u5c06\u5176\u6362\u6210np.nan\u5f97\u5230\u65b0\u7684\u5f20\u91cf #tf.where\u548cnp.where\u4f5c\u7528\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3aif\u7684\u5f20\u91cf\u7248\u672c c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) d = tf . where ( c < 0 , tf . fill ( c . shape , np . nan ), c ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[nan, 1., nan], [ 2., 2., nan], [ 3., nan, 3.]], dtype=float32)> #\u5982\u679cwhere\u53ea\u6709\u4e00\u4e2a\u53c2\u6570\uff0c\u5c06\u8fd4\u56de\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684\u4f4d\u7f6e\u5750\u6807 indices = tf . where ( c < 0 ) indices <tf.Tensor: shape=(4, 2), dtype=int64, numpy= array([[0, 0], [0, 2], [1, 2], [2, 1]])> #\u5c06\u5f20\u91cf\u7684\u7b2c[0,0]\u548c[2,1]\u4e24\u4e2a\u4f4d\u7f6e\u5143\u7d20\u66ff\u6362\u4e3a0\u5f97\u5230\u65b0\u7684\u5f20\u91cf d = c - tf . scatter_nd ([[ 0 , 0 ],[ 2 , 1 ]],[ c [ 0 , 0 ], c [ 2 , 1 ]], c . shape ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[ 0., 1., -1.], [ 2., 2., -2.], [ 3., 0., 3.]], dtype=float32)> #scatter_nd\u7684\u4f5c\u7528\u548cgather_nd\u6709\u4e9b\u76f8\u53cd #\u53ef\u4ee5\u5c06\u67d0\u4e9b\u503c\u63d2\u5165\u5230\u4e00\u4e2a\u7ed9\u5b9ashape\u7684\u51680\u7684\u5f20\u91cf\u7684\u6307\u5b9a\u4f4d\u7f6e\u5904\u3002 indices = tf . where ( c < 0 ) tf . scatter_nd ( indices , tf . gather_nd ( c , indices ), c . shape ) <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[-1., 0., -1.], [ 0., 0., -2.], [ 0., -3., 0.]], dtype=float32)>","title":"\u4e8c \uff0c\u7d22\u5f15\u5207\u7247"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u4e09\u7ef4\u5ea6\u53d8\u6362","text":"\u7ef4\u5ea6\u53d8\u6362\u76f8\u5173\u51fd\u6570\u4e3b\u8981\u6709 tf.reshape, tf.squeeze, tf.expand_dims, tf.transpose. tf.reshape \u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\u3002 tf.squeeze \u53ef\u4ee5\u51cf\u5c11\u7ef4\u5ea6\u3002 tf.expand_dims \u53ef\u4ee5\u589e\u52a0\u7ef4\u5ea6\u3002 tf.transpose \u53ef\u4ee5\u4ea4\u6362\u7ef4\u5ea6\u3002 tf.reshape\u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\uff0c\u4f46\u662f\u5176\u672c\u8d28\u4e0a\u4e0d\u4f1a\u6539\u53d8\u5f20\u91cf\u5143\u7d20\u7684\u5b58\u50a8\u987a\u5e8f\uff0c\u6240\u4ee5\uff0c\u8be5\u64cd\u4f5c\u5b9e\u9645\u4e0a\u975e\u5e38\u8fc5\u901f\uff0c\u5e76\u4e14\u662f\u53ef\u9006\u7684\u3002 a = tf . random . uniform ( shape = [ 1 , 3 , 3 , 2 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) tf . print ( a ) TensorShape([1, 3, 3, 2]) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] # \u6539\u6210 \uff083,6\uff09\u5f62\u72b6\u7684\u5f20\u91cf b = tf . reshape ( a ,[ 3 , 6 ]) tf . print ( b . shape ) tf . print ( b ) TensorShape([3, 6]) [[135 178 26 116 29 224] [179 219 153 209 111 215] [39 7 138 129 59 205]] # \u6539\u56de\u6210 [1,3,3,2] \u5f62\u72b6\u7684\u5f20\u91cf c = tf . reshape ( b ,[ 1 , 3 , 3 , 2 ]) tf . print ( c ) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] \u5982\u679c\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\uff0c\u5229\u7528tf.squeeze\u53ef\u4ee5\u6d88\u9664\u8fd9\u4e2a\u7ef4\u5ea6\u3002 \u548ctf.reshape\u76f8\u4f3c\uff0c\u5b83\u672c\u8d28\u4e0a\u4e0d\u4f1a\u6539\u53d8\u5f20\u91cf\u5143\u7d20\u7684\u5b58\u50a8\u987a\u5e8f\u3002 \u5f20\u91cf\u7684\u5404\u4e2a\u5143\u7d20\u5728\u5185\u5b58\u4e2d\u662f\u7ebf\u6027\u5b58\u50a8\u7684\uff0c\u5176\u4e00\u822c\u89c4\u5f8b\u662f\uff0c\u540c\u4e00\u5c42\u7ea7\u4e2d\u7684\u76f8\u90bb\u5143\u7d20\u7684\u7269\u7406\u5730\u5740\u4e5f\u76f8\u90bb\u3002 s = tf . squeeze ( a ) tf . print ( s . shape ) tf . print ( s ) TensorShape([3, 3, 2]) [[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]] d = tf . expand_dims ( s , axis = 0 ) #\u5728\u7b2c0\u7ef4\u63d2\u5165\u957f\u5ea6\u4e3a1\u7684\u4e00\u4e2a\u7ef4\u5ea6 d <tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy= array([[[[135, 178], [ 26, 116], [ 29, 224]], [[179, 219], [153, 209], [111, 215]], [[ 39, 7], [138, 129], [ 59, 205]]]], dtype=int32)> tf.transpose\u53ef\u4ee5\u4ea4\u6362\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u4e0etf.reshape\u4e0d\u540c\uff0c\u5b83\u4f1a\u6539\u53d8\u5f20\u91cf\u5143\u7d20\u7684\u5b58\u50a8\u987a\u5e8f\u3002 tf.transpose\u5e38\u7528\u4e8e\u56fe\u7247\u5b58\u50a8\u683c\u5f0f\u7684\u53d8\u6362\u4e0a\u3002 # Batch,Height,Width,Channel a = tf . random . uniform ( shape = [ 100 , 600 , 600 , 4 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) # \u8f6c\u6362\u6210 Channel,Height,Width,Batch s = tf . transpose ( a , perm = [ 3 , 1 , 2 , 0 ]) tf . print ( s . shape ) TensorShape([100, 600, 600, 4]) TensorShape([4, 600, 600, 100])","title":"\u4e09\uff0c\u7ef4\u5ea6\u53d8\u6362"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u56db\u5408\u5e76\u5206\u5272","text":"\u548cnumpy\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u7528tf.concat\u548ctf.stack\u65b9\u6cd5\u5bf9\u591a\u4e2a\u5f20\u91cf\u8fdb\u884c\u5408\u5e76\uff0c\u53ef\u4ee5\u7528tf.split\u65b9\u6cd5\u628a\u4e00\u4e2a\u5f20\u91cf\u5206\u5272\u6210\u591a\u4e2a\u5f20\u91cf\u3002 tf.concat\u548ctf.stack\u6709\u7565\u5fae\u7684\u533a\u522b\uff0ctf.concat\u662f\u8fde\u63a5\uff0c\u4e0d\u4f1a\u589e\u52a0\u7ef4\u5ea6\uff0c\u800ctf.stack\u662f\u5806\u53e0\uff0c\u4f1a\u589e\u52a0\u7ef4\u5ea6\u3002 a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) tf . concat ([ a , b , c ], axis = 0 ) <tf.Tensor: shape=(6, 2), dtype=float32, numpy= array([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]], dtype=float32)> tf . concat ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 6), dtype=float32, numpy= array([[ 1., 2., 5., 6., 9., 10.], [ 3., 4., 7., 8., 11., 12.]], dtype=float32)> tf . stack ([ a , b , c ]) <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 3., 4.]], [[ 5., 6.], [ 7., 8.]], [[ 9., 10.], [11., 12.]]], dtype=float32)> tf . stack ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 5., 6.], [ 9., 10.]], [[ 3., 4.], [ 7., 8.], [11., 12.]]], dtype=float32)> a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) c = tf . concat ([ a , b , c ], axis = 0 ) tf.split\u662ftf.concat\u7684\u9006\u8fd0\u7b97\uff0c\u53ef\u4ee5\u6307\u5b9a\u5206\u5272\u4efd\u6570\u5e73\u5747\u5206\u5272\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9a\u6bcf\u4efd\u7684\u8bb0\u5f55\u6570\u91cf\u8fdb\u884c\u5206\u5272\u3002 #tf.split(value,num_or_size_splits,axis) tf . split ( c , 3 , axis = 0 ) #\u6307\u5b9a\u5206\u5272\u4efd\u6570\uff0c\u5e73\u5747\u5206\u5272 [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] tf . split ( c ,[ 2 , 2 , 2 ], axis = 0 ) #\u6307\u5b9a\u6bcf\u4efd\u7684\u8bb0\u5f55\u6570\u91cf [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u5408\u5e76\u5206\u5272"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/","text":"4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97 # \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u4e00\uff0c\u6807\u91cf\u8fd0\u7b97 # \u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u53ef\u4ee5\u5206\u4e3a\u6807\u91cf\u8fd0\u7b97\u7b26\u3001\u5411\u91cf\u8fd0\u7b97\u7b26\u3001\u4ee5\u53ca\u77e9\u9635\u8fd0\u7b97\u7b26\u3002 \u52a0\u51cf\u4e58\u9664\u4e58\u65b9\uff0c\u4ee5\u53ca\u4e09\u89d2\u51fd\u6570\uff0c\u6307\u6570\uff0c\u5bf9\u6570\u7b49\u5e38\u89c1\u51fd\u6570\uff0c\u903b\u8f91\u6bd4\u8f83\u8fd0\u7b97\u7b26\u7b49\u90fd\u662f\u6807\u91cf\u8fd0\u7b97\u7b26\u3002 \u6807\u91cf\u8fd0\u7b97\u7b26\u7684\u7279\u70b9\u662f\u5bf9\u5f20\u91cf\u5b9e\u65bd\u9010\u5143\u7d20\u8fd0\u7b97\u3002 \u6709\u4e9b\u6807\u91cf\u8fd0\u7b97\u7b26\u5bf9\u5e38\u7528\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u8fdb\u884c\u4e86\u91cd\u8f7d\u3002\u5e76\u4e14\u652f\u6301\u7c7b\u4f3cnumpy\u7684\u5e7f\u64ad\u7279\u6027\u3002 \u8bb8\u591a\u6807\u91cf\u8fd0\u7b97\u7b26\u90fd\u5728 tf.math\u6a21\u5757\u4e0b\u3002 import tensorflow as tf import numpy as np a = tf . constant ([[ 1.0 , 2 ],[ - 3 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6 ],[ 7.0 , 8.0 ]]) a + b #\u8fd0\u7b97\u7b26\u91cd\u8f7d <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 6., 8.], [ 4., 12.]], dtype=float32)> a - b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ -4., -4.], [-10., -4.]], dtype=float32)> a * b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 5., 12.], [-21., 32.]], dtype=float32)> a / b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0.2 , 0.33333334], [-0.42857143, 0.5 ]], dtype=float32)> a ** 2 <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 1., 4.], [ 9., 16.]], dtype=float32)> a ** ( 0.5 ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a % 3 #mod\u7684\u8fd0\u7b97\u7b26\u91cd\u8f7d\uff0c\u7b49\u4ef7\u4e8em = tf.math.mod(a,3) <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)> a // 3 #\u5730\u677f\u9664\u6cd5 <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0., 0.], [-1., 1.]], dtype=float32)> ( a >= 2 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, True]])> ( a >= 2 ) & ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, False]])> ( a >= 2 ) | ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[ True, True], [ True, True]])> a == 5 #tf.equal(a,5) <tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])> tf . sqrt ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a = tf . constant ([ 1.0 , 8.0 ]) b = tf . constant ([ 5.0 , 6.0 ]) c = tf . constant ([ 6.0 , 7.0 ]) tf . add_n ([ a , b , c ]) <tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)> tf . print ( tf . maximum ( a , b )) [5 8] tf . print ( tf . minimum ( a , b )) [1 6] x = tf . constant ([ 2.6 , - 2.7 ]) tf . print ( tf . math . round ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u56db\u820d\u4e94\u5165 tf . print ( tf . math . floor ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0b\u5f52\u6574 tf . print ( tf . math . ceil ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0a\u5f52\u6574 [3 -3] [2 -3] [3 -2] # \u5e45\u503c\u88c1\u526a x = tf . constant ([ 0.9 , - 0.8 , 100.0 , - 20.0 , 0.7 ]) y = tf . clip_by_value ( x , clip_value_min =- 1 , clip_value_max = 1 ) z = tf . clip_by_norm ( x , clip_norm = 3 ) tf . print ( y ) tf . print ( z ) [0.9 -0.8 1 -1 0.7] [0.0264732055 -0.0235317405 2.94146752 -0.588293493 0.0205902718] \u4e8c\uff0c\u5411\u91cf\u8fd0\u7b97 # \u5411\u91cf\u8fd0\u7b97\u7b26\u53ea\u5728\u4e00\u4e2a\u7279\u5b9a\u8f74\u4e0a\u8fd0\u7b97\uff0c\u5c06\u4e00\u4e2a\u5411\u91cf\u6620\u5c04\u5230\u4e00\u4e2a\u6807\u91cf\u6216\u8005\u53e6\u5916\u4e00\u4e2a\u5411\u91cf\u3002 \u8bb8\u591a\u5411\u91cf\u8fd0\u7b97\u7b26\u90fd\u4ee5reduce\u5f00\u5934\u3002 #\u5411\u91cfreduce a = tf . range ( 1 , 10 ) tf . print ( tf . reduce_sum ( a )) tf . print ( tf . reduce_mean ( a )) tf . print ( tf . reduce_max ( a )) tf . print ( tf . reduce_min ( a )) tf . print ( tf . reduce_prod ( a )) 45 5 9 1 362880 #\u5f20\u91cf\u6307\u5b9a\u7ef4\u5ea6\u8fdb\u884creduce b = tf . reshape ( a ,( 3 , 3 )) tf . print ( tf . reduce_sum ( b , axis = 1 , keepdims = True )) tf . print ( tf . reduce_sum ( b , axis = 0 , keepdims = True )) [[6] [15] [24]] [[12 15 18]] #bool\u7c7b\u578b\u7684reduce p = tf . constant ([ True , False , False ]) q = tf . constant ([ False , False , True ]) tf . print ( tf . reduce_all ( p )) tf . print ( tf . reduce_any ( q )) 0 1 #\u5229\u7528tf.foldr\u5b9e\u73b0tf.reduce_sum s = tf . foldr ( lambda a , b : a + b , tf . range ( 10 )) tf . print ( s ) 45 #cum\u626b\u63cf\u7d2f\u79ef a = tf . range ( 1 , 10 ) tf . print ( tf . math . cumsum ( a )) tf . print ( tf . math . cumprod ( a )) [1 3 6 ... 28 36 45] [1 2 6 ... 5040 40320 362880] #arg\u6700\u5927\u6700\u5c0f\u503c\u7d22\u5f15 a = tf . range ( 1 , 10 ) tf . print ( tf . argmax ( a )) tf . print ( tf . argmin ( a )) 8 0 #tf.math.top_k\u53ef\u4ee5\u7528\u4e8e\u5bf9\u5f20\u91cf\u6392\u5e8f a = tf . constant ([ 1 , 3 , 7 , 5 , 4 , 8 ]) values , indices = tf . math . top_k ( a , 3 , sorted = True ) tf . print ( values ) tf . print ( indices ) #\u5229\u7528tf.math.top_k\u53ef\u4ee5\u5728TensorFlow\u4e2d\u5b9e\u73b0KNN\u7b97\u6cd5 [8 7 5] [5 2 3] \u4e09\uff0c\u77e9\u9635\u8fd0\u7b97 # \u77e9\u9635\u5fc5\u987b\u662f\u4e8c\u7ef4\u7684\u3002\u7c7b\u4f3ctf.constant([1,2,3])\u8fd9\u6837\u7684\u4e0d\u662f\u77e9\u9635\u3002 \u77e9\u9635\u8fd0\u7b97\u5305\u62ec\uff1a\u77e9\u9635\u4e58\u6cd5\uff0c\u77e9\u9635\u8f6c\u7f6e\uff0c\u77e9\u9635\u9006\uff0c\u77e9\u9635\u6c42\u8ff9\uff0c\u77e9\u9635\u8303\u6570\uff0c\u77e9\u9635\u884c\u5217\u5f0f\uff0c\u77e9\u9635\u6c42\u7279\u5f81\u503c\uff0c\u77e9\u9635\u5206\u89e3\u7b49\u8fd0\u7b97\u3002 \u9664\u4e86\u4e00\u4e9b\u5e38\u7528\u7684\u8fd0\u7b97\u5916\uff0c\u5927\u90e8\u5206\u548c\u77e9\u9635\u6709\u5173\u7684\u8fd0\u7b97\u90fd\u5728tf.linalg\u5b50\u5305\u4e2d\u3002 #\u77e9\u9635\u4e58\u6cd5 a = tf . constant ([[ 1 , 2 ],[ 3 , 4 ]]) b = tf . constant ([[ 2 , 0 ],[ 0 , 2 ]]) a @b #\u7b49\u4ef7\u4e8etf.matmul(a,b) <tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[2, 4], [6, 8]], dtype=int32)> #\u77e9\u9635\u8f6c\u7f6e a = tf . constant ([[ 1 , 2 ],[ 3 , 4 ]]) tf . transpose ( a ) <tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]], dtype=int32)> #\u77e9\u9635\u9006\uff0c\u5fc5\u987b\u4e3atf.float32\u6216tf.double\u7c7b\u578b a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) tf . linalg . inv ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[-2.0000002 , 1.0000001 ], [ 1.5000001 , -0.50000006]], dtype=float32)> #\u77e9\u9635\u6c42trace a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) tf . linalg . trace ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.0> #\u77e9\u9635\u6c42\u8303\u6570 a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . norm ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.477226> #\u77e9\u9635\u884c\u5217\u5f0f a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . det ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=-2.0> #\u77e9\u9635\u7279\u5f81\u503c a = tf . constant ([[ 1.0 , 2 ],[ - 5 , 4 ]]) tf . linalg . eigvals ( a ) <tf.Tensor: shape=(2,), dtype=complex64, numpy=array([2.4999995+2.7838817j, 2.5 -2.783882j ], dtype=complex64)> #\u77e9\u9635QR\u5206\u89e3, \u5c06\u4e00\u4e2a\u65b9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635q\u548c\u4e0a\u4e09\u89d2\u77e9\u9635r #QR\u5206\u89e3\u5b9e\u9645\u4e0a\u662f\u5bf9\u77e9\u9635a\u5b9e\u65bdSchmidt\u6b63\u4ea4\u5316\u5f97\u5230q a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]], dtype = tf . float32 ) q , r = tf . linalg . qr ( a ) tf . print ( q ) tf . print ( r ) tf . print ( q @r ) [[-0.316227794 -0.948683321] [-0.948683321 0.316227734]] [[-3.1622777 -4.4271884] [0 -0.632455349]] [[1.00000012 1.99999976] [3 4]] #\u77e9\u9635svd\u5206\u89e3 #svd\u5206\u89e3\u53ef\u4ee5\u5c06\u4efb\u610f\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635u,\u4e00\u4e2a\u5bf9\u89d2\u9635s\u548c\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635v.t()\u7684\u4e58\u79ef #svd\u5e38\u7528\u4e8e\u77e9\u9635\u538b\u7f29\u548c\u964d\u7ef4 a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ],[ 5.0 , 6.0 ]], dtype = tf . float32 ) s , u , v = tf . linalg . svd ( a ) tf . print ( u , \" \\n \" ) tf . print ( s , \" \\n \" ) tf . print ( v , \" \\n \" ) tf . print ( u @tf . linalg . diag ( s ) @tf . transpose ( v )) #\u5229\u7528svd\u5206\u89e3\u53ef\u4ee5\u5728TensorFlow\u4e2d\u5b9e\u73b0\u4e3b\u6210\u5206\u5206\u6790\u964d\u7ef4 [[0.229847744 -0.88346082] [0.524744868 -0.240782902] [0.819642067 0.401896209]] [9.52551842 0.51429987] [[0.619629562 0.784894466] [0.784894466 -0.619629562]] [[1.00000119 2] [3.00000095 4.00000048] [5.00000143 6.00000095]] \u56db\uff0c\u5e7f\u64ad\u673a\u5236 # TensorFlow\u7684\u5e7f\u64ad\u89c4\u5219\u548cnumpy\u662f\u4e00\u6837\u7684: 1\u3001\u5982\u679c\u5f20\u91cf\u7684\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5c06\u7ef4\u5ea6\u8f83\u5c0f\u7684\u5f20\u91cf\u8fdb\u884c\u6269\u5c55\uff0c\u76f4\u5230\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\u90fd\u4e00\u6837\u3002 2\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u662f\u76f8\u540c\u7684\uff0c\u6216\u8005\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u4e3a1\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u8bf4\u8fd9\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u662f\u76f8\u5bb9\u7684\u3002 3\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u662f\u76f8\u5bb9\u7684\uff0c\u5b83\u4eec\u5c31\u80fd\u4f7f\u7528\u5e7f\u64ad\u3002 4\u3001\u5e7f\u64ad\u4e4b\u540e\uff0c\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u957f\u5ea6\u5c06\u53d6\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u957f\u5ea6\u7684\u8f83\u5927\u503c\u3002 5\u3001\u5728\u4efb\u4f55\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684\u957f\u5ea6\u4e3a1\uff0c\u53e6\u4e00\u4e2a\u5f20\u91cf\u957f\u5ea6\u5927\u4e8e1\uff0c\u90a3\u4e48\u5728\u8be5\u7ef4\u5ea6\u4e0a\uff0c\u5c31\u597d\u50cf\u662f\u5bf9\u7b2c\u4e00\u4e2a\u5f20\u91cf\u8fdb\u884c\u4e86\u590d\u5236\u3002 tf.broadcast_to \u4ee5\u663e\u5f0f\u7684\u65b9\u5f0f\u6309\u7167\u5e7f\u64ad\u673a\u5236\u6269\u5c55\u5f20\u91cf\u7684\u7ef4\u5ea6\u3002 a = tf . constant ([ 1 , 2 , 3 ]) b = tf . constant ([[ 0 , 0 , 0 ],[ 1 , 1 , 1 ],[ 2 , 2 , 2 ]]) b + a #\u7b49\u4ef7\u4e8e b + tf.broadcast_to(a,b.shape) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [2, 3, 4], [3, 4, 5]], dtype=int32)> tf . broadcast_to ( a , b . shape ) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [1, 2, 3], [1, 2, 3]], dtype=int32)> #\u8ba1\u7b97\u5e7f\u64ad\u540e\u8ba1\u7b97\u7ed3\u679c\u7684\u5f62\u72b6\uff0c\u9759\u6001\u5f62\u72b6\uff0cTensorShape\u7c7b\u578b\u53c2\u6570 tf . broadcast_static_shape ( a . shape , b . shape ) TensorShape([3, 3]) #\u8ba1\u7b97\u5e7f\u64ad\u540e\u8ba1\u7b97\u7ed3\u679c\u7684\u5f62\u72b6\uff0c\u52a8\u6001\u5f62\u72b6\uff0cTensor\u7c7b\u578b\u53c2\u6570 c = tf . constant ([ 1 , 2 , 3 ]) d = tf . constant ([[ 1 ],[ 2 ],[ 3 ]]) tf . broadcast_dynamic_shape ( tf . shape ( c ), tf . shape ( d )) <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)> #\u5e7f\u64ad\u6548\u679c c + d #\u7b49\u4ef7\u4e8e tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3]) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[2, 3, 4], [3, 4, 5], [4, 5, 6]], dtype=int32)> \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#4-2\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97","text":"\u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002","title":"4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u4e00\u6807\u91cf\u8fd0\u7b97","text":"\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u53ef\u4ee5\u5206\u4e3a\u6807\u91cf\u8fd0\u7b97\u7b26\u3001\u5411\u91cf\u8fd0\u7b97\u7b26\u3001\u4ee5\u53ca\u77e9\u9635\u8fd0\u7b97\u7b26\u3002 \u52a0\u51cf\u4e58\u9664\u4e58\u65b9\uff0c\u4ee5\u53ca\u4e09\u89d2\u51fd\u6570\uff0c\u6307\u6570\uff0c\u5bf9\u6570\u7b49\u5e38\u89c1\u51fd\u6570\uff0c\u903b\u8f91\u6bd4\u8f83\u8fd0\u7b97\u7b26\u7b49\u90fd\u662f\u6807\u91cf\u8fd0\u7b97\u7b26\u3002 \u6807\u91cf\u8fd0\u7b97\u7b26\u7684\u7279\u70b9\u662f\u5bf9\u5f20\u91cf\u5b9e\u65bd\u9010\u5143\u7d20\u8fd0\u7b97\u3002 \u6709\u4e9b\u6807\u91cf\u8fd0\u7b97\u7b26\u5bf9\u5e38\u7528\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u8fdb\u884c\u4e86\u91cd\u8f7d\u3002\u5e76\u4e14\u652f\u6301\u7c7b\u4f3cnumpy\u7684\u5e7f\u64ad\u7279\u6027\u3002 \u8bb8\u591a\u6807\u91cf\u8fd0\u7b97\u7b26\u90fd\u5728 tf.math\u6a21\u5757\u4e0b\u3002 import tensorflow as tf import numpy as np a = tf . constant ([[ 1.0 , 2 ],[ - 3 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6 ],[ 7.0 , 8.0 ]]) a + b #\u8fd0\u7b97\u7b26\u91cd\u8f7d <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 6., 8.], [ 4., 12.]], dtype=float32)> a - b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ -4., -4.], [-10., -4.]], dtype=float32)> a * b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 5., 12.], [-21., 32.]], dtype=float32)> a / b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0.2 , 0.33333334], [-0.42857143, 0.5 ]], dtype=float32)> a ** 2 <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 1., 4.], [ 9., 16.]], dtype=float32)> a ** ( 0.5 ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a % 3 #mod\u7684\u8fd0\u7b97\u7b26\u91cd\u8f7d\uff0c\u7b49\u4ef7\u4e8em = tf.math.mod(a,3) <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)> a // 3 #\u5730\u677f\u9664\u6cd5 <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0., 0.], [-1., 1.]], dtype=float32)> ( a >= 2 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, True]])> ( a >= 2 ) & ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, False]])> ( a >= 2 ) | ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[ True, True], [ True, True]])> a == 5 #tf.equal(a,5) <tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])> tf . sqrt ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a = tf . constant ([ 1.0 , 8.0 ]) b = tf . constant ([ 5.0 , 6.0 ]) c = tf . constant ([ 6.0 , 7.0 ]) tf . add_n ([ a , b , c ]) <tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)> tf . print ( tf . maximum ( a , b )) [5 8] tf . print ( tf . minimum ( a , b )) [1 6] x = tf . constant ([ 2.6 , - 2.7 ]) tf . print ( tf . math . round ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u56db\u820d\u4e94\u5165 tf . print ( tf . math . floor ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0b\u5f52\u6574 tf . print ( tf . math . ceil ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0a\u5f52\u6574 [3 -3] [2 -3] [3 -2] # \u5e45\u503c\u88c1\u526a x = tf . constant ([ 0.9 , - 0.8 , 100.0 , - 20.0 , 0.7 ]) y = tf . clip_by_value ( x , clip_value_min =- 1 , clip_value_max = 1 ) z = tf . clip_by_norm ( x , clip_norm = 3 ) tf . print ( y ) tf . print ( z ) [0.9 -0.8 1 -1 0.7] [0.0264732055 -0.0235317405 2.94146752 -0.588293493 0.0205902718]","title":"\u4e00\uff0c\u6807\u91cf\u8fd0\u7b97"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u4e8c\u5411\u91cf\u8fd0\u7b97","text":"\u5411\u91cf\u8fd0\u7b97\u7b26\u53ea\u5728\u4e00\u4e2a\u7279\u5b9a\u8f74\u4e0a\u8fd0\u7b97\uff0c\u5c06\u4e00\u4e2a\u5411\u91cf\u6620\u5c04\u5230\u4e00\u4e2a\u6807\u91cf\u6216\u8005\u53e6\u5916\u4e00\u4e2a\u5411\u91cf\u3002 \u8bb8\u591a\u5411\u91cf\u8fd0\u7b97\u7b26\u90fd\u4ee5reduce\u5f00\u5934\u3002 #\u5411\u91cfreduce a = tf . range ( 1 , 10 ) tf . print ( tf . reduce_sum ( a )) tf . print ( tf . reduce_mean ( a )) tf . print ( tf . reduce_max ( a )) tf . print ( tf . reduce_min ( a )) tf . print ( tf . reduce_prod ( a )) 45 5 9 1 362880 #\u5f20\u91cf\u6307\u5b9a\u7ef4\u5ea6\u8fdb\u884creduce b = tf . reshape ( a ,( 3 , 3 )) tf . print ( tf . reduce_sum ( b , axis = 1 , keepdims = True )) tf . print ( tf . reduce_sum ( b , axis = 0 , keepdims = True )) [[6] [15] [24]] [[12 15 18]] #bool\u7c7b\u578b\u7684reduce p = tf . constant ([ True , False , False ]) q = tf . constant ([ False , False , True ]) tf . print ( tf . reduce_all ( p )) tf . print ( tf . reduce_any ( q )) 0 1 #\u5229\u7528tf.foldr\u5b9e\u73b0tf.reduce_sum s = tf . foldr ( lambda a , b : a + b , tf . range ( 10 )) tf . print ( s ) 45 #cum\u626b\u63cf\u7d2f\u79ef a = tf . range ( 1 , 10 ) tf . print ( tf . math . cumsum ( a )) tf . print ( tf . math . cumprod ( a )) [1 3 6 ... 28 36 45] [1 2 6 ... 5040 40320 362880] #arg\u6700\u5927\u6700\u5c0f\u503c\u7d22\u5f15 a = tf . range ( 1 , 10 ) tf . print ( tf . argmax ( a )) tf . print ( tf . argmin ( a )) 8 0 #tf.math.top_k\u53ef\u4ee5\u7528\u4e8e\u5bf9\u5f20\u91cf\u6392\u5e8f a = tf . constant ([ 1 , 3 , 7 , 5 , 4 , 8 ]) values , indices = tf . math . top_k ( a , 3 , sorted = True ) tf . print ( values ) tf . print ( indices ) #\u5229\u7528tf.math.top_k\u53ef\u4ee5\u5728TensorFlow\u4e2d\u5b9e\u73b0KNN\u7b97\u6cd5 [8 7 5] [5 2 3]","title":"\u4e8c\uff0c\u5411\u91cf\u8fd0\u7b97"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u4e09\u77e9\u9635\u8fd0\u7b97","text":"\u77e9\u9635\u5fc5\u987b\u662f\u4e8c\u7ef4\u7684\u3002\u7c7b\u4f3ctf.constant([1,2,3])\u8fd9\u6837\u7684\u4e0d\u662f\u77e9\u9635\u3002 \u77e9\u9635\u8fd0\u7b97\u5305\u62ec\uff1a\u77e9\u9635\u4e58\u6cd5\uff0c\u77e9\u9635\u8f6c\u7f6e\uff0c\u77e9\u9635\u9006\uff0c\u77e9\u9635\u6c42\u8ff9\uff0c\u77e9\u9635\u8303\u6570\uff0c\u77e9\u9635\u884c\u5217\u5f0f\uff0c\u77e9\u9635\u6c42\u7279\u5f81\u503c\uff0c\u77e9\u9635\u5206\u89e3\u7b49\u8fd0\u7b97\u3002 \u9664\u4e86\u4e00\u4e9b\u5e38\u7528\u7684\u8fd0\u7b97\u5916\uff0c\u5927\u90e8\u5206\u548c\u77e9\u9635\u6709\u5173\u7684\u8fd0\u7b97\u90fd\u5728tf.linalg\u5b50\u5305\u4e2d\u3002 #\u77e9\u9635\u4e58\u6cd5 a = tf . constant ([[ 1 , 2 ],[ 3 , 4 ]]) b = tf . constant ([[ 2 , 0 ],[ 0 , 2 ]]) a @b #\u7b49\u4ef7\u4e8etf.matmul(a,b) <tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[2, 4], [6, 8]], dtype=int32)> #\u77e9\u9635\u8f6c\u7f6e a = tf . constant ([[ 1 , 2 ],[ 3 , 4 ]]) tf . transpose ( a ) <tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]], dtype=int32)> #\u77e9\u9635\u9006\uff0c\u5fc5\u987b\u4e3atf.float32\u6216tf.double\u7c7b\u578b a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) tf . linalg . inv ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[-2.0000002 , 1.0000001 ], [ 1.5000001 , -0.50000006]], dtype=float32)> #\u77e9\u9635\u6c42trace a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) tf . linalg . trace ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.0> #\u77e9\u9635\u6c42\u8303\u6570 a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . norm ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.477226> #\u77e9\u9635\u884c\u5217\u5f0f a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . det ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=-2.0> #\u77e9\u9635\u7279\u5f81\u503c a = tf . constant ([[ 1.0 , 2 ],[ - 5 , 4 ]]) tf . linalg . eigvals ( a ) <tf.Tensor: shape=(2,), dtype=complex64, numpy=array([2.4999995+2.7838817j, 2.5 -2.783882j ], dtype=complex64)> #\u77e9\u9635QR\u5206\u89e3, \u5c06\u4e00\u4e2a\u65b9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635q\u548c\u4e0a\u4e09\u89d2\u77e9\u9635r #QR\u5206\u89e3\u5b9e\u9645\u4e0a\u662f\u5bf9\u77e9\u9635a\u5b9e\u65bdSchmidt\u6b63\u4ea4\u5316\u5f97\u5230q a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]], dtype = tf . float32 ) q , r = tf . linalg . qr ( a ) tf . print ( q ) tf . print ( r ) tf . print ( q @r ) [[-0.316227794 -0.948683321] [-0.948683321 0.316227734]] [[-3.1622777 -4.4271884] [0 -0.632455349]] [[1.00000012 1.99999976] [3 4]] #\u77e9\u9635svd\u5206\u89e3 #svd\u5206\u89e3\u53ef\u4ee5\u5c06\u4efb\u610f\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635u,\u4e00\u4e2a\u5bf9\u89d2\u9635s\u548c\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635v.t()\u7684\u4e58\u79ef #svd\u5e38\u7528\u4e8e\u77e9\u9635\u538b\u7f29\u548c\u964d\u7ef4 a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ],[ 5.0 , 6.0 ]], dtype = tf . float32 ) s , u , v = tf . linalg . svd ( a ) tf . print ( u , \" \\n \" ) tf . print ( s , \" \\n \" ) tf . print ( v , \" \\n \" ) tf . print ( u @tf . linalg . diag ( s ) @tf . transpose ( v )) #\u5229\u7528svd\u5206\u89e3\u53ef\u4ee5\u5728TensorFlow\u4e2d\u5b9e\u73b0\u4e3b\u6210\u5206\u5206\u6790\u964d\u7ef4 [[0.229847744 -0.88346082] [0.524744868 -0.240782902] [0.819642067 0.401896209]] [9.52551842 0.51429987] [[0.619629562 0.784894466] [0.784894466 -0.619629562]] [[1.00000119 2] [3.00000095 4.00000048] [5.00000143 6.00000095]]","title":"\u4e09\uff0c\u77e9\u9635\u8fd0\u7b97"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u56db\u5e7f\u64ad\u673a\u5236","text":"TensorFlow\u7684\u5e7f\u64ad\u89c4\u5219\u548cnumpy\u662f\u4e00\u6837\u7684: 1\u3001\u5982\u679c\u5f20\u91cf\u7684\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5c06\u7ef4\u5ea6\u8f83\u5c0f\u7684\u5f20\u91cf\u8fdb\u884c\u6269\u5c55\uff0c\u76f4\u5230\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\u90fd\u4e00\u6837\u3002 2\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u662f\u76f8\u540c\u7684\uff0c\u6216\u8005\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u4e3a1\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u8bf4\u8fd9\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u662f\u76f8\u5bb9\u7684\u3002 3\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u662f\u76f8\u5bb9\u7684\uff0c\u5b83\u4eec\u5c31\u80fd\u4f7f\u7528\u5e7f\u64ad\u3002 4\u3001\u5e7f\u64ad\u4e4b\u540e\uff0c\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u957f\u5ea6\u5c06\u53d6\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u957f\u5ea6\u7684\u8f83\u5927\u503c\u3002 5\u3001\u5728\u4efb\u4f55\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684\u957f\u5ea6\u4e3a1\uff0c\u53e6\u4e00\u4e2a\u5f20\u91cf\u957f\u5ea6\u5927\u4e8e1\uff0c\u90a3\u4e48\u5728\u8be5\u7ef4\u5ea6\u4e0a\uff0c\u5c31\u597d\u50cf\u662f\u5bf9\u7b2c\u4e00\u4e2a\u5f20\u91cf\u8fdb\u884c\u4e86\u590d\u5236\u3002 tf.broadcast_to \u4ee5\u663e\u5f0f\u7684\u65b9\u5f0f\u6309\u7167\u5e7f\u64ad\u673a\u5236\u6269\u5c55\u5f20\u91cf\u7684\u7ef4\u5ea6\u3002 a = tf . constant ([ 1 , 2 , 3 ]) b = tf . constant ([[ 0 , 0 , 0 ],[ 1 , 1 , 1 ],[ 2 , 2 , 2 ]]) b + a #\u7b49\u4ef7\u4e8e b + tf.broadcast_to(a,b.shape) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [2, 3, 4], [3, 4, 5]], dtype=int32)> tf . broadcast_to ( a , b . shape ) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [1, 2, 3], [1, 2, 3]], dtype=int32)> #\u8ba1\u7b97\u5e7f\u64ad\u540e\u8ba1\u7b97\u7ed3\u679c\u7684\u5f62\u72b6\uff0c\u9759\u6001\u5f62\u72b6\uff0cTensorShape\u7c7b\u578b\u53c2\u6570 tf . broadcast_static_shape ( a . shape , b . shape ) TensorShape([3, 3]) #\u8ba1\u7b97\u5e7f\u64ad\u540e\u8ba1\u7b97\u7ed3\u679c\u7684\u5f62\u72b6\uff0c\u52a8\u6001\u5f62\u72b6\uff0cTensor\u7c7b\u578b\u53c2\u6570 c = tf . constant ([ 1 , 2 , 3 ]) d = tf . constant ([[ 1 ],[ 2 ],[ 3 ]]) tf . broadcast_dynamic_shape ( tf . shape ( c ), tf . shape ( d )) <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)> #\u5e7f\u64ad\u6548\u679c c + d #\u7b49\u4ef7\u4e8e tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3]) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[2, 3, 4], [3, 4, 5], [4, 5, 6]], dtype=int32)> \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u5e7f\u64ad\u673a\u5236"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-3%2CAutoGraph%E7%9A%84%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/","text":"4-3,AutoGraph\u7684\u4f7f\u7528\u89c4\u8303 # \u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph\u3002 TensorFlow 2.0\u4e3b\u8981\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6613\u4e8e\u8c03\u8bd5\uff0c\u7f16\u7801\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u6267\u884c\u6548\u7387\u504f\u4f4e\u3002 \u9759\u6001\u8ba1\u7b97\u56fe\u6267\u884c\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u8f83\u96be\u8c03\u8bd5\u3002 \u800cAutograph\u673a\u5236\u53ef\u4ee5\u5c06\u52a8\u6001\u56fe\u8f6c\u6362\u6210\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u517c\u6536\u6267\u884c\u6548\u7387\u548c\u7f16\u7801\u6548\u7387\u4e4b\u5229\u3002 \u5f53\u7136Autograph\u673a\u5236\u80fd\u591f\u8f6c\u6362\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u6ca1\u6709\u4efb\u4f55\u7ea6\u675f\u7684\uff0c\u6709\u4e00\u4e9b\u7f16\u7801\u89c4\u8303\u9700\u8981\u9075\u5faa\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u8f6c\u6362\u5931\u8d25\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u3002 \u6211\u4eec\u5c06\u7740\u91cd\u4ecb\u7ecdAutograph\u7684\u7f16\u7801\u89c4\u8303\u548cAutograph\u8f6c\u6362\u6210\u9759\u6001\u56fe\u7684\u539f\u7406\u3002 \u5e76\u4ecb\u7ecd\u4f7f\u7528tf.Module\u6765\u66f4\u597d\u5730\u6784\u5efaAutograph\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u4f7f\u7528Autograph\u7684\u7f16\u7801\u89c4\u8303\u3002 \u4e00\uff0cAutograph\u7f16\u7801\u89c4\u8303\u603b\u7ed3 # 1\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5e94\u5c3d\u53ef\u80fd\u4f7f\u7528TensorFlow\u4e2d\u7684\u51fd\u6570\u800c\u4e0d\u662fPython\u4e2d\u7684\u5176\u4ed6\u51fd\u6570\u3002\u4f8b\u5982\u4f7f\u7528tf.print\u800c\u4e0d\u662fprint\uff0c\u4f7f\u7528tf.range\u800c\u4e0d\u662frange\uff0c\u4f7f\u7528tf.constant(True)\u800c\u4e0d\u662fTrue. 2\uff0c\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. 3\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u4e0d\u53ef\u4fee\u6539\u8be5\u51fd\u6570\u5916\u90e8\u7684Python\u5217\u8868\u6216\u5b57\u5178\u7b49\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u3002 \u4e8c\uff0cAutograph\u7f16\u7801\u89c4\u8303\u89e3\u6790 # 1\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5e94\u5c3d\u91cf\u4f7f\u7528TensorFlow\u4e2d\u7684\u51fd\u6570\u800c\u4e0d\u662fPython\u4e2d\u7684\u5176\u4ed6\u51fd\u6570\u3002 import numpy as np import tensorflow as tf @tf . function def np_random (): a = np . random . randn ( 3 , 3 ) tf . print ( a ) @tf . function def tf_random (): a = tf . random . normal (( 3 , 3 )) tf . print ( a ) #np_random\u6bcf\u6b21\u6267\u884c\u90fd\u662f\u4e00\u6837\u7684\u7ed3\u679c\u3002 np_random () np_random () array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) #tf_random\u6bcf\u6b21\u6267\u884c\u90fd\u4f1a\u6709\u91cd\u65b0\u751f\u6210\u968f\u673a\u6570\u3002 tf_random () tf_random () [[-1.38956189 -0.394843668 0.420657277] [2.87235498 -1.33740318 -0.533843279] [0.918233037 0.118598573 -0.399486482]] [[-0.858178258 1.67509317 0.511889517] [-0.545829177 -2.20118237 -0.968222201] [0.733958483 -0.61904633 0.77440238]] 2\uff0c\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. # \u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. x = tf . Variable ( 1.0 , dtype = tf . float32 ) @tf . function def outer_var (): x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) outer_var () outer_var () @tf . function def inner_var (): x = tf . Variable ( 1.0 , dtype = tf . float32 ) x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) #\u6267\u884c\u5c06\u62a5\u9519 #inner_var() #inner_var() --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-12-c95a7c3c1ddd> in <module> 7 8 #\u6267\u884c\u5c06\u62a5\u9519 ----> 9 inner_var() 10 inner_var() ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds) 566 xla_context.Exit() 567 else: --> 568 result = self._call(*args, **kwds) 569 570 if tracing_count == self._get_tracing_count(): ...... ValueError: tf.function-decorated function tried to create variables on non-first call. 3,\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u4e0d\u53ef\u4fee\u6539\u8be5\u51fd\u6570\u5916\u90e8\u7684Python\u5217\u8868\u6216\u5b57\u5178\u7b49\u7ed3\u6784\u7c7b\u578b\u53d8\u91cf\u3002 tensor_list = [] #@tf.function #\u52a0\u4e0a\u8fd9\u4e00\u884c\u5207\u6362\u6210Autograph\u7ed3\u679c\u5c06\u4e0d\u7b26\u5408\u9884\u671f\uff01\uff01\uff01 def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>] tensor_list = [] @tf . function #\u52a0\u4e0a\u8fd9\u4e00\u884c\u5207\u6362\u6210Autograph\u7ed3\u679c\u5c06\u4e0d\u7b26\u5408\u9884\u671f\uff01\uff01\uff01 def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor 'x:0' shape=() dtype=float32>] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-3,AutoGraph\u7684\u4f7f\u7528\u89c4\u8303"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-3%2CAutoGraph%E7%9A%84%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/#4-3autograph\u7684\u4f7f\u7528\u89c4\u8303","text":"\u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph\u3002 TensorFlow 2.0\u4e3b\u8981\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6613\u4e8e\u8c03\u8bd5\uff0c\u7f16\u7801\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u6267\u884c\u6548\u7387\u504f\u4f4e\u3002 \u9759\u6001\u8ba1\u7b97\u56fe\u6267\u884c\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u8f83\u96be\u8c03\u8bd5\u3002 \u800cAutograph\u673a\u5236\u53ef\u4ee5\u5c06\u52a8\u6001\u56fe\u8f6c\u6362\u6210\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u517c\u6536\u6267\u884c\u6548\u7387\u548c\u7f16\u7801\u6548\u7387\u4e4b\u5229\u3002 \u5f53\u7136Autograph\u673a\u5236\u80fd\u591f\u8f6c\u6362\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u6ca1\u6709\u4efb\u4f55\u7ea6\u675f\u7684\uff0c\u6709\u4e00\u4e9b\u7f16\u7801\u89c4\u8303\u9700\u8981\u9075\u5faa\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u8f6c\u6362\u5931\u8d25\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u3002 \u6211\u4eec\u5c06\u7740\u91cd\u4ecb\u7ecdAutograph\u7684\u7f16\u7801\u89c4\u8303\u548cAutograph\u8f6c\u6362\u6210\u9759\u6001\u56fe\u7684\u539f\u7406\u3002 \u5e76\u4ecb\u7ecd\u4f7f\u7528tf.Module\u6765\u66f4\u597d\u5730\u6784\u5efaAutograph\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u4f7f\u7528Autograph\u7684\u7f16\u7801\u89c4\u8303\u3002","title":"4-3,AutoGraph\u7684\u4f7f\u7528\u89c4\u8303"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-3%2CAutoGraph%E7%9A%84%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/#\u4e00autograph\u7f16\u7801\u89c4\u8303\u603b\u7ed3","text":"1\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5e94\u5c3d\u53ef\u80fd\u4f7f\u7528TensorFlow\u4e2d\u7684\u51fd\u6570\u800c\u4e0d\u662fPython\u4e2d\u7684\u5176\u4ed6\u51fd\u6570\u3002\u4f8b\u5982\u4f7f\u7528tf.print\u800c\u4e0d\u662fprint\uff0c\u4f7f\u7528tf.range\u800c\u4e0d\u662frange\uff0c\u4f7f\u7528tf.constant(True)\u800c\u4e0d\u662fTrue. 2\uff0c\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. 3\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u4e0d\u53ef\u4fee\u6539\u8be5\u51fd\u6570\u5916\u90e8\u7684Python\u5217\u8868\u6216\u5b57\u5178\u7b49\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u3002","title":"\u4e00\uff0cAutograph\u7f16\u7801\u89c4\u8303\u603b\u7ed3"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-3%2CAutoGraph%E7%9A%84%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/#\u4e8cautograph\u7f16\u7801\u89c4\u8303\u89e3\u6790","text":"1\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5e94\u5c3d\u91cf\u4f7f\u7528TensorFlow\u4e2d\u7684\u51fd\u6570\u800c\u4e0d\u662fPython\u4e2d\u7684\u5176\u4ed6\u51fd\u6570\u3002 import numpy as np import tensorflow as tf @tf . function def np_random (): a = np . random . randn ( 3 , 3 ) tf . print ( a ) @tf . function def tf_random (): a = tf . random . normal (( 3 , 3 )) tf . print ( a ) #np_random\u6bcf\u6b21\u6267\u884c\u90fd\u662f\u4e00\u6837\u7684\u7ed3\u679c\u3002 np_random () np_random () array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) #tf_random\u6bcf\u6b21\u6267\u884c\u90fd\u4f1a\u6709\u91cd\u65b0\u751f\u6210\u968f\u673a\u6570\u3002 tf_random () tf_random () [[-1.38956189 -0.394843668 0.420657277] [2.87235498 -1.33740318 -0.533843279] [0.918233037 0.118598573 -0.399486482]] [[-0.858178258 1.67509317 0.511889517] [-0.545829177 -2.20118237 -0.968222201] [0.733958483 -0.61904633 0.77440238]] 2\uff0c\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. # \u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. x = tf . Variable ( 1.0 , dtype = tf . float32 ) @tf . function def outer_var (): x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) outer_var () outer_var () @tf . function def inner_var (): x = tf . Variable ( 1.0 , dtype = tf . float32 ) x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) #\u6267\u884c\u5c06\u62a5\u9519 #inner_var() #inner_var() --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-12-c95a7c3c1ddd> in <module> 7 8 #\u6267\u884c\u5c06\u62a5\u9519 ----> 9 inner_var() 10 inner_var() ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds) 566 xla_context.Exit() 567 else: --> 568 result = self._call(*args, **kwds) 569 570 if tracing_count == self._get_tracing_count(): ...... ValueError: tf.function-decorated function tried to create variables on non-first call. 3,\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u4e0d\u53ef\u4fee\u6539\u8be5\u51fd\u6570\u5916\u90e8\u7684Python\u5217\u8868\u6216\u5b57\u5178\u7b49\u7ed3\u6784\u7c7b\u578b\u53d8\u91cf\u3002 tensor_list = [] #@tf.function #\u52a0\u4e0a\u8fd9\u4e00\u884c\u5207\u6362\u6210Autograph\u7ed3\u679c\u5c06\u4e0d\u7b26\u5408\u9884\u671f\uff01\uff01\uff01 def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>] tensor_list = [] @tf . function #\u52a0\u4e0a\u8fd9\u4e00\u884c\u5207\u6362\u6210Autograph\u7ed3\u679c\u5c06\u4e0d\u7b26\u5408\u9884\u671f\uff01\uff01\uff01 def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor 'x:0' shape=() dtype=float32>] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0cAutograph\u7f16\u7801\u89c4\u8303\u89e3\u6790"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-4%2CAutoGraph%E7%9A%84%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/","text":"4-4,AutoGraph\u7684\u673a\u5236\u539f\u7406 # \u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph\u3002 TensorFlow 2.0\u4e3b\u8981\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6613\u4e8e\u8c03\u8bd5\uff0c\u7f16\u7801\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u6267\u884c\u6548\u7387\u504f\u4f4e\u3002 \u9759\u6001\u8ba1\u7b97\u56fe\u6267\u884c\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u8f83\u96be\u8c03\u8bd5\u3002 \u800cAutograph\u673a\u5236\u53ef\u4ee5\u5c06\u52a8\u6001\u56fe\u8f6c\u6362\u6210\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u517c\u6536\u6267\u884c\u6548\u7387\u548c\u7f16\u7801\u6548\u7387\u4e4b\u5229\u3002 \u5f53\u7136Autograph\u673a\u5236\u80fd\u591f\u8f6c\u6362\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u6ca1\u6709\u4efb\u4f55\u7ea6\u675f\u7684\uff0c\u6709\u4e00\u4e9b\u7f16\u7801\u89c4\u8303\u9700\u8981\u9075\u5faa\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u8f6c\u6362\u5931\u8d25\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u3002 \u6211\u4eec\u4f1a\u4ecb\u7ecdAutograph\u7684\u7f16\u7801\u89c4\u8303\u548cAutograph\u8f6c\u6362\u6210\u9759\u6001\u56fe\u7684\u539f\u7406\u3002 \u5e76\u4ecb\u7ecd\u4f7f\u7528tf.Module\u6765\u66f4\u597d\u5730\u6784\u5efaAutograph\u3002 \u4e0a\u7bc7\u6211\u4eec\u4ecb\u7ecd\u4e86Autograph\u7684\u7f16\u7801\u89c4\u8303\uff0c\u672c\u7bc7\u6211\u4eec\u4ecb\u7ecdAutograph\u7684\u673a\u5236\u539f\u7406\u3002 \u4e00\uff0cAutograph\u7684\u673a\u5236\u539f\u7406 # \u5f53\u6211\u4eec\u4f7f\u7528@tf.function\u88c5\u9970\u4e00\u4e2a\u51fd\u6570\u7684\u65f6\u5019\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\u5462\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 import tensorflow as tf import numpy as np @tf . function ( autograph = True ) def myadd ( a , b ): for i in tf . range ( 3 ): tf . print ( i ) c = a + b print ( \"tracing\" ) return c \u540e\u9762\u4ec0\u4e48\u90fd\u6ca1\u6709\u53d1\u751f\u3002\u4ec5\u4ec5\u662f\u5728Python\u5806\u6808\u4e2d\u8bb0\u5f55\u4e86\u8fd9\u6837\u4e00\u4e2a\u51fd\u6570\u7684\u7b7e\u540d\u3002 \u5f53\u6211\u4eec\u7b2c\u4e00\u6b21\u8c03\u7528\u8fd9\u4e2a\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 myadd ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) tracing 0 1 2 \u53d1\u751f\u4e862\u4ef6\u4e8b\u60c5\uff0c \u7b2c\u4e00\u4ef6\u4e8b\u60c5\u662f\u521b\u5efa\u8ba1\u7b97\u56fe\u3002 \u5373\u521b\u5efa\u4e00\u4e2a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u8ddf\u8e2a\u6267\u884c\u4e00\u904d\u51fd\u6570\u4f53\u4e2d\u7684Python\u4ee3\u7801\uff0c\u786e\u5b9a\u5404\u4e2a\u53d8\u91cf\u7684Tensor\u7c7b\u578b\uff0c\u5e76\u6839\u636e\u6267\u884c\u987a\u5e8f\u5c06\u7b97\u5b50\u6dfb\u52a0\u5230\u8ba1\u7b97\u56fe\u4e2d\u3002 \u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u5f00\u542f\u4e86autograph=True(\u9ed8\u8ba4\u5f00\u542f),\u4f1a\u5c06Python\u63a7\u5236\u6d41\u8f6c\u6362\u6210TensorFlow\u56fe\u5185\u63a7\u5236\u6d41\u3002 \u4e3b\u8981\u662f\u5c06if\u8bed\u53e5\u8f6c\u6362\u6210 tf.cond\u7b97\u5b50\u8868\u8fbe\uff0c\u5c06while\u548cfor\u5faa\u73af\u8bed\u53e5\u8f6c\u6362\u6210tf.while_loop\u7b97\u5b50\u8868\u8fbe\uff0c\u5e76\u5728\u5fc5\u8981\u7684\u65f6\u5019\u6dfb\u52a0 tf.control_dependencies\u6307\u5b9a\u6267\u884c\u987a\u5e8f\u4f9d\u8d56\u5173\u7cfb\u3002 \u76f8\u5f53\u4e8e\u5728 tensorflow1.0\u6267\u884c\u4e86\u7c7b\u4f3c\u4e0b\u9762\u7684\u8bed\u53e5\uff1a g = tf . Graph () with g . as_default (): a = tf . placeholder ( shape = [], dtype = tf . string ) b = tf . placeholder ( shape = [], dtype = tf . string ) cond = lambda i : i < tf . constant ( 3 ) def body ( i ): tf . print ( i ) return ( i + 1 ) loop = tf . while_loop ( cond , body , loop_vars = [ 0 ]) loop with tf . control_dependencies ( loop ): c = tf . strings . join ([ a , b ]) print ( \"tracing\" ) \u7b2c\u4e8c\u4ef6\u4e8b\u60c5\u662f\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u76f8\u5f53\u4e8e\u5728 tensorflow1.0\u4e2d\u6267\u884c\u4e86\u4e0b\u9762\u7684\u8bed\u53e5\uff1a with tf . Session ( graph = g ) as sess : sess . run ( c , feed_dict = { a : tf . constant ( \"hello\" ), b : tf . constant ( \"world\" )}) \u56e0\u6b64\u6211\u4eec\u5148\u770b\u5230\u7684\u662f\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1a\u5373Python\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u5370\"tracing\"\u8bed\u53e5\u3002 \u7136\u540e\u770b\u5230\u7b2c\u4e8c\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1aTensorFlow\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u53701,2,3\u3002 \u5f53\u6211\u4eec\u518d\u6b21\u7528\u76f8\u540c\u7684\u8f93\u5165\u53c2\u6570\u7c7b\u578b\u8c03\u7528\u8fd9\u4e2a\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 myadd ( tf . constant ( \"good\" ), tf . constant ( \"morning\" )) 0 1 2 \u53ea\u4f1a\u53d1\u751f\u4e00\u4ef6\u4e8b\u60c5\uff0c\u90a3\u5c31\u662f\u4e0a\u9762\u6b65\u9aa4\u7684\u7b2c\u4e8c\u6b65\uff0c\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u6240\u4ee5\u8fd9\u4e00\u6b21\u6211\u4eec\u6ca1\u6709\u770b\u5230\u6253\u5370\"tracing\"\u7684\u7ed3\u679c\u3002 \u5f53\u6211\u4eec\u518d\u6b21\u7528\u4e0d\u540c\u7684\u7684\u8f93\u5165\u53c2\u6570\u7c7b\u578b\u8c03\u7528\u8fd9\u4e2a\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 myadd ( tf . constant ( 1 ), tf . constant ( 2 )) tracing 0 1 2 \u7531\u4e8e\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\u5df2\u7ecf\u53d1\u751f\u53d8\u5316\uff0c\u5df2\u7ecf\u521b\u5efa\u7684\u8ba1\u7b97\u56fe\u4e0d\u80fd\u591f\u518d\u6b21\u4f7f\u7528\u3002 \u9700\u8981\u91cd\u65b0\u505a2\u4ef6\u4e8b\u60c5\uff1a\u521b\u5efa\u65b0\u7684\u8ba1\u7b97\u56fe\u3001\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u6240\u4ee5\u6211\u4eec\u53c8\u4f1a\u5148\u770b\u5230\u7684\u662f\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1a\u5373Python\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u5370\"tracing\"\u8bed\u53e5\u3002 \u7136\u540e\u518d\u770b\u5230\u7b2c\u4e8c\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1aTensorFlow\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u53701,2,3\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5982\u679c\u8c03\u7528\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\u8f93\u5165\u7684\u53c2\u6570\u4e0d\u662fTensor\u7c7b\u578b\uff0c\u5219\u6bcf\u6b21\u90fd\u4f1a\u91cd\u65b0\u521b\u5efa\u8ba1\u7b97\u56fe\u3002 \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002\u4e24\u6b21\u90fd\u4f1a\u91cd\u65b0\u521b\u5efa\u8ba1\u7b97\u56fe\u3002\u56e0\u6b64\uff0c\u4e00\u822c\u5efa\u8bae\u8c03\u7528@tf.function\u65f6\u5e94\u4f20\u5165Tensor\u7c7b\u578b\u3002 myadd ( \"hello\" , \"world\" ) myadd ( \"good\" , \"morning\" ) tracing 0 1 2 tracing 0 1 2 \u4e8c\uff0c\u91cd\u65b0\u7406\u89e3Autograph\u7684\u7f16\u7801\u89c4\u8303 # \u4e86\u89e3\u4e86\u4ee5\u4e0aAutograph\u7684\u673a\u5236\u539f\u7406\uff0c\u6211\u4eec\u4e5f\u5c31\u80fd\u591f\u7406\u89e3Autograph\u7f16\u7801\u89c4\u8303\u76843\u6761\u5efa\u8bae\u4e86\u3002 1\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5e94\u5c3d\u91cf\u4f7f\u7528TensorFlow\u4e2d\u7684\u51fd\u6570\u800c\u4e0d\u662fPython\u4e2d\u7684\u5176\u4ed6\u51fd\u6570\u3002\u4f8b\u5982\u4f7f\u7528tf.print\u800c\u4e0d\u662fprint. \u89e3\u91ca\uff1aPython\u4e2d\u7684\u51fd\u6570\u4ec5\u4ec5\u4f1a\u5728\u8ddf\u8e2a\u6267\u884c\u51fd\u6570\u4ee5\u521b\u5efa\u9759\u6001\u56fe\u7684\u9636\u6bb5\u4f7f\u7528\uff0c\u666e\u901aPython\u51fd\u6570\u662f\u65e0\u6cd5\u5d4c\u5165\u5230\u9759\u6001\u8ba1\u7b97\u56fe\u4e2d\u7684\uff0c\u6240\u4ee5 \u5728\u8ba1\u7b97\u56fe\u6784\u5efa\u597d\u4e4b\u540e\u518d\u6b21\u8c03\u7528\u7684\u65f6\u5019\uff0c\u8fd9\u4e9bPython\u51fd\u6570\u5e76\u6ca1\u6709\u88ab\u8ba1\u7b97\uff0c\u800cTensorFlow\u4e2d\u7684\u51fd\u6570\u5219\u53ef\u4ee5\u5d4c\u5165\u5230\u8ba1\u7b97\u56fe\u4e2d\u3002\u4f7f\u7528\u666e\u901a\u7684Python\u51fd\u6570\u4f1a\u5bfc\u81f4 \u88ab@tf.function\u4fee\u9970\u524d\u3010eager\u6267\u884c\u3011\u548c\u88ab@tf.function\u4fee\u9970\u540e\u3010\u9759\u6001\u56fe\u6267\u884c\u3011\u7684\u8f93\u51fa\u4e0d\u4e00\u81f4\u3002 2\uff0c\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. \u89e3\u91ca\uff1a\u5982\u679c\u51fd\u6570\u5185\u90e8\u5b9a\u4e49\u4e86tf.Variable,\u90a3\u4e48\u5728\u3010eager\u6267\u884c\u3011\u65f6\uff0c\u8fd9\u79cd\u521b\u5efatf.Variable\u7684\u884c\u4e3a\u5728\u6bcf\u6b21\u51fd\u6570\u8c03\u7528\u65f6\u5019\u90fd\u4f1a\u53d1\u751f\u3002\u4f46\u662f\u5728\u3010\u9759\u6001\u56fe\u6267\u884c\u3011\u65f6\uff0c\u8fd9\u79cd\u521b\u5efatf.Variable\u7684\u884c\u4e3a\u53ea\u4f1a\u53d1\u751f\u5728\u7b2c\u4e00\u6b65\u8ddf\u8e2aPython\u4ee3\u7801\u903b\u8f91\u521b\u5efa\u8ba1\u7b97\u56fe\u65f6\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u88ab@tf.function\u4fee\u9970\u524d\u3010eager\u6267\u884c\u3011\u548c\u88ab@tf.function\u4fee\u9970\u540e\u3010\u9759\u6001\u56fe\u6267\u884c\u3011\u7684\u8f93\u51fa\u4e0d\u4e00\u81f4\u3002\u5b9e\u9645\u4e0a\uff0cTensorFlow\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u4e00\u822c\u4f1a\u62a5\u9519\u3002 3\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u4e0d\u53ef\u4fee\u6539\u8be5\u51fd\u6570\u5916\u90e8\u7684Python\u5217\u8868\u6216\u5b57\u5178\u7b49\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u3002 \u89e3\u91ca\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\u662f\u88ab\u7f16\u8bd1\u6210C++\u4ee3\u7801\u5728TensorFlow\u5185\u6838\u4e2d\u6267\u884c\u7684\u3002Python\u4e2d\u7684\u5217\u8868\u548c\u5b57\u5178\u7b49\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u662f\u65e0\u6cd5\u5d4c\u5165\u5230\u8ba1\u7b97\u56fe\u4e2d\uff0c\u5b83\u4eec\u4ec5\u4ec5\u80fd\u591f\u5728\u521b\u5efa\u8ba1\u7b97\u56fe\u65f6\u88ab\u8bfb\u53d6\uff0c\u5728\u6267\u884c\u8ba1\u7b97\u56fe\u65f6\u662f\u65e0\u6cd5\u4fee\u6539Python\u4e2d\u7684\u5217\u8868\u6216\u5b57\u5178\u8fd9\u6837\u7684\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u7684\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-4,AutoGraph\u7684\u673a\u5236\u539f\u7406"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-4%2CAutoGraph%E7%9A%84%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/#4-4autograph\u7684\u673a\u5236\u539f\u7406","text":"\u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph\u3002 TensorFlow 2.0\u4e3b\u8981\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6613\u4e8e\u8c03\u8bd5\uff0c\u7f16\u7801\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u6267\u884c\u6548\u7387\u504f\u4f4e\u3002 \u9759\u6001\u8ba1\u7b97\u56fe\u6267\u884c\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u8f83\u96be\u8c03\u8bd5\u3002 \u800cAutograph\u673a\u5236\u53ef\u4ee5\u5c06\u52a8\u6001\u56fe\u8f6c\u6362\u6210\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u517c\u6536\u6267\u884c\u6548\u7387\u548c\u7f16\u7801\u6548\u7387\u4e4b\u5229\u3002 \u5f53\u7136Autograph\u673a\u5236\u80fd\u591f\u8f6c\u6362\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u6ca1\u6709\u4efb\u4f55\u7ea6\u675f\u7684\uff0c\u6709\u4e00\u4e9b\u7f16\u7801\u89c4\u8303\u9700\u8981\u9075\u5faa\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u8f6c\u6362\u5931\u8d25\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u3002 \u6211\u4eec\u4f1a\u4ecb\u7ecdAutograph\u7684\u7f16\u7801\u89c4\u8303\u548cAutograph\u8f6c\u6362\u6210\u9759\u6001\u56fe\u7684\u539f\u7406\u3002 \u5e76\u4ecb\u7ecd\u4f7f\u7528tf.Module\u6765\u66f4\u597d\u5730\u6784\u5efaAutograph\u3002 \u4e0a\u7bc7\u6211\u4eec\u4ecb\u7ecd\u4e86Autograph\u7684\u7f16\u7801\u89c4\u8303\uff0c\u672c\u7bc7\u6211\u4eec\u4ecb\u7ecdAutograph\u7684\u673a\u5236\u539f\u7406\u3002","title":"4-4,AutoGraph\u7684\u673a\u5236\u539f\u7406"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-4%2CAutoGraph%E7%9A%84%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/#\u4e00autograph\u7684\u673a\u5236\u539f\u7406","text":"\u5f53\u6211\u4eec\u4f7f\u7528@tf.function\u88c5\u9970\u4e00\u4e2a\u51fd\u6570\u7684\u65f6\u5019\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\u5462\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 import tensorflow as tf import numpy as np @tf . function ( autograph = True ) def myadd ( a , b ): for i in tf . range ( 3 ): tf . print ( i ) c = a + b print ( \"tracing\" ) return c \u540e\u9762\u4ec0\u4e48\u90fd\u6ca1\u6709\u53d1\u751f\u3002\u4ec5\u4ec5\u662f\u5728Python\u5806\u6808\u4e2d\u8bb0\u5f55\u4e86\u8fd9\u6837\u4e00\u4e2a\u51fd\u6570\u7684\u7b7e\u540d\u3002 \u5f53\u6211\u4eec\u7b2c\u4e00\u6b21\u8c03\u7528\u8fd9\u4e2a\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 myadd ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) tracing 0 1 2 \u53d1\u751f\u4e862\u4ef6\u4e8b\u60c5\uff0c \u7b2c\u4e00\u4ef6\u4e8b\u60c5\u662f\u521b\u5efa\u8ba1\u7b97\u56fe\u3002 \u5373\u521b\u5efa\u4e00\u4e2a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u8ddf\u8e2a\u6267\u884c\u4e00\u904d\u51fd\u6570\u4f53\u4e2d\u7684Python\u4ee3\u7801\uff0c\u786e\u5b9a\u5404\u4e2a\u53d8\u91cf\u7684Tensor\u7c7b\u578b\uff0c\u5e76\u6839\u636e\u6267\u884c\u987a\u5e8f\u5c06\u7b97\u5b50\u6dfb\u52a0\u5230\u8ba1\u7b97\u56fe\u4e2d\u3002 \u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u5f00\u542f\u4e86autograph=True(\u9ed8\u8ba4\u5f00\u542f),\u4f1a\u5c06Python\u63a7\u5236\u6d41\u8f6c\u6362\u6210TensorFlow\u56fe\u5185\u63a7\u5236\u6d41\u3002 \u4e3b\u8981\u662f\u5c06if\u8bed\u53e5\u8f6c\u6362\u6210 tf.cond\u7b97\u5b50\u8868\u8fbe\uff0c\u5c06while\u548cfor\u5faa\u73af\u8bed\u53e5\u8f6c\u6362\u6210tf.while_loop\u7b97\u5b50\u8868\u8fbe\uff0c\u5e76\u5728\u5fc5\u8981\u7684\u65f6\u5019\u6dfb\u52a0 tf.control_dependencies\u6307\u5b9a\u6267\u884c\u987a\u5e8f\u4f9d\u8d56\u5173\u7cfb\u3002 \u76f8\u5f53\u4e8e\u5728 tensorflow1.0\u6267\u884c\u4e86\u7c7b\u4f3c\u4e0b\u9762\u7684\u8bed\u53e5\uff1a g = tf . Graph () with g . as_default (): a = tf . placeholder ( shape = [], dtype = tf . string ) b = tf . placeholder ( shape = [], dtype = tf . string ) cond = lambda i : i < tf . constant ( 3 ) def body ( i ): tf . print ( i ) return ( i + 1 ) loop = tf . while_loop ( cond , body , loop_vars = [ 0 ]) loop with tf . control_dependencies ( loop ): c = tf . strings . join ([ a , b ]) print ( \"tracing\" ) \u7b2c\u4e8c\u4ef6\u4e8b\u60c5\u662f\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u76f8\u5f53\u4e8e\u5728 tensorflow1.0\u4e2d\u6267\u884c\u4e86\u4e0b\u9762\u7684\u8bed\u53e5\uff1a with tf . Session ( graph = g ) as sess : sess . run ( c , feed_dict = { a : tf . constant ( \"hello\" ), b : tf . constant ( \"world\" )}) \u56e0\u6b64\u6211\u4eec\u5148\u770b\u5230\u7684\u662f\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1a\u5373Python\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u5370\"tracing\"\u8bed\u53e5\u3002 \u7136\u540e\u770b\u5230\u7b2c\u4e8c\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1aTensorFlow\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u53701,2,3\u3002 \u5f53\u6211\u4eec\u518d\u6b21\u7528\u76f8\u540c\u7684\u8f93\u5165\u53c2\u6570\u7c7b\u578b\u8c03\u7528\u8fd9\u4e2a\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 myadd ( tf . constant ( \"good\" ), tf . constant ( \"morning\" )) 0 1 2 \u53ea\u4f1a\u53d1\u751f\u4e00\u4ef6\u4e8b\u60c5\uff0c\u90a3\u5c31\u662f\u4e0a\u9762\u6b65\u9aa4\u7684\u7b2c\u4e8c\u6b65\uff0c\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u6240\u4ee5\u8fd9\u4e00\u6b21\u6211\u4eec\u6ca1\u6709\u770b\u5230\u6253\u5370\"tracing\"\u7684\u7ed3\u679c\u3002 \u5f53\u6211\u4eec\u518d\u6b21\u7528\u4e0d\u540c\u7684\u7684\u8f93\u5165\u53c2\u6570\u7c7b\u578b\u8c03\u7528\u8fd9\u4e2a\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\uff0c\u540e\u9762\u5230\u5e95\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002 myadd ( tf . constant ( 1 ), tf . constant ( 2 )) tracing 0 1 2 \u7531\u4e8e\u8f93\u5165\u53c2\u6570\u7684\u7c7b\u578b\u5df2\u7ecf\u53d1\u751f\u53d8\u5316\uff0c\u5df2\u7ecf\u521b\u5efa\u7684\u8ba1\u7b97\u56fe\u4e0d\u80fd\u591f\u518d\u6b21\u4f7f\u7528\u3002 \u9700\u8981\u91cd\u65b0\u505a2\u4ef6\u4e8b\u60c5\uff1a\u521b\u5efa\u65b0\u7684\u8ba1\u7b97\u56fe\u3001\u6267\u884c\u8ba1\u7b97\u56fe\u3002 \u6240\u4ee5\u6211\u4eec\u53c8\u4f1a\u5148\u770b\u5230\u7684\u662f\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1a\u5373Python\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u5370\"tracing\"\u8bed\u53e5\u3002 \u7136\u540e\u518d\u770b\u5230\u7b2c\u4e8c\u4e2a\u6b65\u9aa4\u7684\u7ed3\u679c\uff1aTensorFlow\u8c03\u7528\u6807\u51c6\u8f93\u51fa\u6d41\u6253\u53701,2,3\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5982\u679c\u8c03\u7528\u88ab@tf.function\u88c5\u9970\u7684\u51fd\u6570\u65f6\u8f93\u5165\u7684\u53c2\u6570\u4e0d\u662fTensor\u7c7b\u578b\uff0c\u5219\u6bcf\u6b21\u90fd\u4f1a\u91cd\u65b0\u521b\u5efa\u8ba1\u7b97\u56fe\u3002 \u4f8b\u5982\u6211\u4eec\u5199\u4e0b\u5982\u4e0b\u4ee3\u7801\u3002\u4e24\u6b21\u90fd\u4f1a\u91cd\u65b0\u521b\u5efa\u8ba1\u7b97\u56fe\u3002\u56e0\u6b64\uff0c\u4e00\u822c\u5efa\u8bae\u8c03\u7528@tf.function\u65f6\u5e94\u4f20\u5165Tensor\u7c7b\u578b\u3002 myadd ( \"hello\" , \"world\" ) myadd ( \"good\" , \"morning\" ) tracing 0 1 2 tracing 0 1 2","title":"\u4e00\uff0cAutograph\u7684\u673a\u5236\u539f\u7406"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-4%2CAutoGraph%E7%9A%84%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/#\u4e8c\u91cd\u65b0\u7406\u89e3autograph\u7684\u7f16\u7801\u89c4\u8303","text":"\u4e86\u89e3\u4e86\u4ee5\u4e0aAutograph\u7684\u673a\u5236\u539f\u7406\uff0c\u6211\u4eec\u4e5f\u5c31\u80fd\u591f\u7406\u89e3Autograph\u7f16\u7801\u89c4\u8303\u76843\u6761\u5efa\u8bae\u4e86\u3002 1\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5e94\u5c3d\u91cf\u4f7f\u7528TensorFlow\u4e2d\u7684\u51fd\u6570\u800c\u4e0d\u662fPython\u4e2d\u7684\u5176\u4ed6\u51fd\u6570\u3002\u4f8b\u5982\u4f7f\u7528tf.print\u800c\u4e0d\u662fprint. \u89e3\u91ca\uff1aPython\u4e2d\u7684\u51fd\u6570\u4ec5\u4ec5\u4f1a\u5728\u8ddf\u8e2a\u6267\u884c\u51fd\u6570\u4ee5\u521b\u5efa\u9759\u6001\u56fe\u7684\u9636\u6bb5\u4f7f\u7528\uff0c\u666e\u901aPython\u51fd\u6570\u662f\u65e0\u6cd5\u5d4c\u5165\u5230\u9759\u6001\u8ba1\u7b97\u56fe\u4e2d\u7684\uff0c\u6240\u4ee5 \u5728\u8ba1\u7b97\u56fe\u6784\u5efa\u597d\u4e4b\u540e\u518d\u6b21\u8c03\u7528\u7684\u65f6\u5019\uff0c\u8fd9\u4e9bPython\u51fd\u6570\u5e76\u6ca1\u6709\u88ab\u8ba1\u7b97\uff0c\u800cTensorFlow\u4e2d\u7684\u51fd\u6570\u5219\u53ef\u4ee5\u5d4c\u5165\u5230\u8ba1\u7b97\u56fe\u4e2d\u3002\u4f7f\u7528\u666e\u901a\u7684Python\u51fd\u6570\u4f1a\u5bfc\u81f4 \u88ab@tf.function\u4fee\u9970\u524d\u3010eager\u6267\u884c\u3011\u548c\u88ab@tf.function\u4fee\u9970\u540e\u3010\u9759\u6001\u56fe\u6267\u884c\u3011\u7684\u8f93\u51fa\u4e0d\u4e00\u81f4\u3002 2\uff0c\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. \u89e3\u91ca\uff1a\u5982\u679c\u51fd\u6570\u5185\u90e8\u5b9a\u4e49\u4e86tf.Variable,\u90a3\u4e48\u5728\u3010eager\u6267\u884c\u3011\u65f6\uff0c\u8fd9\u79cd\u521b\u5efatf.Variable\u7684\u884c\u4e3a\u5728\u6bcf\u6b21\u51fd\u6570\u8c03\u7528\u65f6\u5019\u90fd\u4f1a\u53d1\u751f\u3002\u4f46\u662f\u5728\u3010\u9759\u6001\u56fe\u6267\u884c\u3011\u65f6\uff0c\u8fd9\u79cd\u521b\u5efatf.Variable\u7684\u884c\u4e3a\u53ea\u4f1a\u53d1\u751f\u5728\u7b2c\u4e00\u6b65\u8ddf\u8e2aPython\u4ee3\u7801\u903b\u8f91\u521b\u5efa\u8ba1\u7b97\u56fe\u65f6\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u88ab@tf.function\u4fee\u9970\u524d\u3010eager\u6267\u884c\u3011\u548c\u88ab@tf.function\u4fee\u9970\u540e\u3010\u9759\u6001\u56fe\u6267\u884c\u3011\u7684\u8f93\u51fa\u4e0d\u4e00\u81f4\u3002\u5b9e\u9645\u4e0a\uff0cTensorFlow\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u4e00\u822c\u4f1a\u62a5\u9519\u3002 3\uff0c\u88ab@tf.function\u4fee\u9970\u7684\u51fd\u6570\u4e0d\u53ef\u4fee\u6539\u8be5\u51fd\u6570\u5916\u90e8\u7684Python\u5217\u8868\u6216\u5b57\u5178\u7b49\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u3002 \u89e3\u91ca\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\u662f\u88ab\u7f16\u8bd1\u6210C++\u4ee3\u7801\u5728TensorFlow\u5185\u6838\u4e2d\u6267\u884c\u7684\u3002Python\u4e2d\u7684\u5217\u8868\u548c\u5b57\u5178\u7b49\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u662f\u65e0\u6cd5\u5d4c\u5165\u5230\u8ba1\u7b97\u56fe\u4e2d\uff0c\u5b83\u4eec\u4ec5\u4ec5\u80fd\u591f\u5728\u521b\u5efa\u8ba1\u7b97\u56fe\u65f6\u88ab\u8bfb\u53d6\uff0c\u5728\u6267\u884c\u8ba1\u7b97\u56fe\u65f6\u662f\u65e0\u6cd5\u4fee\u6539Python\u4e2d\u7684\u5217\u8868\u6216\u5b57\u5178\u8fd9\u6837\u7684\u6570\u636e\u7ed3\u6784\u53d8\u91cf\u7684\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u91cd\u65b0\u7406\u89e3Autograph\u7684\u7f16\u7801\u89c4\u8303"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-5%2CAutoGraph%E5%92%8Ctf.Module/","text":"4-5,AutoGraph\u548ctf.Module # \u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph\u3002 TensorFlow 2.0\u4e3b\u8981\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6613\u4e8e\u8c03\u8bd5\uff0c\u7f16\u7801\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u6267\u884c\u6548\u7387\u504f\u4f4e\u3002 \u9759\u6001\u8ba1\u7b97\u56fe\u6267\u884c\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u8f83\u96be\u8c03\u8bd5\u3002 \u800cAutograph\u673a\u5236\u53ef\u4ee5\u5c06\u52a8\u6001\u56fe\u8f6c\u6362\u6210\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u517c\u6536\u6267\u884c\u6548\u7387\u548c\u7f16\u7801\u6548\u7387\u4e4b\u5229\u3002 \u5f53\u7136Autograph\u673a\u5236\u80fd\u591f\u8f6c\u6362\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u6ca1\u6709\u4efb\u4f55\u7ea6\u675f\u7684\uff0c\u6709\u4e00\u4e9b\u7f16\u7801\u89c4\u8303\u9700\u8981\u9075\u5faa\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u8f6c\u6362\u5931\u8d25\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u3002 \u524d\u9762\u6211\u4eec\u4ecb\u7ecd\u4e86Autograph\u7684\u7f16\u7801\u89c4\u8303\u548cAutograph\u8f6c\u6362\u6210\u9759\u6001\u56fe\u7684\u539f\u7406\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u4f7f\u7528tf.Module\u6765\u66f4\u597d\u5730\u6784\u5efaAutograph\u3002 \u4e00\uff0cAutograph\u548ctf.Module\u6982\u8ff0 # \u524d\u9762\u5728\u4ecb\u7ecdAutograph\u7684\u7f16\u7801\u89c4\u8303\u65f6\u63d0\u5230\u6784\u5efaAutograph\u65f6\u5e94\u8be5\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. \u4f46\u662f\u5982\u679c\u5728\u51fd\u6570\u5916\u90e8\u5b9a\u4e49tf.Variable\u7684\u8bdd\uff0c\u53c8\u4f1a\u663e\u5f97\u8fd9\u4e2a\u51fd\u6570\u6709\u5916\u90e8\u53d8\u91cf\u4f9d\u8d56\uff0c\u5c01\u88c5\u4e0d\u591f\u5b8c\u7f8e\u3002 \u4e00\u79cd\u7b80\u5355\u7684\u601d\u8def\u662f\u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff0c\u5e76\u5c06\u76f8\u5173\u7684tf.Variable\u521b\u5efa\u653e\u5728\u7c7b\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u4e2d\u3002\u800c\u5c06\u51fd\u6570\u7684\u903b\u8f91\u653e\u5728\u5176\u4ed6\u65b9\u6cd5\u4e2d\u3002 \u8fd9\u6837\u4e00\u987f\u731b\u5982\u864e\u7684\u64cd\u4f5c\u4e4b\u540e\uff0c\u6211\u4eec\u4f1a\u89c9\u5f97\u4e00\u5207\u90fd\u5982\u540c\u4eba\u6cd5\u5730\u5730\u6cd5\u5929\u5929\u6cd5\u9053\u9053\u6cd5\u81ea\u7136\u822c\u7684\u81ea\u7136\u3002 \u60ca\u559c\u7684\u662f\uff0cTensorFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u7c7btf.Module\uff0c\u901a\u8fc7\u7ee7\u627f\u5b83\u6784\u5efa\u5b50\u7c7b\uff0c\u6211\u4eec\u4e0d\u4ec5\u53ef\u4ee5\u83b7\u5f97\u4ee5\u4e0a\u7684\u81ea\u7136\u800c\u7136\uff0c\u800c\u4e14\u53ef\u4ee5\u975e\u5e38\u65b9\u4fbf\u5730\u7ba1\u7406\u53d8\u91cf\uff0c\u8fd8\u53ef\u4ee5\u975e\u5e38\u65b9\u4fbf\u5730\u7ba1\u7406\u5b83\u5f15\u7528\u7684\u5176\u5b83Module\uff0c\u6700\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u80fd\u591f\u5229\u7528tf.saved_model\u4fdd\u5b58\u6a21\u578b\u5e76\u5b9e\u73b0\u8de8\u5e73\u53f0\u90e8\u7f72\u4f7f\u7528\u3002 \u5b9e\u9645\u4e0a\uff0ctf.keras.models.Model,tf.keras.layers.Layer \u90fd\u662f\u7ee7\u627f\u81eatf.Module\u7684\uff0c\u63d0\u4f9b\u4e86\u65b9\u4fbf\u7684\u53d8\u91cf\u7ba1\u7406\u548c\u6240\u5f15\u7528\u7684\u5b50\u6a21\u5757\u7ba1\u7406\u7684\u529f\u80fd\u3002 \u56e0\u6b64\uff0c\u5229\u7528tf.Module\u63d0\u4f9b\u7684\u5c01\u88c5\uff0c\u518d\u7ed3\u5408TensoFlow\u4e30\u5bcc\u7684\u4f4e\u9636API\uff0c\u5b9e\u9645\u4e0a\u6211\u4eec\u80fd\u591f\u57fa\u4e8eTensorFlow\u5f00\u53d1\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b(\u800c\u975e\u4ec5\u4ec5\u662f\u795e\u7ecf\u7f51\u7edc\u6a21\u578b)\uff0c\u5e76\u5b9e\u73b0\u8de8\u5e73\u53f0\u90e8\u7f72\u4f7f\u7528\u3002 \u4e8c\uff0c\u5e94\u7528tf.Module\u5c01\u88c5Autograph # \u5b9a\u4e49\u4e00\u4e2a\u7b80\u5355\u7684function\u3002 import tensorflow as tf x = tf . Variable ( 1.0 , dtype = tf . float32 ) #\u5728tf.function\u4e2d\u7528input_signature\u9650\u5b9a\u8f93\u5165\u5f20\u91cf\u7684\u7b7e\u540d\u7c7b\u578b\uff1ashape\u548cdtype @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def add_print ( a ): x . assign_add ( a ) tf . print ( x ) return ( x ) add_print ( tf . constant ( 3.0 )) #add_print(tf.constant(3)) #\u8f93\u5165\u4e0d\u7b26\u5408\u5f20\u91cf\u7b7e\u540d\u7684\u53c2\u6570\u5c06\u62a5\u9519 4 \u4e0b\u9762\u5229\u7528tf.Module\u7684\u5b50\u7c7b\u5316\u5c06\u5176\u5c01\u88c5\u4e00\u4e0b\u3002 class DemoModule ( tf . Module ): def __init__ ( self , init_value = tf . constant ( 0.0 ), name = None ): super ( DemoModule , self ) . __init__ ( name = name ) with self . name_scope : #\u76f8\u5f53\u4e8ewith tf.name_scope(\"demo_module\") self . x = tf . Variable ( init_value , dtype = tf . float32 , trainable = True ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( self , a ): with self . name_scope : self . x . assign_add ( a ) tf . print ( self . x ) return ( self . x ) #\u6267\u884c demo = DemoModule ( init_value = tf . constant ( 1.0 )) result = demo . addprint ( tf . constant ( 5.0 )) 6 #\u67e5\u770b\u6a21\u5757\u4e2d\u7684\u5168\u90e8\u53d8\u91cf\u548c\u5168\u90e8\u53ef\u8bad\u7ec3\u53d8\u91cf print ( demo . variables ) print ( demo . trainable_variables ) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) #\u67e5\u770b\u6a21\u5757\u4e2d\u7684\u5168\u90e8\u5b50\u6a21\u5757 demo . submodules #\u4f7f\u7528tf.saved_model \u4fdd\u5b58\u6a21\u578b\uff0c\u5e76\u6307\u5b9a\u9700\u8981\u8de8\u5e73\u53f0\u90e8\u7f72\u7684\u65b9\u6cd5 tf . saved_model . save ( demo , \"../../data/demo/1\" , signatures = { \"serving_default\" : demo . addprint }) #\u52a0\u8f7d\u6a21\u578b demo2 = tf . saved_model . load ( \"../../data/demo/1\" ) demo2 . addprint ( tf . constant ( 5.0 )) 11 # \u67e5\u770b\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f\uff0c\u7ea2\u6846\u6807\u51fa\u6765\u7684\u8f93\u51fa\u4fe1\u606f\u5728\u6a21\u578b\u90e8\u7f72\u548c\u8de8\u5e73\u53f0\u4f7f\u7528\u65f6\u6709\u53ef\u80fd\u4f1a\u7528\u5230 ! saved_model_cli show -- dir ../../ data / demo / 1 -- all \u5728tensorboard\u4e2d\u67e5\u770b\u8ba1\u7b97\u56fe\uff0c\u6a21\u5757\u4f1a\u88ab\u6dfb\u52a0\u6a21\u5757\u540ddemo_module,\u65b9\u4fbf\u5c42\u6b21\u5316\u5448\u73b0\u8ba1\u7b97\u56fe\u7ed3\u6784\u3002 import datetime # \u521b\u5efa\u65e5\u5fd7 stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = '../../data/demomodule/ %s ' % stamp writer = tf . summary . create_file_writer ( logdir ) #\u5f00\u542fautograph\u8ddf\u8e2a tf . summary . trace_on ( graph = True , profiler = True ) #\u6267\u884cautograph demo = DemoModule ( init_value = tf . constant ( 0.0 )) result = demo . addprint ( tf . constant ( 5.0 )) #\u5c06\u8ba1\u7b97\u56fe\u4fe1\u606f\u5199\u5165\u65e5\u5fd7 with writer . as_default (): tf . summary . trace_export ( name = \"demomodule\" , step = 0 , profiler_outdir = logdir ) #\u542f\u52a8 tensorboard\u5728jupyter\u4e2d\u7684\u9b54\u6cd5\u547d\u4ee4 % reload_ext tensorboard from tensorboard import notebook notebook . list () notebook . start ( \"--logdir ../../data/demomodule/\" ) \u9664\u4e86\u5229\u7528tf.Module\u7684\u5b50\u7c7b\u5316\u5b9e\u73b0\u5c01\u88c5\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ed9tf.Module\u6dfb\u52a0\u5c5e\u6027\u7684\u65b9\u6cd5\u8fdb\u884c\u5c01\u88c5\u3002 mymodule = tf . Module () mymodule . x = tf . Variable ( 0.0 ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( a ): mymodule . x . assign_add ( a ) tf . print ( mymodule . x ) return ( mymodule . x ) mymodule . addprint = addprint mymodule . addprint ( tf . constant ( 1.0 )) . numpy () 1.0 print ( mymodule . variables ) (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>,) #\u4f7f\u7528tf.saved_model \u4fdd\u5b58\u6a21\u578b tf . saved_model . save ( mymodule , \"../../data/mymodule\" , signatures = { \"serving_default\" : mymodule . addprint }) #\u52a0\u8f7d\u6a21\u578b mymodule2 = tf . saved_model . load ( \"../../data/mymodule\" ) mymodule2 . addprint ( tf . constant ( 5.0 )) INFO:tensorflow:Assets written to: ../../data/mymodule/assets 5 \u4e09\uff0ctf.Module\u548ctf.keras.Model\uff0ctf.keras.layers.Layer # tf.keras\u4e2d\u7684\u6a21\u578b\u548c\u5c42\u90fd\u662f\u7ee7\u627ftf.Module\u5b9e\u73b0\u7684\uff0c\u4e5f\u5177\u6709\u53d8\u91cf\u7ba1\u7406\u548c\u5b50\u6a21\u5757\u7ba1\u7406\u529f\u80fd\u3002 import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics print ( issubclass ( tf . keras . Model , tf . Module )) print ( issubclass ( tf . keras . layers . Layer , tf . Module )) print ( issubclass ( tf . keras . Model , tf . keras . layers . Layer )) True True True tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 4 , input_shape = ( 10 ,))) model . add ( layers . Dense ( 2 )) model . add ( layers . Dense ( 1 )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 4) 44 _________________________________________________________________ dense_1 (Dense) (None, 2) 10 _________________________________________________________________ dense_2 (Dense) (None, 1) 3 ================================================================= Total params: 57 Trainable params: 57 Non-trainable params: 0 _________________________________________________________________ model . variables [<tf.Variable 'dense/kernel:0' shape=(10, 4) dtype=float32, numpy= array([[-0.06741005, 0.45534766, 0.5190817 , -0.01806331], [-0.14258742, -0.49711505, 0.26030976, 0.18607801], [-0.62806034, 0.5327399 , 0.42206633, 0.29201728], [-0.16602087, -0.18901917, 0.55159235, -0.01091868], [ 0.04533798, 0.326845 , -0.582667 , 0.19431782], [ 0.6494713 , -0.16174704, 0.4062966 , 0.48760796], [ 0.58400524, -0.6280886 , -0.11265379, -0.6438277 ], [ 0.26642334, 0.49275804, 0.20793378, -0.43889117], [ 0.4092741 , 0.09871006, -0.2073121 , 0.26047975], [ 0.43910992, 0.00199282, -0.07711256, -0.27966842]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . layers [ 0 ] . trainable = False #\u51bb\u7ed3\u7b2c0\u5c42\u7684\u53d8\u91cf,\u4f7f\u5176\u4e0d\u53ef\u8bad\u7ec3 model . trainable_variables [<tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . submodules (<tensorflow.python.keras.engine.input_layer.InputLayer at 0x144d8c080>, <tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>) model . layers [<tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>] print ( model . name ) print ( model . name_scope ()) sequential sequential \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-5,AutoGraph\u548ctf.Module"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-5%2CAutoGraph%E5%92%8Ctf.Module/#4-5autograph\u548ctfmodule","text":"\u6709\u4e09\u79cd\u8ba1\u7b97\u56fe\u7684\u6784\u5efa\u65b9\u5f0f\uff1a\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\uff0c\u4ee5\u53caAutograph\u3002 TensorFlow 2.0\u4e3b\u8981\u4f7f\u7528\u7684\u662f\u52a8\u6001\u8ba1\u7b97\u56fe\u548cAutograph\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6613\u4e8e\u8c03\u8bd5\uff0c\u7f16\u7801\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u6267\u884c\u6548\u7387\u504f\u4f4e\u3002 \u9759\u6001\u8ba1\u7b97\u56fe\u6267\u884c\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u8f83\u96be\u8c03\u8bd5\u3002 \u800cAutograph\u673a\u5236\u53ef\u4ee5\u5c06\u52a8\u6001\u56fe\u8f6c\u6362\u6210\u9759\u6001\u8ba1\u7b97\u56fe\uff0c\u517c\u6536\u6267\u884c\u6548\u7387\u548c\u7f16\u7801\u6548\u7387\u4e4b\u5229\u3002 \u5f53\u7136Autograph\u673a\u5236\u80fd\u591f\u8f6c\u6362\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u6ca1\u6709\u4efb\u4f55\u7ea6\u675f\u7684\uff0c\u6709\u4e00\u4e9b\u7f16\u7801\u89c4\u8303\u9700\u8981\u9075\u5faa\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u8f6c\u6362\u5931\u8d25\u6216\u8005\u4e0d\u7b26\u5408\u9884\u671f\u3002 \u524d\u9762\u6211\u4eec\u4ecb\u7ecd\u4e86Autograph\u7684\u7f16\u7801\u89c4\u8303\u548cAutograph\u8f6c\u6362\u6210\u9759\u6001\u56fe\u7684\u539f\u7406\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u4f7f\u7528tf.Module\u6765\u66f4\u597d\u5730\u6784\u5efaAutograph\u3002","title":"4-5,AutoGraph\u548ctf.Module"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-5%2CAutoGraph%E5%92%8Ctf.Module/#\u4e00autograph\u548ctfmodule\u6982\u8ff0","text":"\u524d\u9762\u5728\u4ecb\u7ecdAutograph\u7684\u7f16\u7801\u89c4\u8303\u65f6\u63d0\u5230\u6784\u5efaAutograph\u65f6\u5e94\u8be5\u907f\u514d\u5728@tf.function\u4fee\u9970\u7684\u51fd\u6570\u5185\u90e8\u5b9a\u4e49tf.Variable. \u4f46\u662f\u5982\u679c\u5728\u51fd\u6570\u5916\u90e8\u5b9a\u4e49tf.Variable\u7684\u8bdd\uff0c\u53c8\u4f1a\u663e\u5f97\u8fd9\u4e2a\u51fd\u6570\u6709\u5916\u90e8\u53d8\u91cf\u4f9d\u8d56\uff0c\u5c01\u88c5\u4e0d\u591f\u5b8c\u7f8e\u3002 \u4e00\u79cd\u7b80\u5355\u7684\u601d\u8def\u662f\u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff0c\u5e76\u5c06\u76f8\u5173\u7684tf.Variable\u521b\u5efa\u653e\u5728\u7c7b\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u4e2d\u3002\u800c\u5c06\u51fd\u6570\u7684\u903b\u8f91\u653e\u5728\u5176\u4ed6\u65b9\u6cd5\u4e2d\u3002 \u8fd9\u6837\u4e00\u987f\u731b\u5982\u864e\u7684\u64cd\u4f5c\u4e4b\u540e\uff0c\u6211\u4eec\u4f1a\u89c9\u5f97\u4e00\u5207\u90fd\u5982\u540c\u4eba\u6cd5\u5730\u5730\u6cd5\u5929\u5929\u6cd5\u9053\u9053\u6cd5\u81ea\u7136\u822c\u7684\u81ea\u7136\u3002 \u60ca\u559c\u7684\u662f\uff0cTensorFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u7c7btf.Module\uff0c\u901a\u8fc7\u7ee7\u627f\u5b83\u6784\u5efa\u5b50\u7c7b\uff0c\u6211\u4eec\u4e0d\u4ec5\u53ef\u4ee5\u83b7\u5f97\u4ee5\u4e0a\u7684\u81ea\u7136\u800c\u7136\uff0c\u800c\u4e14\u53ef\u4ee5\u975e\u5e38\u65b9\u4fbf\u5730\u7ba1\u7406\u53d8\u91cf\uff0c\u8fd8\u53ef\u4ee5\u975e\u5e38\u65b9\u4fbf\u5730\u7ba1\u7406\u5b83\u5f15\u7528\u7684\u5176\u5b83Module\uff0c\u6700\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u80fd\u591f\u5229\u7528tf.saved_model\u4fdd\u5b58\u6a21\u578b\u5e76\u5b9e\u73b0\u8de8\u5e73\u53f0\u90e8\u7f72\u4f7f\u7528\u3002 \u5b9e\u9645\u4e0a\uff0ctf.keras.models.Model,tf.keras.layers.Layer \u90fd\u662f\u7ee7\u627f\u81eatf.Module\u7684\uff0c\u63d0\u4f9b\u4e86\u65b9\u4fbf\u7684\u53d8\u91cf\u7ba1\u7406\u548c\u6240\u5f15\u7528\u7684\u5b50\u6a21\u5757\u7ba1\u7406\u7684\u529f\u80fd\u3002 \u56e0\u6b64\uff0c\u5229\u7528tf.Module\u63d0\u4f9b\u7684\u5c01\u88c5\uff0c\u518d\u7ed3\u5408TensoFlow\u4e30\u5bcc\u7684\u4f4e\u9636API\uff0c\u5b9e\u9645\u4e0a\u6211\u4eec\u80fd\u591f\u57fa\u4e8eTensorFlow\u5f00\u53d1\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b(\u800c\u975e\u4ec5\u4ec5\u662f\u795e\u7ecf\u7f51\u7edc\u6a21\u578b)\uff0c\u5e76\u5b9e\u73b0\u8de8\u5e73\u53f0\u90e8\u7f72\u4f7f\u7528\u3002","title":"\u4e00\uff0cAutograph\u548ctf.Module\u6982\u8ff0"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-5%2CAutoGraph%E5%92%8Ctf.Module/#\u4e8c\u5e94\u7528tfmodule\u5c01\u88c5autograph","text":"\u5b9a\u4e49\u4e00\u4e2a\u7b80\u5355\u7684function\u3002 import tensorflow as tf x = tf . Variable ( 1.0 , dtype = tf . float32 ) #\u5728tf.function\u4e2d\u7528input_signature\u9650\u5b9a\u8f93\u5165\u5f20\u91cf\u7684\u7b7e\u540d\u7c7b\u578b\uff1ashape\u548cdtype @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def add_print ( a ): x . assign_add ( a ) tf . print ( x ) return ( x ) add_print ( tf . constant ( 3.0 )) #add_print(tf.constant(3)) #\u8f93\u5165\u4e0d\u7b26\u5408\u5f20\u91cf\u7b7e\u540d\u7684\u53c2\u6570\u5c06\u62a5\u9519 4 \u4e0b\u9762\u5229\u7528tf.Module\u7684\u5b50\u7c7b\u5316\u5c06\u5176\u5c01\u88c5\u4e00\u4e0b\u3002 class DemoModule ( tf . Module ): def __init__ ( self , init_value = tf . constant ( 0.0 ), name = None ): super ( DemoModule , self ) . __init__ ( name = name ) with self . name_scope : #\u76f8\u5f53\u4e8ewith tf.name_scope(\"demo_module\") self . x = tf . Variable ( init_value , dtype = tf . float32 , trainable = True ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( self , a ): with self . name_scope : self . x . assign_add ( a ) tf . print ( self . x ) return ( self . x ) #\u6267\u884c demo = DemoModule ( init_value = tf . constant ( 1.0 )) result = demo . addprint ( tf . constant ( 5.0 )) 6 #\u67e5\u770b\u6a21\u5757\u4e2d\u7684\u5168\u90e8\u53d8\u91cf\u548c\u5168\u90e8\u53ef\u8bad\u7ec3\u53d8\u91cf print ( demo . variables ) print ( demo . trainable_variables ) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) #\u67e5\u770b\u6a21\u5757\u4e2d\u7684\u5168\u90e8\u5b50\u6a21\u5757 demo . submodules #\u4f7f\u7528tf.saved_model \u4fdd\u5b58\u6a21\u578b\uff0c\u5e76\u6307\u5b9a\u9700\u8981\u8de8\u5e73\u53f0\u90e8\u7f72\u7684\u65b9\u6cd5 tf . saved_model . save ( demo , \"../../data/demo/1\" , signatures = { \"serving_default\" : demo . addprint }) #\u52a0\u8f7d\u6a21\u578b demo2 = tf . saved_model . load ( \"../../data/demo/1\" ) demo2 . addprint ( tf . constant ( 5.0 )) 11 # \u67e5\u770b\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f\uff0c\u7ea2\u6846\u6807\u51fa\u6765\u7684\u8f93\u51fa\u4fe1\u606f\u5728\u6a21\u578b\u90e8\u7f72\u548c\u8de8\u5e73\u53f0\u4f7f\u7528\u65f6\u6709\u53ef\u80fd\u4f1a\u7528\u5230 ! saved_model_cli show -- dir ../../ data / demo / 1 -- all \u5728tensorboard\u4e2d\u67e5\u770b\u8ba1\u7b97\u56fe\uff0c\u6a21\u5757\u4f1a\u88ab\u6dfb\u52a0\u6a21\u5757\u540ddemo_module,\u65b9\u4fbf\u5c42\u6b21\u5316\u5448\u73b0\u8ba1\u7b97\u56fe\u7ed3\u6784\u3002 import datetime # \u521b\u5efa\u65e5\u5fd7 stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = '../../data/demomodule/ %s ' % stamp writer = tf . summary . create_file_writer ( logdir ) #\u5f00\u542fautograph\u8ddf\u8e2a tf . summary . trace_on ( graph = True , profiler = True ) #\u6267\u884cautograph demo = DemoModule ( init_value = tf . constant ( 0.0 )) result = demo . addprint ( tf . constant ( 5.0 )) #\u5c06\u8ba1\u7b97\u56fe\u4fe1\u606f\u5199\u5165\u65e5\u5fd7 with writer . as_default (): tf . summary . trace_export ( name = \"demomodule\" , step = 0 , profiler_outdir = logdir ) #\u542f\u52a8 tensorboard\u5728jupyter\u4e2d\u7684\u9b54\u6cd5\u547d\u4ee4 % reload_ext tensorboard from tensorboard import notebook notebook . list () notebook . start ( \"--logdir ../../data/demomodule/\" ) \u9664\u4e86\u5229\u7528tf.Module\u7684\u5b50\u7c7b\u5316\u5b9e\u73b0\u5c01\u88c5\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ed9tf.Module\u6dfb\u52a0\u5c5e\u6027\u7684\u65b9\u6cd5\u8fdb\u884c\u5c01\u88c5\u3002 mymodule = tf . Module () mymodule . x = tf . Variable ( 0.0 ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( a ): mymodule . x . assign_add ( a ) tf . print ( mymodule . x ) return ( mymodule . x ) mymodule . addprint = addprint mymodule . addprint ( tf . constant ( 1.0 )) . numpy () 1.0 print ( mymodule . variables ) (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>,) #\u4f7f\u7528tf.saved_model \u4fdd\u5b58\u6a21\u578b tf . saved_model . save ( mymodule , \"../../data/mymodule\" , signatures = { \"serving_default\" : mymodule . addprint }) #\u52a0\u8f7d\u6a21\u578b mymodule2 = tf . saved_model . load ( \"../../data/mymodule\" ) mymodule2 . addprint ( tf . constant ( 5.0 )) INFO:tensorflow:Assets written to: ../../data/mymodule/assets 5","title":"\u4e8c\uff0c\u5e94\u7528tf.Module\u5c01\u88c5Autograph"},{"location":"chinese/4.%E4%BD%8E%E9%98%B6API/4-5%2CAutoGraph%E5%92%8Ctf.Module/#\u4e09tfmodule\u548ctfkerasmodeltfkeraslayerslayer","text":"tf.keras\u4e2d\u7684\u6a21\u578b\u548c\u5c42\u90fd\u662f\u7ee7\u627ftf.Module\u5b9e\u73b0\u7684\uff0c\u4e5f\u5177\u6709\u53d8\u91cf\u7ba1\u7406\u548c\u5b50\u6a21\u5757\u7ba1\u7406\u529f\u80fd\u3002 import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics print ( issubclass ( tf . keras . Model , tf . Module )) print ( issubclass ( tf . keras . layers . Layer , tf . Module )) print ( issubclass ( tf . keras . Model , tf . keras . layers . Layer )) True True True tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 4 , input_shape = ( 10 ,))) model . add ( layers . Dense ( 2 )) model . add ( layers . Dense ( 1 )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 4) 44 _________________________________________________________________ dense_1 (Dense) (None, 2) 10 _________________________________________________________________ dense_2 (Dense) (None, 1) 3 ================================================================= Total params: 57 Trainable params: 57 Non-trainable params: 0 _________________________________________________________________ model . variables [<tf.Variable 'dense/kernel:0' shape=(10, 4) dtype=float32, numpy= array([[-0.06741005, 0.45534766, 0.5190817 , -0.01806331], [-0.14258742, -0.49711505, 0.26030976, 0.18607801], [-0.62806034, 0.5327399 , 0.42206633, 0.29201728], [-0.16602087, -0.18901917, 0.55159235, -0.01091868], [ 0.04533798, 0.326845 , -0.582667 , 0.19431782], [ 0.6494713 , -0.16174704, 0.4062966 , 0.48760796], [ 0.58400524, -0.6280886 , -0.11265379, -0.6438277 ], [ 0.26642334, 0.49275804, 0.20793378, -0.43889117], [ 0.4092741 , 0.09871006, -0.2073121 , 0.26047975], [ 0.43910992, 0.00199282, -0.07711256, -0.27966842]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . layers [ 0 ] . trainable = False #\u51bb\u7ed3\u7b2c0\u5c42\u7684\u53d8\u91cf,\u4f7f\u5176\u4e0d\u53ef\u8bad\u7ec3 model . trainable_variables [<tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . submodules (<tensorflow.python.keras.engine.input_layer.InputLayer at 0x144d8c080>, <tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>) model . layers [<tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>] print ( model . name ) print ( model . name_scope ()) sequential sequential \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0ctf.Module\u548ctf.keras.Model\uff0ctf.keras.layers.Layer"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/","text":"\u4e94\u3001TensorFlow\u7684\u4e2d\u9636API # TensorFlow\u7684\u4e2d\u9636API\u4e3b\u8981\u5305\u62ec: \u6570\u636e\u7ba1\u9053(tf.data) \u7279\u5f81\u5217(tf.feature_column) \u6fc0\u6d3b\u51fd\u6570(tf.nn) \u6a21\u578b\u5c42(tf.keras.layers) \u635f\u5931\u51fd\u6570(tf.keras.losses) \u8bc4\u4f30\u51fd\u6570(tf.keras.metrics) \u4f18\u5316\u5668(tf.keras.optimizers) \u56de\u8c03\u51fd\u6570(tf.keras.callbacks) \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4e2d\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\u3001TensorFlow\u7684\u4e2d\u9636API"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/#\u4e94tensorflow\u7684\u4e2d\u9636api","text":"TensorFlow\u7684\u4e2d\u9636API\u4e3b\u8981\u5305\u62ec: \u6570\u636e\u7ba1\u9053(tf.data) \u7279\u5f81\u5217(tf.feature_column) \u6fc0\u6d3b\u51fd\u6570(tf.nn) \u6a21\u578b\u5c42(tf.keras.layers) \u635f\u5931\u51fd\u6570(tf.keras.losses) \u8bc4\u4f30\u51fd\u6570(tf.keras.metrics) \u4f18\u5316\u5668(tf.keras.optimizers) \u56de\u8c03\u51fd\u6570(tf.keras.callbacks) \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4e2d\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\u3001TensorFlow\u7684\u4e2d\u9636API"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-1%2C%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93Dataset/","text":"5-1,\u6570\u636e\u7ba1\u9053Dataset # \u5982\u679c\u9700\u8981\u8bad\u7ec3\u7684\u6570\u636e\u5927\u5c0f\u4e0d\u5927\uff0c\u4f8b\u5982\u4e0d\u52301G\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u5168\u90e8\u8bfb\u5165\u5185\u5b58\u4e2d\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u6837\u4e00\u822c\u6548\u7387\u6700\u9ad8\u3002 \u4f46\u5982\u679c\u9700\u8981\u8bad\u7ec3\u7684\u6570\u636e\u5f88\u5927\uff0c\u4f8b\u5982\u8d85\u8fc710G\uff0c\u65e0\u6cd5\u4e00\u6b21\u8f7d\u5165\u5185\u5b58\uff0c\u90a3\u4e48\u901a\u5e38\u9700\u8981\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u5206\u6279\u9010\u6e10\u8bfb\u5165\u3002 \u4f7f\u7528 tf.data API \u53ef\u4ee5\u6784\u5efa\u6570\u636e\u8f93\u5165\u7ba1\u9053\uff0c\u8f7b\u677e\u5904\u7406\u5927\u91cf\u7684\u6570\u636e\uff0c\u4e0d\u540c\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4ee5\u53ca\u4e0d\u540c\u7684\u6570\u636e\u8f6c\u6362\u3002 \u4e00\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u53ef\u4ee5\u4ece Numpy array, Pandas DataFrame, Python generator, csv\u6587\u4ef6, \u6587\u672c\u6587\u4ef6, \u6587\u4ef6\u8def\u5f84, tfrecords\u6587\u4ef6\u7b49\u65b9\u5f0f\u6784\u5efa\u6570\u636e\u7ba1\u9053\u3002 \u5176\u4e2d\u901a\u8fc7Numpy array, Pandas DataFrame, \u6587\u4ef6\u8def\u5f84\u6784\u5efa\u6570\u636e\u7ba1\u9053\u662f\u6700\u5e38\u7528\u7684\u65b9\u6cd5\u3002 \u901a\u8fc7tfrecords\u6587\u4ef6\u65b9\u5f0f\u6784\u5efa\u6570\u636e\u7ba1\u9053\u8f83\u4e3a\u590d\u6742\uff0c\u9700\u8981\u5bf9\u6837\u672c\u6784\u5efatf.Example\u540e\u538b\u7f29\u6210\u5b57\u7b26\u4e32\u5199\u5230tfrecords\u6587\u4ef6\uff0c\u8bfb\u53d6\u540e\u518d\u89e3\u6790\u6210tf.Example\u3002 \u4f46tfrecords\u6587\u4ef6\u7684\u4f18\u70b9\u662f\u538b\u7f29\u540e\u6587\u4ef6\u8f83\u5c0f\uff0c\u4fbf\u4e8e\u7f51\u7edc\u4f20\u64ad\uff0c\u52a0\u8f7d\u901f\u5ea6\u8f83\u5feb\u3002 1,\u4eceNumpy array\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4eceNumpy array\u6784\u5efa\u6570\u636e\u7ba1\u9053 import tensorflow as tf import numpy as np from sklearn import datasets iris = datasets . load_iris () ds1 = tf . data . Dataset . from_tensor_slices (( iris [ \"data\" ], iris [ \"target\" ])) for features , label in ds1 . take ( 5 ): print ( features , label ) tf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.9 3. 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([5. 3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) 2,\u4ece Pandas DataFrame\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ece Pandas DataFrame\u6784\u5efa\u6570\u636e\u7ba1\u9053 import tensorflow as tf from sklearn import datasets import pandas as pd iris = datasets . load_iris () dfiris = pd . DataFrame ( iris [ \"data\" ], columns = iris . feature_names ) ds2 = tf . data . Dataset . from_tensor_slices (( dfiris . to_dict ( \"list\" ), iris [ \"target\" ])) for features , label in ds2 . take ( 3 ): print ( features , label ) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) 3,\u4ecePython generator\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ecePython generator\u6784\u5efa\u6570\u636e\u7ba1\u9053 import tensorflow as tf from matplotlib import pyplot as plt from tensorflow.keras.preprocessing.image import ImageDataGenerator # \u5b9a\u4e49\u4e00\u4e2a\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u56fe\u7247\u7684generator image_generator = ImageDataGenerator ( rescale = 1.0 / 255 ) . flow_from_directory ( \"../../data/cifar2/test/\" , target_size = ( 32 , 32 ), batch_size = 20 , class_mode = 'binary' ) classdict = image_generator . class_indices print ( classdict ) def generator (): for features , label in image_generator : yield ( features , label ) ds3 = tf . data . Dataset . from_generator ( generator , output_types = ( tf . float32 , tf . int32 )) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds3 . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 4,\u4ececsv\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ececsv\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 ds4 = tf . data . experimental . make_csv_dataset ( file_pattern = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ], batch_size = 3 , label_name = \"Survived\" , na_value = \"\" , num_epochs = 1 , ignore_errors = True ) for data , label in ds4 . take ( 2 ): print ( data , label ) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([540, 58, 764], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 1], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Frolicher, Miss. Hedwig Margaritha', b'Novel, Mr. Mansouer', b'Carter, Mrs. William Ernest (Lucile Polk)'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'female', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([22. , 28.5, 36. ], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 2], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'13568', b'2697', b'113760'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 49.5 , 7.2292, 120. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'B39', b'', b'B96 B98'], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'C', b'C', b'S'], dtype=object)>)]) tf.Tensor([1 0 1], shape=(3,), dtype=int32) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([845, 66, 390], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 2], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Culumovic, Mr. Jeso', b'Moubarek, Master. Gerios', b'Lehmann, Miss. Bertha'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([17., 0., 17.], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'315090', b'2661', b'SC 1748'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8.6625, 15.2458, 12. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'', b'', b''], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'C', b'C'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32) 5,\u4ece\u6587\u672c\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ece\u6587\u672c\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 ds5 = tf . data . TextLineDataset ( filenames = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ] ) . skip ( 1 ) #\u7565\u53bb\u7b2c\u4e00\u884cheader for line in ds5 . take ( 5 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) tf.Tensor(b'687,0,3,\"Panula, Mr. Jaako Arnold\",male,14.0,4,1,3101295,39.6875,,S', shape=(), dtype=string) 6,\u4ece\u6587\u4ef6\u8def\u5f84\u6784\u5efa\u6570\u636e\u7ba1\u9053 ds6 = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) for file in ds6 . take ( 5 ): print ( file ) tf.Tensor(b'../../data/cifar2/train/automobile/1263.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/2837.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/4264.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/4241.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/192.jpg', shape=(), dtype=string) from matplotlib import pyplot as plt def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , size ) return ( img , label ) % matplotlib inline % config InlineBackend . figure_format = 'svg' for i ,( img , label ) in enumerate ( ds6 . map ( load_image ) . take ( 2 )): plt . figure ( i ) plt . imshow (( img / 255.0 ) . numpy ()) plt . title ( \"label = %d \" % label ) plt . xticks ([]) plt . yticks ([]) 7,\u4ecetfrecords\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 import os import numpy as np # inpath\uff1a\u539f\u59cb\u6570\u636e\u8def\u5f84 outpath:TFRecord\u6587\u4ef6\u8f93\u51fa\u8def\u5f84 def create_tfrecords ( inpath , outpath ): writer = tf . io . TFRecordWriter ( outpath ) dirs = os . listdir ( inpath ) for index , name in enumerate ( dirs ): class_path = inpath + \"/\" + name + \"/\" for img_name in os . listdir ( class_path ): img_path = class_path + img_name img = tf . io . read_file ( img_path ) #img = tf.image.decode_image(img) #img = tf.image.encode_jpeg(img) #\u7edf\u4e00\u6210jpeg\u683c\u5f0f\u538b\u7f29 example = tf . train . Example ( features = tf . train . Features ( feature = { 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = [ index ])), 'img_raw' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ img . numpy ()])) })) writer . write ( example . SerializeToString ()) writer . close () create_tfrecords ( \"../../data/cifar2/test/\" , \"../../data/cifar2_test.tfrecords/\" ) from matplotlib import pyplot as plt def parse_example ( proto ): description = { 'img_raw' : tf . io . FixedLenFeature ([], tf . string ), 'label' : tf . io . FixedLenFeature ([], tf . int64 )} example = tf . io . parse_single_example ( proto , description ) img = tf . image . decode_jpeg ( example [ \"img_raw\" ]) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , ( 32 , 32 )) label = example [ \"label\" ] return ( img , label ) ds7 = tf . data . TFRecordDataset ( \"../../data/cifar2_test.tfrecords\" ) . map ( parse_example ) . shuffle ( 3000 ) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds7 . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow (( img / 255.0 ) . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () \u4e8c\uff0c\u5e94\u7528\u6570\u636e\u8f6c\u6362 # Dataset\u6570\u636e\u7ed3\u6784\u5e94\u7528\u975e\u5e38\u7075\u6d3b\uff0c\u56e0\u4e3a\u5b83\u672c\u8d28\u4e0a\u662f\u4e00\u4e2aSequece\u5e8f\u5217\uff0c\u5176\u6bcf\u4e2a\u5143\u7d20\u53ef\u4ee5\u662f\u5404\u79cd\u7c7b\u578b\uff0c\u4f8b\u5982\u53ef\u4ee5\u662f\u5f20\u91cf\uff0c\u5217\u8868\uff0c\u5b57\u5178\uff0c\u4e5f\u53ef\u4ee5\u662fDataset\u3002 Dataset\u5305\u542b\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u6570\u636e\u8f6c\u6362\u529f\u80fd\u3002 map: \u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u6bcf\u4e00\u4e2a\u5143\u7d20\u3002 flat_map: \u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u5e76\u5c06\u5d4c\u5957\u7684Dataset\u538b\u5e73\u3002 interleave: \u6548\u679c\u7c7b\u4f3cflat_map,\u4f46\u53ef\u4ee5\u5c06\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 filter: \u8fc7\u6ee4\u6389\u67d0\u4e9b\u5143\u7d20\u3002 zip: \u5c06\u4e24\u4e2a\u957f\u5ea6\u76f8\u540c\u7684Dataset\u6a2a\u5411\u94f0\u5408\u3002 concatenate: \u5c06\u4e24\u4e2aDataset\u7eb5\u5411\u8fde\u63a5\u3002 reduce: \u6267\u884c\u5f52\u5e76\u64cd\u4f5c\u3002 batch : \u6784\u5efa\u6279\u6b21\uff0c\u6bcf\u6b21\u653e\u4e00\u4e2a\u6279\u6b21\u3002\u6bd4\u539f\u59cb\u6570\u636e\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\u3002 \u5176\u9006\u64cd\u4f5c\u4e3aunbatch\u3002 padded_batch: \u6784\u5efa\u6279\u6b21\uff0c\u7c7b\u4f3cbatch, \u4f46\u53ef\u4ee5\u586b\u5145\u5230\u76f8\u540c\u7684\u5f62\u72b6\u3002 window :\u6784\u5efa\u6ed1\u52a8\u7a97\u53e3\uff0c\u8fd4\u56deDataset of Dataset. shuffle: \u6570\u636e\u987a\u5e8f\u6d17\u724c\u3002 repeat: \u91cd\u590d\u6570\u636e\u82e5\u5e72\u6b21\uff0c\u4e0d\u5e26\u53c2\u6570\u65f6\uff0c\u91cd\u590d\u65e0\u6570\u6b21\u3002 shard: \u91c7\u6837\uff0c\u4ece\u67d0\u4e2a\u4f4d\u7f6e\u5f00\u59cb\u9694\u56fa\u5b9a\u8ddd\u79bb\u91c7\u6837\u4e00\u4e2a\u5143\u7d20\u3002 take: \u91c7\u6837\uff0c\u4ece\u5f00\u59cb\u4f4d\u7f6e\u53d6\u524d\u51e0\u4e2a\u5143\u7d20\u3002 #map:\u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u6bcf\u4e00\u4e2a\u5143\u7d20 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_map = ds . map ( lambda x : tf . strings . split ( x , \" \" )) for x in ds_map : print ( x ) tf.Tensor([b'hello' b'world'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'China'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'Beijing'], shape=(2,), dtype=string) #flat_map:\u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u5e76\u5c06\u5d4c\u5957\u7684Dataset\u538b\u5e73\u3002 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_flatmap = ds . flat_map ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_flatmap : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) # interleave: \u6548\u679c\u7c7b\u4f3cflat_map,\u4f46\u53ef\u4ee5\u5c06\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_interleave = ds . interleave ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_interleave : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) #filter:\u8fc7\u6ee4\u6389\u67d0\u4e9b\u5143\u7d20\u3002 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) #\u627e\u51fa\u542b\u6709\u5b57\u6bcda\u6216B\u7684\u5143\u7d20 ds_filter = ds . filter ( lambda x : tf . strings . regex_full_match ( x , \".*[a|B].*\" )) for x in ds_filter : print ( x ) tf.Tensor(b'hello China', shape=(), dtype=string) tf.Tensor(b'hello Beijing', shape=(), dtype=string) #zip:\u5c06\u4e24\u4e2a\u957f\u5ea6\u76f8\u540c\u7684Dataset\u6a2a\u5411\u94f0\u5408\u3002 ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds3 = tf . data . Dataset . range ( 6 , 9 ) ds_zip = tf . data . Dataset . zip (( ds1 , ds2 , ds3 )) for x , y , z in ds_zip : print ( x . numpy (), y . numpy (), z . numpy ()) 0 3 6 1 4 7 2 5 8 #condatenate:\u5c06\u4e24\u4e2aDataset\u7eb5\u5411\u8fde\u63a5\u3002 ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds_concat = tf . data . Dataset . concatenate ( ds1 , ds2 ) for x in ds_concat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) #reduce:\u6267\u884c\u5f52\u5e76\u64cd\u4f5c\u3002 ds = tf . data . Dataset . from_tensor_slices ([ 1 , 2 , 3 , 4 , 5.0 ]) result = ds . reduce ( 0.0 , lambda x , y : tf . add ( x , y )) result <tf.Tensor: shape=(), dtype=float32, numpy=15.0> #batch:\u6784\u5efa\u6279\u6b21\uff0c\u6bcf\u6b21\u653e\u4e00\u4e2a\u6279\u6b21\u3002\u6bd4\u539f\u59cb\u6570\u636e\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\u3002 \u5176\u9006\u64cd\u4f5c\u4e3aunbatch\u3002 ds = tf . data . Dataset . range ( 12 ) ds_batch = ds . batch ( 4 ) for x in ds_batch : print ( x ) tf.Tensor([0 1 2 3], shape=(4,), dtype=int64) tf.Tensor([4 5 6 7], shape=(4,), dtype=int64) tf.Tensor([ 8 9 10 11], shape=(4,), dtype=int64) #padded_batch:\u6784\u5efa\u6279\u6b21\uff0c\u7c7b\u4f3cbatch, \u4f46\u53ef\u4ee5\u586b\u5145\u5230\u76f8\u540c\u7684\u5f62\u72b6\u3002 elements = [[ 1 , 2 ],[ 3 , 4 , 5 ],[ 6 , 7 ],[ 8 ]] ds = tf . data . Dataset . from_generator ( lambda : iter ( elements ), tf . int32 ) ds_padded_batch = ds . padded_batch ( 2 , padded_shapes = [ 4 ,]) for x in ds_padded_batch : print ( x ) tf.Tensor( [[1 2 0 0] [3 4 5 0]], shape=(2, 4), dtype=int32) tf.Tensor( [[6 7 0 0] [8 0 0 0]], shape=(2, 4), dtype=int32) #window:\u6784\u5efa\u6ed1\u52a8\u7a97\u53e3\uff0c\u8fd4\u56deDataset of Dataset. ds = tf . data . Dataset . range ( 12 ) #window\u8fd4\u56de\u7684\u662fDataset of Dataset,\u53ef\u4ee5\u7528flat_map\u538b\u5e73 ds_window = ds . window ( 3 , shift = 1 ) . flat_map ( lambda x : x . batch ( 3 , drop_remainder = True )) for x in ds_window : print ( x ) tf.Tensor([0 1 2], shape=(3,), dtype=int64) tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([2 3 4], shape=(3,), dtype=int64) tf.Tensor([3 4 5], shape=(3,), dtype=int64) tf.Tensor([4 5 6], shape=(3,), dtype=int64) tf.Tensor([5 6 7], shape=(3,), dtype=int64) tf.Tensor([6 7 8], shape=(3,), dtype=int64) tf.Tensor([7 8 9], shape=(3,), dtype=int64) tf.Tensor([ 8 9 10], shape=(3,), dtype=int64) tf.Tensor([ 9 10 11], shape=(3,), dtype=int64) #shuffle:\u6570\u636e\u987a\u5e8f\u6d17\u724c\u3002 ds = tf . data . Dataset . range ( 12 ) ds_shuffle = ds . shuffle ( buffer_size = 5 ) for x in ds_shuffle : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(6, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(11, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(9, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) tf.Tensor(8, shape=(), dtype=int64) #repeat:\u91cd\u590d\u6570\u636e\u82e5\u5e72\u6b21\uff0c\u4e0d\u5e26\u53c2\u6570\u65f6\uff0c\u91cd\u590d\u65e0\u6570\u6b21\u3002 ds = tf . data . Dataset . range ( 3 ) ds_repeat = ds . repeat ( 3 ) for x in ds_repeat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) #shard:\u91c7\u6837\uff0c\u4ece\u67d0\u4e2a\u4f4d\u7f6e\u5f00\u59cb\u9694\u56fa\u5b9a\u8ddd\u79bb\u91c7\u6837\u4e00\u4e2a\u5143\u7d20\u3002 ds = tf . data . Dataset . range ( 12 ) ds_shard = ds . shard ( 3 , index = 1 ) for x in ds_shard : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) #take:\u91c7\u6837\uff0c\u4ece\u5f00\u59cb\u4f4d\u7f6e\u53d6\u524d\u51e0\u4e2a\u5143\u7d20\u3002 ds = tf . data . Dataset . range ( 12 ) ds_take = ds . take ( 3 ) list ( ds_take . as_numpy_iterator ()) [0, 1, 2] \u4e09\uff0c\u63d0\u5347\u7ba1\u9053\u6027\u80fd # \u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e38\u5e38\u4f1a\u975e\u5e38\u8017\u65f6\u3002 \u6a21\u578b\u8bad\u7ec3\u7684\u8017\u65f6\u4e3b\u8981\u6765\u81ea\u4e8e\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u6765\u81ea**\u6570\u636e\u51c6\u5907**\uff0c\u53e6\u4e00\u90e8\u5206\u6765\u81ea**\u53c2\u6570\u8fed\u4ee3**\u3002 \u53c2\u6570\u8fed\u4ee3\u8fc7\u7a0b\u7684\u8017\u65f6\u901a\u5e38\u4f9d\u8d56\u4e8eGPU\u6765\u63d0\u5347\u3002 \u800c\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u7684\u8017\u65f6\u5219\u53ef\u4ee5\u901a\u8fc7\u6784\u5efa\u9ad8\u6548\u7684\u6570\u636e\u7ba1\u9053\u8fdb\u884c\u63d0\u5347\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e9b\u6784\u5efa\u9ad8\u6548\u6570\u636e\u7ba1\u9053\u7684\u5efa\u8bae\u3002 1\uff0c\u4f7f\u7528 prefetch \u65b9\u6cd5\u8ba9\u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u76f8\u4e92\u5e76\u884c\u3002 2\uff0c\u4f7f\u7528 interleave \u65b9\u6cd5\u53ef\u4ee5\u8ba9\u6570\u636e\u8bfb\u53d6\u8fc7\u7a0b\u591a\u8fdb\u7a0b\u6267\u884c,\u5e76\u5c06\u4e0d\u540c\u6765\u6e90\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 3\uff0c\u4f7f\u7528 map \u65f6\u8bbe\u7f6enum_parallel_calls \u8ba9\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u591a\u8fdb\u7a0b\u6267\u884c\u3002 4\uff0c\u4f7f\u7528 cache \u65b9\u6cd5\u8ba9\u6570\u636e\u5728\u7b2c\u4e00\u4e2aepoch\u540e\u7f13\u5b58\u5230\u5185\u5b58\u4e2d\uff0c\u4ec5\u9650\u4e8e\u6570\u636e\u96c6\u4e0d\u5927\u60c5\u5f62\u3002 5\uff0c\u4f7f\u7528 map\u8f6c\u6362\u65f6\uff0c\u5148batch, \u7136\u540e\u91c7\u7528\u5411\u91cf\u5316\u7684\u8f6c\u6362\u65b9\u6cd5\u5bf9\u6bcf\u4e2abatch\u8fdb\u884c\u8f6c\u6362\u3002 1\uff0c\u4f7f\u7528 prefetch \u65b9\u6cd5\u8ba9\u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u76f8\u4e92\u5e76\u884c\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) import time # \u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u662f\u4e32\u884c\u7684\u3002 # \u6a21\u62df\u6570\u636e\u51c6\u5907 def generator (): for i in range ( 10 ): #\u5047\u8bbe\u6bcf\u6b21\u51c6\u5907\u6570\u636e\u9700\u89812s time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # \u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): #\u5047\u8bbe\u6bcf\u4e00\u6b65\u8bad\u7ec3\u9700\u89811s time . sleep ( 1 ) # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 10*2+10*1 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for x in ds : train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) # \u4f7f\u7528 prefetch \u65b9\u6cd5\u8ba9\u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u76f8\u4e92\u5e76\u884c\u3002 # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 max(10*2,10*1) = 20s printbar () tf . print ( tf . constant ( \"start training with prefetch...\" )) # tf.data.experimental.AUTOTUNE \u53ef\u4ee5\u8ba9\u7a0b\u5e8f\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u53c2\u6570 for x in ds . prefetch ( buffer_size = tf . data . experimental . AUTOTUNE ): train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) 2\uff0c\u4f7f\u7528 interleave \u65b9\u6cd5\u53ef\u4ee5\u8ba9\u6570\u636e\u8bfb\u53d6\u8fc7\u7a0b\u591a\u8fdb\u7a0b\u6267\u884c,\u5e76\u5c06\u4e0d\u540c\u6765\u6e90\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . flat_map ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 4 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . interleave ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 8 ): print ( line ) tf.Tensor(b'181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S', shape=(), dtype=string) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'405,0,3,\"Oreskovic, Miss. Marija\",female,20.0,0,0,315096,8.6625,,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'635,0,3,\"Skoog, Miss. Mabel\",female,9.0,3,2,347088,27.9,,S', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18.0,1,0,PC 17757,227.525,C62 C64,C', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) 3\uff0c\u4f7f\u7528 map \u65f6\u8bbe\u7f6enum_parallel_calls \u8ba9\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u591a\u8fdb\u884c\u6267\u884c\u3002 ds = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , size ) return ( img , label ) #\u5355\u8fdb\u7a0b\u8f6c\u6362 printbar () tf . print ( tf . constant ( \"start transformation...\" )) ds_map = ds . map ( load_image ) for _ in ds_map : pass printbar () tf . print ( tf . constant ( \"end transformation...\" )) #\u591a\u8fdb\u7a0b\u8f6c\u6362 printbar () tf . print ( tf . constant ( \"start parallel transformation...\" )) ds_map_parallel = ds . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) for _ in ds_map_parallel : pass printbar () tf . print ( tf . constant ( \"end parallel transformation...\" )) 4\uff0c\u4f7f\u7528 cache \u65b9\u6cd5\u8ba9\u6570\u636e\u5728\u7b2c\u4e00\u4e2aepoch\u540e\u7f13\u5b58\u5230\u5185\u5b58\u4e2d\uff0c\u4ec5\u9650\u4e8e\u6570\u636e\u96c6\u4e0d\u5927\u60c5\u5f62\u3002 import time # \u6a21\u62df\u6570\u636e\u51c6\u5907 def generator (): for i in range ( 5 ): #\u5047\u8bbe\u6bcf\u6b21\u51c6\u5907\u6570\u636e\u9700\u89812s time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # \u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): #\u5047\u8bbe\u6bcf\u4e00\u6b65\u8bad\u7ec3\u9700\u89810s pass # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 (5*2+5*0)*3 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) import time # \u6a21\u62df\u6570\u636e\u51c6\u5907 def generator (): for i in range ( 5 ): #\u5047\u8bbe\u6bcf\u6b21\u51c6\u5907\u6570\u636e\u9700\u89812s time . sleep ( 2 ) yield i # \u4f7f\u7528 cache \u65b9\u6cd5\u8ba9\u6570\u636e\u5728\u7b2c\u4e00\u4e2aepoch\u540e\u7f13\u5b58\u5230\u5185\u5b58\u4e2d\uff0c\u4ec5\u9650\u4e8e\u6570\u636e\u96c6\u4e0d\u5927\u60c5\u5f62\u3002 ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) . cache () # \u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): #\u5047\u8bbe\u6bcf\u4e00\u6b65\u8bad\u7ec3\u9700\u89810s time . sleep ( 0 ) # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 (5*2+5*0)+(5*0+5*0)*2 = 10s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) 5\uff0c\u4f7f\u7528 map\u8f6c\u6362\u65f6\uff0c\u5148batch, \u7136\u540e\u91c7\u7528\u5411\u91cf\u5316\u7684\u8f6c\u6362\u65b9\u6cd5\u5bf9\u6bcf\u4e2abatch\u8fdb\u884c\u8f6c\u6362\u3002 #\u5148map\u540ebatch ds = tf . data . Dataset . range ( 100000 ) ds_map_batch = ds . map ( lambda x : x ** 2 ) . batch ( 20 ) printbar () tf . print ( tf . constant ( \"start scalar transformation...\" )) for x in ds_map_batch : pass printbar () tf . print ( tf . constant ( \"end scalar transformation...\" )) #\u5148batch\u540emap ds = tf . data . Dataset . range ( 100000 ) ds_batch_map = ds . batch ( 20 ) . map ( lambda x : x ** 2 ) printbar () tf . print ( tf . constant ( \"start vector transformation...\" )) for x in ds_batch_map : pass printbar () tf . print ( tf . constant ( \"end vector transformation...\" )) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-1,\u6570\u636e\u7ba1\u9053Dataset"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-1%2C%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93Dataset/#5-1\u6570\u636e\u7ba1\u9053dataset","text":"\u5982\u679c\u9700\u8981\u8bad\u7ec3\u7684\u6570\u636e\u5927\u5c0f\u4e0d\u5927\uff0c\u4f8b\u5982\u4e0d\u52301G\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u5168\u90e8\u8bfb\u5165\u5185\u5b58\u4e2d\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u6837\u4e00\u822c\u6548\u7387\u6700\u9ad8\u3002 \u4f46\u5982\u679c\u9700\u8981\u8bad\u7ec3\u7684\u6570\u636e\u5f88\u5927\uff0c\u4f8b\u5982\u8d85\u8fc710G\uff0c\u65e0\u6cd5\u4e00\u6b21\u8f7d\u5165\u5185\u5b58\uff0c\u90a3\u4e48\u901a\u5e38\u9700\u8981\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u5206\u6279\u9010\u6e10\u8bfb\u5165\u3002 \u4f7f\u7528 tf.data API \u53ef\u4ee5\u6784\u5efa\u6570\u636e\u8f93\u5165\u7ba1\u9053\uff0c\u8f7b\u677e\u5904\u7406\u5927\u91cf\u7684\u6570\u636e\uff0c\u4e0d\u540c\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4ee5\u53ca\u4e0d\u540c\u7684\u6570\u636e\u8f6c\u6362\u3002","title":"5-1,\u6570\u636e\u7ba1\u9053Dataset"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-1%2C%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93Dataset/#\u4e00\u6784\u5efa\u6570\u636e\u7ba1\u9053","text":"\u53ef\u4ee5\u4ece Numpy array, Pandas DataFrame, Python generator, csv\u6587\u4ef6, \u6587\u672c\u6587\u4ef6, \u6587\u4ef6\u8def\u5f84, tfrecords\u6587\u4ef6\u7b49\u65b9\u5f0f\u6784\u5efa\u6570\u636e\u7ba1\u9053\u3002 \u5176\u4e2d\u901a\u8fc7Numpy array, Pandas DataFrame, \u6587\u4ef6\u8def\u5f84\u6784\u5efa\u6570\u636e\u7ba1\u9053\u662f\u6700\u5e38\u7528\u7684\u65b9\u6cd5\u3002 \u901a\u8fc7tfrecords\u6587\u4ef6\u65b9\u5f0f\u6784\u5efa\u6570\u636e\u7ba1\u9053\u8f83\u4e3a\u590d\u6742\uff0c\u9700\u8981\u5bf9\u6837\u672c\u6784\u5efatf.Example\u540e\u538b\u7f29\u6210\u5b57\u7b26\u4e32\u5199\u5230tfrecords\u6587\u4ef6\uff0c\u8bfb\u53d6\u540e\u518d\u89e3\u6790\u6210tf.Example\u3002 \u4f46tfrecords\u6587\u4ef6\u7684\u4f18\u70b9\u662f\u538b\u7f29\u540e\u6587\u4ef6\u8f83\u5c0f\uff0c\u4fbf\u4e8e\u7f51\u7edc\u4f20\u64ad\uff0c\u52a0\u8f7d\u901f\u5ea6\u8f83\u5feb\u3002 1,\u4eceNumpy array\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4eceNumpy array\u6784\u5efa\u6570\u636e\u7ba1\u9053 import tensorflow as tf import numpy as np from sklearn import datasets iris = datasets . load_iris () ds1 = tf . data . Dataset . from_tensor_slices (( iris [ \"data\" ], iris [ \"target\" ])) for features , label in ds1 . take ( 5 ): print ( features , label ) tf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.9 3. 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([5. 3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) 2,\u4ece Pandas DataFrame\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ece Pandas DataFrame\u6784\u5efa\u6570\u636e\u7ba1\u9053 import tensorflow as tf from sklearn import datasets import pandas as pd iris = datasets . load_iris () dfiris = pd . DataFrame ( iris [ \"data\" ], columns = iris . feature_names ) ds2 = tf . data . Dataset . from_tensor_slices (( dfiris . to_dict ( \"list\" ), iris [ \"target\" ])) for features , label in ds2 . take ( 3 ): print ( features , label ) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) 3,\u4ecePython generator\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ecePython generator\u6784\u5efa\u6570\u636e\u7ba1\u9053 import tensorflow as tf from matplotlib import pyplot as plt from tensorflow.keras.preprocessing.image import ImageDataGenerator # \u5b9a\u4e49\u4e00\u4e2a\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u56fe\u7247\u7684generator image_generator = ImageDataGenerator ( rescale = 1.0 / 255 ) . flow_from_directory ( \"../../data/cifar2/test/\" , target_size = ( 32 , 32 ), batch_size = 20 , class_mode = 'binary' ) classdict = image_generator . class_indices print ( classdict ) def generator (): for features , label in image_generator : yield ( features , label ) ds3 = tf . data . Dataset . from_generator ( generator , output_types = ( tf . float32 , tf . int32 )) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds3 . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 4,\u4ececsv\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ececsv\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 ds4 = tf . data . experimental . make_csv_dataset ( file_pattern = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ], batch_size = 3 , label_name = \"Survived\" , na_value = \"\" , num_epochs = 1 , ignore_errors = True ) for data , label in ds4 . take ( 2 ): print ( data , label ) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([540, 58, 764], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 1], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Frolicher, Miss. Hedwig Margaritha', b'Novel, Mr. Mansouer', b'Carter, Mrs. William Ernest (Lucile Polk)'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'female', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([22. , 28.5, 36. ], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 2], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'13568', b'2697', b'113760'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 49.5 , 7.2292, 120. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'B39', b'', b'B96 B98'], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'C', b'C', b'S'], dtype=object)>)]) tf.Tensor([1 0 1], shape=(3,), dtype=int32) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([845, 66, 390], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 2], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Culumovic, Mr. Jeso', b'Moubarek, Master. Gerios', b'Lehmann, Miss. Bertha'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([17., 0., 17.], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'315090', b'2661', b'SC 1748'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8.6625, 15.2458, 12. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'', b'', b''], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'C', b'C'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32) 5,\u4ece\u6587\u672c\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 # \u4ece\u6587\u672c\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 ds5 = tf . data . TextLineDataset ( filenames = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ] ) . skip ( 1 ) #\u7565\u53bb\u7b2c\u4e00\u884cheader for line in ds5 . take ( 5 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) tf.Tensor(b'687,0,3,\"Panula, Mr. Jaako Arnold\",male,14.0,4,1,3101295,39.6875,,S', shape=(), dtype=string) 6,\u4ece\u6587\u4ef6\u8def\u5f84\u6784\u5efa\u6570\u636e\u7ba1\u9053 ds6 = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) for file in ds6 . take ( 5 ): print ( file ) tf.Tensor(b'../../data/cifar2/train/automobile/1263.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/2837.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/4264.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/4241.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/192.jpg', shape=(), dtype=string) from matplotlib import pyplot as plt def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , size ) return ( img , label ) % matplotlib inline % config InlineBackend . figure_format = 'svg' for i ,( img , label ) in enumerate ( ds6 . map ( load_image ) . take ( 2 )): plt . figure ( i ) plt . imshow (( img / 255.0 ) . numpy ()) plt . title ( \"label = %d \" % label ) plt . xticks ([]) plt . yticks ([]) 7,\u4ecetfrecords\u6587\u4ef6\u6784\u5efa\u6570\u636e\u7ba1\u9053 import os import numpy as np # inpath\uff1a\u539f\u59cb\u6570\u636e\u8def\u5f84 outpath:TFRecord\u6587\u4ef6\u8f93\u51fa\u8def\u5f84 def create_tfrecords ( inpath , outpath ): writer = tf . io . TFRecordWriter ( outpath ) dirs = os . listdir ( inpath ) for index , name in enumerate ( dirs ): class_path = inpath + \"/\" + name + \"/\" for img_name in os . listdir ( class_path ): img_path = class_path + img_name img = tf . io . read_file ( img_path ) #img = tf.image.decode_image(img) #img = tf.image.encode_jpeg(img) #\u7edf\u4e00\u6210jpeg\u683c\u5f0f\u538b\u7f29 example = tf . train . Example ( features = tf . train . Features ( feature = { 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = [ index ])), 'img_raw' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ img . numpy ()])) })) writer . write ( example . SerializeToString ()) writer . close () create_tfrecords ( \"../../data/cifar2/test/\" , \"../../data/cifar2_test.tfrecords/\" ) from matplotlib import pyplot as plt def parse_example ( proto ): description = { 'img_raw' : tf . io . FixedLenFeature ([], tf . string ), 'label' : tf . io . FixedLenFeature ([], tf . int64 )} example = tf . io . parse_single_example ( proto , description ) img = tf . image . decode_jpeg ( example [ \"img_raw\" ]) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , ( 32 , 32 )) label = example [ \"label\" ] return ( img , label ) ds7 = tf . data . TFRecordDataset ( \"../../data/cifar2_test.tfrecords\" ) . map ( parse_example ) . shuffle ( 3000 ) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds7 . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow (( img / 255.0 ) . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show ()","title":"\u4e00\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-1%2C%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93Dataset/#\u4e8c\u5e94\u7528\u6570\u636e\u8f6c\u6362","text":"Dataset\u6570\u636e\u7ed3\u6784\u5e94\u7528\u975e\u5e38\u7075\u6d3b\uff0c\u56e0\u4e3a\u5b83\u672c\u8d28\u4e0a\u662f\u4e00\u4e2aSequece\u5e8f\u5217\uff0c\u5176\u6bcf\u4e2a\u5143\u7d20\u53ef\u4ee5\u662f\u5404\u79cd\u7c7b\u578b\uff0c\u4f8b\u5982\u53ef\u4ee5\u662f\u5f20\u91cf\uff0c\u5217\u8868\uff0c\u5b57\u5178\uff0c\u4e5f\u53ef\u4ee5\u662fDataset\u3002 Dataset\u5305\u542b\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u6570\u636e\u8f6c\u6362\u529f\u80fd\u3002 map: \u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u6bcf\u4e00\u4e2a\u5143\u7d20\u3002 flat_map: \u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u5e76\u5c06\u5d4c\u5957\u7684Dataset\u538b\u5e73\u3002 interleave: \u6548\u679c\u7c7b\u4f3cflat_map,\u4f46\u53ef\u4ee5\u5c06\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 filter: \u8fc7\u6ee4\u6389\u67d0\u4e9b\u5143\u7d20\u3002 zip: \u5c06\u4e24\u4e2a\u957f\u5ea6\u76f8\u540c\u7684Dataset\u6a2a\u5411\u94f0\u5408\u3002 concatenate: \u5c06\u4e24\u4e2aDataset\u7eb5\u5411\u8fde\u63a5\u3002 reduce: \u6267\u884c\u5f52\u5e76\u64cd\u4f5c\u3002 batch : \u6784\u5efa\u6279\u6b21\uff0c\u6bcf\u6b21\u653e\u4e00\u4e2a\u6279\u6b21\u3002\u6bd4\u539f\u59cb\u6570\u636e\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\u3002 \u5176\u9006\u64cd\u4f5c\u4e3aunbatch\u3002 padded_batch: \u6784\u5efa\u6279\u6b21\uff0c\u7c7b\u4f3cbatch, \u4f46\u53ef\u4ee5\u586b\u5145\u5230\u76f8\u540c\u7684\u5f62\u72b6\u3002 window :\u6784\u5efa\u6ed1\u52a8\u7a97\u53e3\uff0c\u8fd4\u56deDataset of Dataset. shuffle: \u6570\u636e\u987a\u5e8f\u6d17\u724c\u3002 repeat: \u91cd\u590d\u6570\u636e\u82e5\u5e72\u6b21\uff0c\u4e0d\u5e26\u53c2\u6570\u65f6\uff0c\u91cd\u590d\u65e0\u6570\u6b21\u3002 shard: \u91c7\u6837\uff0c\u4ece\u67d0\u4e2a\u4f4d\u7f6e\u5f00\u59cb\u9694\u56fa\u5b9a\u8ddd\u79bb\u91c7\u6837\u4e00\u4e2a\u5143\u7d20\u3002 take: \u91c7\u6837\uff0c\u4ece\u5f00\u59cb\u4f4d\u7f6e\u53d6\u524d\u51e0\u4e2a\u5143\u7d20\u3002 #map:\u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u6bcf\u4e00\u4e2a\u5143\u7d20 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_map = ds . map ( lambda x : tf . strings . split ( x , \" \" )) for x in ds_map : print ( x ) tf.Tensor([b'hello' b'world'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'China'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'Beijing'], shape=(2,), dtype=string) #flat_map:\u5c06\u8f6c\u6362\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u96c6\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u5e76\u5c06\u5d4c\u5957\u7684Dataset\u538b\u5e73\u3002 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_flatmap = ds . flat_map ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_flatmap : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) # interleave: \u6548\u679c\u7c7b\u4f3cflat_map,\u4f46\u53ef\u4ee5\u5c06\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_interleave = ds . interleave ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_interleave : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) #filter:\u8fc7\u6ee4\u6389\u67d0\u4e9b\u5143\u7d20\u3002 ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) #\u627e\u51fa\u542b\u6709\u5b57\u6bcda\u6216B\u7684\u5143\u7d20 ds_filter = ds . filter ( lambda x : tf . strings . regex_full_match ( x , \".*[a|B].*\" )) for x in ds_filter : print ( x ) tf.Tensor(b'hello China', shape=(), dtype=string) tf.Tensor(b'hello Beijing', shape=(), dtype=string) #zip:\u5c06\u4e24\u4e2a\u957f\u5ea6\u76f8\u540c\u7684Dataset\u6a2a\u5411\u94f0\u5408\u3002 ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds3 = tf . data . Dataset . range ( 6 , 9 ) ds_zip = tf . data . Dataset . zip (( ds1 , ds2 , ds3 )) for x , y , z in ds_zip : print ( x . numpy (), y . numpy (), z . numpy ()) 0 3 6 1 4 7 2 5 8 #condatenate:\u5c06\u4e24\u4e2aDataset\u7eb5\u5411\u8fde\u63a5\u3002 ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds_concat = tf . data . Dataset . concatenate ( ds1 , ds2 ) for x in ds_concat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) #reduce:\u6267\u884c\u5f52\u5e76\u64cd\u4f5c\u3002 ds = tf . data . Dataset . from_tensor_slices ([ 1 , 2 , 3 , 4 , 5.0 ]) result = ds . reduce ( 0.0 , lambda x , y : tf . add ( x , y )) result <tf.Tensor: shape=(), dtype=float32, numpy=15.0> #batch:\u6784\u5efa\u6279\u6b21\uff0c\u6bcf\u6b21\u653e\u4e00\u4e2a\u6279\u6b21\u3002\u6bd4\u539f\u59cb\u6570\u636e\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\u3002 \u5176\u9006\u64cd\u4f5c\u4e3aunbatch\u3002 ds = tf . data . Dataset . range ( 12 ) ds_batch = ds . batch ( 4 ) for x in ds_batch : print ( x ) tf.Tensor([0 1 2 3], shape=(4,), dtype=int64) tf.Tensor([4 5 6 7], shape=(4,), dtype=int64) tf.Tensor([ 8 9 10 11], shape=(4,), dtype=int64) #padded_batch:\u6784\u5efa\u6279\u6b21\uff0c\u7c7b\u4f3cbatch, \u4f46\u53ef\u4ee5\u586b\u5145\u5230\u76f8\u540c\u7684\u5f62\u72b6\u3002 elements = [[ 1 , 2 ],[ 3 , 4 , 5 ],[ 6 , 7 ],[ 8 ]] ds = tf . data . Dataset . from_generator ( lambda : iter ( elements ), tf . int32 ) ds_padded_batch = ds . padded_batch ( 2 , padded_shapes = [ 4 ,]) for x in ds_padded_batch : print ( x ) tf.Tensor( [[1 2 0 0] [3 4 5 0]], shape=(2, 4), dtype=int32) tf.Tensor( [[6 7 0 0] [8 0 0 0]], shape=(2, 4), dtype=int32) #window:\u6784\u5efa\u6ed1\u52a8\u7a97\u53e3\uff0c\u8fd4\u56deDataset of Dataset. ds = tf . data . Dataset . range ( 12 ) #window\u8fd4\u56de\u7684\u662fDataset of Dataset,\u53ef\u4ee5\u7528flat_map\u538b\u5e73 ds_window = ds . window ( 3 , shift = 1 ) . flat_map ( lambda x : x . batch ( 3 , drop_remainder = True )) for x in ds_window : print ( x ) tf.Tensor([0 1 2], shape=(3,), dtype=int64) tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([2 3 4], shape=(3,), dtype=int64) tf.Tensor([3 4 5], shape=(3,), dtype=int64) tf.Tensor([4 5 6], shape=(3,), dtype=int64) tf.Tensor([5 6 7], shape=(3,), dtype=int64) tf.Tensor([6 7 8], shape=(3,), dtype=int64) tf.Tensor([7 8 9], shape=(3,), dtype=int64) tf.Tensor([ 8 9 10], shape=(3,), dtype=int64) tf.Tensor([ 9 10 11], shape=(3,), dtype=int64) #shuffle:\u6570\u636e\u987a\u5e8f\u6d17\u724c\u3002 ds = tf . data . Dataset . range ( 12 ) ds_shuffle = ds . shuffle ( buffer_size = 5 ) for x in ds_shuffle : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(6, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(11, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(9, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) tf.Tensor(8, shape=(), dtype=int64) #repeat:\u91cd\u590d\u6570\u636e\u82e5\u5e72\u6b21\uff0c\u4e0d\u5e26\u53c2\u6570\u65f6\uff0c\u91cd\u590d\u65e0\u6570\u6b21\u3002 ds = tf . data . Dataset . range ( 3 ) ds_repeat = ds . repeat ( 3 ) for x in ds_repeat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) #shard:\u91c7\u6837\uff0c\u4ece\u67d0\u4e2a\u4f4d\u7f6e\u5f00\u59cb\u9694\u56fa\u5b9a\u8ddd\u79bb\u91c7\u6837\u4e00\u4e2a\u5143\u7d20\u3002 ds = tf . data . Dataset . range ( 12 ) ds_shard = ds . shard ( 3 , index = 1 ) for x in ds_shard : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) #take:\u91c7\u6837\uff0c\u4ece\u5f00\u59cb\u4f4d\u7f6e\u53d6\u524d\u51e0\u4e2a\u5143\u7d20\u3002 ds = tf . data . Dataset . range ( 12 ) ds_take = ds . take ( 3 ) list ( ds_take . as_numpy_iterator ()) [0, 1, 2]","title":"\u4e8c\uff0c\u5e94\u7528\u6570\u636e\u8f6c\u6362"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-1%2C%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93Dataset/#\u4e09\u63d0\u5347\u7ba1\u9053\u6027\u80fd","text":"\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e38\u5e38\u4f1a\u975e\u5e38\u8017\u65f6\u3002 \u6a21\u578b\u8bad\u7ec3\u7684\u8017\u65f6\u4e3b\u8981\u6765\u81ea\u4e8e\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u6765\u81ea**\u6570\u636e\u51c6\u5907**\uff0c\u53e6\u4e00\u90e8\u5206\u6765\u81ea**\u53c2\u6570\u8fed\u4ee3**\u3002 \u53c2\u6570\u8fed\u4ee3\u8fc7\u7a0b\u7684\u8017\u65f6\u901a\u5e38\u4f9d\u8d56\u4e8eGPU\u6765\u63d0\u5347\u3002 \u800c\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u7684\u8017\u65f6\u5219\u53ef\u4ee5\u901a\u8fc7\u6784\u5efa\u9ad8\u6548\u7684\u6570\u636e\u7ba1\u9053\u8fdb\u884c\u63d0\u5347\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e9b\u6784\u5efa\u9ad8\u6548\u6570\u636e\u7ba1\u9053\u7684\u5efa\u8bae\u3002 1\uff0c\u4f7f\u7528 prefetch \u65b9\u6cd5\u8ba9\u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u76f8\u4e92\u5e76\u884c\u3002 2\uff0c\u4f7f\u7528 interleave \u65b9\u6cd5\u53ef\u4ee5\u8ba9\u6570\u636e\u8bfb\u53d6\u8fc7\u7a0b\u591a\u8fdb\u7a0b\u6267\u884c,\u5e76\u5c06\u4e0d\u540c\u6765\u6e90\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 3\uff0c\u4f7f\u7528 map \u65f6\u8bbe\u7f6enum_parallel_calls \u8ba9\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u591a\u8fdb\u7a0b\u6267\u884c\u3002 4\uff0c\u4f7f\u7528 cache \u65b9\u6cd5\u8ba9\u6570\u636e\u5728\u7b2c\u4e00\u4e2aepoch\u540e\u7f13\u5b58\u5230\u5185\u5b58\u4e2d\uff0c\u4ec5\u9650\u4e8e\u6570\u636e\u96c6\u4e0d\u5927\u60c5\u5f62\u3002 5\uff0c\u4f7f\u7528 map\u8f6c\u6362\u65f6\uff0c\u5148batch, \u7136\u540e\u91c7\u7528\u5411\u91cf\u5316\u7684\u8f6c\u6362\u65b9\u6cd5\u5bf9\u6bcf\u4e2abatch\u8fdb\u884c\u8f6c\u6362\u3002 1\uff0c\u4f7f\u7528 prefetch \u65b9\u6cd5\u8ba9\u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u76f8\u4e92\u5e76\u884c\u3002 import tensorflow as tf #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) import time # \u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u662f\u4e32\u884c\u7684\u3002 # \u6a21\u62df\u6570\u636e\u51c6\u5907 def generator (): for i in range ( 10 ): #\u5047\u8bbe\u6bcf\u6b21\u51c6\u5907\u6570\u636e\u9700\u89812s time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # \u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): #\u5047\u8bbe\u6bcf\u4e00\u6b65\u8bad\u7ec3\u9700\u89811s time . sleep ( 1 ) # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 10*2+10*1 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for x in ds : train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) # \u4f7f\u7528 prefetch \u65b9\u6cd5\u8ba9\u6570\u636e\u51c6\u5907\u548c\u53c2\u6570\u8fed\u4ee3\u4e24\u4e2a\u8fc7\u7a0b\u76f8\u4e92\u5e76\u884c\u3002 # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 max(10*2,10*1) = 20s printbar () tf . print ( tf . constant ( \"start training with prefetch...\" )) # tf.data.experimental.AUTOTUNE \u53ef\u4ee5\u8ba9\u7a0b\u5e8f\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u53c2\u6570 for x in ds . prefetch ( buffer_size = tf . data . experimental . AUTOTUNE ): train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) 2\uff0c\u4f7f\u7528 interleave \u65b9\u6cd5\u53ef\u4ee5\u8ba9\u6570\u636e\u8bfb\u53d6\u8fc7\u7a0b\u591a\u8fdb\u7a0b\u6267\u884c,\u5e76\u5c06\u4e0d\u540c\u6765\u6e90\u6570\u636e\u5939\u5728\u4e00\u8d77\u3002 ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . flat_map ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 4 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . interleave ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 8 ): print ( line ) tf.Tensor(b'181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S', shape=(), dtype=string) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'405,0,3,\"Oreskovic, Miss. Marija\",female,20.0,0,0,315096,8.6625,,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'635,0,3,\"Skoog, Miss. Mabel\",female,9.0,3,2,347088,27.9,,S', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18.0,1,0,PC 17757,227.525,C62 C64,C', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) 3\uff0c\u4f7f\u7528 map \u65f6\u8bbe\u7f6enum_parallel_calls \u8ba9\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u591a\u8fdb\u884c\u6267\u884c\u3002 ds = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #\u6ce8\u610f\u6b64\u5904\u4e3ajpeg\u683c\u5f0f img = tf . image . resize ( img , size ) return ( img , label ) #\u5355\u8fdb\u7a0b\u8f6c\u6362 printbar () tf . print ( tf . constant ( \"start transformation...\" )) ds_map = ds . map ( load_image ) for _ in ds_map : pass printbar () tf . print ( tf . constant ( \"end transformation...\" )) #\u591a\u8fdb\u7a0b\u8f6c\u6362 printbar () tf . print ( tf . constant ( \"start parallel transformation...\" )) ds_map_parallel = ds . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) for _ in ds_map_parallel : pass printbar () tf . print ( tf . constant ( \"end parallel transformation...\" )) 4\uff0c\u4f7f\u7528 cache \u65b9\u6cd5\u8ba9\u6570\u636e\u5728\u7b2c\u4e00\u4e2aepoch\u540e\u7f13\u5b58\u5230\u5185\u5b58\u4e2d\uff0c\u4ec5\u9650\u4e8e\u6570\u636e\u96c6\u4e0d\u5927\u60c5\u5f62\u3002 import time # \u6a21\u62df\u6570\u636e\u51c6\u5907 def generator (): for i in range ( 5 ): #\u5047\u8bbe\u6bcf\u6b21\u51c6\u5907\u6570\u636e\u9700\u89812s time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # \u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): #\u5047\u8bbe\u6bcf\u4e00\u6b65\u8bad\u7ec3\u9700\u89810s pass # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 (5*2+5*0)*3 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) import time # \u6a21\u62df\u6570\u636e\u51c6\u5907 def generator (): for i in range ( 5 ): #\u5047\u8bbe\u6bcf\u6b21\u51c6\u5907\u6570\u636e\u9700\u89812s time . sleep ( 2 ) yield i # \u4f7f\u7528 cache \u65b9\u6cd5\u8ba9\u6570\u636e\u5728\u7b2c\u4e00\u4e2aepoch\u540e\u7f13\u5b58\u5230\u5185\u5b58\u4e2d\uff0c\u4ec5\u9650\u4e8e\u6570\u636e\u96c6\u4e0d\u5927\u60c5\u5f62\u3002 ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) . cache () # \u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): #\u5047\u8bbe\u6bcf\u4e00\u6b65\u8bad\u7ec3\u9700\u89810s time . sleep ( 0 ) # \u8bad\u7ec3\u8fc7\u7a0b\u9884\u8ba1\u8017\u65f6 (5*2+5*0)+(5*0+5*0)*2 = 10s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) 5\uff0c\u4f7f\u7528 map\u8f6c\u6362\u65f6\uff0c\u5148batch, \u7136\u540e\u91c7\u7528\u5411\u91cf\u5316\u7684\u8f6c\u6362\u65b9\u6cd5\u5bf9\u6bcf\u4e2abatch\u8fdb\u884c\u8f6c\u6362\u3002 #\u5148map\u540ebatch ds = tf . data . Dataset . range ( 100000 ) ds_map_batch = ds . map ( lambda x : x ** 2 ) . batch ( 20 ) printbar () tf . print ( tf . constant ( \"start scalar transformation...\" )) for x in ds_map_batch : pass printbar () tf . print ( tf . constant ( \"end scalar transformation...\" )) #\u5148batch\u540emap ds = tf . data . Dataset . range ( 100000 ) ds_batch_map = ds . batch ( 20 ) . map ( lambda x : x ** 2 ) printbar () tf . print ( tf . constant ( \"start vector transformation...\" )) for x in ds_batch_map : pass printbar () tf . print ( tf . constant ( \"end vector transformation...\" )) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u63d0\u5347\u7ba1\u9053\u6027\u80fd"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-2%2C%E7%89%B9%E5%BE%81%E5%88%97feature_column/","text":"5-2,\u7279\u5f81\u5217feature_column # \u7279\u5f81\u5217 \u901a\u5e38\u7528\u4e8e\u5bf9\u7ed3\u6784\u5316\u6570\u636e\u5b9e\u65bd\u7279\u5f81\u5de5\u7a0b\u65f6\u5019\u4f7f\u7528\uff0c\u56fe\u50cf\u6216\u8005\u6587\u672c\u6570\u636e\u4e00\u822c\u4e0d\u4f1a\u7528\u5230\u7279\u5f81\u5217\u3002 \u4e00\uff0c\u7279\u5f81\u5217\u7528\u6cd5\u6982\u8ff0 # \u4f7f\u7528\u7279\u5f81\u5217\u53ef\u4ee5\u5c06\u7c7b\u522b\u7279\u5f81\u8f6c\u6362\u4e3aone-hot\u7f16\u7801\u7279\u5f81\uff0c\u5c06\u8fde\u7eed\u7279\u5f81\u6784\u5efa\u5206\u6876\u7279\u5f81\uff0c\u4ee5\u53ca\u5bf9\u591a\u4e2a\u7279\u5f81\u751f\u6210\u4ea4\u53c9\u7279\u5f81\u7b49\u7b49\u3002 \u8981\u521b\u5efa\u7279\u5f81\u5217\uff0c\u8bf7\u8c03\u7528 tf.feature_column \u6a21\u5757\u7684\u51fd\u6570\u3002\u8be5\u6a21\u5757\u4e2d\u5e38\u7528\u7684\u4e5d\u4e2a\u51fd\u6570\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6240\u6709\u4e5d\u4e2a\u51fd\u6570\u90fd\u4f1a\u8fd4\u56de\u4e00\u4e2a Categorical-Column \u6216\u4e00\u4e2a Dense-Column \u5bf9\u8c61\uff0c\u4f46\u5374\u4e0d\u4f1a\u8fd4\u56de bucketized_column\uff0c\u540e\u8005\u7ee7\u627f\u81ea\u8fd9\u4e24\u4e2a\u7c7b\u3002 \u6ce8\u610f\uff1a\u6240\u6709\u7684Catogorical Column\u7c7b\u578b\u6700\u7ec8\u90fd\u8981\u901a\u8fc7indicator_column\u8f6c\u6362\u6210Dense Column\u7c7b\u578b\u624d\u80fd\u4f20\u5165\u6a21\u578b\uff01 numeric_column \u6570\u503c\u5217\uff0c\u6700\u5e38\u7528\u3002 bucketized_column \u5206\u6876\u5217\uff0c\u7531\u6570\u503c\u5217\u751f\u6210\uff0c\u53ef\u4ee5\u7531\u4e00\u4e2a\u6570\u503c\u5217\u51fa\u591a\u4e2a\u7279\u5f81\uff0cone-hot\u7f16\u7801\u3002 categorical_column_with_identity \u5206\u7c7b\u6807\u8bc6\u5217\uff0cone-hot\u7f16\u7801\uff0c\u76f8\u5f53\u4e8e\u5206\u6876\u5217\u6bcf\u4e2a\u6876\u4e3a1\u4e2a\u6574\u6570\u7684\u60c5\u51b5\u3002 categorical_column_with_vocabulary_list \u5206\u7c7b\u8bcd\u6c47\u5217\uff0cone-hot\u7f16\u7801\uff0c\u7531list\u6307\u5b9a\u8bcd\u5178\u3002 categorical_column_with_vocabulary_file \u5206\u7c7b\u8bcd\u6c47\u5217\uff0c\u7531\u6587\u4ef6file\u6307\u5b9a\u8bcd\u5178\u3002 categorical_column_with_hash_bucket \u54c8\u5e0c\u5217\uff0c\u6574\u6570\u6216\u8bcd\u5178\u8f83\u5927\u65f6\u91c7\u7528\u3002 indicator_column \u6307\u6807\u5217\uff0c\u7531Categorical Column\u751f\u6210\uff0cone-hot\u7f16\u7801 embedding_column \u5d4c\u5165\u5217\uff0c\u7531Categorical Column\u751f\u6210\uff0c\u5d4c\u5165\u77e2\u91cf\u5206\u5e03\u53c2\u6570\u9700\u8981\u5b66\u4e60\u3002\u5d4c\u5165\u77e2\u91cf\u7ef4\u6570\u5efa\u8bae\u53d6\u7c7b\u522b\u6570\u91cf\u7684 4 \u6b21\u65b9\u6839\u3002 crossed_column \u4ea4\u53c9\u5217\uff0c\u53ef\u4ee5\u7531\u9664categorical_column_with_hash_bucket\u7684\u4efb\u610f\u5206\u7c7b\u5217\u6784\u6210\u3002 \u4e8c\uff0c\u7279\u5f81\u5217\u4f7f\u7528\u8303\u4f8b # \u4ee5\u4e0b\u662f\u4e00\u4e2a\u4f7f\u7528\u7279\u5f81\u5217\u89e3\u51b3Titanic\u751f\u5b58\u95ee\u9898\u7684\u5b8c\u6574\u8303\u4f8b\u3002 import datetime import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , models #\u6253\u5370\u65e5\u5fd7 def printlog ( info ): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( info + '... \\n\\n ' ) #================================================================================ # \u4e00\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053 #================================================================================ printlog ( \"step1: prepare dataset...\" ) dftrain_raw = pd . read_csv ( \"../../data/titanic/train.csv\" ) dftest_raw = pd . read_csv ( \"../../data/titanic/test.csv\" ) dfraw = pd . concat ([ dftrain_raw , dftest_raw ]) def prepare_dfdata ( dfraw ): dfdata = dfraw . copy () dfdata . columns = [ x . lower () for x in dfdata . columns ] dfdata = dfdata . rename ( columns = { 'survived' : 'label' }) dfdata = dfdata . drop ([ 'passengerid' , 'name' ], axis = 1 ) for col , dtype in dict ( dfdata . dtypes ) . items (): # \u5224\u65ad\u662f\u5426\u5305\u542b\u7f3a\u5931\u503c if dfdata [ col ] . hasnans : # \u6dfb\u52a0\u6807\u8bc6\u662f\u5426\u7f3a\u5931\u5217 dfdata [ col + '_nan' ] = pd . isna ( dfdata [ col ]) . astype ( 'int32' ) # \u586b\u5145 if dtype not in [ np . object , np . str , np . unicode ]: dfdata [ col ] . fillna ( dfdata [ col ] . mean (), inplace = True ) else : dfdata [ col ] . fillna ( '' , inplace = True ) return ( dfdata ) dfdata = prepare_dfdata ( dfraw ) dftrain = dfdata . iloc [ 0 : len ( dftrain_raw ),:] dftest = dfdata . iloc [ len ( dftrain_raw ):,:] # \u4ece dataframe \u5bfc\u5165\u6570\u636e def df_to_dataset ( df , shuffle = True , batch_size = 32 ): dfdata = df . copy () if 'label' not in dfdata . columns : ds = tf . data . Dataset . from_tensor_slices ( dfdata . to_dict ( orient = 'list' )) else : labels = dfdata . pop ( 'label' ) ds = tf . data . Dataset . from_tensor_slices (( dfdata . to_dict ( orient = 'list' ), labels )) if shuffle : ds = ds . shuffle ( buffer_size = len ( dfdata )) ds = ds . batch ( batch_size ) return ds ds_train = df_to_dataset ( dftrain ) ds_test = df_to_dataset ( dftest ) #================================================================================ # \u4e8c\uff0c\u5b9a\u4e49\u7279\u5f81\u5217 #================================================================================ printlog ( \"step2: make feature columns...\" ) feature_columns = [] # \u6570\u503c\u5217 for col in [ 'age' , 'fare' , 'parch' , 'sibsp' ] + [ c for c in dfdata . columns if c . endswith ( '_nan' )]: feature_columns . append ( tf . feature_column . numeric_column ( col )) # \u5206\u6876\u5217 age = tf . feature_column . numeric_column ( 'age' ) age_buckets = tf . feature_column . bucketized_column ( age , boundaries = [ 18 , 25 , 30 , 35 , 40 , 45 , 50 , 55 , 60 , 65 ]) feature_columns . append ( age_buckets ) # \u7c7b\u522b\u5217 # \u6ce8\u610f\uff1a\u6240\u6709\u7684Catogorical Column\u7c7b\u578b\u6700\u7ec8\u90fd\u8981\u901a\u8fc7indicator_column\u8f6c\u6362\u6210Dense Column\u7c7b\u578b\u624d\u80fd\u4f20\u5165\u6a21\u578b\uff01\uff01 sex = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'sex' , vocabulary_list = [ \"male\" , \"female\" ])) feature_columns . append ( sex ) pclass = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ])) feature_columns . append ( pclass ) ticket = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'ticket' , 3 )) feature_columns . append ( ticket ) embarked = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'embarked' , vocabulary_list = [ 'S' , 'C' , 'B' ])) feature_columns . append ( embarked ) # \u5d4c\u5165\u5217 cabin = tf . feature_column . embedding_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'cabin' , 32 ), 2 ) feature_columns . append ( cabin ) # \u4ea4\u53c9\u5217 pclass_cate = tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ]) crossed_feature = tf . feature_column . indicator_column ( tf . feature_column . crossed_column ([ age_buckets , pclass_cate ], hash_bucket_size = 15 )) feature_columns . append ( crossed_feature ) #================================================================================ # \u4e09\uff0c\u5b9a\u4e49\u6a21\u578b #================================================================================ printlog ( \"step3: define model...\" ) tf . keras . backend . clear_session () model = tf . keras . Sequential ([ layers . DenseFeatures ( feature_columns ), #\u5c06\u7279\u5f81\u5217\u653e\u5165\u5230tf.keras.layers.DenseFeatures\u4e2d!!! layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 1 , activation = 'sigmoid' ) ]) #================================================================================ # \u56db\uff0c\u8bad\u7ec3\u6a21\u578b #================================================================================ printlog ( \"step4: train model...\" ) model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' ]) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) #================================================================================ # \u4e94\uff0c\u8bc4\u4f30\u6a21\u578b #================================================================================ printlog ( \"step5: eval model...\" ) model . summary () % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"accuracy\" ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_features (DenseFeature multiple 64 _________________________________________________________________ dense (Dense) multiple 3008 _________________________________________________________________ dense_1 (Dense) multiple 4160 _________________________________________________________________ dense_2 (Dense) multiple 65 ================================================================= Total params: 7,297 Trainable params: 7,297 Non-trainable params: 0 _________________________________________________________________ \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-2,\u7279\u5f81\u5217feature_column"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-2%2C%E7%89%B9%E5%BE%81%E5%88%97feature_column/#5-2\u7279\u5f81\u5217feature_column","text":"\u7279\u5f81\u5217 \u901a\u5e38\u7528\u4e8e\u5bf9\u7ed3\u6784\u5316\u6570\u636e\u5b9e\u65bd\u7279\u5f81\u5de5\u7a0b\u65f6\u5019\u4f7f\u7528\uff0c\u56fe\u50cf\u6216\u8005\u6587\u672c\u6570\u636e\u4e00\u822c\u4e0d\u4f1a\u7528\u5230\u7279\u5f81\u5217\u3002","title":"5-2,\u7279\u5f81\u5217feature_column"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-2%2C%E7%89%B9%E5%BE%81%E5%88%97feature_column/#\u4e00\u7279\u5f81\u5217\u7528\u6cd5\u6982\u8ff0","text":"\u4f7f\u7528\u7279\u5f81\u5217\u53ef\u4ee5\u5c06\u7c7b\u522b\u7279\u5f81\u8f6c\u6362\u4e3aone-hot\u7f16\u7801\u7279\u5f81\uff0c\u5c06\u8fde\u7eed\u7279\u5f81\u6784\u5efa\u5206\u6876\u7279\u5f81\uff0c\u4ee5\u53ca\u5bf9\u591a\u4e2a\u7279\u5f81\u751f\u6210\u4ea4\u53c9\u7279\u5f81\u7b49\u7b49\u3002 \u8981\u521b\u5efa\u7279\u5f81\u5217\uff0c\u8bf7\u8c03\u7528 tf.feature_column \u6a21\u5757\u7684\u51fd\u6570\u3002\u8be5\u6a21\u5757\u4e2d\u5e38\u7528\u7684\u4e5d\u4e2a\u51fd\u6570\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6240\u6709\u4e5d\u4e2a\u51fd\u6570\u90fd\u4f1a\u8fd4\u56de\u4e00\u4e2a Categorical-Column \u6216\u4e00\u4e2a Dense-Column \u5bf9\u8c61\uff0c\u4f46\u5374\u4e0d\u4f1a\u8fd4\u56de bucketized_column\uff0c\u540e\u8005\u7ee7\u627f\u81ea\u8fd9\u4e24\u4e2a\u7c7b\u3002 \u6ce8\u610f\uff1a\u6240\u6709\u7684Catogorical Column\u7c7b\u578b\u6700\u7ec8\u90fd\u8981\u901a\u8fc7indicator_column\u8f6c\u6362\u6210Dense Column\u7c7b\u578b\u624d\u80fd\u4f20\u5165\u6a21\u578b\uff01 numeric_column \u6570\u503c\u5217\uff0c\u6700\u5e38\u7528\u3002 bucketized_column \u5206\u6876\u5217\uff0c\u7531\u6570\u503c\u5217\u751f\u6210\uff0c\u53ef\u4ee5\u7531\u4e00\u4e2a\u6570\u503c\u5217\u51fa\u591a\u4e2a\u7279\u5f81\uff0cone-hot\u7f16\u7801\u3002 categorical_column_with_identity \u5206\u7c7b\u6807\u8bc6\u5217\uff0cone-hot\u7f16\u7801\uff0c\u76f8\u5f53\u4e8e\u5206\u6876\u5217\u6bcf\u4e2a\u6876\u4e3a1\u4e2a\u6574\u6570\u7684\u60c5\u51b5\u3002 categorical_column_with_vocabulary_list \u5206\u7c7b\u8bcd\u6c47\u5217\uff0cone-hot\u7f16\u7801\uff0c\u7531list\u6307\u5b9a\u8bcd\u5178\u3002 categorical_column_with_vocabulary_file \u5206\u7c7b\u8bcd\u6c47\u5217\uff0c\u7531\u6587\u4ef6file\u6307\u5b9a\u8bcd\u5178\u3002 categorical_column_with_hash_bucket \u54c8\u5e0c\u5217\uff0c\u6574\u6570\u6216\u8bcd\u5178\u8f83\u5927\u65f6\u91c7\u7528\u3002 indicator_column \u6307\u6807\u5217\uff0c\u7531Categorical Column\u751f\u6210\uff0cone-hot\u7f16\u7801 embedding_column \u5d4c\u5165\u5217\uff0c\u7531Categorical Column\u751f\u6210\uff0c\u5d4c\u5165\u77e2\u91cf\u5206\u5e03\u53c2\u6570\u9700\u8981\u5b66\u4e60\u3002\u5d4c\u5165\u77e2\u91cf\u7ef4\u6570\u5efa\u8bae\u53d6\u7c7b\u522b\u6570\u91cf\u7684 4 \u6b21\u65b9\u6839\u3002 crossed_column \u4ea4\u53c9\u5217\uff0c\u53ef\u4ee5\u7531\u9664categorical_column_with_hash_bucket\u7684\u4efb\u610f\u5206\u7c7b\u5217\u6784\u6210\u3002","title":"\u4e00\uff0c\u7279\u5f81\u5217\u7528\u6cd5\u6982\u8ff0"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-2%2C%E7%89%B9%E5%BE%81%E5%88%97feature_column/#\u4e8c\u7279\u5f81\u5217\u4f7f\u7528\u8303\u4f8b","text":"\u4ee5\u4e0b\u662f\u4e00\u4e2a\u4f7f\u7528\u7279\u5f81\u5217\u89e3\u51b3Titanic\u751f\u5b58\u95ee\u9898\u7684\u5b8c\u6574\u8303\u4f8b\u3002 import datetime import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , models #\u6253\u5370\u65e5\u5fd7 def printlog ( info ): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( info + '... \\n\\n ' ) #================================================================================ # \u4e00\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053 #================================================================================ printlog ( \"step1: prepare dataset...\" ) dftrain_raw = pd . read_csv ( \"../../data/titanic/train.csv\" ) dftest_raw = pd . read_csv ( \"../../data/titanic/test.csv\" ) dfraw = pd . concat ([ dftrain_raw , dftest_raw ]) def prepare_dfdata ( dfraw ): dfdata = dfraw . copy () dfdata . columns = [ x . lower () for x in dfdata . columns ] dfdata = dfdata . rename ( columns = { 'survived' : 'label' }) dfdata = dfdata . drop ([ 'passengerid' , 'name' ], axis = 1 ) for col , dtype in dict ( dfdata . dtypes ) . items (): # \u5224\u65ad\u662f\u5426\u5305\u542b\u7f3a\u5931\u503c if dfdata [ col ] . hasnans : # \u6dfb\u52a0\u6807\u8bc6\u662f\u5426\u7f3a\u5931\u5217 dfdata [ col + '_nan' ] = pd . isna ( dfdata [ col ]) . astype ( 'int32' ) # \u586b\u5145 if dtype not in [ np . object , np . str , np . unicode ]: dfdata [ col ] . fillna ( dfdata [ col ] . mean (), inplace = True ) else : dfdata [ col ] . fillna ( '' , inplace = True ) return ( dfdata ) dfdata = prepare_dfdata ( dfraw ) dftrain = dfdata . iloc [ 0 : len ( dftrain_raw ),:] dftest = dfdata . iloc [ len ( dftrain_raw ):,:] # \u4ece dataframe \u5bfc\u5165\u6570\u636e def df_to_dataset ( df , shuffle = True , batch_size = 32 ): dfdata = df . copy () if 'label' not in dfdata . columns : ds = tf . data . Dataset . from_tensor_slices ( dfdata . to_dict ( orient = 'list' )) else : labels = dfdata . pop ( 'label' ) ds = tf . data . Dataset . from_tensor_slices (( dfdata . to_dict ( orient = 'list' ), labels )) if shuffle : ds = ds . shuffle ( buffer_size = len ( dfdata )) ds = ds . batch ( batch_size ) return ds ds_train = df_to_dataset ( dftrain ) ds_test = df_to_dataset ( dftest ) #================================================================================ # \u4e8c\uff0c\u5b9a\u4e49\u7279\u5f81\u5217 #================================================================================ printlog ( \"step2: make feature columns...\" ) feature_columns = [] # \u6570\u503c\u5217 for col in [ 'age' , 'fare' , 'parch' , 'sibsp' ] + [ c for c in dfdata . columns if c . endswith ( '_nan' )]: feature_columns . append ( tf . feature_column . numeric_column ( col )) # \u5206\u6876\u5217 age = tf . feature_column . numeric_column ( 'age' ) age_buckets = tf . feature_column . bucketized_column ( age , boundaries = [ 18 , 25 , 30 , 35 , 40 , 45 , 50 , 55 , 60 , 65 ]) feature_columns . append ( age_buckets ) # \u7c7b\u522b\u5217 # \u6ce8\u610f\uff1a\u6240\u6709\u7684Catogorical Column\u7c7b\u578b\u6700\u7ec8\u90fd\u8981\u901a\u8fc7indicator_column\u8f6c\u6362\u6210Dense Column\u7c7b\u578b\u624d\u80fd\u4f20\u5165\u6a21\u578b\uff01\uff01 sex = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'sex' , vocabulary_list = [ \"male\" , \"female\" ])) feature_columns . append ( sex ) pclass = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ])) feature_columns . append ( pclass ) ticket = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'ticket' , 3 )) feature_columns . append ( ticket ) embarked = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'embarked' , vocabulary_list = [ 'S' , 'C' , 'B' ])) feature_columns . append ( embarked ) # \u5d4c\u5165\u5217 cabin = tf . feature_column . embedding_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'cabin' , 32 ), 2 ) feature_columns . append ( cabin ) # \u4ea4\u53c9\u5217 pclass_cate = tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ]) crossed_feature = tf . feature_column . indicator_column ( tf . feature_column . crossed_column ([ age_buckets , pclass_cate ], hash_bucket_size = 15 )) feature_columns . append ( crossed_feature ) #================================================================================ # \u4e09\uff0c\u5b9a\u4e49\u6a21\u578b #================================================================================ printlog ( \"step3: define model...\" ) tf . keras . backend . clear_session () model = tf . keras . Sequential ([ layers . DenseFeatures ( feature_columns ), #\u5c06\u7279\u5f81\u5217\u653e\u5165\u5230tf.keras.layers.DenseFeatures\u4e2d!!! layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 1 , activation = 'sigmoid' ) ]) #================================================================================ # \u56db\uff0c\u8bad\u7ec3\u6a21\u578b #================================================================================ printlog ( \"step4: train model...\" ) model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' ]) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) #================================================================================ # \u4e94\uff0c\u8bc4\u4f30\u6a21\u578b #================================================================================ printlog ( \"step5: eval model...\" ) model . summary () % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"accuracy\" ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_features (DenseFeature multiple 64 _________________________________________________________________ dense (Dense) multiple 3008 _________________________________________________________________ dense_1 (Dense) multiple 4160 _________________________________________________________________ dense_2 (Dense) multiple 65 ================================================================= Total params: 7,297 Trainable params: 7,297 Non-trainable params: 0 _________________________________________________________________ \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u7279\u5f81\u5217\u4f7f\u7528\u8303\u4f8b"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0activation/","text":"5-3,\u6fc0\u6d3b\u51fd\u6570activation # \u6fc0\u6d3b\u51fd\u6570\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u626e\u6f14\u7740\u975e\u5e38\u91cd\u8981\u7684\u89d2\u8272\uff0c\u5b83\u7ed9\u7f51\u7edc\u8d4b\u4e88\u4e86\u975e\u7ebf\u6027\uff0c\u4ece\u800c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u62df\u5408\u4efb\u610f\u590d\u6742\u7684\u51fd\u6570\u3002 \u5982\u679c\u6ca1\u6709\u6fc0\u6d3b\u51fd\u6570\uff0c\u65e0\u8bba\u591a\u590d\u6742\u7684\u7f51\u7edc\uff0c\u90fd\u7b49\u4ef7\u4e8e\u5355\u4e00\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u65e0\u6cd5\u5bf9\u975e\u7ebf\u6027\u51fd\u6570\u8fdb\u884c\u62df\u5408\u3002 \u76ee\u524d\uff0c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6700\u6d41\u884c\u7684\u6fc0\u6d3b\u51fd\u6570\u4e3a relu, \u4f46\u4e5f\u6709\u4e9b\u65b0\u63a8\u51fa\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f8b\u5982 swish\u3001GELU \u636e\u79f0\u6548\u679c\u4f18\u4e8erelu\u6fc0\u6d3b\u51fd\u6570\u3002 \u6fc0\u6d3b\u51fd\u6570\u7684\u7efc\u8ff0\u4ecb\u7ecd\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u4e24\u7bc7\u6587\u7ae0\u3002 \u300a\u4e00\u6587\u6982\u89c8\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b https://zhuanlan.zhihu.com/p/98472075 \u300a\u4eceReLU\u5230GELU,\u4e00\u6587\u6982\u89c8\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b https://zhuanlan.zhihu.com/p/98863801 \u4e00\uff0c\u5e38\u7528\u6fc0\u6d3b\u51fd\u6570 # tf.nn.sigmoid\uff1a\u5c06\u5b9e\u6570\u538b\u7f29\u52300\u52301\u4e4b\u95f4\uff0c\u4e00\u822c\u53ea\u5728\u4e8c\u5206\u7c7b\u7684\u6700\u540e\u8f93\u51fa\u5c42\u4f7f\u7528\u3002\u4e3b\u8981\u7f3a\u9677\u4e3a\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u8f93\u51fa\u4e0d\u4ee50\u4e3a\u4e2d\u5fc3\u3002 tf.nn.softmax\uff1asigmoid\u7684\u591a\u5206\u7c7b\u6269\u5c55\uff0c\u4e00\u822c\u53ea\u5728\u591a\u5206\u7c7b\u95ee\u9898\u7684\u6700\u540e\u8f93\u51fa\u5c42\u4f7f\u7528\u3002 tf.nn.tanh\uff1a\u5c06\u5b9e\u6570\u538b\u7f29\u5230-1\u52301\u4e4b\u95f4\uff0c\u8f93\u51fa\u671f\u671b\u4e3a0\u3002\u4e3b\u8981\u7f3a\u9677\u4e3a\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002 tf.nn.relu\uff1a\u4fee\u6b63\u7ebf\u6027\u5355\u5143\uff0c\u6700\u6d41\u884c\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u4e00\u822c\u9690\u85cf\u5c42\u4f7f\u7528\u3002\u4e3b\u8981\u7f3a\u9677\u662f\uff1a\u8f93\u51fa\u4e0d\u4ee50\u4e3a\u4e2d\u5fc3\uff0c\u8f93\u5165\u5c0f\u4e8e0\u65f6\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898(\u6b7b\u4ea1relu)\u3002 tf.nn.leaky_relu\uff1a\u5bf9\u4fee\u6b63\u7ebf\u6027\u5355\u5143\u7684\u6539\u8fdb\uff0c\u89e3\u51b3\u4e86\u6b7b\u4ea1relu\u95ee\u9898\u3002 tf.nn.elu\uff1a\u6307\u6570\u7ebf\u6027\u5355\u5143\u3002\u5bf9relu\u7684\u6539\u8fdb\uff0c\u80fd\u591f\u7f13\u89e3\u6b7b\u4ea1relu\u95ee\u9898\u3002 tf.nn.selu\uff1a\u6269\u5c55\u578b\u6307\u6570\u7ebf\u6027\u5355\u5143\u3002\u5728\u6743\u91cd\u7528tf.keras.initializers.lecun_normal\u521d\u59cb\u5316\u524d\u63d0\u4e0b\u80fd\u591f\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u81ea\u5f52\u4e00\u5316\u3002\u4e0d\u53ef\u80fd\u51fa\u73b0\u68af\u5ea6\u7206\u70b8\u6216\u8005\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u9700\u8981\u548cDropout\u7684\u53d8\u79cdAlphaDropout\u4e00\u8d77\u4f7f\u7528\u3002 tf.nn.swish\uff1a\u81ea\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\u3002\u8c37\u6b4c\u51fa\u54c1\uff0c\u76f8\u5173\u7814\u7a76\u6307\u51fa\u7528swish\u66ff\u4ee3relu\u5c06\u83b7\u5f97\u8f7b\u5fae\u6548\u679c\u63d0\u5347\u3002 gelu\uff1a\u9ad8\u65af\u8bef\u5dee\u7ebf\u6027\u5355\u5143\u6fc0\u6d3b\u51fd\u6570\u3002\u5728Transformer\u4e2d\u8868\u73b0\u6700\u597d\u3002tf.nn\u6a21\u5757\u5c1a\u6ca1\u6709\u5b9e\u73b0\u8be5\u51fd\u6570\u3002 \u4e8c\uff0c\u5728\u6a21\u578b\u4e2d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570 # \u5728keras\u6a21\u578b\u4e2d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570\u4e00\u822c\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u4f5c\u4e3a\u67d0\u4e9b\u5c42\u7684activation\u53c2\u6570\u6307\u5b9a\uff0c\u53e6\u4e00\u79cd\u662f\u663e\u5f0f\u6dfb\u52a0layers.Activation\u6fc0\u6d3b\u5c42\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 32 , input_shape = ( None , 16 ), activation = tf . nn . relu )) #\u901a\u8fc7activation\u53c2\u6570\u6307\u5b9a model . add ( layers . Dense ( 10 )) model . add ( layers . Activation ( tf . nn . softmax )) # \u663e\u5f0f\u6dfb\u52a0layers.Activation\u6fc0\u6d3b\u5c42 model . summary () \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-3,\u6fc0\u6d3b\u51fd\u6570activation"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0activation/#5-3\u6fc0\u6d3b\u51fd\u6570activation","text":"\u6fc0\u6d3b\u51fd\u6570\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u626e\u6f14\u7740\u975e\u5e38\u91cd\u8981\u7684\u89d2\u8272\uff0c\u5b83\u7ed9\u7f51\u7edc\u8d4b\u4e88\u4e86\u975e\u7ebf\u6027\uff0c\u4ece\u800c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u62df\u5408\u4efb\u610f\u590d\u6742\u7684\u51fd\u6570\u3002 \u5982\u679c\u6ca1\u6709\u6fc0\u6d3b\u51fd\u6570\uff0c\u65e0\u8bba\u591a\u590d\u6742\u7684\u7f51\u7edc\uff0c\u90fd\u7b49\u4ef7\u4e8e\u5355\u4e00\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u65e0\u6cd5\u5bf9\u975e\u7ebf\u6027\u51fd\u6570\u8fdb\u884c\u62df\u5408\u3002 \u76ee\u524d\uff0c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6700\u6d41\u884c\u7684\u6fc0\u6d3b\u51fd\u6570\u4e3a relu, \u4f46\u4e5f\u6709\u4e9b\u65b0\u63a8\u51fa\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f8b\u5982 swish\u3001GELU \u636e\u79f0\u6548\u679c\u4f18\u4e8erelu\u6fc0\u6d3b\u51fd\u6570\u3002 \u6fc0\u6d3b\u51fd\u6570\u7684\u7efc\u8ff0\u4ecb\u7ecd\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u4e24\u7bc7\u6587\u7ae0\u3002 \u300a\u4e00\u6587\u6982\u89c8\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b https://zhuanlan.zhihu.com/p/98472075 \u300a\u4eceReLU\u5230GELU,\u4e00\u6587\u6982\u89c8\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b https://zhuanlan.zhihu.com/p/98863801","title":"5-3,\u6fc0\u6d3b\u51fd\u6570activation"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0activation/#\u4e00\u5e38\u7528\u6fc0\u6d3b\u51fd\u6570","text":"tf.nn.sigmoid\uff1a\u5c06\u5b9e\u6570\u538b\u7f29\u52300\u52301\u4e4b\u95f4\uff0c\u4e00\u822c\u53ea\u5728\u4e8c\u5206\u7c7b\u7684\u6700\u540e\u8f93\u51fa\u5c42\u4f7f\u7528\u3002\u4e3b\u8981\u7f3a\u9677\u4e3a\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u8f93\u51fa\u4e0d\u4ee50\u4e3a\u4e2d\u5fc3\u3002 tf.nn.softmax\uff1asigmoid\u7684\u591a\u5206\u7c7b\u6269\u5c55\uff0c\u4e00\u822c\u53ea\u5728\u591a\u5206\u7c7b\u95ee\u9898\u7684\u6700\u540e\u8f93\u51fa\u5c42\u4f7f\u7528\u3002 tf.nn.tanh\uff1a\u5c06\u5b9e\u6570\u538b\u7f29\u5230-1\u52301\u4e4b\u95f4\uff0c\u8f93\u51fa\u671f\u671b\u4e3a0\u3002\u4e3b\u8981\u7f3a\u9677\u4e3a\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002 tf.nn.relu\uff1a\u4fee\u6b63\u7ebf\u6027\u5355\u5143\uff0c\u6700\u6d41\u884c\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u4e00\u822c\u9690\u85cf\u5c42\u4f7f\u7528\u3002\u4e3b\u8981\u7f3a\u9677\u662f\uff1a\u8f93\u51fa\u4e0d\u4ee50\u4e3a\u4e2d\u5fc3\uff0c\u8f93\u5165\u5c0f\u4e8e0\u65f6\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898(\u6b7b\u4ea1relu)\u3002 tf.nn.leaky_relu\uff1a\u5bf9\u4fee\u6b63\u7ebf\u6027\u5355\u5143\u7684\u6539\u8fdb\uff0c\u89e3\u51b3\u4e86\u6b7b\u4ea1relu\u95ee\u9898\u3002 tf.nn.elu\uff1a\u6307\u6570\u7ebf\u6027\u5355\u5143\u3002\u5bf9relu\u7684\u6539\u8fdb\uff0c\u80fd\u591f\u7f13\u89e3\u6b7b\u4ea1relu\u95ee\u9898\u3002 tf.nn.selu\uff1a\u6269\u5c55\u578b\u6307\u6570\u7ebf\u6027\u5355\u5143\u3002\u5728\u6743\u91cd\u7528tf.keras.initializers.lecun_normal\u521d\u59cb\u5316\u524d\u63d0\u4e0b\u80fd\u591f\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u81ea\u5f52\u4e00\u5316\u3002\u4e0d\u53ef\u80fd\u51fa\u73b0\u68af\u5ea6\u7206\u70b8\u6216\u8005\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u9700\u8981\u548cDropout\u7684\u53d8\u79cdAlphaDropout\u4e00\u8d77\u4f7f\u7528\u3002 tf.nn.swish\uff1a\u81ea\u95e8\u63a7\u6fc0\u6d3b\u51fd\u6570\u3002\u8c37\u6b4c\u51fa\u54c1\uff0c\u76f8\u5173\u7814\u7a76\u6307\u51fa\u7528swish\u66ff\u4ee3relu\u5c06\u83b7\u5f97\u8f7b\u5fae\u6548\u679c\u63d0\u5347\u3002 gelu\uff1a\u9ad8\u65af\u8bef\u5dee\u7ebf\u6027\u5355\u5143\u6fc0\u6d3b\u51fd\u6570\u3002\u5728Transformer\u4e2d\u8868\u73b0\u6700\u597d\u3002tf.nn\u6a21\u5757\u5c1a\u6ca1\u6709\u5b9e\u73b0\u8be5\u51fd\u6570\u3002","title":"\u4e00\uff0c\u5e38\u7528\u6fc0\u6d3b\u51fd\u6570"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0activation/#\u4e8c\u5728\u6a21\u578b\u4e2d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570","text":"\u5728keras\u6a21\u578b\u4e2d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570\u4e00\u822c\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u4f5c\u4e3a\u67d0\u4e9b\u5c42\u7684activation\u53c2\u6570\u6307\u5b9a\uff0c\u53e6\u4e00\u79cd\u662f\u663e\u5f0f\u6dfb\u52a0layers.Activation\u6fc0\u6d3b\u5c42\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 32 , input_shape = ( None , 16 ), activation = tf . nn . relu )) #\u901a\u8fc7activation\u53c2\u6570\u6307\u5b9a model . add ( layers . Dense ( 10 )) model . add ( layers . Activation ( tf . nn . softmax )) # \u663e\u5f0f\u6dfb\u52a0layers.Activation\u6fc0\u6d3b\u5c42 model . summary () \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u5728\u6a21\u578b\u4e2d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-4%2C%E6%A8%A1%E5%9E%8B%E5%B1%82layers/","text":"5-4,\u6a21\u578b\u5c42layers # \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e00\u822c\u7531\u5404\u79cd\u6a21\u578b\u5c42\u7ec4\u5408\u800c\u6210\u3002 tf.keras.layers\u5185\u7f6e\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u5404\u79cd\u529f\u80fd\u7684\u6a21\u578b\u5c42\u3002\u4f8b\u5982\uff0c layers.Dense,layers.Flatten,layers.Input,layers.DenseFeature,layers.Dropout layers.Conv2D,layers.MaxPooling2D,layers.Conv1D layers.Embedding,layers.GRU,layers.LSTM,layers.Bidirectional\u7b49\u7b49\u3002 \u5982\u679c\u8fd9\u4e9b\u5185\u7f6e\u6a21\u578b\u5c42\u4e0d\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7f16\u5199tf.keras.Lambda\u533f\u540d\u6a21\u578b\u5c42\u6216\u7ee7\u627ftf.keras.layers.Layer\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u5c42\u3002 \u5176\u4e2dtf.keras.Lambda\u533f\u540d\u6a21\u578b\u5c42\u53ea\u9002\u7528\u4e8e\u6784\u9020\u6ca1\u6709\u5b66\u4e60\u53c2\u6570\u7684\u6a21\u578b\u5c42\u3002 \u4e00\uff0c\u5185\u7f6e\u6a21\u578b\u5c42 # \u4e00\u4e9b\u5e38\u7528\u7684\u5185\u7f6e\u6a21\u578b\u5c42\u7b80\u5355\u4ecb\u7ecd\u5982\u4e0b\u3002 \u57fa\u7840\u5c42 Dense\uff1a\u5bc6\u96c6\u8fde\u63a5\u5c42\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u5c42\u7279\u5f81\u6570\u00d7 \u8f93\u51fa\u5c42\u7279\u5f81\u6570(weight)\uff0b \u8f93\u51fa\u5c42\u7279\u5f81\u6570(bias) Activation\uff1a\u6fc0\u6d3b\u51fd\u6570\u5c42\u3002\u4e00\u822c\u653e\u5728Dense\u5c42\u540e\u9762\uff0c\u7b49\u4ef7\u4e8e\u5728Dense\u5c42\u4e2d\u6307\u5b9aactivation\u3002 Dropout\uff1a\u968f\u673a\u7f6e\u96f6\u5c42\u3002\u8bad\u7ec3\u671f\u95f4\u4ee5\u4e00\u5b9a\u51e0\u7387\u5c06\u8f93\u5165\u7f6e0\uff0c\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\u3002 BatchNormalization\uff1a\u6279\u6807\u51c6\u5316\u5c42\u3002\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5c06\u8f93\u5165\u6279\u6b21\u7f29\u653e\u5e73\u79fb\u5230\u7a33\u5b9a\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u3002\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u8f93\u5165\u4e0d\u540c\u5206\u5e03\u7684\u9002\u5e94\u6027\uff0c\u52a0\u5feb\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\uff0c\u6709\u8f7b\u5fae\u6b63\u5219\u5316\u6548\u679c\u3002\u4e00\u822c\u5728\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u4f7f\u7528\u3002 SpatialDropout2D\uff1a\u7a7a\u95f4\u968f\u673a\u7f6e\u96f6\u5c42\u3002\u8bad\u7ec3\u671f\u95f4\u4ee5\u4e00\u5b9a\u51e0\u7387\u5c06\u6574\u4e2a\u7279\u5f81\u56fe\u7f6e0\uff0c\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\uff0c\u6709\u5229\u4e8e\u907f\u514d\u7279\u5f81\u56fe\u4e4b\u95f4\u8fc7\u9ad8\u7684\u76f8\u5173\u6027\u3002 Input\uff1a\u8f93\u5165\u5c42\u3002\u901a\u5e38\u4f7f\u7528Functional API\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\u65f6\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u3002 DenseFeature\uff1a\u7279\u5f81\u5217\u63a5\u5165\u5c42\uff0c\u7528\u4e8e\u63a5\u6536\u4e00\u4e2a\u7279\u5f81\u5217\u5217\u8868\u5e76\u4ea7\u751f\u4e00\u4e2a\u5bc6\u96c6\u8fde\u63a5\u5c42\u3002 Flatten\uff1a\u538b\u5e73\u5c42\uff0c\u7528\u4e8e\u5c06\u591a\u7ef4\u5f20\u91cf\u538b\u6210\u4e00\u7ef4\u3002 Reshape\uff1a\u5f62\u72b6\u91cd\u5851\u5c42\uff0c\u6539\u53d8\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\u3002 Concatenate\uff1a\u62fc\u63a5\u5c42\uff0c\u5c06\u591a\u4e2a\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u62fc\u63a5\u3002 Add\uff1a\u52a0\u6cd5\u5c42\u3002 Subtract\uff1a \u51cf\u6cd5\u5c42\u3002 Maximum\uff1a\u53d6\u6700\u5927\u503c\u5c42\u3002 Minimum\uff1a\u53d6\u6700\u5c0f\u503c\u5c42\u3002 \u5377\u79ef\u7f51\u7edc\u76f8\u5173\u5c42 Conv1D\uff1a\u666e\u901a\u4e00\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u6587\u672c\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 Conv2D\uff1a\u666e\u901a\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 Conv3D\uff1a\u666e\u901a\u4e09\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u89c6\u9891\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 SeparableConv2D\uff1a\u4e8c\u7ef4\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5c42\u3002\u4e0d\u540c\u4e8e\u666e\u901a\u5377\u79ef\u540c\u65f6\u5bf9\u533a\u57df\u548c\u901a\u9053\u64cd\u4f5c\uff0c\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5148\u64cd\u4f5c\u533a\u57df\uff0c\u518d\u64cd\u4f5c\u901a\u9053\u3002\u5373\u5148\u5bf9\u6bcf\u4e2a\u901a\u9053\u505a\u72ec\u7acb\u5377\u79ef\u64cd\u4f5c\u533a\u57df\uff0c\u518d\u75281\u4e581\u5377\u79ef\u8de8\u901a\u9053\u7ec4\u5408\u64cd\u4f5c\u901a\u9053\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8 + \u8f93\u5165\u901a\u9053\u6570\u00d71\u00d71\u00d7\u8f93\u51fa\u901a\u9053\u6570\u3002\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u7684\u53c2\u6570\u6570\u91cf\u4e00\u822c\u8fdc\u5c0f\u4e8e\u666e\u901a\u5377\u79ef\uff0c\u6548\u679c\u4e00\u822c\u4e5f\u66f4\u597d\u3002 DepthwiseConv2D\uff1a\u4e8c\u7ef4\u6df1\u5ea6\u5377\u79ef\u5c42\u3002\u4ec5\u6709SeparableConv2D\u524d\u534a\u90e8\u5206\u64cd\u4f5c\uff0c\u5373\u53ea\u64cd\u4f5c\u533a\u57df\uff0c\u4e0d\u64cd\u4f5c\u901a\u9053\uff0c\u4e00\u822c\u8f93\u51fa\u901a\u9053\u6570\u548c\u8f93\u5165\u901a\u9053\u6570\u76f8\u540c\uff0c\u4f46\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6edepth_multiplier\u8ba9\u8f93\u51fa\u901a\u9053\u4e3a\u8f93\u5165\u901a\u9053\u7684\u82e5\u5e72\u500d\u6570\u3002\u8f93\u51fa\u901a\u9053\u6570 = \u8f93\u5165\u901a\u9053\u6570 \u00d7 depth_multiplier\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8\u00d7 depth_multiplier\u3002 Conv2DTranspose\uff1a\u4e8c\u7ef4\u5377\u79ef\u8f6c\u7f6e\u5c42\uff0c\u4fd7\u79f0\u53cd\u5377\u79ef\u5c42\u3002\u5e76\u975e\u5377\u79ef\u7684\u9006\u64cd\u4f5c\uff0c\u4f46\u5728\u5377\u79ef\u6838\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u5176\u8f93\u5165\u5c3a\u5bf8\u662f\u5377\u79ef\u64cd\u4f5c\u8f93\u51fa\u5c3a\u5bf8\u7684\u60c5\u51b5\u4e0b\uff0c\u5377\u79ef\u8f6c\u7f6e\u7684\u8f93\u51fa\u5c3a\u5bf8\u6070\u597d\u662f\u5377\u79ef\u64cd\u4f5c\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 LocallyConnected2D: \u4e8c\u7ef4\u5c40\u90e8\u8fde\u63a5\u5c42\u3002\u7c7b\u4f3cConv2D\uff0c\u552f\u4e00\u7684\u5dee\u522b\u662f\u6ca1\u6709\u7a7a\u95f4\u4e0a\u7684\u6743\u503c\u5171\u4eab\uff0c\u6240\u4ee5\u5176\u53c2\u6570\u4e2a\u6570\u8fdc\u9ad8\u4e8e\u4e8c\u7ef4\u5377\u79ef\u3002 MaxPool2D: \u4e8c\u7ef4\u6700\u5927\u6c60\u5316\u5c42\u3002\u4e5f\u79f0\u4f5c\u4e0b\u91c7\u6837\u5c42\u3002\u6c60\u5316\u5c42\u65e0\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4e3b\u8981\u4f5c\u7528\u662f\u964d\u7ef4\u3002 AveragePooling2D: \u4e8c\u7ef4\u5e73\u5747\u6c60\u5316\u5c42\u3002 GlobalMaxPool2D: \u5168\u5c40\u6700\u5927\u6c60\u5316\u5c42\u3002\u6bcf\u4e2a\u901a\u9053\u4ec5\u4fdd\u7559\u4e00\u4e2a\u503c\u3002\u4e00\u822c\u4ece\u5377\u79ef\u5c42\u8fc7\u6e21\u5230\u5168\u8fde\u63a5\u5c42\u65f6\u4f7f\u7528\uff0c\u662fFlatten\u7684\u66ff\u4ee3\u65b9\u6848\u3002 GlobalAvgPool2D: \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u3002\u6bcf\u4e2a\u901a\u9053\u4ec5\u4fdd\u7559\u4e00\u4e2a\u503c\u3002 \u5faa\u73af\u7f51\u7edc\u76f8\u5173\u5c42 Embedding\uff1a\u5d4c\u5165\u5c42\u3002\u4e00\u79cd\u6bd4Onehot\u66f4\u52a0\u6709\u6548\u7684\u5bf9\u79bb\u6563\u7279\u5f81\u8fdb\u884c\u7f16\u7801\u7684\u65b9\u6cd5\u3002\u4e00\u822c\u7528\u4e8e\u5c06\u8f93\u5165\u4e2d\u7684\u5355\u8bcd\u6620\u5c04\u4e3a\u7a20\u5bc6\u5411\u91cf\u3002\u5d4c\u5165\u5c42\u7684\u53c2\u6570\u9700\u8981\u5b66\u4e60\u3002 LSTM\uff1a\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u6700\u666e\u904d\u4f7f\u7528\u7684\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u9057\u5fd8\u95e8\uff0c\u66f4\u65b0\u95e8\uff0c\u8f93\u51fa\u95e8\u3002\u53ef\u4ee5\u8f83\u4e3a\u6709\u6548\u5730\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4ece\u800c\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u8bbe\u7f6ereturn_sequences = True\u65f6\u53ef\u4ee5\u8fd4\u56de\u5404\u4e2a\u4e2d\u95f4\u6b65\u9aa4\u8f93\u51fa\uff0c\u5426\u5219\u53ea\u8fd4\u56de\u6700\u7ec8\u8f93\u51fa\u3002 GRU\uff1a\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u5c42\u3002LSTM\u7684\u4f4e\u914d\u7248\uff0c\u4e0d\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u53c2\u6570\u6570\u91cf\u5c11\u4e8eLSTM\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002 SimpleRNN\uff1a\u7b80\u5355\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u5bb9\u6613\u5b58\u5728\u68af\u5ea6\u6d88\u5931\uff0c\u4e0d\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 ConvLSTM2D\uff1a\u5377\u79ef\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u7ed3\u6784\u4e0a\u7c7b\u4f3cLSTM\uff0c\u4f46\u5bf9\u8f93\u5165\u7684\u8f6c\u6362\u64cd\u4f5c\u548c\u5bf9\u72b6\u6001\u7684\u8f6c\u6362\u64cd\u4f5c\u90fd\u662f\u5377\u79ef\u8fd0\u7b97\u3002 Bidirectional\uff1a\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u5305\u88c5\u5668\u3002\u53ef\u4ee5\u5c06LSTM\uff0cGRU\u7b49\u5c42\u5305\u88c5\u6210\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u3002\u4ece\u800c\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002 RNN\uff1aRNN\u57fa\u672c\u5c42\u3002\u63a5\u53d7\u4e00\u4e2a\u5faa\u73af\u7f51\u7edc\u5355\u5143\u6216\u4e00\u4e2a\u5faa\u73af\u5355\u5143\u5217\u8868\uff0c\u901a\u8fc7\u8c03\u7528tf.keras.backend.rnn\u51fd\u6570\u5728\u5e8f\u5217\u4e0a\u8fdb\u884c\u8fed\u4ee3\u4ece\u800c\u8f6c\u6362\u6210\u5faa\u73af\u7f51\u7edc\u5c42\u3002 LSTMCell\uff1aLSTM\u5355\u5143\u3002\u548cLSTM\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u53ef\u4ee5\u7b80\u5355\u7406\u89e3LSTM\u5373RNN\u57fa\u672c\u5c42\u5305\u88f9LSTMCell\u3002 GRUCell\uff1aGRU\u5355\u5143\u3002\u548cGRU\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002 SimpleRNNCell\uff1aSimpleRNN\u5355\u5143\u3002\u548cSimpleRNN\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002 AbstractRNNCell\uff1a\u62bd\u8c61RNN\u5355\u5143\u3002\u901a\u8fc7\u5bf9\u5b83\u7684\u5b50\u7c7b\u5316\u7528\u6237\u53ef\u4ee5\u81ea\u5b9a\u4e49RNN\u5355\u5143\uff0c\u518d\u901a\u8fc7RNN\u57fa\u672c\u5c42\u7684\u5305\u88f9\u5b9e\u73b0\u7528\u6237\u81ea\u5b9a\u4e49\u5faa\u73af\u7f51\u7edc\u5c42\u3002 Attention\uff1aDot-product\u7c7b\u578b\u6ce8\u610f\u529b\u673a\u5236\u5c42\u3002\u53ef\u4ee5\u7528\u4e8e\u6784\u5efa\u6ce8\u610f\u529b\u6a21\u578b\u3002 AdditiveAttention\uff1aAdditive\u7c7b\u578b\u6ce8\u610f\u529b\u673a\u5236\u5c42\u3002\u53ef\u4ee5\u7528\u4e8e\u6784\u5efa\u6ce8\u610f\u529b\u6a21\u578b\u3002 TimeDistributed\uff1a\u65f6\u95f4\u5206\u5e03\u5305\u88c5\u5668\u3002\u5305\u88c5\u540e\u53ef\u4ee5\u5c06Dense\u3001Conv2D\u7b49\u4f5c\u7528\u5230\u6bcf\u4e00\u4e2a\u65f6\u95f4\u7247\u6bb5\u4e0a\u3002 \u4e8c\uff0c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42 # \u5982\u679c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u6ca1\u6709\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u4e00\u822c\u63a8\u8350\u4f7f\u7528Lamda\u5c42\u5b9e\u73b0\u3002 \u5982\u679c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u6709\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u5bf9Layer\u57fa\u7c7b\u5b50\u7c7b\u5316\u5b9e\u73b0\u3002 Lambda\u5c42\u7531\u4e8e\u6ca1\u6709\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u53ea\u9700\u8981\u5b9a\u4e49\u6b63\u5411\u4f20\u64ad\u903b\u8f91\u5373\u53ef\uff0c\u4f7f\u7528\u6bd4Layer\u57fa\u7c7b\u5b50\u7c7b\u5316\u66f4\u52a0\u7b80\u5355\u3002 Lambda\u5c42\u7684\u6b63\u5411\u903b\u8f91\u53ef\u4ee5\u4f7f\u7528Python\u7684lambda\u51fd\u6570\u6765\u8868\u8fbe\uff0c\u4e5f\u53ef\u4ee5\u7528def\u5173\u952e\u5b57\u5b9a\u4e49\u51fd\u6570\u6765\u8868\u8fbe\u3002 import tensorflow as tf from tensorflow.keras import layers , models , regularizers mypower = layers . Lambda ( lambda x : tf . math . pow ( x , 2 )) mypower ( tf . range ( 5 )) <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0, 1, 4, 9, 16], dtype=int32)> Layer\u7684\u5b50\u7c7b\u5316\u4e00\u822c\u9700\u8981\u91cd\u65b0\u5b9e\u73b0\u521d\u59cb\u5316\u65b9\u6cd5\uff0cBuild\u65b9\u6cd5\u548cCall\u65b9\u6cd5\u3002\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5316\u7684\u7ebf\u6027\u5c42\u7684\u8303\u4f8b\uff0c\u7c7b\u4f3cDense. class Linear ( layers . Layer ): def __init__ ( self , units = 32 , ** kwargs ): super ( Linear , self ) . __init__ ( ** kwargs ) self . units = units #build\u65b9\u6cd5\u4e00\u822c\u5b9a\u4e49Layer\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\u3002 def build ( self , input_shape ): self . w = self . add_weight ( \"w\" , shape = ( input_shape [ - 1 ], self . units ), initializer = 'random_normal' , trainable = True ) #\u6ce8\u610f\u5fc5\u987b\u8981\u6709\u53c2\u6570\u540d\u79f0\"w\",\u5426\u5219\u4f1a\u62a5\u9519 self . b = self . add_weight ( \"b\" , shape = ( self . units ,), initializer = 'random_normal' , trainable = True ) super ( Linear , self ) . build ( input_shape ) # \u76f8\u5f53\u4e8e\u8bbe\u7f6eself.built = True #call\u65b9\u6cd5\u4e00\u822c\u5b9a\u4e49\u6b63\u5411\u4f20\u64ad\u8fd0\u7b97\u903b\u8f91\uff0c__call__\u65b9\u6cd5\u8c03\u7528\u4e86\u5b83\u3002 @tf . function def call ( self , inputs ): return tf . matmul ( inputs , self . w ) + self . b #\u5982\u679c\u8981\u8ba9\u81ea\u5b9a\u4e49\u7684Layer\u901a\u8fc7Functional API \u7ec4\u5408\u6210\u6a21\u578b\u65f6\u53ef\u4ee5\u88ab\u4fdd\u5b58\u6210h5\u6a21\u578b\uff0c\u9700\u8981\u81ea\u5b9a\u4e49get_config\u65b9\u6cd5\u3002 def get_config ( self ): config = super ( Linear , self ) . get_config () config . update ({ 'units' : self . units }) return config linear = Linear ( units = 8 ) print ( linear . built ) #\u6307\u5b9ainput_shape\uff0c\u663e\u5f0f\u8c03\u7528build\u65b9\u6cd5\uff0c\u7b2c0\u7ef4\u4ee3\u8868\u6837\u672c\u6570\u91cf\uff0c\u7528None\u586b\u5145 linear . build ( input_shape = ( None , 16 )) print ( linear . built ) False True linear = Linear ( units = 8 ) print ( linear . built ) linear . build ( input_shape = ( None , 16 )) print ( linear . compute_output_shape ( input_shape = ( None , 16 ))) False (None, 8) linear = Linear ( units = 16 ) print ( linear . built ) #\u5982\u679cbuilt = False\uff0c\u8c03\u7528__call__\u65f6\u4f1a\u5148\u8c03\u7528build\u65b9\u6cd5, \u518d\u8c03\u7528call\u65b9\u6cd5\u3002 linear ( tf . random . uniform (( 100 , 64 ))) print ( linear . built ) config = linear . get_config () print ( config ) False True {'name': 'linear_3', 'trainable': True, 'dtype': 'float32', 'units': 16} tf . keras . backend . clear_session () model = models . Sequential () #\u6ce8\u610f\u8be5\u5904\u7684input_shape\u4f1a\u88ab\u6a21\u578b\u52a0\u5de5\uff0c\u65e0\u9700\u4f7f\u7528None\u4ee3\u8868\u6837\u672c\u6570\u91cf\u7ef4 model . add ( Linear ( units = 1 , input_shape = ( 2 ,))) print ( \"model.input_shape: \" , model . input_shape ) print ( \"model.output_shape: \" , model . output_shape ) model . summary () model.input_shape: (None, 2) model.output_shape: (None, 1) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= linear (Linear) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 _________________________________________________________________ model . compile ( optimizer = \"sgd\" , loss = \"mse\" , metrics = [ \"mae\" ]) print ( model . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # \u4fdd\u5b58\u6210 h5\u6a21\u578b model . save ( \"../../data/linear_model.h5\" , save_format = \"h5\" ) model_loaded_keras = tf . keras . models . load_model ( \"../../data/linear_model.h5\" , custom_objects = { \"Linear\" : Linear }) print ( model_loaded_keras . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # \u4fdd\u5b58\u6210 tf\u6a21\u578b model . save ( \"../../data/linear_model\" , save_format = \"tf\" ) model_loaded_tf = tf . keras . models . load_model ( \"../../data/linear_model\" ) print ( model_loaded_tf . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) [[-0.04092304] [-0.06150477]] [[-0.04092304] [-0.06150477]] INFO:tensorflow:Assets written to: ../../data/linear_model/assets [[-0.04092304] [-0.06150477]] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-4,\u6a21\u578b\u5c42layers"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-4%2C%E6%A8%A1%E5%9E%8B%E5%B1%82layers/#5-4\u6a21\u578b\u5c42layers","text":"\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e00\u822c\u7531\u5404\u79cd\u6a21\u578b\u5c42\u7ec4\u5408\u800c\u6210\u3002 tf.keras.layers\u5185\u7f6e\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u5404\u79cd\u529f\u80fd\u7684\u6a21\u578b\u5c42\u3002\u4f8b\u5982\uff0c layers.Dense,layers.Flatten,layers.Input,layers.DenseFeature,layers.Dropout layers.Conv2D,layers.MaxPooling2D,layers.Conv1D layers.Embedding,layers.GRU,layers.LSTM,layers.Bidirectional\u7b49\u7b49\u3002 \u5982\u679c\u8fd9\u4e9b\u5185\u7f6e\u6a21\u578b\u5c42\u4e0d\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7f16\u5199tf.keras.Lambda\u533f\u540d\u6a21\u578b\u5c42\u6216\u7ee7\u627ftf.keras.layers.Layer\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u5c42\u3002 \u5176\u4e2dtf.keras.Lambda\u533f\u540d\u6a21\u578b\u5c42\u53ea\u9002\u7528\u4e8e\u6784\u9020\u6ca1\u6709\u5b66\u4e60\u53c2\u6570\u7684\u6a21\u578b\u5c42\u3002","title":"5-4,\u6a21\u578b\u5c42layers"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-4%2C%E6%A8%A1%E5%9E%8B%E5%B1%82layers/#\u4e00\u5185\u7f6e\u6a21\u578b\u5c42","text":"\u4e00\u4e9b\u5e38\u7528\u7684\u5185\u7f6e\u6a21\u578b\u5c42\u7b80\u5355\u4ecb\u7ecd\u5982\u4e0b\u3002 \u57fa\u7840\u5c42 Dense\uff1a\u5bc6\u96c6\u8fde\u63a5\u5c42\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u5c42\u7279\u5f81\u6570\u00d7 \u8f93\u51fa\u5c42\u7279\u5f81\u6570(weight)\uff0b \u8f93\u51fa\u5c42\u7279\u5f81\u6570(bias) Activation\uff1a\u6fc0\u6d3b\u51fd\u6570\u5c42\u3002\u4e00\u822c\u653e\u5728Dense\u5c42\u540e\u9762\uff0c\u7b49\u4ef7\u4e8e\u5728Dense\u5c42\u4e2d\u6307\u5b9aactivation\u3002 Dropout\uff1a\u968f\u673a\u7f6e\u96f6\u5c42\u3002\u8bad\u7ec3\u671f\u95f4\u4ee5\u4e00\u5b9a\u51e0\u7387\u5c06\u8f93\u5165\u7f6e0\uff0c\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\u3002 BatchNormalization\uff1a\u6279\u6807\u51c6\u5316\u5c42\u3002\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5c06\u8f93\u5165\u6279\u6b21\u7f29\u653e\u5e73\u79fb\u5230\u7a33\u5b9a\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u3002\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u8f93\u5165\u4e0d\u540c\u5206\u5e03\u7684\u9002\u5e94\u6027\uff0c\u52a0\u5feb\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\uff0c\u6709\u8f7b\u5fae\u6b63\u5219\u5316\u6548\u679c\u3002\u4e00\u822c\u5728\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u4f7f\u7528\u3002 SpatialDropout2D\uff1a\u7a7a\u95f4\u968f\u673a\u7f6e\u96f6\u5c42\u3002\u8bad\u7ec3\u671f\u95f4\u4ee5\u4e00\u5b9a\u51e0\u7387\u5c06\u6574\u4e2a\u7279\u5f81\u56fe\u7f6e0\uff0c\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\uff0c\u6709\u5229\u4e8e\u907f\u514d\u7279\u5f81\u56fe\u4e4b\u95f4\u8fc7\u9ad8\u7684\u76f8\u5173\u6027\u3002 Input\uff1a\u8f93\u5165\u5c42\u3002\u901a\u5e38\u4f7f\u7528Functional API\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\u65f6\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u3002 DenseFeature\uff1a\u7279\u5f81\u5217\u63a5\u5165\u5c42\uff0c\u7528\u4e8e\u63a5\u6536\u4e00\u4e2a\u7279\u5f81\u5217\u5217\u8868\u5e76\u4ea7\u751f\u4e00\u4e2a\u5bc6\u96c6\u8fde\u63a5\u5c42\u3002 Flatten\uff1a\u538b\u5e73\u5c42\uff0c\u7528\u4e8e\u5c06\u591a\u7ef4\u5f20\u91cf\u538b\u6210\u4e00\u7ef4\u3002 Reshape\uff1a\u5f62\u72b6\u91cd\u5851\u5c42\uff0c\u6539\u53d8\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\u3002 Concatenate\uff1a\u62fc\u63a5\u5c42\uff0c\u5c06\u591a\u4e2a\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u62fc\u63a5\u3002 Add\uff1a\u52a0\u6cd5\u5c42\u3002 Subtract\uff1a \u51cf\u6cd5\u5c42\u3002 Maximum\uff1a\u53d6\u6700\u5927\u503c\u5c42\u3002 Minimum\uff1a\u53d6\u6700\u5c0f\u503c\u5c42\u3002 \u5377\u79ef\u7f51\u7edc\u76f8\u5173\u5c42 Conv1D\uff1a\u666e\u901a\u4e00\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u6587\u672c\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 Conv2D\uff1a\u666e\u901a\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 Conv3D\uff1a\u666e\u901a\u4e09\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u89c6\u9891\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 SeparableConv2D\uff1a\u4e8c\u7ef4\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5c42\u3002\u4e0d\u540c\u4e8e\u666e\u901a\u5377\u79ef\u540c\u65f6\u5bf9\u533a\u57df\u548c\u901a\u9053\u64cd\u4f5c\uff0c\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5148\u64cd\u4f5c\u533a\u57df\uff0c\u518d\u64cd\u4f5c\u901a\u9053\u3002\u5373\u5148\u5bf9\u6bcf\u4e2a\u901a\u9053\u505a\u72ec\u7acb\u5377\u79ef\u64cd\u4f5c\u533a\u57df\uff0c\u518d\u75281\u4e581\u5377\u79ef\u8de8\u901a\u9053\u7ec4\u5408\u64cd\u4f5c\u901a\u9053\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8 + \u8f93\u5165\u901a\u9053\u6570\u00d71\u00d71\u00d7\u8f93\u51fa\u901a\u9053\u6570\u3002\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u7684\u53c2\u6570\u6570\u91cf\u4e00\u822c\u8fdc\u5c0f\u4e8e\u666e\u901a\u5377\u79ef\uff0c\u6548\u679c\u4e00\u822c\u4e5f\u66f4\u597d\u3002 DepthwiseConv2D\uff1a\u4e8c\u7ef4\u6df1\u5ea6\u5377\u79ef\u5c42\u3002\u4ec5\u6709SeparableConv2D\u524d\u534a\u90e8\u5206\u64cd\u4f5c\uff0c\u5373\u53ea\u64cd\u4f5c\u533a\u57df\uff0c\u4e0d\u64cd\u4f5c\u901a\u9053\uff0c\u4e00\u822c\u8f93\u51fa\u901a\u9053\u6570\u548c\u8f93\u5165\u901a\u9053\u6570\u76f8\u540c\uff0c\u4f46\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6edepth_multiplier\u8ba9\u8f93\u51fa\u901a\u9053\u4e3a\u8f93\u5165\u901a\u9053\u7684\u82e5\u5e72\u500d\u6570\u3002\u8f93\u51fa\u901a\u9053\u6570 = \u8f93\u5165\u901a\u9053\u6570 \u00d7 depth_multiplier\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8\u00d7 depth_multiplier\u3002 Conv2DTranspose\uff1a\u4e8c\u7ef4\u5377\u79ef\u8f6c\u7f6e\u5c42\uff0c\u4fd7\u79f0\u53cd\u5377\u79ef\u5c42\u3002\u5e76\u975e\u5377\u79ef\u7684\u9006\u64cd\u4f5c\uff0c\u4f46\u5728\u5377\u79ef\u6838\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u5176\u8f93\u5165\u5c3a\u5bf8\u662f\u5377\u79ef\u64cd\u4f5c\u8f93\u51fa\u5c3a\u5bf8\u7684\u60c5\u51b5\u4e0b\uff0c\u5377\u79ef\u8f6c\u7f6e\u7684\u8f93\u51fa\u5c3a\u5bf8\u6070\u597d\u662f\u5377\u79ef\u64cd\u4f5c\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 LocallyConnected2D: \u4e8c\u7ef4\u5c40\u90e8\u8fde\u63a5\u5c42\u3002\u7c7b\u4f3cConv2D\uff0c\u552f\u4e00\u7684\u5dee\u522b\u662f\u6ca1\u6709\u7a7a\u95f4\u4e0a\u7684\u6743\u503c\u5171\u4eab\uff0c\u6240\u4ee5\u5176\u53c2\u6570\u4e2a\u6570\u8fdc\u9ad8\u4e8e\u4e8c\u7ef4\u5377\u79ef\u3002 MaxPool2D: \u4e8c\u7ef4\u6700\u5927\u6c60\u5316\u5c42\u3002\u4e5f\u79f0\u4f5c\u4e0b\u91c7\u6837\u5c42\u3002\u6c60\u5316\u5c42\u65e0\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4e3b\u8981\u4f5c\u7528\u662f\u964d\u7ef4\u3002 AveragePooling2D: \u4e8c\u7ef4\u5e73\u5747\u6c60\u5316\u5c42\u3002 GlobalMaxPool2D: \u5168\u5c40\u6700\u5927\u6c60\u5316\u5c42\u3002\u6bcf\u4e2a\u901a\u9053\u4ec5\u4fdd\u7559\u4e00\u4e2a\u503c\u3002\u4e00\u822c\u4ece\u5377\u79ef\u5c42\u8fc7\u6e21\u5230\u5168\u8fde\u63a5\u5c42\u65f6\u4f7f\u7528\uff0c\u662fFlatten\u7684\u66ff\u4ee3\u65b9\u6848\u3002 GlobalAvgPool2D: \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u3002\u6bcf\u4e2a\u901a\u9053\u4ec5\u4fdd\u7559\u4e00\u4e2a\u503c\u3002 \u5faa\u73af\u7f51\u7edc\u76f8\u5173\u5c42 Embedding\uff1a\u5d4c\u5165\u5c42\u3002\u4e00\u79cd\u6bd4Onehot\u66f4\u52a0\u6709\u6548\u7684\u5bf9\u79bb\u6563\u7279\u5f81\u8fdb\u884c\u7f16\u7801\u7684\u65b9\u6cd5\u3002\u4e00\u822c\u7528\u4e8e\u5c06\u8f93\u5165\u4e2d\u7684\u5355\u8bcd\u6620\u5c04\u4e3a\u7a20\u5bc6\u5411\u91cf\u3002\u5d4c\u5165\u5c42\u7684\u53c2\u6570\u9700\u8981\u5b66\u4e60\u3002 LSTM\uff1a\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u6700\u666e\u904d\u4f7f\u7528\u7684\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u9057\u5fd8\u95e8\uff0c\u66f4\u65b0\u95e8\uff0c\u8f93\u51fa\u95e8\u3002\u53ef\u4ee5\u8f83\u4e3a\u6709\u6548\u5730\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4ece\u800c\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u8bbe\u7f6ereturn_sequences = True\u65f6\u53ef\u4ee5\u8fd4\u56de\u5404\u4e2a\u4e2d\u95f4\u6b65\u9aa4\u8f93\u51fa\uff0c\u5426\u5219\u53ea\u8fd4\u56de\u6700\u7ec8\u8f93\u51fa\u3002 GRU\uff1a\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u5c42\u3002LSTM\u7684\u4f4e\u914d\u7248\uff0c\u4e0d\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u53c2\u6570\u6570\u91cf\u5c11\u4e8eLSTM\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002 SimpleRNN\uff1a\u7b80\u5355\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u5bb9\u6613\u5b58\u5728\u68af\u5ea6\u6d88\u5931\uff0c\u4e0d\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 ConvLSTM2D\uff1a\u5377\u79ef\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u7ed3\u6784\u4e0a\u7c7b\u4f3cLSTM\uff0c\u4f46\u5bf9\u8f93\u5165\u7684\u8f6c\u6362\u64cd\u4f5c\u548c\u5bf9\u72b6\u6001\u7684\u8f6c\u6362\u64cd\u4f5c\u90fd\u662f\u5377\u79ef\u8fd0\u7b97\u3002 Bidirectional\uff1a\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u5305\u88c5\u5668\u3002\u53ef\u4ee5\u5c06LSTM\uff0cGRU\u7b49\u5c42\u5305\u88c5\u6210\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u3002\u4ece\u800c\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002 RNN\uff1aRNN\u57fa\u672c\u5c42\u3002\u63a5\u53d7\u4e00\u4e2a\u5faa\u73af\u7f51\u7edc\u5355\u5143\u6216\u4e00\u4e2a\u5faa\u73af\u5355\u5143\u5217\u8868\uff0c\u901a\u8fc7\u8c03\u7528tf.keras.backend.rnn\u51fd\u6570\u5728\u5e8f\u5217\u4e0a\u8fdb\u884c\u8fed\u4ee3\u4ece\u800c\u8f6c\u6362\u6210\u5faa\u73af\u7f51\u7edc\u5c42\u3002 LSTMCell\uff1aLSTM\u5355\u5143\u3002\u548cLSTM\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u53ef\u4ee5\u7b80\u5355\u7406\u89e3LSTM\u5373RNN\u57fa\u672c\u5c42\u5305\u88f9LSTMCell\u3002 GRUCell\uff1aGRU\u5355\u5143\u3002\u548cGRU\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002 SimpleRNNCell\uff1aSimpleRNN\u5355\u5143\u3002\u548cSimpleRNN\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002 AbstractRNNCell\uff1a\u62bd\u8c61RNN\u5355\u5143\u3002\u901a\u8fc7\u5bf9\u5b83\u7684\u5b50\u7c7b\u5316\u7528\u6237\u53ef\u4ee5\u81ea\u5b9a\u4e49RNN\u5355\u5143\uff0c\u518d\u901a\u8fc7RNN\u57fa\u672c\u5c42\u7684\u5305\u88f9\u5b9e\u73b0\u7528\u6237\u81ea\u5b9a\u4e49\u5faa\u73af\u7f51\u7edc\u5c42\u3002 Attention\uff1aDot-product\u7c7b\u578b\u6ce8\u610f\u529b\u673a\u5236\u5c42\u3002\u53ef\u4ee5\u7528\u4e8e\u6784\u5efa\u6ce8\u610f\u529b\u6a21\u578b\u3002 AdditiveAttention\uff1aAdditive\u7c7b\u578b\u6ce8\u610f\u529b\u673a\u5236\u5c42\u3002\u53ef\u4ee5\u7528\u4e8e\u6784\u5efa\u6ce8\u610f\u529b\u6a21\u578b\u3002 TimeDistributed\uff1a\u65f6\u95f4\u5206\u5e03\u5305\u88c5\u5668\u3002\u5305\u88c5\u540e\u53ef\u4ee5\u5c06Dense\u3001Conv2D\u7b49\u4f5c\u7528\u5230\u6bcf\u4e00\u4e2a\u65f6\u95f4\u7247\u6bb5\u4e0a\u3002","title":"\u4e00\uff0c\u5185\u7f6e\u6a21\u578b\u5c42"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-4%2C%E6%A8%A1%E5%9E%8B%E5%B1%82layers/#\u4e8c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42","text":"\u5982\u679c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u6ca1\u6709\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u4e00\u822c\u63a8\u8350\u4f7f\u7528Lamda\u5c42\u5b9e\u73b0\u3002 \u5982\u679c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u6709\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u5bf9Layer\u57fa\u7c7b\u5b50\u7c7b\u5316\u5b9e\u73b0\u3002 Lambda\u5c42\u7531\u4e8e\u6ca1\u6709\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u53ea\u9700\u8981\u5b9a\u4e49\u6b63\u5411\u4f20\u64ad\u903b\u8f91\u5373\u53ef\uff0c\u4f7f\u7528\u6bd4Layer\u57fa\u7c7b\u5b50\u7c7b\u5316\u66f4\u52a0\u7b80\u5355\u3002 Lambda\u5c42\u7684\u6b63\u5411\u903b\u8f91\u53ef\u4ee5\u4f7f\u7528Python\u7684lambda\u51fd\u6570\u6765\u8868\u8fbe\uff0c\u4e5f\u53ef\u4ee5\u7528def\u5173\u952e\u5b57\u5b9a\u4e49\u51fd\u6570\u6765\u8868\u8fbe\u3002 import tensorflow as tf from tensorflow.keras import layers , models , regularizers mypower = layers . Lambda ( lambda x : tf . math . pow ( x , 2 )) mypower ( tf . range ( 5 )) <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0, 1, 4, 9, 16], dtype=int32)> Layer\u7684\u5b50\u7c7b\u5316\u4e00\u822c\u9700\u8981\u91cd\u65b0\u5b9e\u73b0\u521d\u59cb\u5316\u65b9\u6cd5\uff0cBuild\u65b9\u6cd5\u548cCall\u65b9\u6cd5\u3002\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5316\u7684\u7ebf\u6027\u5c42\u7684\u8303\u4f8b\uff0c\u7c7b\u4f3cDense. class Linear ( layers . Layer ): def __init__ ( self , units = 32 , ** kwargs ): super ( Linear , self ) . __init__ ( ** kwargs ) self . units = units #build\u65b9\u6cd5\u4e00\u822c\u5b9a\u4e49Layer\u9700\u8981\u88ab\u8bad\u7ec3\u7684\u53c2\u6570\u3002 def build ( self , input_shape ): self . w = self . add_weight ( \"w\" , shape = ( input_shape [ - 1 ], self . units ), initializer = 'random_normal' , trainable = True ) #\u6ce8\u610f\u5fc5\u987b\u8981\u6709\u53c2\u6570\u540d\u79f0\"w\",\u5426\u5219\u4f1a\u62a5\u9519 self . b = self . add_weight ( \"b\" , shape = ( self . units ,), initializer = 'random_normal' , trainable = True ) super ( Linear , self ) . build ( input_shape ) # \u76f8\u5f53\u4e8e\u8bbe\u7f6eself.built = True #call\u65b9\u6cd5\u4e00\u822c\u5b9a\u4e49\u6b63\u5411\u4f20\u64ad\u8fd0\u7b97\u903b\u8f91\uff0c__call__\u65b9\u6cd5\u8c03\u7528\u4e86\u5b83\u3002 @tf . function def call ( self , inputs ): return tf . matmul ( inputs , self . w ) + self . b #\u5982\u679c\u8981\u8ba9\u81ea\u5b9a\u4e49\u7684Layer\u901a\u8fc7Functional API \u7ec4\u5408\u6210\u6a21\u578b\u65f6\u53ef\u4ee5\u88ab\u4fdd\u5b58\u6210h5\u6a21\u578b\uff0c\u9700\u8981\u81ea\u5b9a\u4e49get_config\u65b9\u6cd5\u3002 def get_config ( self ): config = super ( Linear , self ) . get_config () config . update ({ 'units' : self . units }) return config linear = Linear ( units = 8 ) print ( linear . built ) #\u6307\u5b9ainput_shape\uff0c\u663e\u5f0f\u8c03\u7528build\u65b9\u6cd5\uff0c\u7b2c0\u7ef4\u4ee3\u8868\u6837\u672c\u6570\u91cf\uff0c\u7528None\u586b\u5145 linear . build ( input_shape = ( None , 16 )) print ( linear . built ) False True linear = Linear ( units = 8 ) print ( linear . built ) linear . build ( input_shape = ( None , 16 )) print ( linear . compute_output_shape ( input_shape = ( None , 16 ))) False (None, 8) linear = Linear ( units = 16 ) print ( linear . built ) #\u5982\u679cbuilt = False\uff0c\u8c03\u7528__call__\u65f6\u4f1a\u5148\u8c03\u7528build\u65b9\u6cd5, \u518d\u8c03\u7528call\u65b9\u6cd5\u3002 linear ( tf . random . uniform (( 100 , 64 ))) print ( linear . built ) config = linear . get_config () print ( config ) False True {'name': 'linear_3', 'trainable': True, 'dtype': 'float32', 'units': 16} tf . keras . backend . clear_session () model = models . Sequential () #\u6ce8\u610f\u8be5\u5904\u7684input_shape\u4f1a\u88ab\u6a21\u578b\u52a0\u5de5\uff0c\u65e0\u9700\u4f7f\u7528None\u4ee3\u8868\u6837\u672c\u6570\u91cf\u7ef4 model . add ( Linear ( units = 1 , input_shape = ( 2 ,))) print ( \"model.input_shape: \" , model . input_shape ) print ( \"model.output_shape: \" , model . output_shape ) model . summary () model.input_shape: (None, 2) model.output_shape: (None, 1) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= linear (Linear) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 _________________________________________________________________ model . compile ( optimizer = \"sgd\" , loss = \"mse\" , metrics = [ \"mae\" ]) print ( model . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # \u4fdd\u5b58\u6210 h5\u6a21\u578b model . save ( \"../../data/linear_model.h5\" , save_format = \"h5\" ) model_loaded_keras = tf . keras . models . load_model ( \"../../data/linear_model.h5\" , custom_objects = { \"Linear\" : Linear }) print ( model_loaded_keras . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # \u4fdd\u5b58\u6210 tf\u6a21\u578b model . save ( \"../../data/linear_model\" , save_format = \"tf\" ) model_loaded_tf = tf . keras . models . load_model ( \"../../data/linear_model\" ) print ( model_loaded_tf . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) [[-0.04092304] [-0.06150477]] [[-0.04092304] [-0.06150477]] INFO:tensorflow:Assets written to: ../../data/linear_model/assets [[-0.04092304] [-0.06150477]] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-5%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0losses/","text":"5-5,\u635f\u5931\u51fd\u6570losses # \u4e00\u822c\u6765\u8bf4\uff0c\u76d1\u7763\u5b66\u4e60\u7684\u76ee\u6807\u51fd\u6570\u7531\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879\u7ec4\u6210\u3002\uff08Objective = Loss + Regularization\uff09 \u5bf9\u4e8ekeras\u6a21\u578b\uff0c\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u6b63\u5219\u5316\u9879\u4e00\u822c\u5728\u5404\u5c42\u4e2d\u6307\u5b9a\uff0c\u4f8b\u5982\u4f7f\u7528Dense\u7684 kernel_regularizer \u548c bias_regularizer\u7b49\u53c2\u6570\u6307\u5b9a\u6743\u91cd\u4f7f\u7528l1\u6216\u8005l2\u6b63\u5219\u5316\u9879\uff0c\u6b64\u5916\u8fd8\u53ef\u4ee5\u7528kernel_constraint \u548c bias_constraint\u7b49\u53c2\u6570\u7ea6\u675f\u6743\u91cd\u7684\u53d6\u503c\u8303\u56f4\uff0c\u8fd9\u4e5f\u662f\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\u3002 \u635f\u5931\u51fd\u6570\u5728\u6a21\u578b\u7f16\u8bd1\u65f6\u5019\u6307\u5b9a\u3002\u5bf9\u4e8e\u56de\u5f52\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u662f\u5747\u65b9\u635f\u5931\u51fd\u6570 mean_squared_error\u3002 \u5bf9\u4e8e\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u662f\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 binary_crossentropy\u3002 \u5bf9\u4e8e\u591a\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u679clabel\u662fone-hot\u7f16\u7801\u7684\uff0c\u5219\u4f7f\u7528\u7c7b\u522b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 categorical_crossentropy\u3002\u5982\u679clabel\u662f\u7c7b\u522b\u5e8f\u53f7\u7f16\u7801\u7684\uff0c\u5219\u9700\u8981\u4f7f\u7528\u7a00\u758f\u7c7b\u522b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 sparse_categorical_crossentropy\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u9700\u8981\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_true,y_pred\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , regularizers , constraints \u4e00\uff0c\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879 # tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 64 , input_dim = 64 , kernel_regularizer = regularizers . l2 ( 0.01 ), activity_regularizer = regularizers . l1 ( 0.01 ), kernel_constraint = constraints . MaxNorm ( max_value = 2 , axis = 0 ))) model . add ( layers . Dense ( 10 , kernel_regularizer = regularizers . l1_l2 ( 0.01 , 0.01 ), activation = \"sigmoid\" )) model . compile ( optimizer = \"rmsprop\" , loss = \"binary_crossentropy\" , metrics = [ \"AUC\" ]) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 64) 4160 _________________________________________________________________ dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 4,810 Trainable params: 4,810 Non-trainable params: 0 _________________________________________________________________ \u4e8c\uff0c\u5185\u7f6e\u635f\u5931\u51fd\u6570 # \u5185\u7f6e\u7684\u635f\u5931\u51fd\u6570\u4e00\u822c\u6709\u7c7b\u7684\u5b9e\u73b0\u548c\u51fd\u6570\u7684\u5b9e\u73b0\u4e24\u79cd\u5f62\u5f0f\u3002 \u5982\uff1aCategoricalCrossentropy \u548c categorical_crossentropy \u90fd\u662f\u7c7b\u522b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u524d\u8005\u662f\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\uff0c\u540e\u8005\u662f\u51fd\u6570\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002 \u5e38\u7528\u7684\u4e00\u4e9b\u5185\u7f6e\u635f\u5931\u51fd\u6570\u8bf4\u660e\u5982\u4e0b\u3002 mean_squared_error\uff08\u5747\u65b9\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u7b80\u5199\u4e3a mse, \u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a MeanSquaredError \u548c MSE\uff09 mean_absolute_error (\u5e73\u5747\u7edd\u5bf9\u503c\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u7b80\u5199\u4e3a mae, \u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a MeanAbsoluteError \u548c MAE) mean_absolute_percentage_error (\u5e73\u5747\u767e\u5206\u6bd4\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u7b80\u5199\u4e3a mape, \u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a MeanAbsolutePercentageError \u548c MAPE) Huber(Huber\u635f\u5931\uff0c\u53ea\u6709\u7c7b\u5b9e\u73b0\u5f62\u5f0f\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u4ecb\u4e8emse\u548cmae\u4e4b\u95f4\uff0c\u5bf9\u5f02\u5e38\u503c\u6bd4\u8f83\u9c81\u68d2\uff0c\u76f8\u5bf9mse\u6709\u4e00\u5b9a\u7684\u4f18\u52bf) binary_crossentropy(\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a BinaryCrossentropy) categorical_crossentropy(\u7c7b\u522b\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3aonehot\u7f16\u7801\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a CategoricalCrossentropy) sparse_categorical_crossentropy(\u7a00\u758f\u7c7b\u522b\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3a\u5e8f\u53f7\u7f16\u7801\u5f62\u5f0f\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a SparseCategoricalCrossentropy) hinge(\u5408\u9875\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u6700\u8457\u540d\u7684\u5e94\u7528\u662f\u4f5c\u4e3a\u652f\u6301\u5411\u91cf\u673aSVM\u7684\u635f\u5931\u51fd\u6570\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a Hinge) kld(\u76f8\u5bf9\u71b5\u635f\u5931\uff0c\u4e5f\u53ebKL\u6563\u5ea6\uff0c\u5e38\u7528\u4e8e\u6700\u5927\u671f\u671b\u7b97\u6cd5EM\u7684\u635f\u5931\u51fd\u6570\uff0c\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u5dee\u5f02\u7684\u4e00\u79cd\u4fe1\u606f\u5ea6\u91cf\u3002\u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a KLDivergence \u6216 KLD) cosine_similarity(\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u53ef\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a CosineSimilarity) \u4e09\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570 # \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_true,y_pred\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 \u4e5f\u53ef\u4ee5\u5bf9tf.keras.losses.Loss\u8fdb\u884c\u5b50\u7c7b\u5316\uff0c\u91cd\u5199call\u65b9\u6cd5\u5b9e\u73b0\u635f\u5931\u7684\u8ba1\u7b97\u903b\u8f91\uff0c\u4ece\u800c\u5f97\u5230\u635f\u5931\u51fd\u6570\u7684\u7c7b\u7684\u5b9e\u73b0\u3002 \u4e0b\u9762\u662f\u4e00\u4e2aFocal Loss\u7684\u81ea\u5b9a\u4e49\u5b9e\u73b0\u793a\u8303\u3002Focal Loss\u662f\u4e00\u79cd\u5bf9binary_crossentropy\u7684\u6539\u8fdb\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u3002 \u5b83\u5728\u6837\u672c\u4e0d\u5747\u8861\u548c\u5b58\u5728\u8f83\u591a\u6613\u5206\u7c7b\u7684\u6837\u672c\u65f6\u76f8\u6bd4binary_crossentropy\u5177\u6709\u660e\u663e\u7684\u4f18\u52bf\u3002 \u5b83\u6709\u4e24\u4e2a\u53ef\u8c03\u53c2\u6570\uff0calpha\u53c2\u6570\u548cgamma\u53c2\u6570\u3002\u5176\u4e2dalpha\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u8d1f\u6837\u672c\u7684\u6743\u91cd\uff0cgamma\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u5bb9\u6613\u8bad\u7ec3\u6837\u672c\u7684\u6743\u91cd\u3002 \u4ece\u800c\u8ba9\u6a21\u578b\u66f4\u52a0\u805a\u7126\u5728\u6b63\u6837\u672c\u548c\u56f0\u96be\u6837\u672c\u4e0a\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u53eb\u505aFocal Loss\u3002 \u8be6\u89c1\u300a5\u5206\u949f\u7406\u89e3Focal Loss\u4e0eGHM\u2014\u2014\u89e3\u51b3\u6837\u672c\u4e0d\u5e73\u8861\u5229\u5668\u300b https://zhuanlan.zhihu.com/p/80594704 focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} def focal_loss ( gamma = 2. , alpha = 0.75 ): def focal_loss_fixed ( y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * alpha + ( 1 - y_true ) * ( 1 - alpha ) modulating_factor = tf . pow ( 1.0 - p_t , gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss return focal_loss_fixed class FocalLoss ( tf . keras . losses . Loss ): def __init__ ( self , gamma = 2.0 , alpha = 0.75 , name = \"focal_loss\" ): self . gamma = gamma self . alpha = alpha def call ( self , y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * self . alpha + ( 1 - y_true ) * ( 1 - self . alpha ) modulating_factor = tf . pow ( 1.0 - p_t , self . gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-5,\u635f\u5931\u51fd\u6570losses"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-5%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0losses/#5-5\u635f\u5931\u51fd\u6570losses","text":"\u4e00\u822c\u6765\u8bf4\uff0c\u76d1\u7763\u5b66\u4e60\u7684\u76ee\u6807\u51fd\u6570\u7531\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879\u7ec4\u6210\u3002\uff08Objective = Loss + Regularization\uff09 \u5bf9\u4e8ekeras\u6a21\u578b\uff0c\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u6b63\u5219\u5316\u9879\u4e00\u822c\u5728\u5404\u5c42\u4e2d\u6307\u5b9a\uff0c\u4f8b\u5982\u4f7f\u7528Dense\u7684 kernel_regularizer \u548c bias_regularizer\u7b49\u53c2\u6570\u6307\u5b9a\u6743\u91cd\u4f7f\u7528l1\u6216\u8005l2\u6b63\u5219\u5316\u9879\uff0c\u6b64\u5916\u8fd8\u53ef\u4ee5\u7528kernel_constraint \u548c bias_constraint\u7b49\u53c2\u6570\u7ea6\u675f\u6743\u91cd\u7684\u53d6\u503c\u8303\u56f4\uff0c\u8fd9\u4e5f\u662f\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\u3002 \u635f\u5931\u51fd\u6570\u5728\u6a21\u578b\u7f16\u8bd1\u65f6\u5019\u6307\u5b9a\u3002\u5bf9\u4e8e\u56de\u5f52\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u662f\u5747\u65b9\u635f\u5931\u51fd\u6570 mean_squared_error\u3002 \u5bf9\u4e8e\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u662f\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 binary_crossentropy\u3002 \u5bf9\u4e8e\u591a\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u679clabel\u662fone-hot\u7f16\u7801\u7684\uff0c\u5219\u4f7f\u7528\u7c7b\u522b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 categorical_crossentropy\u3002\u5982\u679clabel\u662f\u7c7b\u522b\u5e8f\u53f7\u7f16\u7801\u7684\uff0c\u5219\u9700\u8981\u4f7f\u7528\u7a00\u758f\u7c7b\u522b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 sparse_categorical_crossentropy\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u9700\u8981\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_true,y_pred\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , regularizers , constraints","title":"5-5,\u635f\u5931\u51fd\u6570losses"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-5%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0losses/#\u4e00\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879","text":"tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 64 , input_dim = 64 , kernel_regularizer = regularizers . l2 ( 0.01 ), activity_regularizer = regularizers . l1 ( 0.01 ), kernel_constraint = constraints . MaxNorm ( max_value = 2 , axis = 0 ))) model . add ( layers . Dense ( 10 , kernel_regularizer = regularizers . l1_l2 ( 0.01 , 0.01 ), activation = \"sigmoid\" )) model . compile ( optimizer = \"rmsprop\" , loss = \"binary_crossentropy\" , metrics = [ \"AUC\" ]) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 64) 4160 _________________________________________________________________ dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 4,810 Trainable params: 4,810 Non-trainable params: 0 _________________________________________________________________","title":"\u4e00\uff0c\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-5%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0losses/#\u4e8c\u5185\u7f6e\u635f\u5931\u51fd\u6570","text":"\u5185\u7f6e\u7684\u635f\u5931\u51fd\u6570\u4e00\u822c\u6709\u7c7b\u7684\u5b9e\u73b0\u548c\u51fd\u6570\u7684\u5b9e\u73b0\u4e24\u79cd\u5f62\u5f0f\u3002 \u5982\uff1aCategoricalCrossentropy \u548c categorical_crossentropy \u90fd\u662f\u7c7b\u522b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u524d\u8005\u662f\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\uff0c\u540e\u8005\u662f\u51fd\u6570\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002 \u5e38\u7528\u7684\u4e00\u4e9b\u5185\u7f6e\u635f\u5931\u51fd\u6570\u8bf4\u660e\u5982\u4e0b\u3002 mean_squared_error\uff08\u5747\u65b9\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u7b80\u5199\u4e3a mse, \u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a MeanSquaredError \u548c MSE\uff09 mean_absolute_error (\u5e73\u5747\u7edd\u5bf9\u503c\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u7b80\u5199\u4e3a mae, \u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a MeanAbsoluteError \u548c MAE) mean_absolute_percentage_error (\u5e73\u5747\u767e\u5206\u6bd4\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u7b80\u5199\u4e3a mape, \u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a MeanAbsolutePercentageError \u548c MAPE) Huber(Huber\u635f\u5931\uff0c\u53ea\u6709\u7c7b\u5b9e\u73b0\u5f62\u5f0f\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u4ecb\u4e8emse\u548cmae\u4e4b\u95f4\uff0c\u5bf9\u5f02\u5e38\u503c\u6bd4\u8f83\u9c81\u68d2\uff0c\u76f8\u5bf9mse\u6709\u4e00\u5b9a\u7684\u4f18\u52bf) binary_crossentropy(\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a BinaryCrossentropy) categorical_crossentropy(\u7c7b\u522b\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3aonehot\u7f16\u7801\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a CategoricalCrossentropy) sparse_categorical_crossentropy(\u7a00\u758f\u7c7b\u522b\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3a\u5e8f\u53f7\u7f16\u7801\u5f62\u5f0f\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a SparseCategoricalCrossentropy) hinge(\u5408\u9875\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u6700\u8457\u540d\u7684\u5e94\u7528\u662f\u4f5c\u4e3a\u652f\u6301\u5411\u91cf\u673aSVM\u7684\u635f\u5931\u51fd\u6570\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a Hinge) kld(\u76f8\u5bf9\u71b5\u635f\u5931\uff0c\u4e5f\u53ebKL\u6563\u5ea6\uff0c\u5e38\u7528\u4e8e\u6700\u5927\u671f\u671b\u7b97\u6cd5EM\u7684\u635f\u5931\u51fd\u6570\uff0c\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u5dee\u5f02\u7684\u4e00\u79cd\u4fe1\u606f\u5ea6\u91cf\u3002\u7c7b\u4e0e\u51fd\u6570\u5b9e\u73b0\u5f62\u5f0f\u5206\u522b\u4e3a KLDivergence \u6216 KLD) cosine_similarity(\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u53ef\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u7c7b\u5b9e\u73b0\u5f62\u5f0f\u4e3a CosineSimilarity)","title":"\u4e8c\uff0c\u5185\u7f6e\u635f\u5931\u51fd\u6570"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-5%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0losses/#\u4e09\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570","text":"\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_true,y_pred\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 \u4e5f\u53ef\u4ee5\u5bf9tf.keras.losses.Loss\u8fdb\u884c\u5b50\u7c7b\u5316\uff0c\u91cd\u5199call\u65b9\u6cd5\u5b9e\u73b0\u635f\u5931\u7684\u8ba1\u7b97\u903b\u8f91\uff0c\u4ece\u800c\u5f97\u5230\u635f\u5931\u51fd\u6570\u7684\u7c7b\u7684\u5b9e\u73b0\u3002 \u4e0b\u9762\u662f\u4e00\u4e2aFocal Loss\u7684\u81ea\u5b9a\u4e49\u5b9e\u73b0\u793a\u8303\u3002Focal Loss\u662f\u4e00\u79cd\u5bf9binary_crossentropy\u7684\u6539\u8fdb\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u3002 \u5b83\u5728\u6837\u672c\u4e0d\u5747\u8861\u548c\u5b58\u5728\u8f83\u591a\u6613\u5206\u7c7b\u7684\u6837\u672c\u65f6\u76f8\u6bd4binary_crossentropy\u5177\u6709\u660e\u663e\u7684\u4f18\u52bf\u3002 \u5b83\u6709\u4e24\u4e2a\u53ef\u8c03\u53c2\u6570\uff0calpha\u53c2\u6570\u548cgamma\u53c2\u6570\u3002\u5176\u4e2dalpha\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u8d1f\u6837\u672c\u7684\u6743\u91cd\uff0cgamma\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u5bb9\u6613\u8bad\u7ec3\u6837\u672c\u7684\u6743\u91cd\u3002 \u4ece\u800c\u8ba9\u6a21\u578b\u66f4\u52a0\u805a\u7126\u5728\u6b63\u6837\u672c\u548c\u56f0\u96be\u6837\u672c\u4e0a\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u53eb\u505aFocal Loss\u3002 \u8be6\u89c1\u300a5\u5206\u949f\u7406\u89e3Focal Loss\u4e0eGHM\u2014\u2014\u89e3\u51b3\u6837\u672c\u4e0d\u5e73\u8861\u5229\u5668\u300b https://zhuanlan.zhihu.com/p/80594704 focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} def focal_loss ( gamma = 2. , alpha = 0.75 ): def focal_loss_fixed ( y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * alpha + ( 1 - y_true ) * ( 1 - alpha ) modulating_factor = tf . pow ( 1.0 - p_t , gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss return focal_loss_fixed class FocalLoss ( tf . keras . losses . Loss ): def __init__ ( self , gamma = 2.0 , alpha = 0.75 , name = \"focal_loss\" ): self . gamma = gamma self . alpha = alpha def call ( self , y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * self . alpha + ( 1 - y_true ) * ( 1 - self . alpha ) modulating_factor = tf . pow ( 1.0 - p_t , self . gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-6%2C%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87metrics/","text":"5-6,\u8bc4\u4f30\u6307\u6807metrics # \u635f\u5931\u51fd\u6570\u9664\u4e86\u4f5c\u4e3a\u6a21\u578b\u8bad\u7ec3\u65f6\u5019\u7684\u4f18\u5316\u76ee\u6807\uff0c\u4e5f\u80fd\u591f\u4f5c\u4e3a\u6a21\u578b\u597d\u574f\u7684\u4e00\u79cd\u8bc4\u4ef7\u6307\u6807\u3002\u4f46\u901a\u5e38\u4eba\u4eec\u8fd8\u4f1a\u4ece\u5176\u5b83\u89d2\u5ea6\u8bc4\u4f30\u6a21\u578b\u7684\u597d\u574f\u3002 \u8fd9\u5c31\u662f\u8bc4\u4f30\u6307\u6807\u3002\u901a\u5e38\u635f\u5931\u51fd\u6570\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5982MAE,MSE,CategoricalCrossentropy\u7b49\u4e5f\u662f\u5e38\u7528\u7684\u8bc4\u4f30\u6307\u6807\u3002 \u4f46\u8bc4\u4f30\u6307\u6807\u4e0d\u4e00\u5b9a\u53ef\u4ee5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f8b\u5982AUC,Accuracy,Precision\u3002\u56e0\u4e3a\u8bc4\u4f30\u6307\u6807\u4e0d\u8981\u6c42\u8fde\u7eed\u53ef\u5bfc\uff0c\u800c\u635f\u5931\u51fd\u6570\u901a\u5e38\u8981\u6c42\u8fde\u7eed\u53ef\u5bfc\u3002 \u7f16\u8bd1\u6a21\u578b\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u5217\u8868\u5f62\u5f0f\u6307\u5b9a\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u3002 \u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u9700\u8981\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_true,y_pred\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u8bc4\u4f30\u503c\u3002 \u4e5f\u53ef\u4ee5\u5bf9tf.keras.metrics.Metric\u8fdb\u884c\u5b50\u7c7b\u5316\uff0c\u91cd\u5199\u521d\u59cb\u5316\u65b9\u6cd5, update_state\u65b9\u6cd5, result\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u4f30\u6307\u6807\u7684\u8ba1\u7b97\u903b\u8f91\uff0c\u4ece\u800c\u5f97\u5230\u8bc4\u4f30\u6307\u6807\u7684\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002 \u7531\u4e8e\u8bad\u7ec3\u7684\u8fc7\u7a0b\u901a\u5e38\u662f\u5206\u6279\u6b21\u8bad\u7ec3\u7684\uff0c\u800c\u8bc4\u4f30\u6307\u6807\u8981\u8dd1\u5b8c\u4e00\u4e2aepoch\u624d\u80fd\u591f\u5f97\u5230\u6574\u4f53\u7684\u6307\u6807\u7ed3\u679c\u3002\u56e0\u6b64\uff0c\u7c7b\u5f62\u5f0f\u7684\u8bc4\u4f30\u6307\u6807\u66f4\u4e3a\u5e38\u89c1\u3002\u5373\u9700\u8981\u7f16\u5199\u521d\u59cb\u5316\u65b9\u6cd5\u4ee5\u521b\u5efa\u4e0e\u8ba1\u7b97\u6307\u6807\u7ed3\u679c\u76f8\u5173\u7684\u4e00\u4e9b\u4e2d\u95f4\u53d8\u91cf\uff0c\u7f16\u5199update_state\u65b9\u6cd5\u5728\u6bcf\u4e2abatch\u540e\u66f4\u65b0\u76f8\u5173\u4e2d\u95f4\u53d8\u91cf\u7684\u72b6\u6001\uff0c\u7f16\u5199result\u65b9\u6cd5\u8f93\u51fa\u6700\u7ec8\u6307\u6807\u7ed3\u679c\u3002 \u5982\u679c\u7f16\u5199\u51fd\u6570\u5f62\u5f0f\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u5219\u53ea\u80fd\u53d6epoch\u4e2d\u5404\u4e2abatch\u8ba1\u7b97\u7684\u8bc4\u4f30\u6307\u6807\u7ed3\u679c\u7684\u5e73\u5747\u503c\u4f5c\u4e3a\u6574\u4e2aepoch\u4e0a\u7684\u8bc4\u4f30\u6307\u6807\u7ed3\u679c\uff0c\u8fd9\u4e2a\u7ed3\u679c\u901a\u5e38\u4f1a\u504f\u79bb\u6574\u4e2aepoch\u6570\u636e\u4e00\u6b21\u8ba1\u7b97\u7684\u7ed3\u679c\u3002 \u4e00\uff0c\u5e38\u7528\u7684\u5185\u7f6e\u8bc4\u4f30\u6307\u6807 # MeanSquaredError\uff08\u5747\u65b9\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u53ef\u4ee5\u7b80\u5199\u4e3aMSE\uff0c\u51fd\u6570\u5f62\u5f0f\u4e3amse\uff09 MeanAbsoluteError (\u5e73\u5747\u7edd\u5bf9\u503c\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u53ef\u4ee5\u7b80\u5199\u4e3aMAE\uff0c\u51fd\u6570\u5f62\u5f0f\u4e3amae) MeanAbsolutePercentageError (\u5e73\u5747\u767e\u5206\u6bd4\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u53ef\u4ee5\u7b80\u5199\u4e3aMAPE\uff0c\u51fd\u6570\u5f62\u5f0f\u4e3amape) RootMeanSquaredError (\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52) Accuracy (\u51c6\u786e\u7387\uff0c\u7528\u4e8e\u5206\u7c7b\uff0c\u53ef\u4ee5\u7528\u5b57\u7b26\u4e32\"Accuracy\"\u8868\u793a\uff0cAccuracy=(TP+TN)/(TP+TN+FP+FN)\uff0c\u8981\u6c42y_true\u548cy_pred\u90fd\u4e3a\u7c7b\u522b\u5e8f\u53f7\u7f16\u7801) Precision (\u7cbe\u786e\u7387\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0cPrecision = TP/(TP+FP)) Recall (\u53ec\u56de\u7387\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0cRecall = TP/(TP+FN)) TruePositives (\u771f\u6b63\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) TrueNegatives (\u771f\u8d1f\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) FalsePositives (\u5047\u6b63\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) FalseNegatives (\u5047\u8d1f\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) AUC(ROC\u66f2\u7ebf(TPR vs FPR)\u4e0b\u7684\u9762\u79ef\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u76f4\u89c2\u89e3\u91ca\u4e3a\u968f\u673a\u62bd\u53d6\u4e00\u4e2a\u6b63\u6837\u672c\u548c\u4e00\u4e2a\u8d1f\u6837\u672c\uff0c\u6b63\u6837\u672c\u7684\u9884\u6d4b\u503c\u5927\u4e8e\u8d1f\u6837\u672c\u7684\u6982\u7387) CategoricalAccuracy\uff08\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4e0eAccuracy\u542b\u4e49\u76f8\u540c\uff0c\u8981\u6c42y_true(label)\u4e3aonehot\u7f16\u7801\u5f62\u5f0f\uff09 SparseCategoricalAccuracy (\u7a00\u758f\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4e0eAccuracy\u542b\u4e49\u76f8\u540c\uff0c\u8981\u6c42y_true(label)\u4e3a\u5e8f\u53f7\u7f16\u7801\u5f62\u5f0f) MeanIoU (Intersection-Over-Union\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u5206\u5272) TopKCategoricalAccuracy (\u591a\u5206\u7c7bTopK\u51c6\u786e\u7387\uff0c\u8981\u6c42y_true(label)\u4e3aonehot\u7f16\u7801\u5f62\u5f0f) SparseTopKCategoricalAccuracy (\u7a00\u758f\u591a\u5206\u7c7bTopK\u51c6\u786e\u7387\uff0c\u8981\u6c42y_true(label)\u4e3a\u5e8f\u53f7\u7f16\u7801\u5f62\u5f0f) Mean (\u5e73\u5747\u503c) Sum (\u6c42\u548c) \u4e8c\uff0c \u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807 # \u6211\u4eec\u4ee5\u91d1\u878d\u98ce\u63a7\u9886\u57df\u5e38\u7528\u7684KS\u6307\u6807\u4e3a\u4f8b\uff0c\u793a\u8303\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u3002 KS\u6307\u6807\u9002\u5408\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u5176\u8ba1\u7b97\u65b9\u5f0f\u4e3a KS=max(TPR-FPR). \u5176\u4e2dTPR=TP/(TP+FN) , FPR = FP/(FP+TN) TPR\u66f2\u7ebf\u5b9e\u9645\u4e0a\u5c31\u662f\u6b63\u6837\u672c\u7684\u7d2f\u79ef\u5206\u5e03\u66f2\u7ebf(CDF)\uff0cFPR\u66f2\u7ebf\u5b9e\u9645\u4e0a\u5c31\u662f\u8d1f\u6837\u672c\u7684\u7d2f\u79ef\u5206\u5e03\u66f2\u7ebf(CDF)\u3002 KS\u6307\u6807\u5c31\u662f\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7d2f\u79ef\u5206\u5e03\u66f2\u7ebf\u5dee\u503c\u7684\u6700\u5927\u503c\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics #\u51fd\u6570\u5f62\u5f0f\u7684\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807 @tf . function def ks ( y_true , y_pred ): y_true = tf . reshape ( y_true ,( - 1 ,)) y_pred = tf . reshape ( y_pred ,( - 1 ,)) length = tf . shape ( y_true )[ 0 ] t = tf . math . top_k ( y_pred , k = length , sorted = False ) y_pred_sorted = tf . gather ( y_pred , t . indices ) y_true_sorted = tf . gather ( y_true , t . indices ) cum_positive_ratio = tf . truediv ( tf . cumsum ( y_true_sorted ), tf . reduce_sum ( y_true_sorted )) cum_negative_ratio = tf . truediv ( tf . cumsum ( 1 - y_true_sorted ), tf . reduce_sum ( 1 - y_true_sorted )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ],[ 0.7 ], [ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) tf . print ( ks ( y_true , y_pred )) 0.625 #\u7c7b\u5f62\u5f0f\u7684\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807 class KS ( metrics . Metric ): def __init__ ( self , name = \"ks\" , ** kwargs ): super ( KS , self ) . __init__ ( name = name , ** kwargs ) self . true_positives = self . add_weight ( name = \"tp\" , shape = ( 101 ,), initializer = \"zeros\" ) self . false_positives = self . add_weight ( name = \"fp\" , shape = ( 101 ,), initializer = \"zeros\" ) @tf . function def update_state ( self , y_true , y_pred ): y_true = tf . cast ( tf . reshape ( y_true ,( - 1 ,)), tf . bool ) y_pred = tf . cast ( 100 * tf . reshape ( y_pred ,( - 1 ,)), tf . int32 ) for i in tf . range ( 0 , tf . shape ( y_true )[ 0 ]): if y_true [ i ]: self . true_positives [ y_pred [ i ]] . assign ( self . true_positives [ y_pred [ i ]] + 1.0 ) else : self . false_positives [ y_pred [ i ]] . assign ( self . false_positives [ y_pred [ i ]] + 1.0 ) return ( self . true_positives , self . false_positives ) @tf . function def result ( self ): cum_positive_ratio = tf . truediv ( tf . cumsum ( self . true_positives ), tf . reduce_sum ( self . true_positives )) cum_negative_ratio = tf . truediv ( tf . cumsum ( self . false_positives ), tf . reduce_sum ( self . false_positives )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ], [ 0.7 ],[ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) myks = KS () myks . update_state ( y_true , y_pred ) tf . print ( myks . result ()) 0.625 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-6,\u8bc4\u4f30\u6307\u6807metrics"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-6%2C%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87metrics/#5-6\u8bc4\u4f30\u6307\u6807metrics","text":"\u635f\u5931\u51fd\u6570\u9664\u4e86\u4f5c\u4e3a\u6a21\u578b\u8bad\u7ec3\u65f6\u5019\u7684\u4f18\u5316\u76ee\u6807\uff0c\u4e5f\u80fd\u591f\u4f5c\u4e3a\u6a21\u578b\u597d\u574f\u7684\u4e00\u79cd\u8bc4\u4ef7\u6307\u6807\u3002\u4f46\u901a\u5e38\u4eba\u4eec\u8fd8\u4f1a\u4ece\u5176\u5b83\u89d2\u5ea6\u8bc4\u4f30\u6a21\u578b\u7684\u597d\u574f\u3002 \u8fd9\u5c31\u662f\u8bc4\u4f30\u6307\u6807\u3002\u901a\u5e38\u635f\u5931\u51fd\u6570\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5982MAE,MSE,CategoricalCrossentropy\u7b49\u4e5f\u662f\u5e38\u7528\u7684\u8bc4\u4f30\u6307\u6807\u3002 \u4f46\u8bc4\u4f30\u6307\u6807\u4e0d\u4e00\u5b9a\u53ef\u4ee5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f8b\u5982AUC,Accuracy,Precision\u3002\u56e0\u4e3a\u8bc4\u4f30\u6307\u6807\u4e0d\u8981\u6c42\u8fde\u7eed\u53ef\u5bfc\uff0c\u800c\u635f\u5931\u51fd\u6570\u901a\u5e38\u8981\u6c42\u8fde\u7eed\u53ef\u5bfc\u3002 \u7f16\u8bd1\u6a21\u578b\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u5217\u8868\u5f62\u5f0f\u6307\u5b9a\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u3002 \u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u9700\u8981\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_true,y_pred\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u8bc4\u4f30\u503c\u3002 \u4e5f\u53ef\u4ee5\u5bf9tf.keras.metrics.Metric\u8fdb\u884c\u5b50\u7c7b\u5316\uff0c\u91cd\u5199\u521d\u59cb\u5316\u65b9\u6cd5, update_state\u65b9\u6cd5, result\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u4f30\u6307\u6807\u7684\u8ba1\u7b97\u903b\u8f91\uff0c\u4ece\u800c\u5f97\u5230\u8bc4\u4f30\u6307\u6807\u7684\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002 \u7531\u4e8e\u8bad\u7ec3\u7684\u8fc7\u7a0b\u901a\u5e38\u662f\u5206\u6279\u6b21\u8bad\u7ec3\u7684\uff0c\u800c\u8bc4\u4f30\u6307\u6807\u8981\u8dd1\u5b8c\u4e00\u4e2aepoch\u624d\u80fd\u591f\u5f97\u5230\u6574\u4f53\u7684\u6307\u6807\u7ed3\u679c\u3002\u56e0\u6b64\uff0c\u7c7b\u5f62\u5f0f\u7684\u8bc4\u4f30\u6307\u6807\u66f4\u4e3a\u5e38\u89c1\u3002\u5373\u9700\u8981\u7f16\u5199\u521d\u59cb\u5316\u65b9\u6cd5\u4ee5\u521b\u5efa\u4e0e\u8ba1\u7b97\u6307\u6807\u7ed3\u679c\u76f8\u5173\u7684\u4e00\u4e9b\u4e2d\u95f4\u53d8\u91cf\uff0c\u7f16\u5199update_state\u65b9\u6cd5\u5728\u6bcf\u4e2abatch\u540e\u66f4\u65b0\u76f8\u5173\u4e2d\u95f4\u53d8\u91cf\u7684\u72b6\u6001\uff0c\u7f16\u5199result\u65b9\u6cd5\u8f93\u51fa\u6700\u7ec8\u6307\u6807\u7ed3\u679c\u3002 \u5982\u679c\u7f16\u5199\u51fd\u6570\u5f62\u5f0f\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u5219\u53ea\u80fd\u53d6epoch\u4e2d\u5404\u4e2abatch\u8ba1\u7b97\u7684\u8bc4\u4f30\u6307\u6807\u7ed3\u679c\u7684\u5e73\u5747\u503c\u4f5c\u4e3a\u6574\u4e2aepoch\u4e0a\u7684\u8bc4\u4f30\u6307\u6807\u7ed3\u679c\uff0c\u8fd9\u4e2a\u7ed3\u679c\u901a\u5e38\u4f1a\u504f\u79bb\u6574\u4e2aepoch\u6570\u636e\u4e00\u6b21\u8ba1\u7b97\u7684\u7ed3\u679c\u3002","title":"5-6,\u8bc4\u4f30\u6307\u6807metrics"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-6%2C%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87metrics/#\u4e00\u5e38\u7528\u7684\u5185\u7f6e\u8bc4\u4f30\u6307\u6807","text":"MeanSquaredError\uff08\u5747\u65b9\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u53ef\u4ee5\u7b80\u5199\u4e3aMSE\uff0c\u51fd\u6570\u5f62\u5f0f\u4e3amse\uff09 MeanAbsoluteError (\u5e73\u5747\u7edd\u5bf9\u503c\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u53ef\u4ee5\u7b80\u5199\u4e3aMAE\uff0c\u51fd\u6570\u5f62\u5f0f\u4e3amae) MeanAbsolutePercentageError (\u5e73\u5747\u767e\u5206\u6bd4\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52\uff0c\u53ef\u4ee5\u7b80\u5199\u4e3aMAPE\uff0c\u51fd\u6570\u5f62\u5f0f\u4e3amape) RootMeanSquaredError (\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u7528\u4e8e\u56de\u5f52) Accuracy (\u51c6\u786e\u7387\uff0c\u7528\u4e8e\u5206\u7c7b\uff0c\u53ef\u4ee5\u7528\u5b57\u7b26\u4e32\"Accuracy\"\u8868\u793a\uff0cAccuracy=(TP+TN)/(TP+TN+FP+FN)\uff0c\u8981\u6c42y_true\u548cy_pred\u90fd\u4e3a\u7c7b\u522b\u5e8f\u53f7\u7f16\u7801) Precision (\u7cbe\u786e\u7387\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0cPrecision = TP/(TP+FP)) Recall (\u53ec\u56de\u7387\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0cRecall = TP/(TP+FN)) TruePositives (\u771f\u6b63\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) TrueNegatives (\u771f\u8d1f\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) FalsePositives (\u5047\u6b63\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) FalseNegatives (\u5047\u8d1f\u4f8b\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b) AUC(ROC\u66f2\u7ebf(TPR vs FPR)\u4e0b\u7684\u9762\u79ef\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u76f4\u89c2\u89e3\u91ca\u4e3a\u968f\u673a\u62bd\u53d6\u4e00\u4e2a\u6b63\u6837\u672c\u548c\u4e00\u4e2a\u8d1f\u6837\u672c\uff0c\u6b63\u6837\u672c\u7684\u9884\u6d4b\u503c\u5927\u4e8e\u8d1f\u6837\u672c\u7684\u6982\u7387) CategoricalAccuracy\uff08\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4e0eAccuracy\u542b\u4e49\u76f8\u540c\uff0c\u8981\u6c42y_true(label)\u4e3aonehot\u7f16\u7801\u5f62\u5f0f\uff09 SparseCategoricalAccuracy (\u7a00\u758f\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4e0eAccuracy\u542b\u4e49\u76f8\u540c\uff0c\u8981\u6c42y_true(label)\u4e3a\u5e8f\u53f7\u7f16\u7801\u5f62\u5f0f) MeanIoU (Intersection-Over-Union\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u5206\u5272) TopKCategoricalAccuracy (\u591a\u5206\u7c7bTopK\u51c6\u786e\u7387\uff0c\u8981\u6c42y_true(label)\u4e3aonehot\u7f16\u7801\u5f62\u5f0f) SparseTopKCategoricalAccuracy (\u7a00\u758f\u591a\u5206\u7c7bTopK\u51c6\u786e\u7387\uff0c\u8981\u6c42y_true(label)\u4e3a\u5e8f\u53f7\u7f16\u7801\u5f62\u5f0f) Mean (\u5e73\u5747\u503c) Sum (\u6c42\u548c)","title":"\u4e00\uff0c\u5e38\u7528\u7684\u5185\u7f6e\u8bc4\u4f30\u6307\u6807"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-6%2C%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87metrics/#\u4e8c-\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807","text":"\u6211\u4eec\u4ee5\u91d1\u878d\u98ce\u63a7\u9886\u57df\u5e38\u7528\u7684KS\u6307\u6807\u4e3a\u4f8b\uff0c\u793a\u8303\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u3002 KS\u6307\u6807\u9002\u5408\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u5176\u8ba1\u7b97\u65b9\u5f0f\u4e3a KS=max(TPR-FPR). \u5176\u4e2dTPR=TP/(TP+FN) , FPR = FP/(FP+TN) TPR\u66f2\u7ebf\u5b9e\u9645\u4e0a\u5c31\u662f\u6b63\u6837\u672c\u7684\u7d2f\u79ef\u5206\u5e03\u66f2\u7ebf(CDF)\uff0cFPR\u66f2\u7ebf\u5b9e\u9645\u4e0a\u5c31\u662f\u8d1f\u6837\u672c\u7684\u7d2f\u79ef\u5206\u5e03\u66f2\u7ebf(CDF)\u3002 KS\u6307\u6807\u5c31\u662f\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7d2f\u79ef\u5206\u5e03\u66f2\u7ebf\u5dee\u503c\u7684\u6700\u5927\u503c\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics #\u51fd\u6570\u5f62\u5f0f\u7684\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807 @tf . function def ks ( y_true , y_pred ): y_true = tf . reshape ( y_true ,( - 1 ,)) y_pred = tf . reshape ( y_pred ,( - 1 ,)) length = tf . shape ( y_true )[ 0 ] t = tf . math . top_k ( y_pred , k = length , sorted = False ) y_pred_sorted = tf . gather ( y_pred , t . indices ) y_true_sorted = tf . gather ( y_true , t . indices ) cum_positive_ratio = tf . truediv ( tf . cumsum ( y_true_sorted ), tf . reduce_sum ( y_true_sorted )) cum_negative_ratio = tf . truediv ( tf . cumsum ( 1 - y_true_sorted ), tf . reduce_sum ( 1 - y_true_sorted )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ],[ 0.7 ], [ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) tf . print ( ks ( y_true , y_pred )) 0.625 #\u7c7b\u5f62\u5f0f\u7684\u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807 class KS ( metrics . Metric ): def __init__ ( self , name = \"ks\" , ** kwargs ): super ( KS , self ) . __init__ ( name = name , ** kwargs ) self . true_positives = self . add_weight ( name = \"tp\" , shape = ( 101 ,), initializer = \"zeros\" ) self . false_positives = self . add_weight ( name = \"fp\" , shape = ( 101 ,), initializer = \"zeros\" ) @tf . function def update_state ( self , y_true , y_pred ): y_true = tf . cast ( tf . reshape ( y_true ,( - 1 ,)), tf . bool ) y_pred = tf . cast ( 100 * tf . reshape ( y_pred ,( - 1 ,)), tf . int32 ) for i in tf . range ( 0 , tf . shape ( y_true )[ 0 ]): if y_true [ i ]: self . true_positives [ y_pred [ i ]] . assign ( self . true_positives [ y_pred [ i ]] + 1.0 ) else : self . false_positives [ y_pred [ i ]] . assign ( self . false_positives [ y_pred [ i ]] + 1.0 ) return ( self . true_positives , self . false_positives ) @tf . function def result ( self ): cum_positive_ratio = tf . truediv ( tf . cumsum ( self . true_positives ), tf . reduce_sum ( self . true_positives )) cum_negative_ratio = tf . truediv ( tf . cumsum ( self . false_positives ), tf . reduce_sum ( self . false_positives )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ], [ 0.7 ],[ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) myks = KS () myks . update_state ( y_true , y_pred ) tf . print ( myks . result ()) 0.625 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c \u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-7%2C%E4%BC%98%E5%8C%96%E5%99%A8optimizers/","text":"5-7,\u4f18\u5316\u5668optimizers # \u673a\u5668\u5b66\u4e60\u754c\u6709\u4e00\u7fa4\u70bc\u4e39\u5e08\uff0c\u4ed6\u4eec\u6bcf\u5929\u7684\u65e5\u5e38\u662f\uff1a \u62ff\u6765\u836f\u6750\uff08\u6570\u636e\uff09\uff0c\u67b6\u8d77\u516b\u5366\u7089\uff08\u6a21\u578b\uff09\uff0c\u70b9\u7740\u516d\u5473\u771f\u706b\uff08\u4f18\u5316\u7b97\u6cd5\uff09\uff0c\u5c31\u6447\u7740\u84b2\u6247\u7b49\u7740\u4e39\u836f\u51fa\u7089\u4e86\u3002 \u4e0d\u8fc7\uff0c\u5f53\u8fc7\u53a8\u5b50\u7684\u90fd\u77e5\u9053\uff0c\u540c\u6837\u7684\u98df\u6750\uff0c\u540c\u6837\u7684\u83dc\u8c31\uff0c\u4f46\u706b\u5019\u4e0d\u4e00\u6837\u4e86\uff0c\u8fd9\u51fa\u6765\u7684\u53e3\u5473\u53ef\u662f\u5343\u5dee\u4e07\u522b\u3002\u706b\u5c0f\u4e86\u5939\u751f\uff0c\u706b\u5927\u4e86\u6613\u7cca\uff0c\u706b\u4e0d\u5300\u5219\u534a\u751f\u534a\u7cca\u3002 \u673a\u5668\u5b66\u4e60\u4e5f\u662f\u4e00\u6837\uff0c\u6a21\u578b\u4f18\u5316\u7b97\u6cd5\u7684\u9009\u62e9\u76f4\u63a5\u5173\u7cfb\u5230\u6700\u7ec8\u6a21\u578b\u7684\u6027\u80fd\u3002\u6709\u65f6\u5019\u6548\u679c\u4e0d\u597d\uff0c\u672a\u5fc5\u662f\u7279\u5f81\u7684\u95ee\u9898\u6216\u8005\u6a21\u578b\u8bbe\u8ba1\u7684\u95ee\u9898\uff0c\u5f88\u53ef\u80fd\u5c31\u662f\u4f18\u5316\u7b97\u6cd5\u7684\u95ee\u9898\u3002 \u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u5927\u6982\u7ecf\u5386\u4e86 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam \u8fd9\u6837\u7684\u53d1\u5c55\u5386\u7a0b\u3002 \u8be6\u89c1\u300a\u4e00\u4e2a\u6846\u67b6\u770b\u61c2\u4f18\u5316\u7b97\u6cd5\u4e4b\u5f02\u540c SGD/AdaGrad/Adam\u300b https://zhuanlan.zhihu.com/p/32230623 \u5bf9\u4e8e\u4e00\u822c\u65b0\u624b\u70bc\u4e39\u5e08\uff0c\u4f18\u5316\u5668\u76f4\u63a5\u4f7f\u7528Adam\uff0c\u5e76\u4f7f\u7528\u5176\u9ed8\u8ba4\u53c2\u6570\u5c31OK\u4e86\u3002 \u4e00\u4e9b\u7231\u5199\u8bba\u6587\u7684\u70bc\u4e39\u5e08\u7531\u4e8e\u8ffd\u6c42\u8bc4\u4f30\u6307\u6807\u6548\u679c\uff0c\u53ef\u80fd\u4f1a\u504f\u7231\u524d\u671f\u4f7f\u7528Adam\u4f18\u5316\u5668\u5feb\u901f\u4e0b\u964d\uff0c\u540e\u671f\u4f7f\u7528SGD\u5e76\u7cbe\u8c03\u4f18\u5316\u5668\u53c2\u6570\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002 \u6b64\u5916\u76ee\u524d\u4e5f\u6709\u4e00\u4e9b\u524d\u6cbf\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u636e\u79f0\u6548\u679c\u6bd4Adam\u66f4\u597d\uff0c\u4f8b\u5982LazyAdam, Look-ahead, RAdam, Ranger\u7b49. \u4e00\uff0c\u4f18\u5316\u5668\u7684\u4f7f\u7528 # \u4f18\u5316\u5668\u4e3b\u8981\u4f7f\u7528apply_gradients\u65b9\u6cd5\u4f20\u5165\u53d8\u91cf\u548c\u5bf9\u5e94\u68af\u5ea6\u4ece\u800c\u6765\u5bf9\u7ed9\u5b9a\u53d8\u91cf\u8fdb\u884c\u8fed\u4ee3\uff0c\u6216\u8005\u76f4\u63a5\u4f7f\u7528minimize\u65b9\u6cd5\u5bf9\u76ee\u6807\u51fd\u6570\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002 \u5f53\u7136\uff0c\u66f4\u5e38\u89c1\u7684\u4f7f\u7528\u662f\u5728\u7f16\u8bd1\u65f6\u5c06\u4f18\u5316\u5668\u4f20\u5165keras\u7684Model,\u901a\u8fc7\u8c03\u7528model.fit\u5b9e\u73b0\u5bf9Loss\u7684\u7684\u8fed\u4ee3\u4f18\u5316\u3002 \u521d\u59cb\u5316\u4f18\u5316\u5668\u65f6\u4f1a\u521b\u5efa\u4e00\u4e2a\u53d8\u91cfoptimier.iterations\u7528\u4e8e\u8bb0\u5f55\u8fed\u4ee3\u7684\u6b21\u6570\u3002\u56e0\u6b64\u4f18\u5316\u5668\u548ctf.Variable\u4e00\u6837\uff0c\u4e00\u822c\u9700\u8981\u5728@tf.function\u5916\u521b\u5efa\u3002 import tensorflow as tf import numpy as np #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) while tf . constant ( True ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) #\u8fed\u4ee3\u7ec8\u6b62\u6761\u4ef6 if tf . abs ( dy_dx ) < tf . constant ( 0.00001 ): break if tf . math . mod ( optimizer . iterations , 100 ) == 0 : printbar () tf . print ( \"step = \" , optimizer . iterations ) tf . print ( \"x = \" , x ) tf . print ( \"\" ) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( \"y =\" , minimizef ()) tf . print ( \"x =\" , x ) # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch = 1000 ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) tf . print ( \"epoch = \" , optimizer . iterations ) return ( f ()) train ( 1000 ) tf . print ( \"y = \" , f ()) tf . print ( \"x = \" , x ) # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528model.fit tf . keras . backend . clear_session () class FakeModel ( tf . keras . models . Model ): def __init__ ( self , a , b , c ): super ( FakeModel , self ) . __init__ () self . a = a self . b = b self . c = c def build ( self ): self . x = tf . Variable ( 0.0 , name = \"x\" ) self . built = True def call ( self , features ): loss = self . a * ( self . x ) ** 2 + self . b * ( self . x ) + self . c return ( tf . ones_like ( features ) * loss ) def myloss ( y_true , y_pred ): return tf . reduce_mean ( y_pred ) model = FakeModel ( tf . constant ( 1.0 ), tf . constant ( - 2.0 ), tf . constant ( 1.0 )) model . build () model . summary () model . compile ( optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ), loss = myloss ) history = model . fit ( tf . zeros (( 100 , 2 )), tf . ones ( 100 ), batch_size = 1 , epochs = 10 ) #\u8fed\u4ee31000\u6b21 tf . print ( \"x=\" , model . x ) tf . print ( \"loss=\" , model ( tf . constant ( 0.0 ))) \u4e8c\uff0c\u5185\u7f6e\u4f18\u5316\u5668 # \u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u5927\u6982\u7ecf\u5386\u4e86 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam \u8fd9\u6837\u7684\u53d1\u5c55\u5386\u7a0b\u3002 \u5728keras.optimizers\u5b50\u6a21\u5757\u4e2d\uff0c\u5b83\u4eec\u57fa\u672c\u4e0a\u90fd\u6709\u5bf9\u5e94\u7684\u7c7b\u7684\u5b9e\u73b0\u3002 SGD, \u9ed8\u8ba4\u53c2\u6570\u4e3a\u7eafSGD, \u8bbe\u7f6emomentum\u53c2\u6570\u4e0d\u4e3a0\u5b9e\u9645\u4e0a\u53d8\u6210SGDM, \u8003\u8651\u4e86\u4e00\u9636\u52a8\u91cf, \u8bbe\u7f6e nesterov\u4e3aTrue\u540e\u53d8\u6210NAG\uff0c\u5373 Nesterov Accelerated Gradient\uff0c\u5728\u8ba1\u7b97\u68af\u5ea6\u65f6\u8ba1\u7b97\u7684\u662f\u5411\u524d\u8d70\u4e00\u6b65\u6240\u5728\u4f4d\u7f6e\u7684\u68af\u5ea6\u3002 Adagrad, \u8003\u8651\u4e86\u4e8c\u9636\u52a8\u91cf\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u53c2\u6570\u6709\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u5373\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u3002\u7f3a\u70b9\u662f\u5b66\u4e60\u7387\u5355\u8c03\u4e0b\u964d\uff0c\u53ef\u80fd\u540e\u671f\u5b66\u4e60\u901f\u7387\u8fc7\u6162\u4e43\u81f3\u63d0\u524d\u505c\u6b62\u5b66\u4e60\u3002 RMSprop, \u8003\u8651\u4e86\u4e8c\u9636\u52a8\u91cf\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u53c2\u6570\u6709\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u5373\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u5bf9Adagrad\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u901a\u8fc7\u6307\u6570\u5e73\u6ed1\u53ea\u8003\u8651\u4e00\u5b9a\u7a97\u53e3\u5185\u7684\u4e8c\u9636\u52a8\u91cf\u3002 Adadelta, \u8003\u8651\u4e86\u4e8c\u9636\u52a8\u91cf\uff0c\u4e0eRMSprop\u7c7b\u4f3c\uff0c\u4f46\u662f\u66f4\u52a0\u590d\u6742\u4e00\u4e9b\uff0c\u81ea\u9002\u5e94\u6027\u66f4\u5f3a\u3002 Adam, \u540c\u65f6\u8003\u8651\u4e86\u4e00\u9636\u52a8\u91cf\u548c\u4e8c\u9636\u52a8\u91cf\uff0c\u53ef\u4ee5\u770b\u6210RMSprop\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u4e86\u4e00\u9636\u52a8\u91cf\u3002 Nadam, \u5728Adam\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u4e86 Nesterov Acceleration\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-7,\u4f18\u5316\u5668optimizers"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-7%2C%E4%BC%98%E5%8C%96%E5%99%A8optimizers/#5-7\u4f18\u5316\u5668optimizers","text":"\u673a\u5668\u5b66\u4e60\u754c\u6709\u4e00\u7fa4\u70bc\u4e39\u5e08\uff0c\u4ed6\u4eec\u6bcf\u5929\u7684\u65e5\u5e38\u662f\uff1a \u62ff\u6765\u836f\u6750\uff08\u6570\u636e\uff09\uff0c\u67b6\u8d77\u516b\u5366\u7089\uff08\u6a21\u578b\uff09\uff0c\u70b9\u7740\u516d\u5473\u771f\u706b\uff08\u4f18\u5316\u7b97\u6cd5\uff09\uff0c\u5c31\u6447\u7740\u84b2\u6247\u7b49\u7740\u4e39\u836f\u51fa\u7089\u4e86\u3002 \u4e0d\u8fc7\uff0c\u5f53\u8fc7\u53a8\u5b50\u7684\u90fd\u77e5\u9053\uff0c\u540c\u6837\u7684\u98df\u6750\uff0c\u540c\u6837\u7684\u83dc\u8c31\uff0c\u4f46\u706b\u5019\u4e0d\u4e00\u6837\u4e86\uff0c\u8fd9\u51fa\u6765\u7684\u53e3\u5473\u53ef\u662f\u5343\u5dee\u4e07\u522b\u3002\u706b\u5c0f\u4e86\u5939\u751f\uff0c\u706b\u5927\u4e86\u6613\u7cca\uff0c\u706b\u4e0d\u5300\u5219\u534a\u751f\u534a\u7cca\u3002 \u673a\u5668\u5b66\u4e60\u4e5f\u662f\u4e00\u6837\uff0c\u6a21\u578b\u4f18\u5316\u7b97\u6cd5\u7684\u9009\u62e9\u76f4\u63a5\u5173\u7cfb\u5230\u6700\u7ec8\u6a21\u578b\u7684\u6027\u80fd\u3002\u6709\u65f6\u5019\u6548\u679c\u4e0d\u597d\uff0c\u672a\u5fc5\u662f\u7279\u5f81\u7684\u95ee\u9898\u6216\u8005\u6a21\u578b\u8bbe\u8ba1\u7684\u95ee\u9898\uff0c\u5f88\u53ef\u80fd\u5c31\u662f\u4f18\u5316\u7b97\u6cd5\u7684\u95ee\u9898\u3002 \u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u5927\u6982\u7ecf\u5386\u4e86 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam \u8fd9\u6837\u7684\u53d1\u5c55\u5386\u7a0b\u3002 \u8be6\u89c1\u300a\u4e00\u4e2a\u6846\u67b6\u770b\u61c2\u4f18\u5316\u7b97\u6cd5\u4e4b\u5f02\u540c SGD/AdaGrad/Adam\u300b https://zhuanlan.zhihu.com/p/32230623 \u5bf9\u4e8e\u4e00\u822c\u65b0\u624b\u70bc\u4e39\u5e08\uff0c\u4f18\u5316\u5668\u76f4\u63a5\u4f7f\u7528Adam\uff0c\u5e76\u4f7f\u7528\u5176\u9ed8\u8ba4\u53c2\u6570\u5c31OK\u4e86\u3002 \u4e00\u4e9b\u7231\u5199\u8bba\u6587\u7684\u70bc\u4e39\u5e08\u7531\u4e8e\u8ffd\u6c42\u8bc4\u4f30\u6307\u6807\u6548\u679c\uff0c\u53ef\u80fd\u4f1a\u504f\u7231\u524d\u671f\u4f7f\u7528Adam\u4f18\u5316\u5668\u5feb\u901f\u4e0b\u964d\uff0c\u540e\u671f\u4f7f\u7528SGD\u5e76\u7cbe\u8c03\u4f18\u5316\u5668\u53c2\u6570\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002 \u6b64\u5916\u76ee\u524d\u4e5f\u6709\u4e00\u4e9b\u524d\u6cbf\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u636e\u79f0\u6548\u679c\u6bd4Adam\u66f4\u597d\uff0c\u4f8b\u5982LazyAdam, Look-ahead, RAdam, Ranger\u7b49.","title":"5-7,\u4f18\u5316\u5668optimizers"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-7%2C%E4%BC%98%E5%8C%96%E5%99%A8optimizers/#\u4e00\u4f18\u5316\u5668\u7684\u4f7f\u7528","text":"\u4f18\u5316\u5668\u4e3b\u8981\u4f7f\u7528apply_gradients\u65b9\u6cd5\u4f20\u5165\u53d8\u91cf\u548c\u5bf9\u5e94\u68af\u5ea6\u4ece\u800c\u6765\u5bf9\u7ed9\u5b9a\u53d8\u91cf\u8fdb\u884c\u8fed\u4ee3\uff0c\u6216\u8005\u76f4\u63a5\u4f7f\u7528minimize\u65b9\u6cd5\u5bf9\u76ee\u6807\u51fd\u6570\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002 \u5f53\u7136\uff0c\u66f4\u5e38\u89c1\u7684\u4f7f\u7528\u662f\u5728\u7f16\u8bd1\u65f6\u5c06\u4f18\u5316\u5668\u4f20\u5165keras\u7684Model,\u901a\u8fc7\u8c03\u7528model.fit\u5b9e\u73b0\u5bf9Loss\u7684\u7684\u8fed\u4ee3\u4f18\u5316\u3002 \u521d\u59cb\u5316\u4f18\u5316\u5668\u65f6\u4f1a\u521b\u5efa\u4e00\u4e2a\u53d8\u91cfoptimier.iterations\u7528\u4e8e\u8bb0\u5f55\u8fed\u4ee3\u7684\u6b21\u6570\u3002\u56e0\u6b64\u4f18\u5316\u5668\u548ctf.Variable\u4e00\u6837\uff0c\u4e00\u822c\u9700\u8981\u5728@tf.function\u5916\u521b\u5efa\u3002 import tensorflow as tf import numpy as np #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) while tf . constant ( True ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) #\u8fed\u4ee3\u7ec8\u6b62\u6761\u4ef6 if tf . abs ( dy_dx ) < tf . constant ( 0.00001 ): break if tf . math . mod ( optimizer . iterations , 100 ) == 0 : printbar () tf . print ( \"step = \" , optimizer . iterations ) tf . print ( \"x = \" , x ) tf . print ( \"\" ) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( \"y =\" , minimizef ()) tf . print ( \"x =\" , x ) # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch = 1000 ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) tf . print ( \"epoch = \" , optimizer . iterations ) return ( f ()) train ( 1000 ) tf . print ( \"y = \" , f ()) tf . print ( \"x = \" , x ) # \u6c42f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c # \u4f7f\u7528model.fit tf . keras . backend . clear_session () class FakeModel ( tf . keras . models . Model ): def __init__ ( self , a , b , c ): super ( FakeModel , self ) . __init__ () self . a = a self . b = b self . c = c def build ( self ): self . x = tf . Variable ( 0.0 , name = \"x\" ) self . built = True def call ( self , features ): loss = self . a * ( self . x ) ** 2 + self . b * ( self . x ) + self . c return ( tf . ones_like ( features ) * loss ) def myloss ( y_true , y_pred ): return tf . reduce_mean ( y_pred ) model = FakeModel ( tf . constant ( 1.0 ), tf . constant ( - 2.0 ), tf . constant ( 1.0 )) model . build () model . summary () model . compile ( optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ), loss = myloss ) history = model . fit ( tf . zeros (( 100 , 2 )), tf . ones ( 100 ), batch_size = 1 , epochs = 10 ) #\u8fed\u4ee31000\u6b21 tf . print ( \"x=\" , model . x ) tf . print ( \"loss=\" , model ( tf . constant ( 0.0 )))","title":"\u4e00\uff0c\u4f18\u5316\u5668\u7684\u4f7f\u7528"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-7%2C%E4%BC%98%E5%8C%96%E5%99%A8optimizers/#\u4e8c\u5185\u7f6e\u4f18\u5316\u5668","text":"\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u5927\u6982\u7ecf\u5386\u4e86 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam \u8fd9\u6837\u7684\u53d1\u5c55\u5386\u7a0b\u3002 \u5728keras.optimizers\u5b50\u6a21\u5757\u4e2d\uff0c\u5b83\u4eec\u57fa\u672c\u4e0a\u90fd\u6709\u5bf9\u5e94\u7684\u7c7b\u7684\u5b9e\u73b0\u3002 SGD, \u9ed8\u8ba4\u53c2\u6570\u4e3a\u7eafSGD, \u8bbe\u7f6emomentum\u53c2\u6570\u4e0d\u4e3a0\u5b9e\u9645\u4e0a\u53d8\u6210SGDM, \u8003\u8651\u4e86\u4e00\u9636\u52a8\u91cf, \u8bbe\u7f6e nesterov\u4e3aTrue\u540e\u53d8\u6210NAG\uff0c\u5373 Nesterov Accelerated Gradient\uff0c\u5728\u8ba1\u7b97\u68af\u5ea6\u65f6\u8ba1\u7b97\u7684\u662f\u5411\u524d\u8d70\u4e00\u6b65\u6240\u5728\u4f4d\u7f6e\u7684\u68af\u5ea6\u3002 Adagrad, \u8003\u8651\u4e86\u4e8c\u9636\u52a8\u91cf\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u53c2\u6570\u6709\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u5373\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u3002\u7f3a\u70b9\u662f\u5b66\u4e60\u7387\u5355\u8c03\u4e0b\u964d\uff0c\u53ef\u80fd\u540e\u671f\u5b66\u4e60\u901f\u7387\u8fc7\u6162\u4e43\u81f3\u63d0\u524d\u505c\u6b62\u5b66\u4e60\u3002 RMSprop, \u8003\u8651\u4e86\u4e8c\u9636\u52a8\u91cf\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u53c2\u6570\u6709\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u5373\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u5bf9Adagrad\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u901a\u8fc7\u6307\u6570\u5e73\u6ed1\u53ea\u8003\u8651\u4e00\u5b9a\u7a97\u53e3\u5185\u7684\u4e8c\u9636\u52a8\u91cf\u3002 Adadelta, \u8003\u8651\u4e86\u4e8c\u9636\u52a8\u91cf\uff0c\u4e0eRMSprop\u7c7b\u4f3c\uff0c\u4f46\u662f\u66f4\u52a0\u590d\u6742\u4e00\u4e9b\uff0c\u81ea\u9002\u5e94\u6027\u66f4\u5f3a\u3002 Adam, \u540c\u65f6\u8003\u8651\u4e86\u4e00\u9636\u52a8\u91cf\u548c\u4e8c\u9636\u52a8\u91cf\uff0c\u53ef\u4ee5\u770b\u6210RMSprop\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u4e86\u4e00\u9636\u52a8\u91cf\u3002 Nadam, \u5728Adam\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u4e86 Nesterov Acceleration\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u5185\u7f6e\u4f18\u5316\u5668"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-8%2C%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0callbacks/","text":"5-8,\u56de\u8c03\u51fd\u6570callbacks # tf.keras\u7684\u56de\u8c03\u51fd\u6570\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u7c7b\uff0c\u4e00\u822c\u662f\u5728model.fit\u65f6\u4f5c\u4e3a\u53c2\u6570\u6307\u5b9a\uff0c\u7528\u4e8e\u63a7\u5236\u5728\u8bad\u7ec3\u8fc7\u7a0b\u5f00\u59cb\u6216\u8005\u5728\u8bad\u7ec3\u8fc7\u7a0b\u7ed3\u675f\uff0c\u5728\u6bcf\u4e2aepoch\u8bad\u7ec3\u5f00\u59cb\u6216\u8005\u8bad\u7ec3\u7ed3\u675f\uff0c\u5728\u6bcf\u4e2abatch\u8bad\u7ec3\u5f00\u59cb\u6216\u8005\u8bad\u7ec3\u7ed3\u675f\u65f6\u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\uff0c\u4f8b\u5982\u6536\u96c6\u4e00\u4e9b\u65e5\u5fd7\u4fe1\u606f\uff0c\u6539\u53d8\u5b66\u4e60\u7387\u7b49\u8d85\u53c2\u6570\uff0c\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u7b49\u7b49\u3002 \u540c\u6837\u5730\uff0c\u9488\u5bf9model.evaluate\u6216\u8005model.predict\u4e5f\u53ef\u4ee5\u6307\u5b9acallbacks\u53c2\u6570\uff0c\u7528\u4e8e\u63a7\u5236\u5728\u8bc4\u4f30\u6216\u9884\u6d4b\u5f00\u59cb\u6216\u8005\u7ed3\u675f\u65f6\uff0c\u5728\u6bcf\u4e2abatch\u5f00\u59cb\u6216\u8005\u7ed3\u675f\u65f6\u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\uff0c\u4f46\u8fd9\u79cd\u7528\u6cd5\u76f8\u5bf9\u5c11\u89c1\u3002 \u5927\u90e8\u5206\u65f6\u5019\uff0ckeras.callbacks\u5b50\u6a21\u5757\u4e2d\u5b9a\u4e49\u7684\u56de\u8c03\u51fd\u6570\u7c7b\u5df2\u7ecf\u8db3\u591f\u4f7f\u7528\u4e86\uff0c\u5982\u679c\u6709\u7279\u5b9a\u7684\u9700\u8981\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5bf9keras.callbacks.Callbacks\u5b9e\u65bd\u5b50\u7c7b\u5316\u6784\u9020\u81ea\u5b9a\u4e49\u7684\u56de\u8c03\u51fd\u6570\u3002 \u6240\u6709\u56de\u8c03\u51fd\u6570\u90fd\u7ee7\u627f\u81f3 keras.callbacks.Callbacks\u57fa\u7c7b\uff0c\u62e5\u6709params\u548cmodel\u8fd9\u4e24\u4e2a\u5c5e\u6027\u3002 \u5176\u4e2dparams \u662f\u4e00\u4e2adict\uff0c\u8bb0\u5f55\u4e86\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 (\u4f8b\u5982 verbosity, batch size, number of epochs \u7b49\u7b49)\u3002 model\u5373\u5f53\u524d\u5173\u8054\u7684\u6a21\u578b\u7684\u5f15\u7528\u3002 \u6b64\u5916\uff0c\u5bf9\u4e8e\u56de\u8c03\u7c7b\u4e2d\u7684\u4e00\u4e9b\u65b9\u6cd5\u5982on_epoch_begin,on_batch_end\uff0c\u8fd8\u4f1a\u6709\u4e00\u4e2a\u8f93\u5165\u53c2\u6570logs, \u63d0\u4f9b\u6709\u5173\u5f53\u524depoch\u6216\u8005batch\u7684\u4e00\u4e9b\u4fe1\u606f\uff0c\u5e76\u80fd\u591f\u8bb0\u5f55\u8ba1\u7b97\u7ed3\u679c\uff0c\u5982\u679cmodel.fit\u6307\u5b9a\u4e86\u591a\u4e2a\u56de\u8c03\u51fd\u6570\u7c7b\uff0c\u8fd9\u4e9blogs\u53d8\u91cf\u5c06\u5728\u8fd9\u4e9b\u56de\u8c03\u51fd\u6570\u7c7b\u7684\u540c\u540d\u51fd\u6570\u95f4\u4f9d\u987a\u5e8f\u4f20\u9012\u3002 \u4e00\uff0c\u5185\u7f6e\u56de\u8c03\u51fd\u6570 # BaseLogger\uff1a \u6536\u96c6\u6bcf\u4e2aepoch\u4e0ametrics\u5728\u5404\u4e2abatch\u4e0a\u7684\u5e73\u5747\u503c\uff0c\u5bf9stateful_metrics\u53c2\u6570\u4e2d\u7684\u5e26\u4e2d\u95f4\u72b6\u6001\u7684\u6307\u6807\u76f4\u63a5\u62ff\u6700\u7ec8\u503c\u65e0\u9700\u5bf9\u5404\u4e2abatch\u5e73\u5747\uff0c\u6307\u6807\u5747\u503c\u7ed3\u679c\u5c06\u6dfb\u52a0\u5230logs\u53d8\u91cf\u4e2d\u3002\u8be5\u56de\u8c03\u51fd\u6570\u88ab\u6240\u6709\u6a21\u578b\u9ed8\u8ba4\u6dfb\u52a0\uff0c\u4e14\u662f\u7b2c\u4e00\u4e2a\u88ab\u6dfb\u52a0\u7684\u3002 History\uff1a \u5c06BaseLogger\u8ba1\u7b97\u7684\u5404\u4e2aepoch\u7684metrics\u7ed3\u679c\u8bb0\u5f55\u5230history\u8fd9\u4e2adict\u53d8\u91cf\u4e2d\uff0c\u5e76\u4f5c\u4e3amodel.fit\u7684\u8fd4\u56de\u503c\u3002\u8be5\u56de\u8c03\u51fd\u6570\u88ab\u6240\u6709\u6a21\u578b\u9ed8\u8ba4\u6dfb\u52a0\uff0c\u5728BaseLogger\u4e4b\u540e\u88ab\u6dfb\u52a0\u3002 EarlyStopping\uff1a \u5f53\u88ab\u76d1\u63a7\u6307\u6807\u5728\u8bbe\u5b9a\u7684\u82e5\u5e72\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002 TensorBoard\uff1a \u4e3aTensorboard\u53ef\u89c6\u5316\u4fdd\u5b58\u65e5\u5fd7\u4fe1\u606f\u3002\u652f\u6301\u8bc4\u4f30\u6307\u6807\uff0c\u8ba1\u7b97\u56fe\uff0c\u6a21\u578b\u53c2\u6570\u7b49\u7684\u53ef\u89c6\u5316\u3002 ModelCheckpoint\uff1a \u5728\u6bcf\u4e2aepoch\u540e\u4fdd\u5b58\u6a21\u578b\u3002 ReduceLROnPlateau\uff1a\u5982\u679c\u76d1\u63a7\u6307\u6807\u5728\u8bbe\u5b9a\u7684\u82e5\u5e72\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u4ee5\u4e00\u5b9a\u7684\u56e0\u5b50\u51cf\u5c11\u5b66\u4e60\u7387\u3002 TerminateOnNaN\uff1a\u5982\u679c\u9047\u5230loss\u4e3aNaN\uff0c\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002 LearningRateScheduler\uff1a\u5b66\u4e60\u7387\u63a7\u5236\u5668\u3002\u7ed9\u5b9a\u5b66\u4e60\u7387lr\u548cepoch\u7684\u51fd\u6570\u5173\u7cfb\uff0c\u6839\u636e\u8be5\u51fd\u6570\u5173\u7cfb\u5728\u6bcf\u4e2aepoch\u524d\u8c03\u6574\u5b66\u4e60\u7387\u3002 CSVLogger\uff1a\u5c06\u6bcf\u4e2aepoch\u540e\u7684logs\u7ed3\u679c\u8bb0\u5f55\u5230CSV\u6587\u4ef6\u4e2d\u3002 ProgbarLogger\uff1a\u5c06\u6bcf\u4e2aepoch\u540e\u7684logs\u7ed3\u679c\u6253\u5370\u5230\u6807\u51c6\u8f93\u51fa\u6d41\u4e2d\u3002 \u4e8c\uff0c\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570 # \u53ef\u4ee5\u4f7f\u7528callbacks.LambdaCallback\u7f16\u5199\u8f83\u4e3a\u7b80\u5355\u7684\u56de\u8c03\u51fd\u6570\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5bf9callbacks.Callback\u5b50\u7c7b\u5316\u7f16\u5199\u66f4\u52a0\u590d\u6742\u7684\u56de\u8c03\u51fd\u6570\u903b\u8f91\u3002 \u5982\u679c\u9700\u8981\u6df1\u5165\u5b66\u4e60tf.Keras\u4e2d\u7684\u56de\u8c03\u51fd\u6570\uff0c\u4e0d\u8981\u72b9\u8c6b\u9605\u8bfb\u5185\u7f6e\u56de\u8c03\u51fd\u6570\u7684\u6e90\u4ee3\u7801\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics , callbacks import tensorflow.keras.backend as K # \u793a\u8303\u4f7f\u7528LambdaCallback\u7f16\u5199\u8f83\u4e3a\u7b80\u5355\u7684\u56de\u8c03\u51fd\u6570 import json json_log = open ( '../../data/keras_log.json' , mode = 'wt' , buffering = 1 ) json_logging_callback = callbacks . LambdaCallback ( on_epoch_end = lambda epoch , logs : json_log . write ( json . dumps ( dict ( epoch = epoch , ** logs )) + ' \\n ' ), on_train_end = lambda logs : json_log . close () ) # \u793a\u8303\u901a\u8fc7Callback\u5b50\u7c7b\u5316\u7f16\u5199\u56de\u8c03\u51fd\u6570\uff08LearningRateScheduler\u7684\u6e90\u4ee3\u7801\uff09 class LearningRateScheduler ( callbacks . Callback ): def __init__ ( self , schedule , verbose = 0 ): super ( LearningRateScheduler , self ) . __init__ () self . schedule = schedule self . verbose = verbose def on_epoch_begin ( self , epoch , logs = None ): if not hasattr ( self . model . optimizer , 'lr' ): raise ValueError ( 'Optimizer must have a \"lr\" attribute.' ) try : lr = float ( K . get_value ( self . model . optimizer . lr )) lr = self . schedule ( epoch , lr ) except TypeError : # Support for old API for backward compatibility lr = self . schedule ( epoch ) if not isinstance ( lr , ( tf . Tensor , float , np . float32 , np . float64 )): raise ValueError ( 'The output of the \"schedule\" function ' 'should be float.' ) if isinstance ( lr , ops . Tensor ) and not lr . dtype . is_floating : raise ValueError ( 'The dtype of Tensor should be float' ) K . set_value ( self . model . optimizer . lr , K . get_value ( lr )) if self . verbose > 0 : print ( ' \\n Epoch %05d : LearningRateScheduler reducing learning ' 'rate to %s .' % ( epoch + 1 , lr )) def on_epoch_end ( self , epoch , logs = None ): logs = logs or {} logs [ 'lr' ] = K . get_value ( self . model . optimizer . lr ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-8,\u56de\u8c03\u51fd\u6570callbacks"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-8%2C%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0callbacks/#5-8\u56de\u8c03\u51fd\u6570callbacks","text":"tf.keras\u7684\u56de\u8c03\u51fd\u6570\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u7c7b\uff0c\u4e00\u822c\u662f\u5728model.fit\u65f6\u4f5c\u4e3a\u53c2\u6570\u6307\u5b9a\uff0c\u7528\u4e8e\u63a7\u5236\u5728\u8bad\u7ec3\u8fc7\u7a0b\u5f00\u59cb\u6216\u8005\u5728\u8bad\u7ec3\u8fc7\u7a0b\u7ed3\u675f\uff0c\u5728\u6bcf\u4e2aepoch\u8bad\u7ec3\u5f00\u59cb\u6216\u8005\u8bad\u7ec3\u7ed3\u675f\uff0c\u5728\u6bcf\u4e2abatch\u8bad\u7ec3\u5f00\u59cb\u6216\u8005\u8bad\u7ec3\u7ed3\u675f\u65f6\u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\uff0c\u4f8b\u5982\u6536\u96c6\u4e00\u4e9b\u65e5\u5fd7\u4fe1\u606f\uff0c\u6539\u53d8\u5b66\u4e60\u7387\u7b49\u8d85\u53c2\u6570\uff0c\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u7b49\u7b49\u3002 \u540c\u6837\u5730\uff0c\u9488\u5bf9model.evaluate\u6216\u8005model.predict\u4e5f\u53ef\u4ee5\u6307\u5b9acallbacks\u53c2\u6570\uff0c\u7528\u4e8e\u63a7\u5236\u5728\u8bc4\u4f30\u6216\u9884\u6d4b\u5f00\u59cb\u6216\u8005\u7ed3\u675f\u65f6\uff0c\u5728\u6bcf\u4e2abatch\u5f00\u59cb\u6216\u8005\u7ed3\u675f\u65f6\u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\uff0c\u4f46\u8fd9\u79cd\u7528\u6cd5\u76f8\u5bf9\u5c11\u89c1\u3002 \u5927\u90e8\u5206\u65f6\u5019\uff0ckeras.callbacks\u5b50\u6a21\u5757\u4e2d\u5b9a\u4e49\u7684\u56de\u8c03\u51fd\u6570\u7c7b\u5df2\u7ecf\u8db3\u591f\u4f7f\u7528\u4e86\uff0c\u5982\u679c\u6709\u7279\u5b9a\u7684\u9700\u8981\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5bf9keras.callbacks.Callbacks\u5b9e\u65bd\u5b50\u7c7b\u5316\u6784\u9020\u81ea\u5b9a\u4e49\u7684\u56de\u8c03\u51fd\u6570\u3002 \u6240\u6709\u56de\u8c03\u51fd\u6570\u90fd\u7ee7\u627f\u81f3 keras.callbacks.Callbacks\u57fa\u7c7b\uff0c\u62e5\u6709params\u548cmodel\u8fd9\u4e24\u4e2a\u5c5e\u6027\u3002 \u5176\u4e2dparams \u662f\u4e00\u4e2adict\uff0c\u8bb0\u5f55\u4e86\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 (\u4f8b\u5982 verbosity, batch size, number of epochs \u7b49\u7b49)\u3002 model\u5373\u5f53\u524d\u5173\u8054\u7684\u6a21\u578b\u7684\u5f15\u7528\u3002 \u6b64\u5916\uff0c\u5bf9\u4e8e\u56de\u8c03\u7c7b\u4e2d\u7684\u4e00\u4e9b\u65b9\u6cd5\u5982on_epoch_begin,on_batch_end\uff0c\u8fd8\u4f1a\u6709\u4e00\u4e2a\u8f93\u5165\u53c2\u6570logs, \u63d0\u4f9b\u6709\u5173\u5f53\u524depoch\u6216\u8005batch\u7684\u4e00\u4e9b\u4fe1\u606f\uff0c\u5e76\u80fd\u591f\u8bb0\u5f55\u8ba1\u7b97\u7ed3\u679c\uff0c\u5982\u679cmodel.fit\u6307\u5b9a\u4e86\u591a\u4e2a\u56de\u8c03\u51fd\u6570\u7c7b\uff0c\u8fd9\u4e9blogs\u53d8\u91cf\u5c06\u5728\u8fd9\u4e9b\u56de\u8c03\u51fd\u6570\u7c7b\u7684\u540c\u540d\u51fd\u6570\u95f4\u4f9d\u987a\u5e8f\u4f20\u9012\u3002","title":"5-8,\u56de\u8c03\u51fd\u6570callbacks"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-8%2C%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0callbacks/#\u4e00\u5185\u7f6e\u56de\u8c03\u51fd\u6570","text":"BaseLogger\uff1a \u6536\u96c6\u6bcf\u4e2aepoch\u4e0ametrics\u5728\u5404\u4e2abatch\u4e0a\u7684\u5e73\u5747\u503c\uff0c\u5bf9stateful_metrics\u53c2\u6570\u4e2d\u7684\u5e26\u4e2d\u95f4\u72b6\u6001\u7684\u6307\u6807\u76f4\u63a5\u62ff\u6700\u7ec8\u503c\u65e0\u9700\u5bf9\u5404\u4e2abatch\u5e73\u5747\uff0c\u6307\u6807\u5747\u503c\u7ed3\u679c\u5c06\u6dfb\u52a0\u5230logs\u53d8\u91cf\u4e2d\u3002\u8be5\u56de\u8c03\u51fd\u6570\u88ab\u6240\u6709\u6a21\u578b\u9ed8\u8ba4\u6dfb\u52a0\uff0c\u4e14\u662f\u7b2c\u4e00\u4e2a\u88ab\u6dfb\u52a0\u7684\u3002 History\uff1a \u5c06BaseLogger\u8ba1\u7b97\u7684\u5404\u4e2aepoch\u7684metrics\u7ed3\u679c\u8bb0\u5f55\u5230history\u8fd9\u4e2adict\u53d8\u91cf\u4e2d\uff0c\u5e76\u4f5c\u4e3amodel.fit\u7684\u8fd4\u56de\u503c\u3002\u8be5\u56de\u8c03\u51fd\u6570\u88ab\u6240\u6709\u6a21\u578b\u9ed8\u8ba4\u6dfb\u52a0\uff0c\u5728BaseLogger\u4e4b\u540e\u88ab\u6dfb\u52a0\u3002 EarlyStopping\uff1a \u5f53\u88ab\u76d1\u63a7\u6307\u6807\u5728\u8bbe\u5b9a\u7684\u82e5\u5e72\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002 TensorBoard\uff1a \u4e3aTensorboard\u53ef\u89c6\u5316\u4fdd\u5b58\u65e5\u5fd7\u4fe1\u606f\u3002\u652f\u6301\u8bc4\u4f30\u6307\u6807\uff0c\u8ba1\u7b97\u56fe\uff0c\u6a21\u578b\u53c2\u6570\u7b49\u7684\u53ef\u89c6\u5316\u3002 ModelCheckpoint\uff1a \u5728\u6bcf\u4e2aepoch\u540e\u4fdd\u5b58\u6a21\u578b\u3002 ReduceLROnPlateau\uff1a\u5982\u679c\u76d1\u63a7\u6307\u6807\u5728\u8bbe\u5b9a\u7684\u82e5\u5e72\u4e2aepoch\u540e\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u4ee5\u4e00\u5b9a\u7684\u56e0\u5b50\u51cf\u5c11\u5b66\u4e60\u7387\u3002 TerminateOnNaN\uff1a\u5982\u679c\u9047\u5230loss\u4e3aNaN\uff0c\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002 LearningRateScheduler\uff1a\u5b66\u4e60\u7387\u63a7\u5236\u5668\u3002\u7ed9\u5b9a\u5b66\u4e60\u7387lr\u548cepoch\u7684\u51fd\u6570\u5173\u7cfb\uff0c\u6839\u636e\u8be5\u51fd\u6570\u5173\u7cfb\u5728\u6bcf\u4e2aepoch\u524d\u8c03\u6574\u5b66\u4e60\u7387\u3002 CSVLogger\uff1a\u5c06\u6bcf\u4e2aepoch\u540e\u7684logs\u7ed3\u679c\u8bb0\u5f55\u5230CSV\u6587\u4ef6\u4e2d\u3002 ProgbarLogger\uff1a\u5c06\u6bcf\u4e2aepoch\u540e\u7684logs\u7ed3\u679c\u6253\u5370\u5230\u6807\u51c6\u8f93\u51fa\u6d41\u4e2d\u3002","title":"\u4e00\uff0c\u5185\u7f6e\u56de\u8c03\u51fd\u6570"},{"location":"chinese/5.%E4%B8%AD%E9%98%B6API/5-8%2C%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0callbacks/#\u4e8c\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570","text":"\u53ef\u4ee5\u4f7f\u7528callbacks.LambdaCallback\u7f16\u5199\u8f83\u4e3a\u7b80\u5355\u7684\u56de\u8c03\u51fd\u6570\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5bf9callbacks.Callback\u5b50\u7c7b\u5316\u7f16\u5199\u66f4\u52a0\u590d\u6742\u7684\u56de\u8c03\u51fd\u6570\u903b\u8f91\u3002 \u5982\u679c\u9700\u8981\u6df1\u5165\u5b66\u4e60tf.Keras\u4e2d\u7684\u56de\u8c03\u51fd\u6570\uff0c\u4e0d\u8981\u72b9\u8c6b\u9605\u8bfb\u5185\u7f6e\u56de\u8c03\u51fd\u6570\u7684\u6e90\u4ee3\u7801\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics , callbacks import tensorflow.keras.backend as K # \u793a\u8303\u4f7f\u7528LambdaCallback\u7f16\u5199\u8f83\u4e3a\u7b80\u5355\u7684\u56de\u8c03\u51fd\u6570 import json json_log = open ( '../../data/keras_log.json' , mode = 'wt' , buffering = 1 ) json_logging_callback = callbacks . LambdaCallback ( on_epoch_end = lambda epoch , logs : json_log . write ( json . dumps ( dict ( epoch = epoch , ** logs )) + ' \\n ' ), on_train_end = lambda logs : json_log . close () ) # \u793a\u8303\u901a\u8fc7Callback\u5b50\u7c7b\u5316\u7f16\u5199\u56de\u8c03\u51fd\u6570\uff08LearningRateScheduler\u7684\u6e90\u4ee3\u7801\uff09 class LearningRateScheduler ( callbacks . Callback ): def __init__ ( self , schedule , verbose = 0 ): super ( LearningRateScheduler , self ) . __init__ () self . schedule = schedule self . verbose = verbose def on_epoch_begin ( self , epoch , logs = None ): if not hasattr ( self . model . optimizer , 'lr' ): raise ValueError ( 'Optimizer must have a \"lr\" attribute.' ) try : lr = float ( K . get_value ( self . model . optimizer . lr )) lr = self . schedule ( epoch , lr ) except TypeError : # Support for old API for backward compatibility lr = self . schedule ( epoch ) if not isinstance ( lr , ( tf . Tensor , float , np . float32 , np . float64 )): raise ValueError ( 'The output of the \"schedule\" function ' 'should be float.' ) if isinstance ( lr , ops . Tensor ) and not lr . dtype . is_floating : raise ValueError ( 'The dtype of Tensor should be float' ) K . set_value ( self . model . optimizer . lr , K . get_value ( lr )) if self . verbose > 0 : print ( ' \\n Epoch %05d : LearningRateScheduler reducing learning ' 'rate to %s .' % ( epoch + 1 , lr )) def on_epoch_end ( self , epoch , logs = None ): logs = logs or {} logs [ 'lr' ] = K . get_value ( self . model . optimizer . lr ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/","text":"\u516d\u3001TensorFlow\u7684\u9ad8\u9636API # TensorFlow\u7684\u9ad8\u9636API\u4e3b\u8981\u662ftensorflow.keras.models. \u672c\u7ae0\u6211\u4eec\u4e3b\u8981\u8be6\u7ec6\u4ecb\u7ecdtensorflow.keras.models\u76f8\u5173\u7684\u4ee5\u4e0b\u5185\u5bb9\u3002 \u6a21\u578b\u7684\u6784\u5efa\uff08Sequential\u3001functional API\u3001Model\u5b50\u7c7b\u5316\uff09 \u6a21\u578b\u7684\u8bad\u7ec3\uff08\u5185\u7f6efit\u65b9\u6cd5\u3001\u5185\u7f6etrain_on_batch\u65b9\u6cd5\u3001\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3001\u5355GPU\u8bad\u7ec3\u6a21\u578b\u3001\u591aGPU\u8bad\u7ec3\u6a21\u578b\u3001TPU\u8bad\u7ec3\u6a21\u578b\uff09 \u6a21\u578b\u7684\u90e8\u7f72\uff08tensorflow serving\u90e8\u7f72\u6a21\u578b\u3001\u4f7f\u7528spark(scala)\u8c03\u7528tensorflow\u6a21\u578b\uff09 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\u3001TensorFlow\u7684\u9ad8\u9636API"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/#\u516dtensorflow\u7684\u9ad8\u9636api","text":"TensorFlow\u7684\u9ad8\u9636API\u4e3b\u8981\u662ftensorflow.keras.models. \u672c\u7ae0\u6211\u4eec\u4e3b\u8981\u8be6\u7ec6\u4ecb\u7ecdtensorflow.keras.models\u76f8\u5173\u7684\u4ee5\u4e0b\u5185\u5bb9\u3002 \u6a21\u578b\u7684\u6784\u5efa\uff08Sequential\u3001functional API\u3001Model\u5b50\u7c7b\u5316\uff09 \u6a21\u578b\u7684\u8bad\u7ec3\uff08\u5185\u7f6efit\u65b9\u6cd5\u3001\u5185\u7f6etrain_on_batch\u65b9\u6cd5\u3001\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3001\u5355GPU\u8bad\u7ec3\u6a21\u578b\u3001\u591aGPU\u8bad\u7ec3\u6a21\u578b\u3001TPU\u8bad\u7ec3\u6a21\u578b\uff09 \u6a21\u578b\u7684\u90e8\u7f72\uff08tensorflow serving\u90e8\u7f72\u6a21\u578b\u3001\u4f7f\u7528spark(scala)\u8c03\u7528tensorflow\u6a21\u578b\uff09 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\u3001TensorFlow\u7684\u9ad8\u9636API"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/","text":"6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 # \u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u5bf9\u4e8e\u987a\u5e8f\u7ed3\u6784\u7684\u6a21\u578b\uff0c\u4f18\u5148\u4f7f\u7528Sequential\u65b9\u6cd5\u6784\u5efa\u3002 \u5982\u679c\u6a21\u578b\u6709\u591a\u8f93\u5165\u6216\u8005\u591a\u8f93\u51fa\uff0c\u6216\u8005\u6a21\u578b\u9700\u8981\u5171\u4eab\u6743\u91cd\uff0c\u6216\u8005\u6a21\u578b\u5177\u6709\u6b8b\u5dee\u8fde\u63a5\u7b49\u975e\u987a\u5e8f\u7ed3\u6784\uff0c\u63a8\u8350\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u8fdb\u884c\u521b\u5efa\u3002 \u5982\u679c\u65e0\u7279\u5b9a\u5fc5\u8981\uff0c\u5c3d\u53ef\u80fd\u907f\u514d\u4f7f\u7528Model\u5b50\u7c7b\u5316\u7684\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff0c\u8fd9\u79cd\u65b9\u5f0f\u63d0\u4f9b\u4e86\u6781\u5927\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u4e5f\u6709\u66f4\u5927\u7684\u6982\u7387\u51fa\u9519\u3002 \u4e0b\u9762\u4ee5IMDB\u7535\u5f71\u8bc4\u8bba\u7684\u5206\u7c7b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a3\u79cd\u521b\u5efa\u6a21\u578b\u7684\u65b9\u6cd5\u3002 import numpy as np import pandas as pd import tensorflow as tf from tqdm import tqdm from tensorflow.keras import * train_token_path = \"../../data/imdb/train_token.csv\" test_token_path = \"../../data/imdb/test_token.csv\" MAX_WORDS = 10000 # We will only consider the top 10,000 words in the dataset MAX_LEN = 200 # We will cut reviews after 200 words BATCH_SIZE = 20 # \u6784\u5efa\u7ba1\u9053 def parse_line ( line ): t = tf . strings . split ( line , \" \\t \" ) label = tf . reshape ( tf . cast ( tf . strings . to_number ( t [ 0 ]), tf . int32 ),( - 1 ,)) features = tf . cast ( tf . strings . to_number ( tf . strings . split ( t [ 1 ], \" \" )), tf . int32 ) return ( features , label ) ds_train = tf . data . TextLineDataset ( filenames = [ train_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . TextLineDataset ( filenames = [ test_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \u4e00\uff0cSequential\u6309\u5c42\u987a\u5e8f\u521b\u5efa\u6a21\u578b # tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 1 , activation = \"sigmoid\" )) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () import datetime baselogger = callbacks . BaseLogger ( stateful_metrics = [ \"AUC\" ]) logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ baselogger , tensorboard_callback ]) % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"AUC\" ) \u4e8c\uff0c\u51fd\u6570\u5f0fAPI\u521b\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b # tf . keras . backend . clear_session () inputs = layers . Input ( shape = [ MAX_LEN ]) x = layers . Embedding ( MAX_WORDS , 7 )( inputs ) branch1 = layers . SeparableConv1D ( 64 , 3 , activation = \"relu\" )( x ) branch1 = layers . MaxPool1D ( 3 )( branch1 ) branch1 = layers . SeparableConv1D ( 32 , 3 , activation = \"relu\" )( branch1 ) branch1 = layers . GlobalMaxPool1D ()( branch1 ) branch2 = layers . SeparableConv1D ( 64 , 5 , activation = \"relu\" )( x ) branch2 = layers . MaxPool1D ( 5 )( branch2 ) branch2 = layers . SeparableConv1D ( 32 , 5 , activation = \"relu\" )( branch2 ) branch2 = layers . GlobalMaxPool1D ()( branch2 ) branch3 = layers . SeparableConv1D ( 64 , 7 , activation = \"relu\" )( x ) branch3 = layers . MaxPool1D ( 7 )( branch3 ) branch3 = layers . SeparableConv1D ( 32 , 7 , activation = \"relu\" )( branch3 ) branch3 = layers . GlobalMaxPool1D ()( branch3 ) concat = layers . Concatenate ()([ branch1 , branch2 , branch3 ]) outputs = layers . Dense ( 1 , activation = \"sigmoid\" )( concat ) model = models . Model ( inputs = inputs , outputs = outputs ) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 200)] 0 __________________________________________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 input_1[0][0] __________________________________________________________________________________________________ separable_conv1d (SeparableConv (None, 198, 64) 533 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_2 (SeparableCo (None, 196, 64) 547 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_4 (SeparableCo (None, 194, 64) 561 embedding[0][0] __________________________________________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 66, 64) 0 separable_conv1d[0][0] __________________________________________________________________________________________________ max_pooling1d_1 (MaxPooling1D) (None, 39, 64) 0 separable_conv1d_2[0][0] __________________________________________________________________________________________________ max_pooling1d_2 (MaxPooling1D) (None, 27, 64) 0 separable_conv1d_4[0][0] __________________________________________________________________________________________________ separable_conv1d_1 (SeparableCo (None, 64, 32) 2272 max_pooling1d[0][0] __________________________________________________________________________________________________ separable_conv1d_3 (SeparableCo (None, 35, 32) 2400 max_pooling1d_1[0][0] __________________________________________________________________________________________________ separable_conv1d_5 (SeparableCo (None, 21, 32) 2528 max_pooling1d_2[0][0] __________________________________________________________________________________________________ global_max_pooling1d (GlobalMax (None, 32) 0 separable_conv1d_1[0][0] __________________________________________________________________________________________________ global_max_pooling1d_1 (GlobalM (None, 32) 0 separable_conv1d_3[0][0] __________________________________________________________________________________________________ global_max_pooling1d_2 (GlobalM (None, 32) 0 separable_conv1d_5[0][0] __________________________________________________________________________________________________ concatenate (Concatenate) (None, 96) 0 global_max_pooling1d[0][0] global_max_pooling1d_1[0][0] global_max_pooling1d_2[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 1) 97 concatenate[0][0] ================================================================================================== Total params: 78,938 Trainable params: 78,938 Non-trainable params: 0 __________________________________________________________________________________________________ import datetime logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192 Epoch 2/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350 Epoch 3/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363 Epoch 4/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311 Epoch 5/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233 Epoch 6/6 1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138 plot_metric ( history , \"AUC\" ) \u4e09\uff0cModel\u5b50\u7c7b\u5316\u521b\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b # # \u5148\u81ea\u5b9a\u4e49\u4e00\u4e2a\u6b8b\u5dee\u6a21\u5757\uff0c\u4e3a\u81ea\u5b9a\u4e49Layer class ResBlock ( layers . Layer ): def __init__ ( self , kernel_size , ** kwargs ): super ( ResBlock , self ) . __init__ ( ** kwargs ) self . kernel_size = kernel_size def build ( self , input_shape ): self . conv1 = layers . Conv1D ( filters = 64 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv2 = layers . Conv1D ( filters = 32 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv3 = layers . Conv1D ( filters = input_shape [ - 1 ], kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . maxpool = layers . MaxPool1D ( 2 ) super ( ResBlock , self ) . build ( input_shape ) # \u76f8\u5f53\u4e8e\u8bbe\u7f6eself.built = True def call ( self , inputs ): x = self . conv1 ( inputs ) x = self . conv2 ( x ) x = self . conv3 ( x ) x = layers . Add ()([ inputs , x ]) x = self . maxpool ( x ) return x #\u5982\u679c\u8981\u8ba9\u81ea\u5b9a\u4e49\u7684Layer\u901a\u8fc7Functional API \u7ec4\u5408\u6210\u6a21\u578b\u65f6\u53ef\u4ee5\u5e8f\u5217\u5316\uff0c\u9700\u8981\u81ea\u5b9a\u4e49get_config\u65b9\u6cd5\u3002 def get_config ( self ): config = super ( ResBlock , self ) . get_config () config . update ({ 'kernel_size' : self . kernel_size }) return config # \u6d4b\u8bd5ResBlock resblock = ResBlock ( kernel_size = 3 ) resblock . build ( input_shape = ( None , 200 , 7 )) resblock . compute_output_shape ( input_shape = ( None , 200 , 7 )) TensorShape([None, 100, 7]) # \u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u5b9e\u9645\u4e0a\u4e5f\u53ef\u4ee5\u4f7f\u7528Sequential\u6216\u8005FunctionalAPI class ImdbModel ( models . Model ): def __init__ ( self ): super ( ImdbModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 ) self . block1 = ResBlock ( 7 ) self . block2 = ResBlock ( 5 ) self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( ImdbModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . block1 ( x ) x = self . block2 ( x ) x = layers . Flatten ()( x ) x = self . dense ( x ) return ( x ) tf . keras . backend . clear_session () model = ImdbModel () model . build ( input_shape = ( None , 200 )) model . summary () model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) Model: \"imdb_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) multiple 70000 _________________________________________________________________ res_block (ResBlock) multiple 19143 _________________________________________________________________ res_block_1 (ResBlock) multiple 13703 _________________________________________________________________ dense (Dense) multiple 351 ================================================================= Total params: 103,197 Trainable params: 103,197 Non-trainable params: 0 _________________________________________________________________ import datetime logdir = \"./tflogs/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286 Epoch 2/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410 Epoch 3/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390 Epoch 4/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292 Epoch 5/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132 Epoch 6/6 1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052 plot_metric ( history , \"AUC\" ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#6-1\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5","text":"\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u6784\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b\uff0c\u7ee7\u627fModel\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 \u5bf9\u4e8e\u987a\u5e8f\u7ed3\u6784\u7684\u6a21\u578b\uff0c\u4f18\u5148\u4f7f\u7528Sequential\u65b9\u6cd5\u6784\u5efa\u3002 \u5982\u679c\u6a21\u578b\u6709\u591a\u8f93\u5165\u6216\u8005\u591a\u8f93\u51fa\uff0c\u6216\u8005\u6a21\u578b\u9700\u8981\u5171\u4eab\u6743\u91cd\uff0c\u6216\u8005\u6a21\u578b\u5177\u6709\u6b8b\u5dee\u8fde\u63a5\u7b49\u975e\u987a\u5e8f\u7ed3\u6784\uff0c\u63a8\u8350\u4f7f\u7528\u51fd\u6570\u5f0fAPI\u8fdb\u884c\u521b\u5efa\u3002 \u5982\u679c\u65e0\u7279\u5b9a\u5fc5\u8981\uff0c\u5c3d\u53ef\u80fd\u907f\u514d\u4f7f\u7528Model\u5b50\u7c7b\u5316\u7684\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff0c\u8fd9\u79cd\u65b9\u5f0f\u63d0\u4f9b\u4e86\u6781\u5927\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u4e5f\u6709\u66f4\u5927\u7684\u6982\u7387\u51fa\u9519\u3002 \u4e0b\u9762\u4ee5IMDB\u7535\u5f71\u8bc4\u8bba\u7684\u5206\u7c7b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a3\u79cd\u521b\u5efa\u6a21\u578b\u7684\u65b9\u6cd5\u3002 import numpy as np import pandas as pd import tensorflow as tf from tqdm import tqdm from tensorflow.keras import * train_token_path = \"../../data/imdb/train_token.csv\" test_token_path = \"../../data/imdb/test_token.csv\" MAX_WORDS = 10000 # We will only consider the top 10,000 words in the dataset MAX_LEN = 200 # We will cut reviews after 200 words BATCH_SIZE = 20 # \u6784\u5efa\u7ba1\u9053 def parse_line ( line ): t = tf . strings . split ( line , \" \\t \" ) label = tf . reshape ( tf . cast ( tf . strings . to_number ( t [ 0 ]), tf . int32 ),( - 1 ,)) features = tf . cast ( tf . strings . to_number ( tf . strings . split ( t [ 1 ], \" \" )), tf . int32 ) return ( features , label ) ds_train = tf . data . TextLineDataset ( filenames = [ train_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . TextLineDataset ( filenames = [ test_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE )","title":"6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e00sequential\u6309\u5c42\u987a\u5e8f\u521b\u5efa\u6a21\u578b","text":"tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 1 , activation = \"sigmoid\" )) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () import datetime baselogger = callbacks . BaseLogger ( stateful_metrics = [ \"AUC\" ]) logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ baselogger , tensorboard_callback ]) % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"AUC\" )","title":"\u4e00\uff0cSequential\u6309\u5c42\u987a\u5e8f\u521b\u5efa\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e8c\u51fd\u6570\u5f0fapi\u521b\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b","text":"tf . keras . backend . clear_session () inputs = layers . Input ( shape = [ MAX_LEN ]) x = layers . Embedding ( MAX_WORDS , 7 )( inputs ) branch1 = layers . SeparableConv1D ( 64 , 3 , activation = \"relu\" )( x ) branch1 = layers . MaxPool1D ( 3 )( branch1 ) branch1 = layers . SeparableConv1D ( 32 , 3 , activation = \"relu\" )( branch1 ) branch1 = layers . GlobalMaxPool1D ()( branch1 ) branch2 = layers . SeparableConv1D ( 64 , 5 , activation = \"relu\" )( x ) branch2 = layers . MaxPool1D ( 5 )( branch2 ) branch2 = layers . SeparableConv1D ( 32 , 5 , activation = \"relu\" )( branch2 ) branch2 = layers . GlobalMaxPool1D ()( branch2 ) branch3 = layers . SeparableConv1D ( 64 , 7 , activation = \"relu\" )( x ) branch3 = layers . MaxPool1D ( 7 )( branch3 ) branch3 = layers . SeparableConv1D ( 32 , 7 , activation = \"relu\" )( branch3 ) branch3 = layers . GlobalMaxPool1D ()( branch3 ) concat = layers . Concatenate ()([ branch1 , branch2 , branch3 ]) outputs = layers . Dense ( 1 , activation = \"sigmoid\" )( concat ) model = models . Model ( inputs = inputs , outputs = outputs ) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 200)] 0 __________________________________________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 input_1[0][0] __________________________________________________________________________________________________ separable_conv1d (SeparableConv (None, 198, 64) 533 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_2 (SeparableCo (None, 196, 64) 547 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_4 (SeparableCo (None, 194, 64) 561 embedding[0][0] __________________________________________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 66, 64) 0 separable_conv1d[0][0] __________________________________________________________________________________________________ max_pooling1d_1 (MaxPooling1D) (None, 39, 64) 0 separable_conv1d_2[0][0] __________________________________________________________________________________________________ max_pooling1d_2 (MaxPooling1D) (None, 27, 64) 0 separable_conv1d_4[0][0] __________________________________________________________________________________________________ separable_conv1d_1 (SeparableCo (None, 64, 32) 2272 max_pooling1d[0][0] __________________________________________________________________________________________________ separable_conv1d_3 (SeparableCo (None, 35, 32) 2400 max_pooling1d_1[0][0] __________________________________________________________________________________________________ separable_conv1d_5 (SeparableCo (None, 21, 32) 2528 max_pooling1d_2[0][0] __________________________________________________________________________________________________ global_max_pooling1d (GlobalMax (None, 32) 0 separable_conv1d_1[0][0] __________________________________________________________________________________________________ global_max_pooling1d_1 (GlobalM (None, 32) 0 separable_conv1d_3[0][0] __________________________________________________________________________________________________ global_max_pooling1d_2 (GlobalM (None, 32) 0 separable_conv1d_5[0][0] __________________________________________________________________________________________________ concatenate (Concatenate) (None, 96) 0 global_max_pooling1d[0][0] global_max_pooling1d_1[0][0] global_max_pooling1d_2[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 1) 97 concatenate[0][0] ================================================================================================== Total params: 78,938 Trainable params: 78,938 Non-trainable params: 0 __________________________________________________________________________________________________ import datetime logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192 Epoch 2/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350 Epoch 3/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363 Epoch 4/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311 Epoch 5/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233 Epoch 6/6 1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138 plot_metric ( history , \"AUC\" )","title":"\u4e8c\uff0c\u51fd\u6570\u5f0fAPI\u521b\u5efa\u4efb\u610f\u7ed3\u6784\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e09model\u5b50\u7c7b\u5316\u521b\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b","text":"# \u5148\u81ea\u5b9a\u4e49\u4e00\u4e2a\u6b8b\u5dee\u6a21\u5757\uff0c\u4e3a\u81ea\u5b9a\u4e49Layer class ResBlock ( layers . Layer ): def __init__ ( self , kernel_size , ** kwargs ): super ( ResBlock , self ) . __init__ ( ** kwargs ) self . kernel_size = kernel_size def build ( self , input_shape ): self . conv1 = layers . Conv1D ( filters = 64 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv2 = layers . Conv1D ( filters = 32 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv3 = layers . Conv1D ( filters = input_shape [ - 1 ], kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . maxpool = layers . MaxPool1D ( 2 ) super ( ResBlock , self ) . build ( input_shape ) # \u76f8\u5f53\u4e8e\u8bbe\u7f6eself.built = True def call ( self , inputs ): x = self . conv1 ( inputs ) x = self . conv2 ( x ) x = self . conv3 ( x ) x = layers . Add ()([ inputs , x ]) x = self . maxpool ( x ) return x #\u5982\u679c\u8981\u8ba9\u81ea\u5b9a\u4e49\u7684Layer\u901a\u8fc7Functional API \u7ec4\u5408\u6210\u6a21\u578b\u65f6\u53ef\u4ee5\u5e8f\u5217\u5316\uff0c\u9700\u8981\u81ea\u5b9a\u4e49get_config\u65b9\u6cd5\u3002 def get_config ( self ): config = super ( ResBlock , self ) . get_config () config . update ({ 'kernel_size' : self . kernel_size }) return config # \u6d4b\u8bd5ResBlock resblock = ResBlock ( kernel_size = 3 ) resblock . build ( input_shape = ( None , 200 , 7 )) resblock . compute_output_shape ( input_shape = ( None , 200 , 7 )) TensorShape([None, 100, 7]) # \u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u5b9e\u9645\u4e0a\u4e5f\u53ef\u4ee5\u4f7f\u7528Sequential\u6216\u8005FunctionalAPI class ImdbModel ( models . Model ): def __init__ ( self ): super ( ImdbModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 ) self . block1 = ResBlock ( 7 ) self . block2 = ResBlock ( 5 ) self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( ImdbModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . block1 ( x ) x = self . block2 ( x ) x = layers . Flatten ()( x ) x = self . dense ( x ) return ( x ) tf . keras . backend . clear_session () model = ImdbModel () model . build ( input_shape = ( None , 200 )) model . summary () model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) Model: \"imdb_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) multiple 70000 _________________________________________________________________ res_block (ResBlock) multiple 19143 _________________________________________________________________ res_block_1 (ResBlock) multiple 13703 _________________________________________________________________ dense (Dense) multiple 351 ================================================================= Total params: 103,197 Trainable params: 103,197 Non-trainable params: 0 _________________________________________________________________ import datetime logdir = \"./tflogs/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286 Epoch 2/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410 Epoch 3/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390 Epoch 4/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292 Epoch 5/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132 Epoch 6/6 1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052 plot_metric ( history , \"AUC\" ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0cModel\u5b50\u7c7b\u5316\u521b\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/","text":"6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 # \u6a21\u578b\u7684\u8bad\u7ec3\u4e3b\u8981\u6709\u5185\u7f6efit\u65b9\u6cd5\u3001\u5185\u7f6etran_on_batch\u65b9\u6cd5\u3001\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002 \u6ce8\uff1afit_generator\u65b9\u6cd5\u5728tf.keras\u4e2d\u4e0d\u63a8\u8350\u4f7f\u7528\uff0c\u5176\u529f\u80fd\u5df2\u7ecf\u88abfit\u5305\u542b\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import * #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () \u4e00\uff0c\u5185\u7f6efit\u65b9\u6cd5 # \u8be5\u65b9\u6cd5\u529f\u80fd\u975e\u5e38\u5f3a\u5927, \u652f\u6301\u5bf9numpy array, tf.data.Dataset\u4ee5\u53ca Python generator\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002 \u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u56de\u8c03\u51fd\u6570\u5b9e\u73b0\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u7684\u590d\u6742\u63a7\u5236\u903b\u8f91\u3002 tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 11s 37ms/step - loss: 2.0231 - sparse_categorical_accuracy: 0.4636 - sparse_top_k_categorical_accuracy: 0.7450 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.7560 Epoch 2/10 281/281 [==============================] - 9s 31ms/step - loss: 1.5079 - sparse_categorical_accuracy: 0.6091 - sparse_top_k_categorical_accuracy: 0.7901 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.6109 - val_sparse_top_k_categorical_accuracy: 0.7792 Epoch 3/10 281/281 [==============================] - 9s 33ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6823 - sparse_top_k_categorical_accuracy: 0.8448 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_top_k_categorical_accuracy: 0.8001 Epoch 4/10 281/281 [==============================] - 9s 33ms/step - loss: 0.9382 - sparse_categorical_accuracy: 0.7543 - sparse_top_k_categorical_accuracy: 0.9075 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.6398 - val_sparse_top_k_categorical_accuracy: 0.8032 Epoch 5/10 281/281 [==============================] - 10s 34ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8255 - sparse_top_k_categorical_accuracy: 0.9513 - val_loss: 1.9426 - val_sparse_categorical_accuracy: 0.6376 - val_sparse_top_k_categorical_accuracy: 0.7956 Epoch 6/10 281/281 [==============================] - 9s 33ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8762 - sparse_top_k_categorical_accuracy: 0.9716 - val_loss: 2.2141 - val_sparse_categorical_accuracy: 0.6291 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 7/10 281/281 [==============================] - 10s 37ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.6264 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 8/10 281/281 [==============================] - 10s 35ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9205 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 2.5366 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7974 Epoch 9/10 281/281 [==============================] - 10s 36ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9299 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 2.6564 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 10/10 281/281 [==============================] - 9s 30ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9334 - sparse_top_k_categorical_accuracy: 0.9947 - val_loss: 2.7365 - val_sparse_categorical_accuracy: 0.6220 - val_sparse_top_k_categorical_accuracy: 0.8005 \u4e8c\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5 # \u8be5\u5185\u7f6e\u65b9\u6cd5\u76f8\u6bd4\u8f83fit\u65b9\u6cd5\u66f4\u52a0\u7075\u6d3b\uff0c\u53ef\u4ee5\u4e0d\u901a\u8fc7\u56de\u8c03\u51fd\u6570\u800c\u76f4\u63a5\u5728\u6279\u6b21\u5c42\u6b21\u4e0a\u66f4\u52a0\u7cbe\u7ec6\u5730\u63a7\u5236\u8bad\u7ec3\u7684\u8fc7\u7a0b\u3002 tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ def train_model ( model , ds_train , ds_valid , epoches ): for epoch in tf . range ( 1 , epoches + 1 ): model . reset_metrics () # \u5728\u540e\u671f\u964d\u4f4e\u5b66\u4e60\u7387 if epoch == 5 : model . optimizer . lr . assign ( model . optimizer . lr / 2.0 ) tf . print ( \"Lowering optimizer Learning Rate... \\n\\n \" ) for x , y in ds_train : train_result = model . train_on_batch ( x , y ) for x , y in ds_valid : valid_result = model . test_on_batch ( x , y , reset_metrics = False ) if epoch % 1 == 0 : printbar () tf . print ( \"epoch = \" , epoch ) print ( \"train:\" , dict ( zip ( model . metrics_names , train_result ))) print ( \"valid:\" , dict ( zip ( model . metrics_names , valid_result ))) print ( \"\" ) train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:09:19 epoch = 1 train: {'loss': 0.82411176, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.8636364} valid: {'loss': 1.9265995, 'sparse_categorical_accuracy': 0.5743544, 'sparse_top_k_categorical_accuracy': 0.75779164} ================================================================================13:09:27 epoch = 2 train: {'loss': 0.6006621, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 1.844159, 'sparse_categorical_accuracy': 0.6126447, 'sparse_top_k_categorical_accuracy': 0.7920748} ================================================================================13:09:35 epoch = 3 train: {'loss': 0.36935613, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 2.163433, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.8045414} ================================================================================13:09:42 epoch = 4 train: {'loss': 0.2304088, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 2.8911984, 'sparse_categorical_accuracy': 0.6344613, 'sparse_top_k_categorical_accuracy': 0.7978629} Lowering optimizer Learning Rate... ================================================================================13:09:51 epoch = 5 train: {'loss': 0.111194365, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 3.6431572, 'sparse_categorical_accuracy': 0.6295637, 'sparse_top_k_categorical_accuracy': 0.7978629} ================================================================================13:09:59 epoch = 6 train: {'loss': 0.07741702, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.074161, 'sparse_categorical_accuracy': 0.6255565, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:07 epoch = 7 train: {'loss': 0.056113098, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.4461513, 'sparse_categorical_accuracy': 0.6273375, 'sparse_top_k_categorical_accuracy': 0.79652715} ================================================================================13:10:17 epoch = 8 train: {'loss': 0.043448802, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.7687583, 'sparse_categorical_accuracy': 0.6224399, 'sparse_top_k_categorical_accuracy': 0.79741764} ================================================================================13:10:26 epoch = 9 train: {'loss': 0.035002146, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.130505, 'sparse_categorical_accuracy': 0.6175423, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:34 epoch = 10 train: {'loss': 0.028303564, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.4559293, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7947462} \u4e09\uff0c\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af # \u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u65e0\u9700\u7f16\u8bd1\u6a21\u578b\uff0c\u76f4\u63a5\u5229\u7528\u4f18\u5316\u5668\u6839\u636e\u635f\u5931\u51fd\u6570\u53cd\u5411\u4f20\u64ad\u8fed\u4ee3\u53c2\u6570\uff0c\u62e5\u6709\u6700\u9ad8\u7684\u7075\u6d3b\u6027\u3002 tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:12:03 Epoch=1,Loss:2.02051544,Accuracy:0.460253835,Valid Loss:1.75700927,Valid Accuracy:0.536954582 ================================================================================13:12:09 Epoch=2,Loss:1.510795,Accuracy:0.610665798,Valid Loss:1.55349839,Valid Accuracy:0.616206586 ================================================================================13:12:17 Epoch=3,Loss:1.19221532,Accuracy:0.696170092,Valid Loss:1.52315605,Valid Accuracy:0.651380241 ================================================================================13:12:23 Epoch=4,Loss:0.90101546,Accuracy:0.766310394,Valid Loss:1.68327653,Valid Accuracy:0.648263574 ================================================================================13:12:30 Epoch=5,Loss:0.655430496,Accuracy:0.831329346,Valid Loss:1.90872383,Valid Accuracy:0.641139805 ================================================================================13:12:37 Epoch=6,Loss:0.492730737,Accuracy:0.877866864,Valid Loss:2.09966016,Valid Accuracy:0.63223511 ================================================================================13:12:44 Epoch=7,Loss:0.391238362,Accuracy:0.904030263,Valid Loss:2.27431226,Valid Accuracy:0.625111282 ================================================================================13:12:51 Epoch=8,Loss:0.327761739,Accuracy:0.922066331,Valid Loss:2.42568827,Valid Accuracy:0.617542326 ================================================================================13:12:58 Epoch=9,Loss:0.285573095,Accuracy:0.930527747,Valid Loss:2.55942106,Valid Accuracy:0.612644672 ================================================================================13:13:05 Epoch=10,Loss:0.255482465,Accuracy:0.936094403,Valid Loss:2.67789412,Valid Accuracy:0.612199485 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#6-2\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5","text":"\u6a21\u578b\u7684\u8bad\u7ec3\u4e3b\u8981\u6709\u5185\u7f6efit\u65b9\u6cd5\u3001\u5185\u7f6etran_on_batch\u65b9\u6cd5\u3001\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002 \u6ce8\uff1afit_generator\u65b9\u6cd5\u5728tf.keras\u4e2d\u4e0d\u63a8\u8350\u4f7f\u7528\uff0c\u5176\u529f\u80fd\u5df2\u7ecf\u88abfit\u5305\u542b\u3002 import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import * #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e00\u5185\u7f6efit\u65b9\u6cd5","text":"\u8be5\u65b9\u6cd5\u529f\u80fd\u975e\u5e38\u5f3a\u5927, \u652f\u6301\u5bf9numpy array, tf.data.Dataset\u4ee5\u53ca Python generator\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002 \u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u56de\u8c03\u51fd\u6570\u5b9e\u73b0\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u7684\u590d\u6742\u63a7\u5236\u903b\u8f91\u3002 tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 11s 37ms/step - loss: 2.0231 - sparse_categorical_accuracy: 0.4636 - sparse_top_k_categorical_accuracy: 0.7450 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.7560 Epoch 2/10 281/281 [==============================] - 9s 31ms/step - loss: 1.5079 - sparse_categorical_accuracy: 0.6091 - sparse_top_k_categorical_accuracy: 0.7901 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.6109 - val_sparse_top_k_categorical_accuracy: 0.7792 Epoch 3/10 281/281 [==============================] - 9s 33ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6823 - sparse_top_k_categorical_accuracy: 0.8448 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_top_k_categorical_accuracy: 0.8001 Epoch 4/10 281/281 [==============================] - 9s 33ms/step - loss: 0.9382 - sparse_categorical_accuracy: 0.7543 - sparse_top_k_categorical_accuracy: 0.9075 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.6398 - val_sparse_top_k_categorical_accuracy: 0.8032 Epoch 5/10 281/281 [==============================] - 10s 34ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8255 - sparse_top_k_categorical_accuracy: 0.9513 - val_loss: 1.9426 - val_sparse_categorical_accuracy: 0.6376 - val_sparse_top_k_categorical_accuracy: 0.7956 Epoch 6/10 281/281 [==============================] - 9s 33ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8762 - sparse_top_k_categorical_accuracy: 0.9716 - val_loss: 2.2141 - val_sparse_categorical_accuracy: 0.6291 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 7/10 281/281 [==============================] - 10s 37ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.6264 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 8/10 281/281 [==============================] - 10s 35ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9205 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 2.5366 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7974 Epoch 9/10 281/281 [==============================] - 10s 36ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9299 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 2.6564 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 10/10 281/281 [==============================] - 9s 30ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9334 - sparse_top_k_categorical_accuracy: 0.9947 - val_loss: 2.7365 - val_sparse_categorical_accuracy: 0.6220 - val_sparse_top_k_categorical_accuracy: 0.8005","title":"\u4e00\uff0c\u5185\u7f6efit\u65b9\u6cd5"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e8c\u5185\u7f6etrain_on_batch\u65b9\u6cd5","text":"\u8be5\u5185\u7f6e\u65b9\u6cd5\u76f8\u6bd4\u8f83fit\u65b9\u6cd5\u66f4\u52a0\u7075\u6d3b\uff0c\u53ef\u4ee5\u4e0d\u901a\u8fc7\u56de\u8c03\u51fd\u6570\u800c\u76f4\u63a5\u5728\u6279\u6b21\u5c42\u6b21\u4e0a\u66f4\u52a0\u7cbe\u7ec6\u5730\u63a7\u5236\u8bad\u7ec3\u7684\u8fc7\u7a0b\u3002 tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ def train_model ( model , ds_train , ds_valid , epoches ): for epoch in tf . range ( 1 , epoches + 1 ): model . reset_metrics () # \u5728\u540e\u671f\u964d\u4f4e\u5b66\u4e60\u7387 if epoch == 5 : model . optimizer . lr . assign ( model . optimizer . lr / 2.0 ) tf . print ( \"Lowering optimizer Learning Rate... \\n\\n \" ) for x , y in ds_train : train_result = model . train_on_batch ( x , y ) for x , y in ds_valid : valid_result = model . test_on_batch ( x , y , reset_metrics = False ) if epoch % 1 == 0 : printbar () tf . print ( \"epoch = \" , epoch ) print ( \"train:\" , dict ( zip ( model . metrics_names , train_result ))) print ( \"valid:\" , dict ( zip ( model . metrics_names , valid_result ))) print ( \"\" ) train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:09:19 epoch = 1 train: {'loss': 0.82411176, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.8636364} valid: {'loss': 1.9265995, 'sparse_categorical_accuracy': 0.5743544, 'sparse_top_k_categorical_accuracy': 0.75779164} ================================================================================13:09:27 epoch = 2 train: {'loss': 0.6006621, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 1.844159, 'sparse_categorical_accuracy': 0.6126447, 'sparse_top_k_categorical_accuracy': 0.7920748} ================================================================================13:09:35 epoch = 3 train: {'loss': 0.36935613, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 2.163433, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.8045414} ================================================================================13:09:42 epoch = 4 train: {'loss': 0.2304088, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 2.8911984, 'sparse_categorical_accuracy': 0.6344613, 'sparse_top_k_categorical_accuracy': 0.7978629} Lowering optimizer Learning Rate... ================================================================================13:09:51 epoch = 5 train: {'loss': 0.111194365, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 3.6431572, 'sparse_categorical_accuracy': 0.6295637, 'sparse_top_k_categorical_accuracy': 0.7978629} ================================================================================13:09:59 epoch = 6 train: {'loss': 0.07741702, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.074161, 'sparse_categorical_accuracy': 0.6255565, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:07 epoch = 7 train: {'loss': 0.056113098, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.4461513, 'sparse_categorical_accuracy': 0.6273375, 'sparse_top_k_categorical_accuracy': 0.79652715} ================================================================================13:10:17 epoch = 8 train: {'loss': 0.043448802, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.7687583, 'sparse_categorical_accuracy': 0.6224399, 'sparse_top_k_categorical_accuracy': 0.79741764} ================================================================================13:10:26 epoch = 9 train: {'loss': 0.035002146, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.130505, 'sparse_categorical_accuracy': 0.6175423, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:34 epoch = 10 train: {'loss': 0.028303564, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.4559293, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7947462}","title":"\u4e8c\uff0c\u5185\u7f6etrain_on_batch\u65b9\u6cd5"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e09\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af","text":"\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u65e0\u9700\u7f16\u8bd1\u6a21\u578b\uff0c\u76f4\u63a5\u5229\u7528\u4f18\u5316\u5668\u6839\u636e\u635f\u5931\u51fd\u6570\u53cd\u5411\u4f20\u64ad\u8fed\u4ee3\u53c2\u6570\uff0c\u62e5\u6709\u6700\u9ad8\u7684\u7075\u6d3b\u6027\u3002 tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:12:03 Epoch=1,Loss:2.02051544,Accuracy:0.460253835,Valid Loss:1.75700927,Valid Accuracy:0.536954582 ================================================================================13:12:09 Epoch=2,Loss:1.510795,Accuracy:0.610665798,Valid Loss:1.55349839,Valid Accuracy:0.616206586 ================================================================================13:12:17 Epoch=3,Loss:1.19221532,Accuracy:0.696170092,Valid Loss:1.52315605,Valid Accuracy:0.651380241 ================================================================================13:12:23 Epoch=4,Loss:0.90101546,Accuracy:0.766310394,Valid Loss:1.68327653,Valid Accuracy:0.648263574 ================================================================================13:12:30 Epoch=5,Loss:0.655430496,Accuracy:0.831329346,Valid Loss:1.90872383,Valid Accuracy:0.641139805 ================================================================================13:12:37 Epoch=6,Loss:0.492730737,Accuracy:0.877866864,Valid Loss:2.09966016,Valid Accuracy:0.63223511 ================================================================================13:12:44 Epoch=7,Loss:0.391238362,Accuracy:0.904030263,Valid Loss:2.27431226,Valid Accuracy:0.625111282 ================================================================================13:12:51 Epoch=8,Loss:0.327761739,Accuracy:0.922066331,Valid Loss:2.42568827,Valid Accuracy:0.617542326 ================================================================================13:12:58 Epoch=9,Loss:0.285573095,Accuracy:0.930527747,Valid Loss:2.55942106,Valid Accuracy:0.612644672 ================================================================================13:13:05 Epoch=10,Loss:0.255482465,Accuracy:0.936094403,Valid Loss:2.67789412,Valid Accuracy:0.612199485 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/","text":"6-3,\u4f7f\u7528\u5355GPU\u8bad\u7ec3\u6a21\u578b # \u6df1\u5ea6\u5b66\u4e60\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5e38\u5e38\u975e\u5e38\u8017\u65f6\uff0c\u4e00\u4e2a\u6a21\u578b\u8bad\u7ec3\u51e0\u4e2a\u5c0f\u65f6\u662f\u5bb6\u5e38\u4fbf\u996d\uff0c\u8bad\u7ec3\u51e0\u5929\u4e5f\u662f\u5e38\u6709\u7684\u4e8b\u60c5\uff0c\u6709\u65f6\u5019\u751a\u81f3\u8981\u8bad\u7ec3\u51e0\u5341\u5929\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u7684\u8017\u65f6\u4e3b\u8981\u6765\u81ea\u4e8e\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u6765\u81ea\u6570\u636e\u51c6\u5907\uff0c\u53e6\u4e00\u90e8\u5206\u6765\u81ea\u53c2\u6570\u8fed\u4ee3\u3002 \u5f53\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u8fd8\u662f\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u66f4\u591a\u8fdb\u7a0b\u6765\u51c6\u5907\u6570\u636e\u3002 \u5f53\u53c2\u6570\u8fed\u4ee3\u8fc7\u7a0b\u6210\u4e3a\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u7684\u65b9\u6cd5\u662f\u5e94\u7528GPU\u6216\u8005Google\u7684TPU\u6765\u8fdb\u884c\u52a0\u901f\u3002 \u8be6\u89c1\u300a\u7528GPU\u52a0\u901fKeras\u6a21\u578b\u2014\u2014Colab\u514d\u8d39GPU\u4f7f\u7528\u653b\u7565\u300b https://zhuanlan.zhihu.com/p/68509398 \u65e0\u8bba\u662f\u5185\u7f6efit\u65b9\u6cd5\uff0c\u8fd8\u662f\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u4eceCPU\u5207\u6362\u6210\u5355GPU\u8bad\u7ec3\u6a21\u578b\u90fd\u662f\u975e\u5e38\u65b9\u4fbf\u7684\uff0c\u65e0\u9700\u66f4\u6539\u4efb\u4f55\u4ee3\u7801\u3002\u5f53\u5b58\u5728\u53ef\u7528\u7684GPU\u65f6\uff0c\u5982\u679c\u4e0d\u7279\u610f\u6307\u5b9adevice\uff0ctensorflow\u4f1a\u81ea\u52a8\u4f18\u5148\u9009\u62e9\u4f7f\u7528GPU\u6765\u521b\u5efa\u5f20\u91cf\u548c\u6267\u884c\u5f20\u91cf\u8ba1\u7b97\u3002 \u4f46\u5982\u679c\u662f\u5728\u516c\u53f8\u6216\u8005\u5b66\u6821\u5b9e\u9a8c\u5ba4\u7684\u670d\u52a1\u5668\u73af\u5883\uff0c\u5b58\u5728\u591a\u4e2aGPU\u548c\u591a\u4e2a\u4f7f\u7528\u8005\u65f6\uff0c\u4e3a\u4e86\u4e0d\u8ba9\u5355\u4e2a\u540c\u5b66\u7684\u4efb\u52a1\u5360\u7528\u5168\u90e8GPU\u8d44\u6e90\u5bfc\u81f4\u5176\u4ed6\u540c\u5b66\u65e0\u6cd5\u4f7f\u7528\uff08tensorflow\u9ed8\u8ba4\u83b7\u53d6\u5168\u90e8GPU\u7684\u5168\u90e8\u5185\u5b58\u8d44\u6e90\u6743\u9650\uff0c\u4f46\u5b9e\u9645\u4e0a\u53ea\u4f7f\u7528\u4e00\u4e2aGPU\u7684\u90e8\u5206\u8d44\u6e90\uff09\uff0c\u6211\u4eec\u901a\u5e38\u4f1a\u5728\u5f00\u5934\u589e\u52a0\u4ee5\u4e0b\u51e0\u884c\u4ee3\u7801\u4ee5\u63a7\u5236\u6bcf\u4e2a\u4efb\u52a1\u4f7f\u7528\u7684GPU\u7f16\u53f7\u548c\u663e\u5b58\u5927\u5c0f\uff0c\u4ee5\u4fbf\u5176\u4ed6\u540c\u5b66\u4e5f\u80fd\u591f\u540c\u65f6\u8bad\u7ec3\u6a21\u578b\u3002 \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 GPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_\u5355GPU\u300b\uff1a https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) \u4e00\uff0cGPU\u8bbe\u7f6e # gpus = tf . config . list_physical_devices ( \"GPU\" ) if gpus : gpu0 = gpus [ 0 ] #\u5982\u679c\u6709\u591a\u4e2aGPU\uff0c\u4ec5\u4f7f\u7528\u7b2c0\u4e2aGPU tf . config . experimental . set_memory_growth ( gpu0 , True ) #\u8bbe\u7f6eGPU\u663e\u5b58\u7528\u91cf\u6309\u9700\u4f7f\u7528 # \u6216\u8005\u4e5f\u53ef\u4ee5\u8bbe\u7f6eGPU\u663e\u5b58\u4e3a\u56fa\u5b9a\u4f7f\u7528\u91cf(\u4f8b\u5982\uff1a4G) #tf.config.experimental.set_virtual_device_configuration(gpu0, # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) tf . config . set_visible_devices ([ gpu0 ], \"GPU\" ) \u6bd4\u8f83GPU\u548cCPU\u7684\u8ba1\u7b97\u901f\u5ea6 printbar () with tf . device ( \"/gpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:01 2.24953778e+11 ================================================================================17:37:01 printbar () with tf . device ( \"/cpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:34 2.24953795e+11 ================================================================================17:37:40 \u4e8c\uff0c\u51c6\u5907\u6570\u636e # MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () \u4e09\uff0c\u5b9a\u4e49\u6a21\u578b # tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ \u56db\uff0c\u8bad\u7ec3\u6a21\u578b # optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================17:13:26 Epoch=1,Loss:1.96735072,Accuracy:0.489200622,Valid Loss:1.64124215,Valid Accuracy:0.582813919 ================================================================================17:13:28 Epoch=2,Loss:1.4640888,Accuracy:0.624805152,Valid Loss:1.5559175,Valid Accuracy:0.607747078 ================================================================================17:13:30 Epoch=3,Loss:1.20681274,Accuracy:0.68581605,Valid Loss:1.58494771,Valid Accuracy:0.622439921 ================================================================================17:13:31 Epoch=4,Loss:0.937500894,Accuracy:0.75361836,Valid Loss:1.77466083,Valid Accuracy:0.621994674 ================================================================================17:13:33 Epoch=5,Loss:0.693960547,Accuracy:0.822199941,Valid Loss:2.00267363,Valid Accuracy:0.6197685 ================================================================================17:13:35 Epoch=6,Loss:0.519614,Accuracy:0.870296121,Valid Loss:2.23463202,Valid Accuracy:0.613980412 ================================================================================17:13:37 Epoch=7,Loss:0.408562034,Accuracy:0.901246965,Valid Loss:2.46969271,Valid Accuracy:0.612199485 ================================================================================17:13:39 Epoch=8,Loss:0.339028627,Accuracy:0.920062363,Valid Loss:2.68585229,Valid Accuracy:0.615316093 ================================================================================17:13:41 Epoch=9,Loss:0.293798745,Accuracy:0.92930305,Valid Loss:2.88995624,Valid Accuracy:0.613535166 ================================================================================17:13:43 Epoch=10,Loss:0.263130337,Accuracy:0.936651051,Valid Loss:3.09705234,Valid Accuracy:0.612644672 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-3,\u4f7f\u7528\u5355GPU\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#6-3\u4f7f\u7528\u5355gpu\u8bad\u7ec3\u6a21\u578b","text":"\u6df1\u5ea6\u5b66\u4e60\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5e38\u5e38\u975e\u5e38\u8017\u65f6\uff0c\u4e00\u4e2a\u6a21\u578b\u8bad\u7ec3\u51e0\u4e2a\u5c0f\u65f6\u662f\u5bb6\u5e38\u4fbf\u996d\uff0c\u8bad\u7ec3\u51e0\u5929\u4e5f\u662f\u5e38\u6709\u7684\u4e8b\u60c5\uff0c\u6709\u65f6\u5019\u751a\u81f3\u8981\u8bad\u7ec3\u51e0\u5341\u5929\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u7684\u8017\u65f6\u4e3b\u8981\u6765\u81ea\u4e8e\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u6765\u81ea\u6570\u636e\u51c6\u5907\uff0c\u53e6\u4e00\u90e8\u5206\u6765\u81ea\u53c2\u6570\u8fed\u4ee3\u3002 \u5f53\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u8fd8\u662f\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u66f4\u591a\u8fdb\u7a0b\u6765\u51c6\u5907\u6570\u636e\u3002 \u5f53\u53c2\u6570\u8fed\u4ee3\u8fc7\u7a0b\u6210\u4e3a\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u7684\u65b9\u6cd5\u662f\u5e94\u7528GPU\u6216\u8005Google\u7684TPU\u6765\u8fdb\u884c\u52a0\u901f\u3002 \u8be6\u89c1\u300a\u7528GPU\u52a0\u901fKeras\u6a21\u578b\u2014\u2014Colab\u514d\u8d39GPU\u4f7f\u7528\u653b\u7565\u300b https://zhuanlan.zhihu.com/p/68509398 \u65e0\u8bba\u662f\u5185\u7f6efit\u65b9\u6cd5\uff0c\u8fd8\u662f\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u4eceCPU\u5207\u6362\u6210\u5355GPU\u8bad\u7ec3\u6a21\u578b\u90fd\u662f\u975e\u5e38\u65b9\u4fbf\u7684\uff0c\u65e0\u9700\u66f4\u6539\u4efb\u4f55\u4ee3\u7801\u3002\u5f53\u5b58\u5728\u53ef\u7528\u7684GPU\u65f6\uff0c\u5982\u679c\u4e0d\u7279\u610f\u6307\u5b9adevice\uff0ctensorflow\u4f1a\u81ea\u52a8\u4f18\u5148\u9009\u62e9\u4f7f\u7528GPU\u6765\u521b\u5efa\u5f20\u91cf\u548c\u6267\u884c\u5f20\u91cf\u8ba1\u7b97\u3002 \u4f46\u5982\u679c\u662f\u5728\u516c\u53f8\u6216\u8005\u5b66\u6821\u5b9e\u9a8c\u5ba4\u7684\u670d\u52a1\u5668\u73af\u5883\uff0c\u5b58\u5728\u591a\u4e2aGPU\u548c\u591a\u4e2a\u4f7f\u7528\u8005\u65f6\uff0c\u4e3a\u4e86\u4e0d\u8ba9\u5355\u4e2a\u540c\u5b66\u7684\u4efb\u52a1\u5360\u7528\u5168\u90e8GPU\u8d44\u6e90\u5bfc\u81f4\u5176\u4ed6\u540c\u5b66\u65e0\u6cd5\u4f7f\u7528\uff08tensorflow\u9ed8\u8ba4\u83b7\u53d6\u5168\u90e8GPU\u7684\u5168\u90e8\u5185\u5b58\u8d44\u6e90\u6743\u9650\uff0c\u4f46\u5b9e\u9645\u4e0a\u53ea\u4f7f\u7528\u4e00\u4e2aGPU\u7684\u90e8\u5206\u8d44\u6e90\uff09\uff0c\u6211\u4eec\u901a\u5e38\u4f1a\u5728\u5f00\u5934\u589e\u52a0\u4ee5\u4e0b\u51e0\u884c\u4ee3\u7801\u4ee5\u63a7\u5236\u6bcf\u4e2a\u4efb\u52a1\u4f7f\u7528\u7684GPU\u7f16\u53f7\u548c\u663e\u5b58\u5927\u5c0f\uff0c\u4ee5\u4fbf\u5176\u4ed6\u540c\u5b66\u4e5f\u80fd\u591f\u540c\u65f6\u8bad\u7ec3\u6a21\u578b\u3002 \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 GPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_\u5355GPU\u300b\uff1a https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * #\u6253\u5370\u65f6\u95f4\u5206\u5272\u7ebf @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"6-3,\u4f7f\u7528\u5355GPU\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e00gpu\u8bbe\u7f6e","text":"gpus = tf . config . list_physical_devices ( \"GPU\" ) if gpus : gpu0 = gpus [ 0 ] #\u5982\u679c\u6709\u591a\u4e2aGPU\uff0c\u4ec5\u4f7f\u7528\u7b2c0\u4e2aGPU tf . config . experimental . set_memory_growth ( gpu0 , True ) #\u8bbe\u7f6eGPU\u663e\u5b58\u7528\u91cf\u6309\u9700\u4f7f\u7528 # \u6216\u8005\u4e5f\u53ef\u4ee5\u8bbe\u7f6eGPU\u663e\u5b58\u4e3a\u56fa\u5b9a\u4f7f\u7528\u91cf(\u4f8b\u5982\uff1a4G) #tf.config.experimental.set_virtual_device_configuration(gpu0, # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) tf . config . set_visible_devices ([ gpu0 ], \"GPU\" ) \u6bd4\u8f83GPU\u548cCPU\u7684\u8ba1\u7b97\u901f\u5ea6 printbar () with tf . device ( \"/gpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:01 2.24953778e+11 ================================================================================17:37:01 printbar () with tf . device ( \"/cpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:34 2.24953795e+11 ================================================================================17:37:40","title":"\u4e00\uff0cGPU\u8bbe\u7f6e"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e8c\u51c6\u5907\u6570\u636e","text":"MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"\u4e8c\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e09\u5b9a\u4e49\u6a21\u578b","text":"tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________","title":"\u4e09\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u56db\u8bad\u7ec3\u6a21\u578b","text":"optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================17:13:26 Epoch=1,Loss:1.96735072,Accuracy:0.489200622,Valid Loss:1.64124215,Valid Accuracy:0.582813919 ================================================================================17:13:28 Epoch=2,Loss:1.4640888,Accuracy:0.624805152,Valid Loss:1.5559175,Valid Accuracy:0.607747078 ================================================================================17:13:30 Epoch=3,Loss:1.20681274,Accuracy:0.68581605,Valid Loss:1.58494771,Valid Accuracy:0.622439921 ================================================================================17:13:31 Epoch=4,Loss:0.937500894,Accuracy:0.75361836,Valid Loss:1.77466083,Valid Accuracy:0.621994674 ================================================================================17:13:33 Epoch=5,Loss:0.693960547,Accuracy:0.822199941,Valid Loss:2.00267363,Valid Accuracy:0.6197685 ================================================================================17:13:35 Epoch=6,Loss:0.519614,Accuracy:0.870296121,Valid Loss:2.23463202,Valid Accuracy:0.613980412 ================================================================================17:13:37 Epoch=7,Loss:0.408562034,Accuracy:0.901246965,Valid Loss:2.46969271,Valid Accuracy:0.612199485 ================================================================================17:13:39 Epoch=8,Loss:0.339028627,Accuracy:0.920062363,Valid Loss:2.68585229,Valid Accuracy:0.615316093 ================================================================================17:13:41 Epoch=9,Loss:0.293798745,Accuracy:0.92930305,Valid Loss:2.88995624,Valid Accuracy:0.613535166 ================================================================================17:13:43 Epoch=10,Loss:0.263130337,Accuracy:0.936651051,Valid Loss:3.09705234,Valid Accuracy:0.612644672 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-4%2C%E4%BD%BF%E7%94%A8%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/","text":"6-4,\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b # \u5982\u679c\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b\uff0c\u63a8\u8350\u4f7f\u7528\u5185\u7f6efit\u65b9\u6cd5\uff0c\u8f83\u4e3a\u65b9\u4fbf\uff0c\u4ec5\u9700\u6dfb\u52a02\u884c\u4ee3\u7801\u3002 \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 GPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_\u591aGPU\u300b\uff1a https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU- MirroredStrategy\u8fc7\u7a0b\u7b80\u4ecb\uff1a \u8bad\u7ec3\u5f00\u59cb\u524d\uff0c\u8be5\u7b56\u7565\u5728\u6240\u6709 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\u4e0a\u5747\u5404\u590d\u5236\u4e00\u4efd\u5b8c\u6574\u7684\u6a21\u578b\uff1b \u6bcf\u6b21\u8bad\u7ec3\u4f20\u5165\u4e00\u4e2a\u6279\u6b21\u7684\u6570\u636e\u65f6\uff0c\u5c06\u6570\u636e\u5206\u6210 N \u4efd\uff0c\u5206\u522b\u4f20\u5165 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\uff08\u5373\u6570\u636e\u5e76\u884c\uff09\uff1b N \u4e2a\u8ba1\u7b97\u8bbe\u5907\u4f7f\u7528\u672c\u5730\u53d8\u91cf\uff08\u955c\u50cf\u53d8\u91cf\uff09\u5206\u522b\u8ba1\u7b97\u81ea\u5df1\u6240\u83b7\u5f97\u7684\u90e8\u5206\u6570\u636e\u7684\u68af\u5ea6\uff1b \u4f7f\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684 All-reduce \u64cd\u4f5c\uff0c\u5728\u8ba1\u7b97\u8bbe\u5907\u95f4\u9ad8\u6548\u4ea4\u6362\u68af\u5ea6\u6570\u636e\u5e76\u8fdb\u884c\u6c42\u548c\uff0c\u4f7f\u5f97\u6700\u7ec8\u6bcf\u4e2a\u8bbe\u5907\u90fd\u6709\u4e86\u6240\u6709\u8bbe\u5907\u7684\u68af\u5ea6\u4e4b\u548c\uff1b \u4f7f\u7528\u68af\u5ea6\u6c42\u548c\u7684\u7ed3\u679c\u66f4\u65b0\u672c\u5730\u53d8\u91cf\uff08\u955c\u50cf\u53d8\u91cf\uff09\uff1b \u5f53\u6240\u6709\u8bbe\u5907\u5747\u66f4\u65b0\u672c\u5730\u53d8\u91cf\u540e\uff0c\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8bad\u7ec3\uff08\u5373\u8be5\u5e76\u884c\u7b56\u7565\u662f\u540c\u6b65\u7684\uff09\u3002 % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * #\u6b64\u5904\u5728colab\u4e0a\u4f7f\u75281\u4e2aGPU\u6a21\u62df\u51fa\u4e24\u4e2a\u903b\u8f91GPU\u8fdb\u884c\u591aGPU\u8bad\u7ec3 gpus = tf . config . experimental . list_physical_devices ( 'GPU' ) if gpus : # \u8bbe\u7f6e\u4e24\u4e2a\u903b\u8f91GPU\u6a21\u62df\u591aGPU\u8bad\u7ec3 try : tf . config . experimental . set_virtual_device_configuration ( gpus [ 0 ], [ tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 ), tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 )]) logical_gpus = tf . config . experimental . list_logical_devices ( 'GPU' ) print ( len ( gpus ), \"Physical GPU,\" , len ( logical_gpus ), \"Logical GPUs\" ) except RuntimeError as e : print ( e ) \u4e00\uff0c\u51c6\u5907\u6570\u636e # MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # #\u589e\u52a0\u4ee5\u4e0b\u4e24\u884c\u4ee3\u7801 strategy = tf . distribute . MirroredStrategy () with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1') Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). Train for 281 steps, validate for 71 steps Epoch 1/10 INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). 281/281 [==============================] - 15s 53ms/step - loss: 2.0270 - sparse_categorical_accuracy: 0.4653 - sparse_top_k_categorical_accuracy: 0.7481 - val_loss: 1.7517 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7578 Epoch 2/10 281/281 [==============================] - 4s 14ms/step - loss: 1.5206 - sparse_categorical_accuracy: 0.6045 - sparse_top_k_categorical_accuracy: 0.7938 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 3/10 281/281 [==============================] - 4s 14ms/step - loss: 1.2178 - sparse_categorical_accuracy: 0.6843 - sparse_top_k_categorical_accuracy: 0.8547 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6327 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 4/10 281/281 [==============================] - 4s 13ms/step - loss: 0.9127 - sparse_categorical_accuracy: 0.7648 - sparse_top_k_categorical_accuracy: 0.9113 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6296 - val_sparse_top_k_categorical_accuracy: 0.8201 Epoch 5/10 281/281 [==============================] - 4s 14ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.8321 - sparse_top_k_categorical_accuracy: 0.9525 - val_loss: 1.8791 - val_sparse_categorical_accuracy: 0.6158 - val_sparse_top_k_categorical_accuracy: 0.8219 Epoch 6/10 281/281 [==============================] - 4s 14ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9725 - val_loss: 2.1282 - val_sparse_categorical_accuracy: 0.6037 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 7/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.9051 - sparse_top_k_categorical_accuracy: 0.9814 - val_loss: 2.3033 - val_sparse_categorical_accuracy: 0.6046 - val_sparse_top_k_categorical_accuracy: 0.8094 Epoch 8/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9207 - sparse_top_k_categorical_accuracy: 0.9863 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.8099 Epoch 9/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 2.5571 - val_sparse_categorical_accuracy: 0.6020 - val_sparse_top_k_categorical_accuracy: 0.8126 Epoch 10/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9342 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 2.6700 - val_sparse_categorical_accuracy: 0.6077 - val_sparse_top_k_categorical_accuracy: 0.8148 CPU times: user 1min 2s, sys: 8.59 s, total: 1min 10s Wall time: 58.5 s \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-4,\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-4%2C%E4%BD%BF%E7%94%A8%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#6-4\u4f7f\u7528\u591agpu\u8bad\u7ec3\u6a21\u578b","text":"\u5982\u679c\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b\uff0c\u63a8\u8350\u4f7f\u7528\u5185\u7f6efit\u65b9\u6cd5\uff0c\u8f83\u4e3a\u65b9\u4fbf\uff0c\u4ec5\u9700\u6dfb\u52a02\u884c\u4ee3\u7801\u3002 \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 GPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_\u591aGPU\u300b\uff1a https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU- MirroredStrategy\u8fc7\u7a0b\u7b80\u4ecb\uff1a \u8bad\u7ec3\u5f00\u59cb\u524d\uff0c\u8be5\u7b56\u7565\u5728\u6240\u6709 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\u4e0a\u5747\u5404\u590d\u5236\u4e00\u4efd\u5b8c\u6574\u7684\u6a21\u578b\uff1b \u6bcf\u6b21\u8bad\u7ec3\u4f20\u5165\u4e00\u4e2a\u6279\u6b21\u7684\u6570\u636e\u65f6\uff0c\u5c06\u6570\u636e\u5206\u6210 N \u4efd\uff0c\u5206\u522b\u4f20\u5165 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\uff08\u5373\u6570\u636e\u5e76\u884c\uff09\uff1b N \u4e2a\u8ba1\u7b97\u8bbe\u5907\u4f7f\u7528\u672c\u5730\u53d8\u91cf\uff08\u955c\u50cf\u53d8\u91cf\uff09\u5206\u522b\u8ba1\u7b97\u81ea\u5df1\u6240\u83b7\u5f97\u7684\u90e8\u5206\u6570\u636e\u7684\u68af\u5ea6\uff1b \u4f7f\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684 All-reduce \u64cd\u4f5c\uff0c\u5728\u8ba1\u7b97\u8bbe\u5907\u95f4\u9ad8\u6548\u4ea4\u6362\u68af\u5ea6\u6570\u636e\u5e76\u8fdb\u884c\u6c42\u548c\uff0c\u4f7f\u5f97\u6700\u7ec8\u6bcf\u4e2a\u8bbe\u5907\u90fd\u6709\u4e86\u6240\u6709\u8bbe\u5907\u7684\u68af\u5ea6\u4e4b\u548c\uff1b \u4f7f\u7528\u68af\u5ea6\u6c42\u548c\u7684\u7ed3\u679c\u66f4\u65b0\u672c\u5730\u53d8\u91cf\uff08\u955c\u50cf\u53d8\u91cf\uff09\uff1b \u5f53\u6240\u6709\u8bbe\u5907\u5747\u66f4\u65b0\u672c\u5730\u53d8\u91cf\u540e\uff0c\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8bad\u7ec3\uff08\u5373\u8be5\u5e76\u884c\u7b56\u7565\u662f\u540c\u6b65\u7684\uff09\u3002 % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * #\u6b64\u5904\u5728colab\u4e0a\u4f7f\u75281\u4e2aGPU\u6a21\u62df\u51fa\u4e24\u4e2a\u903b\u8f91GPU\u8fdb\u884c\u591aGPU\u8bad\u7ec3 gpus = tf . config . experimental . list_physical_devices ( 'GPU' ) if gpus : # \u8bbe\u7f6e\u4e24\u4e2a\u903b\u8f91GPU\u6a21\u62df\u591aGPU\u8bad\u7ec3 try : tf . config . experimental . set_virtual_device_configuration ( gpus [ 0 ], [ tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 ), tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 )]) logical_gpus = tf . config . experimental . list_logical_devices ( 'GPU' ) print ( len ( gpus ), \"Physical GPU,\" , len ( logical_gpus ), \"Logical GPUs\" ) except RuntimeError as e : print ( e )","title":"6-4,\u4f7f\u7528\u591aGPU\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-4%2C%E4%BD%BF%E7%94%A8%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-4%2C%E4%BD%BF%E7%94%A8%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model )","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-4%2C%E4%BD%BF%E7%94%A8%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"#\u589e\u52a0\u4ee5\u4e0b\u4e24\u884c\u4ee3\u7801 strategy = tf . distribute . MirroredStrategy () with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1') Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). Train for 281 steps, validate for 71 steps Epoch 1/10 INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). 281/281 [==============================] - 15s 53ms/step - loss: 2.0270 - sparse_categorical_accuracy: 0.4653 - sparse_top_k_categorical_accuracy: 0.7481 - val_loss: 1.7517 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7578 Epoch 2/10 281/281 [==============================] - 4s 14ms/step - loss: 1.5206 - sparse_categorical_accuracy: 0.6045 - sparse_top_k_categorical_accuracy: 0.7938 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 3/10 281/281 [==============================] - 4s 14ms/step - loss: 1.2178 - sparse_categorical_accuracy: 0.6843 - sparse_top_k_categorical_accuracy: 0.8547 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6327 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 4/10 281/281 [==============================] - 4s 13ms/step - loss: 0.9127 - sparse_categorical_accuracy: 0.7648 - sparse_top_k_categorical_accuracy: 0.9113 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6296 - val_sparse_top_k_categorical_accuracy: 0.8201 Epoch 5/10 281/281 [==============================] - 4s 14ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.8321 - sparse_top_k_categorical_accuracy: 0.9525 - val_loss: 1.8791 - val_sparse_categorical_accuracy: 0.6158 - val_sparse_top_k_categorical_accuracy: 0.8219 Epoch 6/10 281/281 [==============================] - 4s 14ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9725 - val_loss: 2.1282 - val_sparse_categorical_accuracy: 0.6037 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 7/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.9051 - sparse_top_k_categorical_accuracy: 0.9814 - val_loss: 2.3033 - val_sparse_categorical_accuracy: 0.6046 - val_sparse_top_k_categorical_accuracy: 0.8094 Epoch 8/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9207 - sparse_top_k_categorical_accuracy: 0.9863 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.8099 Epoch 9/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 2.5571 - val_sparse_categorical_accuracy: 0.6020 - val_sparse_top_k_categorical_accuracy: 0.8126 Epoch 10/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9342 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 2.6700 - val_sparse_categorical_accuracy: 0.6077 - val_sparse_top_k_categorical_accuracy: 0.8148 CPU times: user 1min 2s, sys: 8.59 s, total: 1min 10s Wall time: 58.5 s \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-5%2C%E4%BD%BF%E7%94%A8TPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/","text":"6-5,\u4f7f\u7528TPU\u8bad\u7ec3\u6a21\u578b # \u5982\u679c\u60f3\u5c1d\u8bd5\u4f7f\u7528Google Colab\u4e0a\u7684TPU\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4e5f\u662f\u975e\u5e38\u65b9\u4fbf\uff0c\u4ec5\u9700\u6dfb\u52a06\u884c\u4ee3\u7801\u3002 \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 TPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_TPU\u300b\uff1a https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * \u4e00\uff0c\u51c6\u5907\u6570\u636e # MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # #\u589e\u52a0\u4ee5\u4e0b6\u884c\u4ee3\u7801 import os resolver = tf . distribute . cluster_resolver . TPUClusterResolver ( tpu = 'grpc://' + os . environ [ 'COLAB_TPU_ADDR' ]) tf . config . experimental_connect_to_cluster ( resolver ) tf . tpu . experimental . initialize_tpu_system ( resolver ) strategy = tf . distribute . experimental . TPUStrategy ( resolver ) with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Found TPU system: INFO:tensorflow:Found TPU system: INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 12s 43ms/step - loss: 3.4466 - sparse_categorical_accuracy: 0.4332 - sparse_top_k_categorical_accuracy: 0.7180 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.5352 - val_sparse_top_k_categorical_accuracy: 0.7195 Epoch 2/10 281/281 [==============================] - 6s 20ms/step - loss: 3.3251 - sparse_categorical_accuracy: 0.5405 - sparse_top_k_categorical_accuracy: 0.7302 - val_loss: 3.3082 - val_sparse_categorical_accuracy: 0.5463 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 3/10 281/281 [==============================] - 6s 20ms/step - loss: 3.2961 - sparse_categorical_accuracy: 0.5729 - sparse_top_k_categorical_accuracy: 0.7280 - val_loss: 3.3026 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 4/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2751 - sparse_categorical_accuracy: 0.5924 - sparse_top_k_categorical_accuracy: 0.7276 - val_loss: 3.2957 - val_sparse_categorical_accuracy: 0.5543 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 5/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2655 - sparse_categorical_accuracy: 0.6008 - sparse_top_k_categorical_accuracy: 0.7290 - val_loss: 3.3022 - val_sparse_categorical_accuracy: 0.5490 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 6/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2616 - sparse_categorical_accuracy: 0.6041 - sparse_top_k_categorical_accuracy: 0.7295 - val_loss: 3.3015 - val_sparse_categorical_accuracy: 0.5503 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 7/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2595 - sparse_categorical_accuracy: 0.6059 - sparse_top_k_categorical_accuracy: 0.7322 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.5454 - val_sparse_top_k_categorical_accuracy: 0.7266 Epoch 8/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2591 - sparse_categorical_accuracy: 0.6063 - sparse_top_k_categorical_accuracy: 0.7327 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 9/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2588 - sparse_categorical_accuracy: 0.6062 - sparse_top_k_categorical_accuracy: 0.7332 - val_loss: 3.2992 - val_sparse_categorical_accuracy: 0.5521 - val_sparse_top_k_categorical_accuracy: 0.7257 Epoch 10/10 281/281 [==============================] - 5s 18ms/step - loss: 3.2577 - sparse_categorical_accuracy: 0.6073 - sparse_top_k_categorical_accuracy: 0.7363 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.5516 - val_sparse_top_k_categorical_accuracy: 0.7306 CPU times: user 18.9 s, sys: 3.86 s, total: 22.7 s Wall time: 1min 1s \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-5,\u4f7f\u7528TPU\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-5%2C%E4%BD%BF%E7%94%A8TPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#6-5\u4f7f\u7528tpu\u8bad\u7ec3\u6a21\u578b","text":"\u5982\u679c\u60f3\u5c1d\u8bd5\u4f7f\u7528Google Colab\u4e0a\u7684TPU\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4e5f\u662f\u975e\u5e38\u65b9\u4fbf\uff0c\u4ec5\u9700\u6dfb\u52a06\u884c\u4ee3\u7801\u3002 \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 TPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_TPU\u300b\uff1a https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import *","title":"6-5,\u4f7f\u7528TPU\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-5%2C%E4%BD%BF%E7%94%A8TPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-5%2C%E4%BD%BF%E7%94%A8TPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model )","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-5%2C%E4%BD%BF%E7%94%A8TPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"#\u589e\u52a0\u4ee5\u4e0b6\u884c\u4ee3\u7801 import os resolver = tf . distribute . cluster_resolver . TPUClusterResolver ( tpu = 'grpc://' + os . environ [ 'COLAB_TPU_ADDR' ]) tf . config . experimental_connect_to_cluster ( resolver ) tf . tpu . experimental . initialize_tpu_system ( resolver ) strategy = tf . distribute . experimental . TPUStrategy ( resolver ) with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Found TPU system: INFO:tensorflow:Found TPU system: INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 12s 43ms/step - loss: 3.4466 - sparse_categorical_accuracy: 0.4332 - sparse_top_k_categorical_accuracy: 0.7180 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.5352 - val_sparse_top_k_categorical_accuracy: 0.7195 Epoch 2/10 281/281 [==============================] - 6s 20ms/step - loss: 3.3251 - sparse_categorical_accuracy: 0.5405 - sparse_top_k_categorical_accuracy: 0.7302 - val_loss: 3.3082 - val_sparse_categorical_accuracy: 0.5463 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 3/10 281/281 [==============================] - 6s 20ms/step - loss: 3.2961 - sparse_categorical_accuracy: 0.5729 - sparse_top_k_categorical_accuracy: 0.7280 - val_loss: 3.3026 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 4/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2751 - sparse_categorical_accuracy: 0.5924 - sparse_top_k_categorical_accuracy: 0.7276 - val_loss: 3.2957 - val_sparse_categorical_accuracy: 0.5543 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 5/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2655 - sparse_categorical_accuracy: 0.6008 - sparse_top_k_categorical_accuracy: 0.7290 - val_loss: 3.3022 - val_sparse_categorical_accuracy: 0.5490 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 6/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2616 - sparse_categorical_accuracy: 0.6041 - sparse_top_k_categorical_accuracy: 0.7295 - val_loss: 3.3015 - val_sparse_categorical_accuracy: 0.5503 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 7/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2595 - sparse_categorical_accuracy: 0.6059 - sparse_top_k_categorical_accuracy: 0.7322 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.5454 - val_sparse_top_k_categorical_accuracy: 0.7266 Epoch 8/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2591 - sparse_categorical_accuracy: 0.6063 - sparse_top_k_categorical_accuracy: 0.7327 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 9/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2588 - sparse_categorical_accuracy: 0.6062 - sparse_top_k_categorical_accuracy: 0.7332 - val_loss: 3.2992 - val_sparse_categorical_accuracy: 0.5521 - val_sparse_top_k_categorical_accuracy: 0.7257 Epoch 10/10 281/281 [==============================] - 5s 18ms/step - loss: 3.2577 - sparse_categorical_accuracy: 0.6073 - sparse_top_k_categorical_accuracy: 0.7363 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.5516 - val_sparse_top_k_categorical_accuracy: 0.7306 CPU times: user 18.9 s, sys: 3.86 s, total: 22.7 s Wall time: 1min 1s \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/","text":"6-6,\u4f7f\u7528tensorflow-serving\u90e8\u7f72\u6a21\u578b # TensorFlow\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4ee5tensorflow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6210protobuf\u6587\u4ef6\u540e\u53ef\u4ee5\u7528\u8bb8\u591a\u65b9\u5f0f\u90e8\u7f72\u8fd0\u884c\u3002 \u4f8b\u5982\uff1a\u901a\u8fc7 tensorflow-js \u53ef\u4ee5\u7528javascrip\u811a\u672c\u52a0\u8f7d\u6a21\u578b\u5e76\u5728\u6d4f\u89c8\u5668\u4e2d\u8fd0\u884c\u6a21\u578b\u3002 \u901a\u8fc7 tensorflow-lite \u53ef\u4ee5\u5728\u79fb\u52a8\u548c\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u52a0\u8f7d\u5e76\u8fd0\u884cTensorFlow\u6a21\u578b\u3002 \u901a\u8fc7 tensorflow-serving \u53ef\u4ee5\u52a0\u8f7d\u6a21\u578b\u540e\u63d0\u4f9b\u7f51\u7edc\u63a5\u53e3API\u670d\u52a1\uff0c\u901a\u8fc7\u4efb\u610f\u7f16\u7a0b\u8bed\u8a00\u53d1\u9001\u7f51\u7edc\u8bf7\u6c42\u90fd\u53ef\u4ee5\u83b7\u53d6\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u3002 \u901a\u8fc7 tensorFlow for Java\u63a5\u53e3\uff0c\u53ef\u4ee5\u5728Java\u6216\u8005spark(scala)\u4e2d\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002 \u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdtensorflow serving\u90e8\u7f72\u6a21\u578b\u3001\u4f7f\u7528spark(scala)\u8c03\u7528tensorflow\u6a21\u578b\u7684\u65b9\u6cd5\u3002 \u3007\uff0ctensorflow serving\u6a21\u578b\u90e8\u7f72\u6982\u8ff0 # \u4f7f\u7528 tensorflow serving \u90e8\u7f72\u6a21\u578b\u8981\u5b8c\u6210\u4ee5\u4e0b\u6b65\u9aa4\u3002 (1) \u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6\u3002 (2) \u5b89\u88c5tensorflow serving\u3002 (3) \u542f\u52a8tensorflow serving \u670d\u52a1\u3002 (4) \u5411API\u670d\u52a1\u53d1\u9001\u8bf7\u6c42\uff0c\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_serving\u300b\uff1a https://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8 % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * \u4e00\uff0c\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6 # \u6211\u4eec\u4f7f\u7528tf.keras \u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u4fdd\u5b58\u6210protobuf\u6587\u4ef6\u3002 import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## \u6837\u672c\u6570\u91cf n = 800 ## \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 ## \u5efa\u7acb\u6a21\u578b tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) #\u8bbe\u7f6e\u8f93\u5165\u540d\u5b57\u4e3ainputs outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) #\u8bbe\u7f6e\u8f93\u51fa\u540d\u5b57\u4e3aoutputs linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## \u5c06\u6a21\u578b\u4fdd\u5b58\u6210pb\u683c\u5f0f\u6587\u4ef6 export_path = \"../../data/linear_model/\" version = \"1\" #\u540e\u7eed\u53ef\u4ee5\u901a\u8fc7\u7248\u672c\u53f7\u8fdb\u884c\u6a21\u578b\u7248\u672c\u8fed\u4ee3\u4e0e\u7ba1\u7406 linear . save ( export_path + version , save_format = \"tf\" ) #\u67e5\u770b\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6 ! ls { export_path + version } assets saved_model.pb variables # \u67e5\u770b\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f ! saved_model_cli show -- dir { export_path + str ( version )} -- all MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs: signature_def['__saved_model_init_op']: The given SavedModel SignatureDef contains the following input(s): The given SavedModel SignatureDef contains the following output(s): outputs['__saved_model_init_op'] tensor_info: dtype: DT_INVALID shape: unknown_rank name: NoOp Method name is: signature_def['serving_default']: The given SavedModel SignatureDef contains the following input(s): inputs['inputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name: serving_default_inputs:0 The given SavedModel SignatureDef contains the following output(s): outputs['outputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 1) name: StatefulPartitionedCall:0 Method name is: tensorflow/serving/predict WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Defined Functions: Function Name: '__call__' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Function Name: '_default_save_signature' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Function Name: 'call_and_return_all_conditional_losses' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None \u4e8c\uff0c\u5b89\u88c5 tensorflow serving # \u5b89\u88c5 tensorflow serving \u67092\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\u901a\u8fc7Docker\u955c\u50cf\u5b89\u88c5\uff0c\u901a\u8fc7apt\u5b89\u88c5\u3002 \u901a\u8fc7Docker\u955c\u50cf\u5b89\u88c5\u662f\u6700\u7b80\u5355\uff0c\u6700\u76f4\u63a5\u7684\u65b9\u6cd5\uff0c\u63a8\u8350\u91c7\u7528\u3002 Docker\u53ef\u4ee5\u7406\u89e3\u6210\u4e00\u79cd\u5bb9\u5668\uff0c\u5176\u4e0a\u9762\u53ef\u4ee5\u7ed9\u5404\u79cd\u4e0d\u540c\u7684\u7a0b\u5e8f\u63d0\u4f9b\u72ec\u7acb\u7684\u8fd0\u884c\u73af\u5883\u3002 \u4e00\u822c\u4e1a\u52a1\u4e2d\u7528\u5230tensorflow\u7684\u4f01\u4e1a\u90fd\u4f1a\u6709\u8fd0\u7ef4\u540c\u5b66\u901a\u8fc7Docker \u642d\u5efa tensorflow serving. \u65e0\u9700\u7b97\u6cd5\u5de5\u7a0b\u5e08\u540c\u5b66\u52a8\u624b\u5b89\u88c5\uff0c\u4ee5\u4e0b\u5b89\u88c5\u8fc7\u7a0b\u4ec5\u4f9b\u53c2\u8003\u3002 \u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u673a\u5668\u4e0a\u5b89\u88c5Docker\u7684\u65b9\u6cd5\u53ef\u4ee5\u53c2\u7167\u4ee5\u4e0b\u94fe\u63a5\u3002 Windows: https://www.runoob.com/docker/windows-docker-install.html MacOs: https://www.runoob.com/docker/macos-docker-install.html CentOS: https://www.runoob.com/docker/centos-docker-install.html \u5b89\u88c5Docker\u6210\u529f\u540e\uff0c\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u52a0\u8f7d tensorflow/serving \u955c\u50cf\u5230Docker\u4e2d docker pull tensorflow/serving \u4e09\uff0c\u542f\u52a8 tensorflow serving \u670d\u52a1 # ! docker run - t -- rm - p 8501 : 8501 \\ - v \"/Users/..../../data/linear_model/\" \\ - e MODEL_NAME = linear_model \\ tensorflow / serving & > server . log 2 >& 1 \u56db\uff0c\u5411API\u670d\u52a1\u53d1\u9001\u8bf7\u6c42 # \u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u7f16\u7a0b\u8bed\u8a00\u7684http\u529f\u80fd\u53d1\u9001\u8bf7\u6c42\uff0c\u4e0b\u9762\u793a\u8303linux\u7684 curl \u547d\u4ee4\u53d1\u9001\u8bf7\u6c42\uff0c\u4ee5\u53caPython\u7684requests\u5e93\u53d1\u9001\u8bf7\u6c42\u3002 ! curl - d '{\"instances\": [[1.0, 2.0], [5.0,7.0]]}' \\ - X POST http : // localhost : 8501 / v1 / models / linear_model : predict { \"predictions\": [[3.06546211], [6.02843142] ] } import json , requests data = json . dumps ({ \"signature_name\" : \"serving_default\" , \"instances\" : [[ 1.0 , 2.0 ], [ 5.0 , 7.0 ]]}) headers = { \"content-type\" : \"application/json\" } json_response = requests . post ( 'http://localhost:8501/v1/models/linear_model:predict' , data = data , headers = headers ) predictions = json . loads ( json_response . text )[ \"predictions\" ] print ( predictions ) [[3.06546211], [6.02843142]] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-6,\u4f7f\u7528tensorflow-serving\u90e8\u7f72\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/#6-6\u4f7f\u7528tensorflow-serving\u90e8\u7f72\u6a21\u578b","text":"TensorFlow\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4ee5tensorflow\u539f\u751f\u65b9\u5f0f\u4fdd\u5b58\u6210protobuf\u6587\u4ef6\u540e\u53ef\u4ee5\u7528\u8bb8\u591a\u65b9\u5f0f\u90e8\u7f72\u8fd0\u884c\u3002 \u4f8b\u5982\uff1a\u901a\u8fc7 tensorflow-js \u53ef\u4ee5\u7528javascrip\u811a\u672c\u52a0\u8f7d\u6a21\u578b\u5e76\u5728\u6d4f\u89c8\u5668\u4e2d\u8fd0\u884c\u6a21\u578b\u3002 \u901a\u8fc7 tensorflow-lite \u53ef\u4ee5\u5728\u79fb\u52a8\u548c\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u52a0\u8f7d\u5e76\u8fd0\u884cTensorFlow\u6a21\u578b\u3002 \u901a\u8fc7 tensorflow-serving \u53ef\u4ee5\u52a0\u8f7d\u6a21\u578b\u540e\u63d0\u4f9b\u7f51\u7edc\u63a5\u53e3API\u670d\u52a1\uff0c\u901a\u8fc7\u4efb\u610f\u7f16\u7a0b\u8bed\u8a00\u53d1\u9001\u7f51\u7edc\u8bf7\u6c42\u90fd\u53ef\u4ee5\u83b7\u53d6\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u3002 \u901a\u8fc7 tensorFlow for Java\u63a5\u53e3\uff0c\u53ef\u4ee5\u5728Java\u6216\u8005spark(scala)\u4e2d\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002 \u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdtensorflow serving\u90e8\u7f72\u6a21\u578b\u3001\u4f7f\u7528spark(scala)\u8c03\u7528tensorflow\u6a21\u578b\u7684\u65b9\u6cd5\u3002","title":"6-6,\u4f7f\u7528tensorflow-serving\u90e8\u7f72\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/#\u3007tensorflow-serving\u6a21\u578b\u90e8\u7f72\u6982\u8ff0","text":"\u4f7f\u7528 tensorflow serving \u90e8\u7f72\u6a21\u578b\u8981\u5b8c\u6210\u4ee5\u4e0b\u6b65\u9aa4\u3002 (1) \u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6\u3002 (2) \u5b89\u88c5tensorflow serving\u3002 (3) \u542f\u52a8tensorflow serving \u670d\u52a1\u3002 (4) \u5411API\u670d\u52a1\u53d1\u9001\u8bf7\u6c42\uff0c\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u3002 \u53ef\u901a\u8fc7\u4ee5\u4e0bcolab\u94fe\u63a5\u6d4b\u8bd5\u6548\u679c\u300atf_serving\u300b\uff1a https://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8 % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import *","title":"\u3007\uff0ctensorflow serving\u6a21\u578b\u90e8\u7f72\u6982\u8ff0"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/#\u4e00\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6","text":"\u6211\u4eec\u4f7f\u7528tf.keras \u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u4fdd\u5b58\u6210protobuf\u6587\u4ef6\u3002 import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## \u6837\u672c\u6570\u91cf n = 800 ## \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 ## \u5efa\u7acb\u6a21\u578b tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) #\u8bbe\u7f6e\u8f93\u5165\u540d\u5b57\u4e3ainputs outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) #\u8bbe\u7f6e\u8f93\u51fa\u540d\u5b57\u4e3aoutputs linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## \u5c06\u6a21\u578b\u4fdd\u5b58\u6210pb\u683c\u5f0f\u6587\u4ef6 export_path = \"../../data/linear_model/\" version = \"1\" #\u540e\u7eed\u53ef\u4ee5\u901a\u8fc7\u7248\u672c\u53f7\u8fdb\u884c\u6a21\u578b\u7248\u672c\u8fed\u4ee3\u4e0e\u7ba1\u7406 linear . save ( export_path + version , save_format = \"tf\" ) #\u67e5\u770b\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6 ! ls { export_path + version } assets saved_model.pb variables # \u67e5\u770b\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f ! saved_model_cli show -- dir { export_path + str ( version )} -- all MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs: signature_def['__saved_model_init_op']: The given SavedModel SignatureDef contains the following input(s): The given SavedModel SignatureDef contains the following output(s): outputs['__saved_model_init_op'] tensor_info: dtype: DT_INVALID shape: unknown_rank name: NoOp Method name is: signature_def['serving_default']: The given SavedModel SignatureDef contains the following input(s): inputs['inputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name: serving_default_inputs:0 The given SavedModel SignatureDef contains the following output(s): outputs['outputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 1) name: StatefulPartitionedCall:0 Method name is: tensorflow/serving/predict WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Defined Functions: Function Name: '__call__' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Function Name: '_default_save_signature' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Function Name: 'call_and_return_all_conditional_losses' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None","title":"\u4e00\uff0c\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/#\u4e8c\u5b89\u88c5-tensorflow-serving","text":"\u5b89\u88c5 tensorflow serving \u67092\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\u901a\u8fc7Docker\u955c\u50cf\u5b89\u88c5\uff0c\u901a\u8fc7apt\u5b89\u88c5\u3002 \u901a\u8fc7Docker\u955c\u50cf\u5b89\u88c5\u662f\u6700\u7b80\u5355\uff0c\u6700\u76f4\u63a5\u7684\u65b9\u6cd5\uff0c\u63a8\u8350\u91c7\u7528\u3002 Docker\u53ef\u4ee5\u7406\u89e3\u6210\u4e00\u79cd\u5bb9\u5668\uff0c\u5176\u4e0a\u9762\u53ef\u4ee5\u7ed9\u5404\u79cd\u4e0d\u540c\u7684\u7a0b\u5e8f\u63d0\u4f9b\u72ec\u7acb\u7684\u8fd0\u884c\u73af\u5883\u3002 \u4e00\u822c\u4e1a\u52a1\u4e2d\u7528\u5230tensorflow\u7684\u4f01\u4e1a\u90fd\u4f1a\u6709\u8fd0\u7ef4\u540c\u5b66\u901a\u8fc7Docker \u642d\u5efa tensorflow serving. \u65e0\u9700\u7b97\u6cd5\u5de5\u7a0b\u5e08\u540c\u5b66\u52a8\u624b\u5b89\u88c5\uff0c\u4ee5\u4e0b\u5b89\u88c5\u8fc7\u7a0b\u4ec5\u4f9b\u53c2\u8003\u3002 \u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u673a\u5668\u4e0a\u5b89\u88c5Docker\u7684\u65b9\u6cd5\u53ef\u4ee5\u53c2\u7167\u4ee5\u4e0b\u94fe\u63a5\u3002 Windows: https://www.runoob.com/docker/windows-docker-install.html MacOs: https://www.runoob.com/docker/macos-docker-install.html CentOS: https://www.runoob.com/docker/centos-docker-install.html \u5b89\u88c5Docker\u6210\u529f\u540e\uff0c\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u52a0\u8f7d tensorflow/serving \u955c\u50cf\u5230Docker\u4e2d docker pull tensorflow/serving","title":"\u4e8c\uff0c\u5b89\u88c5 tensorflow serving"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/#\u4e09\u542f\u52a8-tensorflow-serving-\u670d\u52a1","text":"! docker run - t -- rm - p 8501 : 8501 \\ - v \"/Users/..../../data/linear_model/\" \\ - e MODEL_NAME = linear_model \\ tensorflow / serving & > server . log 2 >& 1","title":"\u4e09\uff0c\u542f\u52a8 tensorflow serving \u670d\u52a1"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-6%2C%E4%BD%BF%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B/#\u56db\u5411api\u670d\u52a1\u53d1\u9001\u8bf7\u6c42","text":"\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u7f16\u7a0b\u8bed\u8a00\u7684http\u529f\u80fd\u53d1\u9001\u8bf7\u6c42\uff0c\u4e0b\u9762\u793a\u8303linux\u7684 curl \u547d\u4ee4\u53d1\u9001\u8bf7\u6c42\uff0c\u4ee5\u53caPython\u7684requests\u5e93\u53d1\u9001\u8bf7\u6c42\u3002 ! curl - d '{\"instances\": [[1.0, 2.0], [5.0,7.0]]}' \\ - X POST http : // localhost : 8501 / v1 / models / linear_model : predict { \"predictions\": [[3.06546211], [6.02843142] ] } import json , requests data = json . dumps ({ \"signature_name\" : \"serving_default\" , \"instances\" : [[ 1.0 , 2.0 ], [ 5.0 , 7.0 ]]}) headers = { \"content-type\" : \"application/json\" } json_response = requests . post ( 'http://localhost:8501/v1/models/linear_model:predict' , data = data , headers = headers ) predictions = json . loads ( json_response . text )[ \"predictions\" ] print ( predictions ) [[3.06546211], [6.02843142]] \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u5411API\u670d\u52a1\u53d1\u9001\u8bf7\u6c42"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/","text":"6-7,\u4f7f\u7528spark-scala\u8c03\u7528tensorflow2.0\u8bad\u7ec3\u597d\u7684\u6a21\u578b # \u672c\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u5728spark\u4e2d\u8c03\u7528\u8bad\u7ec3\u597d\u7684tensorflow\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u7684\u65b9\u6cd5\u3002 \u672c\u6587\u5185\u5bb9\u7684\u5b66\u4e60\u9700\u8981\u4e00\u5b9a\u7684spark\u548cscala\u57fa\u7840\u3002 \u5982\u679c\u4f7f\u7528pyspark\u7684\u8bdd\u4f1a\u6bd4\u8f83\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5728\u6bcf\u4e2aexecutor\u4e0a\u7528Python\u52a0\u8f7d\u6a21\u578b\u5206\u522b\u9884\u6d4b\u5c31\u53ef\u4ee5\u4e86\u3002 \u4f46\u5de5\u7a0b\u4e0a\u4e3a\u4e86\u6027\u80fd\u8003\u8651\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u662fscala\u7248\u672c\u7684spark\u3002 \u672c\u7bc7\u6587\u7ae0\u6211\u4eec\u901a\u8fc7TensorFlow for Java \u5728spark\u4e2d\u8c03\u7528\u8bad\u7ec3\u597d\u7684tensorflow\u6a21\u578b\u3002 \u5229\u7528spark\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u80fd\u529b\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba9\u8bad\u7ec3\u597d\u7684tensorflow\u6a21\u578b\u5728\u6210\u767e\u4e0a\u5343\u7684\u673a\u5668\u4e0a\u5206\u5e03\u5f0f\u5e76\u884c\u6267\u884c\u6a21\u578b\u63a8\u65ad\u3002 \u3007\uff0cspark-scala\u8c03\u7528tensorflow\u6a21\u578b\u6982\u8ff0 # \u5728spark(scala)\u4e2d\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u9700\u8981\u5b8c\u6210\u4ee5\u4e0b\u51e0\u4e2a\u6b65\u9aa4\u3002 \uff081\uff09\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6 \uff082\uff09\u521b\u5efaspark(scala)\u9879\u76ee\uff0c\u5728\u9879\u76ee\u4e2d\u6dfb\u52a0java\u7248\u672c\u7684tensorflow\u5bf9\u5e94\u7684jar\u5305\u4f9d\u8d56 \uff083\uff09\u5728spark(scala)\u9879\u76ee\u4e2ddriver\u7aef\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f \uff084\uff09\u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7RDD\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f \uff085\uff09 \u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7DataFrame\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f \u4e00\uff0c\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6 # \u6211\u4eec\u4f7f\u7528tf.keras \u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u4fdd\u5b58\u6210protobuf\u6587\u4ef6\u3002 import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## \u6837\u672c\u6570\u91cf n = 800 ## \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 ## \u5efa\u7acb\u6a21\u578b tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) #\u8bbe\u7f6e\u8f93\u5165\u540d\u5b57\u4e3ainputs outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) #\u8bbe\u7f6e\u8f93\u51fa\u540d\u5b57\u4e3aoutputs linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## \u5c06\u6a21\u578b\u4fdd\u5b58\u6210pb\u683c\u5f0f\u6587\u4ef6 export_path = \"../../data/linear_model/\" version = \"1\" #\u540e\u7eed\u53ef\u4ee5\u901a\u8fc7\u7248\u672c\u53f7\u8fdb\u884c\u6a21\u578b\u7248\u672c\u8fed\u4ee3\u4e0e\u7ba1\u7406 linear . save ( export_path + version , save_format = \"tf\" ) ! ls { export_path + version } # \u67e5\u770b\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f ! saved_model_cli show -- dir { export_path + str ( version )} -- all \u6a21\u578b\u6587\u4ef6\u4fe1\u606f\u4e2d\u8fd9\u4e9b\u6807\u7ea2\u7684\u90e8\u5206\u90fd\u662f\u540e\u9762\u6709\u53ef\u80fd\u4f1a\u7528\u5230\u7684\u3002 \u4e8c\uff0c\u521b\u5efaspark(scala)\u9879\u76ee\uff0c\u5728\u9879\u76ee\u4e2d\u6dfb\u52a0java\u7248\u672c\u7684tensorflow\u5bf9\u5e94\u7684jar\u5305\u4f9d\u8d56 # \u5982\u679c\u4f7f\u7528maven\u7ba1\u7406\u9879\u76ee\uff0c\u9700\u8981\u6dfb\u52a0\u5982\u4e0b jar\u5305\u4f9d\u8d56 <!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow --> <dependency> <groupId>org.tensorflow</groupId> <artifactId>tensorflow</artifactId> <version>1.15.0</version> </dependency> \u4e5f\u53ef\u4ee5\u4ece\u4e0b\u9762\u7f51\u5740\u4e2d\u76f4\u63a5\u4e0b\u8f7d org.tensorflow.tensorflow\u7684jar\u5305 \u4ee5\u53ca\u5176\u4f9d\u8d56\u7684org.tensorflow.libtensorflow \u548c org.tensorflowlibtensorflow_jni\u7684jar\u5305 \u653e\u5230\u9879\u76ee\u4e2d\u3002 https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0 \u4e09\uff0c \u5728spark(scala)\u9879\u76ee\u4e2ddriver\u7aef\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f # \u6211\u4eec\u7684\u793a\u8303\u4ee3\u7801\u5728jupyter notebook\u4e2d\u8fdb\u884c\u6f14\u793a\uff0c\u9700\u8981\u5b89\u88c5toree\u4ee5\u652f\u6301spark(scala)\u3002 import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } //\u6ce8\uff1aload\u51fd\u6570\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e00\u822c\u90fd\u662f\u201cserve\u201d\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f\u4e2d\u627e\u5230 val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\" , \"serve\" ) //\u6ce8\uff1a\u5728java\u7248\u672c\u7684tensorflow\u4e2d\u8fd8\u662f\u7c7b\u4f3ctensorflow1.0\u4e2d\u9759\u6001\u8ba1\u7b97\u56fe\u7684\u6a21\u5f0f\uff0c\u9700\u8981\u5efa\u7acbSession, \u6307\u5b9afeed\u7684\u6570\u636e\u548cfetch\u7684\u7ed3\u679c, \u7136\u540e run. //\u6ce8\uff1a\u5982\u679c\u6709\u591a\u4e2a\u6570\u636e\u9700\u8981\u5582\u5165\uff0c\u53ef\u4ee5\u8fde\u7eed\u4f7f\u7528\u591a\u4e2afeed\u65b9\u6cd5 //\u6ce8\uff1a\u8f93\u5165\u5fc5\u987b\u662ffloat\u7c7b\u578b val sess = bundle . session () val x = tf . Tensor . create ( Array ( Array ( 1.0f , 2.0f ), Array ( 2.0f , 3.0f ))) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) if ( x != null ) x . close () if ( y != null ) y . close () if ( sess != null ) sess . close () if ( bundle != null ) bundle . close () result \u8f93\u51fa\u5982\u4e0b\uff1a Array(Array(3.019596), Array(3.9878292)) \u56db\uff0c\u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7RDD\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f # \u4e0b\u9762\u6211\u4eec\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u5c06Driver\u7aef\u52a0\u8f7d\u7684TensorFlow\u6a21\u578b\u4f20\u9012\u5230\u5404\u4e2aexecutor\u4e0a\uff0c\u5e76\u5728executor\u4e0a\u5206\u5e03\u5f0f\u5730\u8c03\u7528\u6a21\u578b\u8fdb\u884c\u63a8\u65ad\u3002 import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } val spark = SparkSession . builder () . appName ( \"TfRDD\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext //\u5728Driver\u7aef\u52a0\u8f7d\u6a21\u578b val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) //\u5229\u7528\u5e7f\u64ad\u5c06\u6a21\u578b\u53d1\u9001\u5230executor\u4e0a val broads = sc . broadcast ( bundle ) //\u6784\u9020\u6570\u636e\u96c6 val rdd_data = sc . makeRDD ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 6.0f , 7.0f ), Array ( 8.0f , 3.0f ))) //\u901a\u8fc7mapPartitions\u8c03\u7528\u6a21\u578b\u8fdb\u884c\u6279\u91cf\u63a8\u65ad val rdd_result = rdd_data . mapPartitions ( iter => { val arr = iter . toArray val model = broads . value val sess = model . session () val x = tf . Tensor . create ( arr ) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) //\u5c06\u9884\u6d4b\u7ed3\u679c\u62f7\u8d1d\u5230\u76f8\u540cshape\u7684Float\u7c7b\u578b\u7684Array\u4e2d val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) result . iterator }) rdd_result . take ( 5 ) bundle . close \u8f93\u51fa\u5982\u4e0b\uff1a Array(Array(3.019596), Array(3.9264367), Array(7.8607616), Array(15.974984)) \u4e94\uff0c \u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7DataFrame\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f # \u9664\u4e86\u53ef\u4ee5\u5728Spark\u7684RDD\u6570\u636e\u4e0a\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u63a8\u65ad\uff0c \u6211\u4eec\u4e5f\u53ef\u4ee5\u5728DataFrame\u6570\u636e\u4e0a\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u63a8\u65ad\u3002 \u4e3b\u8981\u601d\u8def\u662f\u5c06\u63a8\u65ad\u65b9\u6cd5\u6ce8\u518c\u6210\u4e3a\u4e00\u4e2asparkSQL\u51fd\u6570\u3002 import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } object TfDataFrame extends Serializable { def main ( args : Array [ String ]) : Unit = { val spark = SparkSession . builder () . appName ( \"TfDataFrame\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext import spark.implicits._ val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) val broads = sc . broadcast ( bundle ) //\u6784\u9020\u9884\u6d4b\u51fd\u6570\uff0c\u5e76\u5c06\u5176\u6ce8\u518c\u6210sparkSQL\u7684udf val tfpredict = ( features : WrappedArray [ Float ]) => { val bund = broads . value val sess = bund . session () val x = tf . Tensor . create ( Array ( features . toArray )) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) val y_pred = result ( 0 )( 0 ) y_pred } spark . udf . register ( \"tfpredict\" , tfpredict ) //\u6784\u9020DataFrame\u6570\u636e\u96c6\uff0c\u5c06features\u653e\u5230\u4e00\u5217\u4e2d val dfdata = sc . parallelize ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 7.0f , 8.0f ))). toDF ( \"features\" ) dfdata . show //\u8c03\u7528sparkSQL\u9884\u6d4b\u51fd\u6570\uff0c\u589e\u52a0\u4e00\u4e2a\u65b0\u7684\u5217\u4f5c\u4e3ay_preds val dfresult = dfdata . selectExpr ( \"features\" , \"tfpredict(features) as y_preds\" ) dfresult . show bundle . close } } TfDataFrame . main ( Array ()) +----------+ | features| +----------+ |[1.0, 2.0]| |[3.0, 5.0]| |[7.0, 8.0]| +----------+ +----------+---------+ | features| y_preds| +----------+---------+ |[1.0, 2.0]| 3.019596| |[3.0, 5.0]|3.9264367| |[7.0, 8.0]| 8.828995| +----------+---------+ \u4ee5\u4e0a\u6211\u4eec\u5206\u522b\u5728spark \u7684RDD\u6570\u636e\u7ed3\u6784\u548cDataFrame\u6570\u636e\u7ed3\u6784\u4e0a\u5b9e\u73b0\u4e86\u8c03\u7528\u4e00\u4e2atf.keras\u5b9e\u73b0\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u63a8\u65ad\u3002 \u5728\u672c\u4f8b\u57fa\u7840\u4e0a\u7a0d\u4f5c\u4fee\u6539\u5219\u53ef\u4ee5\u7528spark\u8c03\u7528\u8bad\u7ec3\u597d\u7684\u5404\u79cd\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u63a8\u65ad\u3002 \u4f46\u5b9e\u9645\u4e0atensorflow\u5e76\u4e0d\u4ec5\u4ec5\u9002\u5408\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u5e95\u5c42\u7684\u8ba1\u7b97\u56fe\u8bed\u8a00\u53ef\u4ee5\u8868\u8fbe\u5404\u79cd\u6570\u503c\u8ba1\u7b97\u8fc7\u7a0b\u3002 \u5229\u7528\u5176\u4e30\u5bcc\u7684\u4f4e\u9636API\uff0c\u6211\u4eec\u53ef\u4ee5\u5728tensorflow2.0\u4e0a\u5b9e\u73b0\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c \u7ed3\u5408tf.Module\u63d0\u4f9b\u7684\u4fbf\u6377\u7684\u5c01\u88c5\u529f\u80fd\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u8bad\u7ec3\u597d\u7684\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bfc\u51fa\u6210\u6a21\u578b\u6587\u4ef6\u5e76\u5728spark\u4e0a\u5206\u5e03\u5f0f\u8c03\u7528\u6267\u884c\u3002 \u8fd9\u65e0\u7591\u4e3a\u6211\u4eec\u7684\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u60f3\u8c61\u7a7a\u95f4\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-7,\u4f7f\u7528spark-scala\u8c03\u7528tensorflow2.0\u8bad\u7ec3\u597d\u7684\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#6-7\u4f7f\u7528spark-scala\u8c03\u7528tensorflow20\u8bad\u7ec3\u597d\u7684\u6a21\u578b","text":"\u672c\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u5728spark\u4e2d\u8c03\u7528\u8bad\u7ec3\u597d\u7684tensorflow\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u7684\u65b9\u6cd5\u3002 \u672c\u6587\u5185\u5bb9\u7684\u5b66\u4e60\u9700\u8981\u4e00\u5b9a\u7684spark\u548cscala\u57fa\u7840\u3002 \u5982\u679c\u4f7f\u7528pyspark\u7684\u8bdd\u4f1a\u6bd4\u8f83\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5728\u6bcf\u4e2aexecutor\u4e0a\u7528Python\u52a0\u8f7d\u6a21\u578b\u5206\u522b\u9884\u6d4b\u5c31\u53ef\u4ee5\u4e86\u3002 \u4f46\u5de5\u7a0b\u4e0a\u4e3a\u4e86\u6027\u80fd\u8003\u8651\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u662fscala\u7248\u672c\u7684spark\u3002 \u672c\u7bc7\u6587\u7ae0\u6211\u4eec\u901a\u8fc7TensorFlow for Java \u5728spark\u4e2d\u8c03\u7528\u8bad\u7ec3\u597d\u7684tensorflow\u6a21\u578b\u3002 \u5229\u7528spark\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u80fd\u529b\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba9\u8bad\u7ec3\u597d\u7684tensorflow\u6a21\u578b\u5728\u6210\u767e\u4e0a\u5343\u7684\u673a\u5668\u4e0a\u5206\u5e03\u5f0f\u5e76\u884c\u6267\u884c\u6a21\u578b\u63a8\u65ad\u3002","title":"6-7,\u4f7f\u7528spark-scala\u8c03\u7528tensorflow2.0\u8bad\u7ec3\u597d\u7684\u6a21\u578b"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#\u3007spark-scala\u8c03\u7528tensorflow\u6a21\u578b\u6982\u8ff0","text":"\u5728spark(scala)\u4e2d\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u9700\u8981\u5b8c\u6210\u4ee5\u4e0b\u51e0\u4e2a\u6b65\u9aa4\u3002 \uff081\uff09\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6 \uff082\uff09\u521b\u5efaspark(scala)\u9879\u76ee\uff0c\u5728\u9879\u76ee\u4e2d\u6dfb\u52a0java\u7248\u672c\u7684tensorflow\u5bf9\u5e94\u7684jar\u5305\u4f9d\u8d56 \uff083\uff09\u5728spark(scala)\u9879\u76ee\u4e2ddriver\u7aef\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f \uff084\uff09\u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7RDD\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f \uff085\uff09 \u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7DataFrame\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f","title":"\u3007\uff0cspark-scala\u8c03\u7528tensorflow\u6a21\u578b\u6982\u8ff0"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#\u4e00\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6","text":"\u6211\u4eec\u4f7f\u7528tf.keras \u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u4fdd\u5b58\u6210protobuf\u6587\u4ef6\u3002 import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## \u6837\u672c\u6570\u91cf n = 800 ## \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 ## \u5efa\u7acb\u6a21\u578b tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) #\u8bbe\u7f6e\u8f93\u5165\u540d\u5b57\u4e3ainputs outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) #\u8bbe\u7f6e\u8f93\u51fa\u540d\u5b57\u4e3aoutputs linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## \u5c06\u6a21\u578b\u4fdd\u5b58\u6210pb\u683c\u5f0f\u6587\u4ef6 export_path = \"../../data/linear_model/\" version = \"1\" #\u540e\u7eed\u53ef\u4ee5\u901a\u8fc7\u7248\u672c\u53f7\u8fdb\u884c\u6a21\u578b\u7248\u672c\u8fed\u4ee3\u4e0e\u7ba1\u7406 linear . save ( export_path + version , save_format = \"tf\" ) ! ls { export_path + version } # \u67e5\u770b\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f ! saved_model_cli show -- dir { export_path + str ( version )} -- all \u6a21\u578b\u6587\u4ef6\u4fe1\u606f\u4e2d\u8fd9\u4e9b\u6807\u7ea2\u7684\u90e8\u5206\u90fd\u662f\u540e\u9762\u6709\u53ef\u80fd\u4f1a\u7528\u5230\u7684\u3002","title":"\u4e00\uff0c\u51c6\u5907protobuf\u6a21\u578b\u6587\u4ef6"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#\u4e8c\u521b\u5efasparkscala\u9879\u76ee\u5728\u9879\u76ee\u4e2d\u6dfb\u52a0java\u7248\u672c\u7684tensorflow\u5bf9\u5e94\u7684jar\u5305\u4f9d\u8d56","text":"\u5982\u679c\u4f7f\u7528maven\u7ba1\u7406\u9879\u76ee\uff0c\u9700\u8981\u6dfb\u52a0\u5982\u4e0b jar\u5305\u4f9d\u8d56 <!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow --> <dependency> <groupId>org.tensorflow</groupId> <artifactId>tensorflow</artifactId> <version>1.15.0</version> </dependency> \u4e5f\u53ef\u4ee5\u4ece\u4e0b\u9762\u7f51\u5740\u4e2d\u76f4\u63a5\u4e0b\u8f7d org.tensorflow.tensorflow\u7684jar\u5305 \u4ee5\u53ca\u5176\u4f9d\u8d56\u7684org.tensorflow.libtensorflow \u548c org.tensorflowlibtensorflow_jni\u7684jar\u5305 \u653e\u5230\u9879\u76ee\u4e2d\u3002 https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0","title":"\u4e8c\uff0c\u521b\u5efaspark(scala)\u9879\u76ee\uff0c\u5728\u9879\u76ee\u4e2d\u6dfb\u52a0java\u7248\u672c\u7684tensorflow\u5bf9\u5e94\u7684jar\u5305\u4f9d\u8d56"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#\u4e09-\u5728sparkscala\u9879\u76ee\u4e2ddriver\u7aef\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f","text":"\u6211\u4eec\u7684\u793a\u8303\u4ee3\u7801\u5728jupyter notebook\u4e2d\u8fdb\u884c\u6f14\u793a\uff0c\u9700\u8981\u5b89\u88c5toree\u4ee5\u652f\u6301spark(scala)\u3002 import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } //\u6ce8\uff1aload\u51fd\u6570\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e00\u822c\u90fd\u662f\u201cserve\u201d\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u6587\u4ef6\u76f8\u5173\u4fe1\u606f\u4e2d\u627e\u5230 val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\" , \"serve\" ) //\u6ce8\uff1a\u5728java\u7248\u672c\u7684tensorflow\u4e2d\u8fd8\u662f\u7c7b\u4f3ctensorflow1.0\u4e2d\u9759\u6001\u8ba1\u7b97\u56fe\u7684\u6a21\u5f0f\uff0c\u9700\u8981\u5efa\u7acbSession, \u6307\u5b9afeed\u7684\u6570\u636e\u548cfetch\u7684\u7ed3\u679c, \u7136\u540e run. //\u6ce8\uff1a\u5982\u679c\u6709\u591a\u4e2a\u6570\u636e\u9700\u8981\u5582\u5165\uff0c\u53ef\u4ee5\u8fde\u7eed\u4f7f\u7528\u591a\u4e2afeed\u65b9\u6cd5 //\u6ce8\uff1a\u8f93\u5165\u5fc5\u987b\u662ffloat\u7c7b\u578b val sess = bundle . session () val x = tf . Tensor . create ( Array ( Array ( 1.0f , 2.0f ), Array ( 2.0f , 3.0f ))) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) if ( x != null ) x . close () if ( y != null ) y . close () if ( sess != null ) sess . close () if ( bundle != null ) bundle . close () result \u8f93\u51fa\u5982\u4e0b\uff1a Array(Array(3.019596), Array(3.9878292))","title":"\u4e09\uff0c \u5728spark(scala)\u9879\u76ee\u4e2ddriver\u7aef\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#\u56db\u5728sparkscala\u9879\u76ee\u4e2d\u901a\u8fc7rdd\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f","text":"\u4e0b\u9762\u6211\u4eec\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u5c06Driver\u7aef\u52a0\u8f7d\u7684TensorFlow\u6a21\u578b\u4f20\u9012\u5230\u5404\u4e2aexecutor\u4e0a\uff0c\u5e76\u5728executor\u4e0a\u5206\u5e03\u5f0f\u5730\u8c03\u7528\u6a21\u578b\u8fdb\u884c\u63a8\u65ad\u3002 import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } val spark = SparkSession . builder () . appName ( \"TfRDD\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext //\u5728Driver\u7aef\u52a0\u8f7d\u6a21\u578b val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) //\u5229\u7528\u5e7f\u64ad\u5c06\u6a21\u578b\u53d1\u9001\u5230executor\u4e0a val broads = sc . broadcast ( bundle ) //\u6784\u9020\u6570\u636e\u96c6 val rdd_data = sc . makeRDD ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 6.0f , 7.0f ), Array ( 8.0f , 3.0f ))) //\u901a\u8fc7mapPartitions\u8c03\u7528\u6a21\u578b\u8fdb\u884c\u6279\u91cf\u63a8\u65ad val rdd_result = rdd_data . mapPartitions ( iter => { val arr = iter . toArray val model = broads . value val sess = model . session () val x = tf . Tensor . create ( arr ) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) //\u5c06\u9884\u6d4b\u7ed3\u679c\u62f7\u8d1d\u5230\u76f8\u540cshape\u7684Float\u7c7b\u578b\u7684Array\u4e2d val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) result . iterator }) rdd_result . take ( 5 ) bundle . close \u8f93\u51fa\u5982\u4e0b\uff1a Array(Array(3.019596), Array(3.9264367), Array(7.8607616), Array(15.974984))","title":"\u56db\uff0c\u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7RDD\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f"},{"location":"chinese/6.%E9%AB%98%E9%98%B6API/6-7%2C%E4%BD%BF%E7%94%A8spark-scala%E8%B0%83%E7%94%A8tensorflow%E6%A8%A1%E5%9E%8B/#\u4e94-\u5728sparkscala\u9879\u76ee\u4e2d\u901a\u8fc7dataframe\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f","text":"\u9664\u4e86\u53ef\u4ee5\u5728Spark\u7684RDD\u6570\u636e\u4e0a\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u63a8\u65ad\uff0c \u6211\u4eec\u4e5f\u53ef\u4ee5\u5728DataFrame\u6570\u636e\u4e0a\u8c03\u7528tensorflow\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u63a8\u65ad\u3002 \u4e3b\u8981\u601d\u8def\u662f\u5c06\u63a8\u65ad\u65b9\u6cd5\u6ce8\u518c\u6210\u4e3a\u4e00\u4e2asparkSQL\u51fd\u6570\u3002 import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } object TfDataFrame extends Serializable { def main ( args : Array [ String ]) : Unit = { val spark = SparkSession . builder () . appName ( \"TfDataFrame\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext import spark.implicits._ val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) val broads = sc . broadcast ( bundle ) //\u6784\u9020\u9884\u6d4b\u51fd\u6570\uff0c\u5e76\u5c06\u5176\u6ce8\u518c\u6210sparkSQL\u7684udf val tfpredict = ( features : WrappedArray [ Float ]) => { val bund = broads . value val sess = bund . session () val x = tf . Tensor . create ( Array ( features . toArray )) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) val y_pred = result ( 0 )( 0 ) y_pred } spark . udf . register ( \"tfpredict\" , tfpredict ) //\u6784\u9020DataFrame\u6570\u636e\u96c6\uff0c\u5c06features\u653e\u5230\u4e00\u5217\u4e2d val dfdata = sc . parallelize ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 7.0f , 8.0f ))). toDF ( \"features\" ) dfdata . show //\u8c03\u7528sparkSQL\u9884\u6d4b\u51fd\u6570\uff0c\u589e\u52a0\u4e00\u4e2a\u65b0\u7684\u5217\u4f5c\u4e3ay_preds val dfresult = dfdata . selectExpr ( \"features\" , \"tfpredict(features) as y_preds\" ) dfresult . show bundle . close } } TfDataFrame . main ( Array ()) +----------+ | features| +----------+ |[1.0, 2.0]| |[3.0, 5.0]| |[7.0, 8.0]| +----------+ +----------+---------+ | features| y_preds| +----------+---------+ |[1.0, 2.0]| 3.019596| |[3.0, 5.0]|3.9264367| |[7.0, 8.0]| 8.828995| +----------+---------+ \u4ee5\u4e0a\u6211\u4eec\u5206\u522b\u5728spark \u7684RDD\u6570\u636e\u7ed3\u6784\u548cDataFrame\u6570\u636e\u7ed3\u6784\u4e0a\u5b9e\u73b0\u4e86\u8c03\u7528\u4e00\u4e2atf.keras\u5b9e\u73b0\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u63a8\u65ad\u3002 \u5728\u672c\u4f8b\u57fa\u7840\u4e0a\u7a0d\u4f5c\u4fee\u6539\u5219\u53ef\u4ee5\u7528spark\u8c03\u7528\u8bad\u7ec3\u597d\u7684\u5404\u79cd\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u63a8\u65ad\u3002 \u4f46\u5b9e\u9645\u4e0atensorflow\u5e76\u4e0d\u4ec5\u4ec5\u9002\u5408\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u5e95\u5c42\u7684\u8ba1\u7b97\u56fe\u8bed\u8a00\u53ef\u4ee5\u8868\u8fbe\u5404\u79cd\u6570\u503c\u8ba1\u7b97\u8fc7\u7a0b\u3002 \u5229\u7528\u5176\u4e30\u5bcc\u7684\u4f4e\u9636API\uff0c\u6211\u4eec\u53ef\u4ee5\u5728tensorflow2.0\u4e0a\u5b9e\u73b0\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c \u7ed3\u5408tf.Module\u63d0\u4f9b\u7684\u4fbf\u6377\u7684\u5c01\u88c5\u529f\u80fd\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u8bad\u7ec3\u597d\u7684\u4efb\u610f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bfc\u51fa\u6210\u6a21\u578b\u6587\u4ef6\u5e76\u5728spark\u4e0a\u5206\u5e03\u5f0f\u8c03\u7528\u6267\u884c\u3002 \u8fd9\u65e0\u7591\u4e3a\u6211\u4eec\u7684\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u60f3\u8c61\u7a7a\u95f4\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\uff0c \u5728spark(scala)\u9879\u76ee\u4e2d\u901a\u8fc7DataFrame\u5728executor\u4e0a\u52a0\u8f7dtensorflow\u6a21\u578b\u8c03\u8bd5\u6210\u529f"},{"location":"english/","text":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25 # Eat TensorFlow2 in 30 days ? * \ud83d\ude80 github: https://github.com/lyhue1991/eat_tensorflow2_in_30_days Eat pytorch in 20 days ? * \ud83d\ude80 github: https://github.com/lyhue1991/eat_pytorch_in_20_days 1. TensorFlow2 \ud83c\udf4e or Pytorch\ud83d\udd25 # Conclusion first: For the engineers, priority goes to TensorFlow2. For the students and researchers\uff0cfirst choice should be Pytorch. The best way is to master both of them if having sufficient time. Reasons: Model implementation is the most important in the industry. Deployment supporting tensorflow models (not Pytorch) exclusively is the present situation in the majority of the Internet enterprises in China. What's more, the industry prefers the models with higher availability; in most cases, they use well-validated modeling architectures with the minimized requirements of adjustment. Fast iterative development and publication is the most important for the researchers since they need to test a lot of new models. Pytorch has advantages in accessing and debugging comparing with TensorFlow2. Pytorch is most frequently used in academy since 2019 with a large amount of the cutting-edge results. Overall, TensorFlow2 and Pytorch are quite similar in programming nowadays, so mastering one helps learning the other. Mastering both framework provides you a lot more open-sourced models and helps you switching between them. 2. Keras\ud83c\udf4f and tf.keras \ud83c\udf4e # Conclusion first: Keras will be discontinued in development after version 2.3.0, so use tf.keras. Keras is a high-level API for the deep learning frameworks. It help the users to define and training DL networks with a more intuitive way. The Keras libraries installed by pip implement this high-level API for the backends in tensorflow, theano, CNTK, etc. tf.keras is the high-level API just for Tensorflow, which is based on low-level APIs in Tensorflow. Most but not all of the functions in tf.keras are the same for those in Keras (which is compatible to many kinds of backend). tf.keras has a tighter combination to TensorFlow comparing to Keras. With the acquisition by Google, Keras will not update after version 2.3.0 , thus the users should use tf.keras from now on, instead of using Keras installed by pip. 3. What Should You Know Before Reading This Book \ud83d\udcd6? # It is suggested that the readers have foundamental knowledges of machine/deep learning and experience of modeling using Keras or TensorFlow 1.0. For those who have zero experience of machine/deep learning, it is strongly suggested to refer to \"Deep Learning with Python\" along with reading this book. \"Deep Learning with Python\" is written by Fran\u00e7ois Chollet, the inventor of Keras. This book is based on Keras and has no machine learning related prerequisites to the reader. \"Deep Learning with Python\" is easy to understand as it uses various examples to demonstrate. No mathematical equation is in this book since it focuses on cultivating the intuitive to the deep learning. 4. Writing Style \ud83c\udf49 of This Book # This is a introduction reference book which is extremely friendly to human being. The lowest goal of the authors is to avoid giving up due to the difficulties, while \"Don't let the readers think\" is the highest target. This book is mainly based on the official documents of TensorFlow together with its functions. However, the authors made a thorough restructuring and a lot optimizations on the demonstrations. It is different from the official documents, which is disordered and contains both tutorial and guidance with lack of systematic logic, that our book redesigns the content according to the difficulties, readers' searching habits, and the architecture of TensorFlow. We now make it progressive for TensorFlow studying with a clear path, and an easy access to the corresponding examples. In contrast to the verbose demonstrating code, the authors of this book try to minimize the length of the examples to make it easy for reading and implementation. What's more, most of the code cells can be used in your project instantaneously. Given the level of difficulty as 9 for learning Tensorflow through official documents, it would be reduced to 3 if learning through this book. This difference in difficulties could be demonstrated as the following figure: 5. How to Learn With This Book \u23f0 # (1) Study Plan The authors wrote this book using the spare time, especially the two-month unexpected \"holiday\" of COVID-19. Most readers should be able to completely master all the content within 30 days. Time required everyday would be between 30 minutes to 2 hours. This book could also be used as library examples to consult when implementing machine learning projects with TensorFlow2. Click the blue captions to enter the corresponding chapter. Date Contents Difficulties Est. Time Update Status [ Chapter 1: Modeling Procedure of TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 1 [1-1 Example: Modeling Procedure for Structured Data] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 2 [1-2 Example: Modeling Procedure for Images] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 3 [1-3 Example: Modeling Procedure for Texts] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 4 [1-4 Example: Modeling Procedure for Temporal Sequences] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 [ Chapter 2: Key Concepts of TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 5 [2-1 Data Structure of Tensor] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 6 [2-2 Three Types of Graph] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 7 [2-3 Automatic Differentiate] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 3: Hierarchy of TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 8 [3-1 Low-level API: Demonstration] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 9 [3-2 Mid-level API: Demonstration] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 10 [3-3 High-level API: Demonstration] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 4: Low-level API in TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 11 [4-1 Structural Operations of the Tensor] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 12 [4-2 Mathematical Operations of the Tensor] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 13 [4-3 Rules of Using the AutoGraph] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 14 [4-4 Mechanisms of the AutoGraph] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 15 [4-5 AutoGraph and tf.Module] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 5: Mid-level API in TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 16 [5-1 Dataset] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 17 [5-2 feature_column] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 18 [5-3 activation] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 19 [5-4 layers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 20 [5-5 losses] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 21 [5-6 metrics] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 22 [5-7 optimizers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 23 [5-8 callbacks] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 6: High-level API in TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 24 [6-1 Three Ways of Modeling] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 25 [6-2 Three Ways of Training] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 26 [6-3 Model Training Using Single GPU] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 27 [6-4 Model Training Using Multiple GPUs] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 28 [6-5 Model Training Using TPU] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 29 [6-6 Model Deploying Using tensorflow-serving] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 30 [6-7 Call Tensorflow Model Using spark-scala] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 [Epilogue: A Story Between a Foodie and Cuisine] \u2b50\ufe0f 0hour \u2705 (2) Software environment for studying All the source codes are tested in jupyter. It is suggested to clone the repository to local machine and run them in jupyter for an interactive learning experience. The authors would suggest to install jupytext that converts markdown files into ipynb, so the readers would be able to open markdown files in jupyter directly. #For the readers in mainland China, using gitee will allow cloning with a faster speed #!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days #It is suggested to install jupytext that converts and run markdown files as ipynb. #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #It is also suggested to install the latest version of TensorFlow to test the demonstrating code in this book #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U tensorflow import tensorflow as tf #Note: all the codes are tested under TensorFlow 2.1 tf . print ( \"tensorflow version:\" , tf . __version__ ) a = tf . constant ( \"hello\" ) b = tf . constant ( \"tensorflow2\" ) c = tf . strings . join ([ a , b ], \" \" ) tf . print ( c ) tensorflow version: 2.1.0 hello tensorflow2 6. Contact and support the author \ud83c\udf88\ud83c\udf88 # If you find this book helpful and want to support the author, please give a star \u2b50\ufe0f to this repository and don't forget to share it to your friends \ud83d\ude0a Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available.","title":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25"},{"location":"english/#how-to-eat-tensorflow2-in-30-days-","text":"Eat TensorFlow2 in 30 days ? * \ud83d\ude80 github: https://github.com/lyhue1991/eat_tensorflow2_in_30_days Eat pytorch in 20 days ? * \ud83d\ude80 github: https://github.com/lyhue1991/eat_pytorch_in_20_days","title":"How to eat TensorFlow2 in 30 days ?\ud83d\udd25\ud83d\udd25"},{"location":"english/#1-tensorflow2--or-pytorch","text":"Conclusion first: For the engineers, priority goes to TensorFlow2. For the students and researchers\uff0cfirst choice should be Pytorch. The best way is to master both of them if having sufficient time. Reasons: Model implementation is the most important in the industry. Deployment supporting tensorflow models (not Pytorch) exclusively is the present situation in the majority of the Internet enterprises in China. What's more, the industry prefers the models with higher availability; in most cases, they use well-validated modeling architectures with the minimized requirements of adjustment. Fast iterative development and publication is the most important for the researchers since they need to test a lot of new models. Pytorch has advantages in accessing and debugging comparing with TensorFlow2. Pytorch is most frequently used in academy since 2019 with a large amount of the cutting-edge results. Overall, TensorFlow2 and Pytorch are quite similar in programming nowadays, so mastering one helps learning the other. Mastering both framework provides you a lot more open-sourced models and helps you switching between them.","title":"1. TensorFlow2 \ud83c\udf4e or Pytorch\ud83d\udd25"},{"location":"english/#2-keras-and-tfkeras-","text":"Conclusion first: Keras will be discontinued in development after version 2.3.0, so use tf.keras. Keras is a high-level API for the deep learning frameworks. It help the users to define and training DL networks with a more intuitive way. The Keras libraries installed by pip implement this high-level API for the backends in tensorflow, theano, CNTK, etc. tf.keras is the high-level API just for Tensorflow, which is based on low-level APIs in Tensorflow. Most but not all of the functions in tf.keras are the same for those in Keras (which is compatible to many kinds of backend). tf.keras has a tighter combination to TensorFlow comparing to Keras. With the acquisition by Google, Keras will not update after version 2.3.0 , thus the users should use tf.keras from now on, instead of using Keras installed by pip.","title":"2. Keras\ud83c\udf4f and tf.keras \ud83c\udf4e"},{"location":"english/#3-what-should-you-know-before-reading-this-book-","text":"It is suggested that the readers have foundamental knowledges of machine/deep learning and experience of modeling using Keras or TensorFlow 1.0. For those who have zero experience of machine/deep learning, it is strongly suggested to refer to \"Deep Learning with Python\" along with reading this book. \"Deep Learning with Python\" is written by Fran\u00e7ois Chollet, the inventor of Keras. This book is based on Keras and has no machine learning related prerequisites to the reader. \"Deep Learning with Python\" is easy to understand as it uses various examples to demonstrate. No mathematical equation is in this book since it focuses on cultivating the intuitive to the deep learning.","title":"3. What Should You Know Before Reading This Book \ud83d\udcd6?"},{"location":"english/#4-writing-style--of-this-book","text":"This is a introduction reference book which is extremely friendly to human being. The lowest goal of the authors is to avoid giving up due to the difficulties, while \"Don't let the readers think\" is the highest target. This book is mainly based on the official documents of TensorFlow together with its functions. However, the authors made a thorough restructuring and a lot optimizations on the demonstrations. It is different from the official documents, which is disordered and contains both tutorial and guidance with lack of systematic logic, that our book redesigns the content according to the difficulties, readers' searching habits, and the architecture of TensorFlow. We now make it progressive for TensorFlow studying with a clear path, and an easy access to the corresponding examples. In contrast to the verbose demonstrating code, the authors of this book try to minimize the length of the examples to make it easy for reading and implementation. What's more, most of the code cells can be used in your project instantaneously. Given the level of difficulty as 9 for learning Tensorflow through official documents, it would be reduced to 3 if learning through this book. This difference in difficulties could be demonstrated as the following figure:","title":"4. Writing Style \ud83c\udf49 of This Book"},{"location":"english/#5-how-to-learn-with-this-book-","text":"(1) Study Plan The authors wrote this book using the spare time, especially the two-month unexpected \"holiday\" of COVID-19. Most readers should be able to completely master all the content within 30 days. Time required everyday would be between 30 minutes to 2 hours. This book could also be used as library examples to consult when implementing machine learning projects with TensorFlow2. Click the blue captions to enter the corresponding chapter. Date Contents Difficulties Est. Time Update Status [ Chapter 1: Modeling Procedure of TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 1 [1-1 Example: Modeling Procedure for Structured Data] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 2 [1-2 Example: Modeling Procedure for Images] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 3 [1-3 Example: Modeling Procedure for Texts] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 4 [1-4 Example: Modeling Procedure for Temporal Sequences] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 [ Chapter 2: Key Concepts of TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 5 [2-1 Data Structure of Tensor] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 6 [2-2 Three Types of Graph] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 7 [2-3 Automatic Differentiate] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 3: Hierarchy of TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 8 [3-1 Low-level API: Demonstration] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 9 [3-2 Mid-level API: Demonstration] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 10 [3-3 High-level API: Demonstration] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 4: Low-level API in TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 11 [4-1 Structural Operations of the Tensor] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 12 [4-2 Mathematical Operations of the Tensor] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 13 [4-3 Rules of Using the AutoGraph] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 14 [4-4 Mechanisms of the AutoGraph] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 15 [4-5 AutoGraph and tf.Module] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 5: Mid-level API in TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 16 [5-1 Dataset] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 Day 17 [5-2 feature_column] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 18 [5-3 activation] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 19 [5-4 layers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 20 [5-5 losses] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 21 [5-6 metrics] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 22 [5-7 optimizers] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 23 [5-8 callbacks] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 [ Chapter 6: High-level API in TensorFlow ] \u2b50\ufe0f 0hour \u2705 Day 24 [6-1 Three Ways of Modeling] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 25 [6-2 Three Ways of Training] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 26 [6-3 Model Training Using Single GPU] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 27 [6-4 Model Training Using Multiple GPUs] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 28 [6-5 Model Training Using TPU] \u2b50\ufe0f\u2b50\ufe0f 0.5hour \u2705 Day 29 [6-6 Model Deploying Using tensorflow-serving] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 Day 30 [6-7 Call Tensorflow Model Using spark-scala] \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hours \u2705 [Epilogue: A Story Between a Foodie and Cuisine] \u2b50\ufe0f 0hour \u2705 (2) Software environment for studying All the source codes are tested in jupyter. It is suggested to clone the repository to local machine and run them in jupyter for an interactive learning experience. The authors would suggest to install jupytext that converts markdown files into ipynb, so the readers would be able to open markdown files in jupyter directly. #For the readers in mainland China, using gitee will allow cloning with a faster speed #!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days #It is suggested to install jupytext that converts and run markdown files as ipynb. #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #It is also suggested to install the latest version of TensorFlow to test the demonstrating code in this book #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U tensorflow import tensorflow as tf #Note: all the codes are tested under TensorFlow 2.1 tf . print ( \"tensorflow version:\" , tf . __version__ ) a = tf . constant ( \"hello\" ) b = tf . constant ( \"tensorflow2\" ) c = tf . strings . join ([ a , b ], \" \" ) tf . print ( c ) tensorflow version: 2.1.0 hello tensorflow2","title":"5. How to Learn With This Book \u23f0"},{"location":"english/#6-contact-and-support-the-author-","text":"If you find this book helpful and want to support the author, please give a star \u2b50\ufe0f to this repository and don't forget to share it to your friends \ud83d\ude0a Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available.","title":"6. Contact and support the author \ud83c\udf88\ud83c\udf88"},{"location":"english/Epilogue/","text":"Epilogue: A Story Between a Foodie and Cuisine # \"How to eat TensorFlow2 in 30 days?\" has been finished and well concluded, and this is the epilogue for this book. This section tells a story about how a foodie got acquaintance to the algorithms, and how he wrote this book. This is a very interesting and humorous story. However it is too long and the translator is too lazy to finish it. TL; DT (Too Long, Don't Translate). Please give your smile or laughing when you read this section to appreciate the author and the translator. Thanks for your persistence to the end of this journey, and wish it alleviates your frustration when start learning TensorFlow. If you find this book helpful and want to support the author, please give a star \u2b50\ufe0f to this repository and don't forget to share it to your friends \ud83d\ude0a Again, please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"Epilogue: A Story Between a Foodie and Cuisine"},{"location":"english/Epilogue/#epilogue-a-story-between-a-foodie-and-cuisine","text":"\"How to eat TensorFlow2 in 30 days?\" has been finished and well concluded, and this is the epilogue for this book. This section tells a story about how a foodie got acquaintance to the algorithms, and how he wrote this book. This is a very interesting and humorous story. However it is too long and the translator is too lazy to finish it. TL; DT (Too Long, Don't Translate). Please give your smile or laughing when you read this section to appreciate the author and the translator. Thanks for your persistence to the end of this journey, and wish it alleviates your frustration when start learning TensorFlow. If you find this book helpful and want to support the author, please give a star \u2b50\ufe0f to this repository and don't forget to share it to your friends \ud83d\ude0a Again, please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"Epilogue: A Story Between a Foodie and Cuisine"},{"location":"english/Chapter1/","text":"Chapter 1: Modeling Procedure of TensorFlow # Although Tensorflow is designed in a smart way to be adaptive to various complex numerical computations, the most popular usage is implementation of machine learning models, especially for those of neural networks. In principle, the neural network could be defined by graphs consist of tensors and trained through automatic differenciate. However, for simplification, we recommend to use high-level Keras API in Tensorflow to implement the neural networks. The common procedures of implementing neural networks using TensorFlow are: Data preparation Model definition Model training Model evaluation Model application Model saving For the beginners, actually, data preparation is the most difficult part. The most common data types are structured data, images, texts, and temporal sequences. We are demonstrating the steps of modeling for these four data types through the following examples, respectively: (1) Predicting the survival on the Titanic; (2) Image classification on CIFAR2 set; (3) Classification of movie reviews on IMDB; (4) Predicting the terminate date of the COVID-19 pandemic in China. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegant Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 1: Modeling Procedure of TensorFlow"},{"location":"english/Chapter1/#chapter-1-modeling-procedure-of-tensorflow","text":"Although Tensorflow is designed in a smart way to be adaptive to various complex numerical computations, the most popular usage is implementation of machine learning models, especially for those of neural networks. In principle, the neural network could be defined by graphs consist of tensors and trained through automatic differenciate. However, for simplification, we recommend to use high-level Keras API in Tensorflow to implement the neural networks. The common procedures of implementing neural networks using TensorFlow are: Data preparation Model definition Model training Model evaluation Model application Model saving For the beginners, actually, data preparation is the most difficult part. The most common data types are structured data, images, texts, and temporal sequences. We are demonstrating the steps of modeling for these four data types through the following examples, respectively: (1) Predicting the survival on the Titanic; (2) Image classification on CIFAR2 set; (3) Classification of movie reviews on IMDB; (4) Predicting the terminate date of the COVID-19 pandemic in China. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegant Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 1: Modeling Procedure of TensorFlow"},{"location":"english/Chapter1/Chapter1-1/","text":"1-1 Example: Modeling Procedure for Structured Data # 1. Data Preparation # The purpose of the Titanic dataset is to predict whether the given passengers could be survived after Titinic hit the iceburg, according to their personal information. We usually use DataFrame from the pandas library to pre-process the structured data. import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers dftrain_raw = pd . read_csv ( '../../data/titanic/train.csv' ) dftest_raw = pd . read_csv ( '../../data/titanic/test.csv' ) dftrain_raw . head ( 10 ) Introduction of each field\uff1a Survived: 0 for death and 1 for survived [y labels] Pclass: Class of the tickets, with three possible values (1,2,3) [converting to one-hot encoding] Name: Name of each passenger [discarded] Sex: Gender of each passenger [converting to bool type] Age: Age of each passenger (partly missing) [numerical feature, should add \"Whether age is missing\" as auxiliary feature] SibSp: Number of siblings and spouse of each passenger (interger) [numerical feature] Parch: Number of parents/children of each passenger (interger) [numerical feature] Ticket: Ticket number (string) [discarded] Fare: Ticket price of each passenger (float, between 0 to 500) [numerical feature] Cabin: Cabin where each passenger is located (partly missing) [should add \"Whether cabin is missing\" as auxiliary feature] Embarked: Which port was each passenger embarked, possible values are S\u3001C\u3001Q (partly missing) [converting to one-hot encoding, four dimensions, S,C,Q,nan] Use data visualization in pandas library for initial EDA (Exploratory Data Analysis). Survival label distribution: % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Survived' ] . value_counts () . plot ( kind = 'bar' , figsize = ( 12 , 8 ), fontsize = 15 , rot = 0 ) ax . set_ylabel ( 'Counts' , fontsize = 15 ) ax . set_xlabel ( 'Survived' , fontsize = 15 ) plt . show () Age distribution: % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Age' ] . plot ( kind = 'hist' , bins = 20 , color = 'purple' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . set_ylabel ( 'Frequency' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () Correlation between age and survival label: % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw . query ( 'Survived == 0' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) dftrain_raw . query ( 'Survived == 1' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . legend ([ 'Survived==0' , 'Survived==1' ], fontsize = 12 ) ax . set_ylabel ( 'Density' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () Below are code for formal data pre-processing: def preprocessing ( dfdata ): dfresult = pd . DataFrame () #Pclass dfPclass = pd . get_dummies ( dfdata [ 'Pclass' ]) dfPclass . columns = [ 'Pclass_' + str ( x ) for x in dfPclass . columns ] dfresult = pd . concat ([ dfresult , dfPclass ], axis = 1 ) #Sex dfSex = pd . get_dummies ( dfdata [ 'Sex' ]) dfresult = pd . concat ([ dfresult , dfSex ], axis = 1 ) #Age dfresult [ 'Age' ] = dfdata [ 'Age' ] . fillna ( 0 ) dfresult [ 'Age_null' ] = pd . isna ( dfdata [ 'Age' ]) . astype ( 'int32' ) #SibSp,Parch,Fare dfresult [ 'SibSp' ] = dfdata [ 'SibSp' ] dfresult [ 'Parch' ] = dfdata [ 'Parch' ] dfresult [ 'Fare' ] = dfdata [ 'Fare' ] #Carbin dfresult [ 'Cabin_null' ] = pd . isna ( dfdata [ 'Cabin' ]) . astype ( 'int32' ) #Embarked dfEmbarked = pd . get_dummies ( dfdata [ 'Embarked' ], dummy_na = True ) dfEmbarked . columns = [ 'Embarked_' + str ( x ) for x in dfEmbarked . columns ] dfresult = pd . concat ([ dfresult , dfEmbarked ], axis = 1 ) return ( dfresult ) x_train = preprocessing ( dftrain_raw ) y_train = dftrain_raw [ 'Survived' ] . values x_test = preprocessing ( dftest_raw ) y_test = dftest_raw [ 'Survived' ] . values print ( \"x_train.shape =\" , x_train . shape ) print ( \"x_test.shape =\" , x_test . shape ) x_train.shape = (712, 15) x_test.shape = (179, 15) 2. Model Definition # Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . Here we take the simplest way: sequential modeling using function Sequential() . tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 20 , activation = 'relu' , input_shape = ( 15 ,))) model . add ( layers . Dense ( 10 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 20) 320 _________________________________________________________________ dense_1 (Dense) (None, 10) 210 _________________________________________________________________ dense_2 (Dense) (None, 1) 11 ================================================================= Total params: 541 Trainable params: 541 Non-trainable params: 0 _________________________________________________________________ 3. Model Training # There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we introduce the simplist way: using internal function fit. # Use binary cross entropy loss function for binary classification model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ]) history = model . fit ( x_train , y_train , batch_size = 64 , epochs = 30 , validation_split = 0.2 #Split part of the training data for validation ) Train on 569 samples, validate on 143 samples Epoch 1/30 569/569 [==============================] - 1s 2ms/sample - loss: 3.5841 - AUC: 0.4079 - val_loss: 3.4429 - val_AUC: 0.4129 Epoch 2/30 569/569 [==============================] - 0s 102us/sample - loss: 2.6093 - AUC: 0.3967 - val_loss: 2.4886 - val_AUC: 0.4139 Epoch 3/30 569/569 [==============================] - 0s 68us/sample - loss: 1.8375 - AUC: 0.4003 - val_loss: 1.7383 - val_AUC: 0.4223 Epoch 4/30 569/569 [==============================] - 0s 83us/sample - loss: 1.2545 - AUC: 0.4390 - val_loss: 1.1936 - val_AUC: 0.4765 Epoch 5/30 569/569 [==============================] - ETA: 0s - loss: 1.4435 - AUC: 0.375 - 0s 90us/sample - loss: 0.9141 - AUC: 0.5192 - val_loss: 0.8274 - val_AUC: 0.5584 Epoch 6/30 569/569 [==============================] - 0s 110us/sample - loss: 0.7052 - AUC: 0.6290 - val_loss: 0.6596 - val_AUC: 0.6880 Epoch 7/30 569/569 [==============================] - 0s 90us/sample - loss: 0.6410 - AUC: 0.7086 - val_loss: 0.6519 - val_AUC: 0.6845 Epoch 8/30 569/569 [==============================] - 0s 93us/sample - loss: 0.6246 - AUC: 0.7080 - val_loss: 0.6480 - val_AUC: 0.6846 Epoch 9/30 569/569 [==============================] - 0s 73us/sample - loss: 0.6088 - AUC: 0.7113 - val_loss: 0.6497 - val_AUC: 0.6838 Epoch 10/30 569/569 [==============================] - 0s 79us/sample - loss: 0.6051 - AUC: 0.7117 - val_loss: 0.6454 - val_AUC: 0.6873 Epoch 11/30 569/569 [==============================] - 0s 96us/sample - loss: 0.5972 - AUC: 0.7218 - val_loss: 0.6369 - val_AUC: 0.6888 Epoch 12/30 569/569 [==============================] - 0s 92us/sample - loss: 0.5918 - AUC: 0.7294 - val_loss: 0.6330 - val_AUC: 0.6908 Epoch 13/30 569/569 [==============================] - 0s 75us/sample - loss: 0.5864 - AUC: 0.7363 - val_loss: 0.6281 - val_AUC: 0.6948 Epoch 14/30 569/569 [==============================] - 0s 104us/sample - loss: 0.5832 - AUC: 0.7426 - val_loss: 0.6240 - val_AUC: 0.7030 Epoch 15/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5777 - AUC: 0.7507 - val_loss: 0.6200 - val_AUC: 0.7066 Epoch 16/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5726 - AUC: 0.7569 - val_loss: 0.6155 - val_AUC: 0.7132 Epoch 17/30 569/569 [==============================] - 0s 99us/sample - loss: 0.5674 - AUC: 0.7643 - val_loss: 0.6070 - val_AUC: 0.7255 Epoch 18/30 569/569 [==============================] - 0s 97us/sample - loss: 0.5631 - AUC: 0.7721 - val_loss: 0.6061 - val_AUC: 0.7305 Epoch 19/30 569/569 [==============================] - 0s 73us/sample - loss: 0.5580 - AUC: 0.7792 - val_loss: 0.6027 - val_AUC: 0.7332 Epoch 20/30 569/569 [==============================] - 0s 85us/sample - loss: 0.5533 - AUC: 0.7861 - val_loss: 0.5997 - val_AUC: 0.7366 Epoch 21/30 569/569 [==============================] - 0s 87us/sample - loss: 0.5497 - AUC: 0.7926 - val_loss: 0.5961 - val_AUC: 0.7433 Epoch 22/30 569/569 [==============================] - 0s 101us/sample - loss: 0.5454 - AUC: 0.7987 - val_loss: 0.5943 - val_AUC: 0.7438 Epoch 23/30 569/569 [==============================] - 0s 100us/sample - loss: 0.5398 - AUC: 0.8057 - val_loss: 0.5926 - val_AUC: 0.7492 Epoch 24/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5328 - AUC: 0.8122 - val_loss: 0.5912 - val_AUC: 0.7493 Epoch 25/30 569/569 [==============================] - 0s 86us/sample - loss: 0.5283 - AUC: 0.8147 - val_loss: 0.5902 - val_AUC: 0.7509 Epoch 26/30 569/569 [==============================] - 0s 67us/sample - loss: 0.5246 - AUC: 0.8196 - val_loss: 0.5845 - val_AUC: 0.7552 Epoch 27/30 569/569 [==============================] - 0s 72us/sample - loss: 0.5205 - AUC: 0.8271 - val_loss: 0.5837 - val_AUC: 0.7584 Epoch 28/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5144 - AUC: 0.8302 - val_loss: 0.5848 - val_AUC: 0.7561 Epoch 29/30 569/569 [==============================] - 0s 77us/sample - loss: 0.5099 - AUC: 0.8326 - val_loss: 0.5809 - val_AUC: 0.7583 Epoch 30/30 569/569 [==============================] - 0s 80us/sample - loss: 0.5071 - AUC: 0.8349 - val_loss: 0.5816 - val_AUC: 0.7605 4. Model Evaluation # First, we evaluate the model performance on the training and validation datasets. % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"AUC\" ) Let's take a look at the performance on the testing dataset. model . evaluate ( x = x_test , y = y_test ) [0.5191367897907448, 0.8122605] 5. Model Application # #Predict the possiblities model . predict ( x_test [ 0 : 10 ]) #model(tf.constant(x_test[0:10].values,dtype = tf.float32)) #Identical way array([[0.26501188], [0.40970832], [0.44285864], [0.78408605], [0.47650957], [0.43849158], [0.27426785], [0.5962582 ], [0.59476686], [0.17882936]], dtype=float32) #Predict the classes model . predict_classes ( x_test [ 0 : 10 ]) array([[0], [0], [0], [1], [0], [0], [0], [1], [1], [0]], dtype=int32) 6. Model Saving # The trained model could be saved through either the way of Keras or the way of original TensorFlow. The former only allows using Python to retrieve the model, while the latter allows cross-platform deployment. The latter way is recommended to save the model. (1) Model Saving with Keras # Saving model structure and parameters model . save ( '../../data/keras_model.h5' ) del model #Deleting current model # Identical to the previous one model = models . load_model ( '../../data/keras_model.h5' ) model . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] # Saving the model structure json_str = model . to_json () # Retrieving the model structure model_json = models . model_from_json ( json_str ) # Saving the weights of the model model . save_weights ( '../../data/keras_model_weight.h5' ) # Retrieving the model structure model_json = models . model_from_json ( json_str ) model_json . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ] ) # Load the weights model_json . load_weights ( '../../data/keras_model_weight.h5' ) model_json . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] (2) Model Saving with Original Way of TensorFlow # Saving the weights, this way only save the tensors of the weights model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # Saving model structure and parameters to a file, so the model allows cross-platform deployment model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( x_test , y_test ) [0.5191365896656527, 0.8122605] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"1-1 Example: Modeling Procedure for Structured Data"},{"location":"english/Chapter1/Chapter1-1/#1-1-example-modeling-procedure-for-structured-data","text":"","title":"1-1 Example: Modeling Procedure for Structured Data"},{"location":"english/Chapter1/Chapter1-1/#1-data-preparation","text":"The purpose of the Titanic dataset is to predict whether the given passengers could be survived after Titinic hit the iceburg, according to their personal information. We usually use DataFrame from the pandas library to pre-process the structured data. import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers dftrain_raw = pd . read_csv ( '../../data/titanic/train.csv' ) dftest_raw = pd . read_csv ( '../../data/titanic/test.csv' ) dftrain_raw . head ( 10 ) Introduction of each field\uff1a Survived: 0 for death and 1 for survived [y labels] Pclass: Class of the tickets, with three possible values (1,2,3) [converting to one-hot encoding] Name: Name of each passenger [discarded] Sex: Gender of each passenger [converting to bool type] Age: Age of each passenger (partly missing) [numerical feature, should add \"Whether age is missing\" as auxiliary feature] SibSp: Number of siblings and spouse of each passenger (interger) [numerical feature] Parch: Number of parents/children of each passenger (interger) [numerical feature] Ticket: Ticket number (string) [discarded] Fare: Ticket price of each passenger (float, between 0 to 500) [numerical feature] Cabin: Cabin where each passenger is located (partly missing) [should add \"Whether cabin is missing\" as auxiliary feature] Embarked: Which port was each passenger embarked, possible values are S\u3001C\u3001Q (partly missing) [converting to one-hot encoding, four dimensions, S,C,Q,nan] Use data visualization in pandas library for initial EDA (Exploratory Data Analysis). Survival label distribution: % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Survived' ] . value_counts () . plot ( kind = 'bar' , figsize = ( 12 , 8 ), fontsize = 15 , rot = 0 ) ax . set_ylabel ( 'Counts' , fontsize = 15 ) ax . set_xlabel ( 'Survived' , fontsize = 15 ) plt . show () Age distribution: % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Age' ] . plot ( kind = 'hist' , bins = 20 , color = 'purple' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . set_ylabel ( 'Frequency' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () Correlation between age and survival label: % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw . query ( 'Survived == 0' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) dftrain_raw . query ( 'Survived == 1' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . legend ([ 'Survived==0' , 'Survived==1' ], fontsize = 12 ) ax . set_ylabel ( 'Density' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () Below are code for formal data pre-processing: def preprocessing ( dfdata ): dfresult = pd . DataFrame () #Pclass dfPclass = pd . get_dummies ( dfdata [ 'Pclass' ]) dfPclass . columns = [ 'Pclass_' + str ( x ) for x in dfPclass . columns ] dfresult = pd . concat ([ dfresult , dfPclass ], axis = 1 ) #Sex dfSex = pd . get_dummies ( dfdata [ 'Sex' ]) dfresult = pd . concat ([ dfresult , dfSex ], axis = 1 ) #Age dfresult [ 'Age' ] = dfdata [ 'Age' ] . fillna ( 0 ) dfresult [ 'Age_null' ] = pd . isna ( dfdata [ 'Age' ]) . astype ( 'int32' ) #SibSp,Parch,Fare dfresult [ 'SibSp' ] = dfdata [ 'SibSp' ] dfresult [ 'Parch' ] = dfdata [ 'Parch' ] dfresult [ 'Fare' ] = dfdata [ 'Fare' ] #Carbin dfresult [ 'Cabin_null' ] = pd . isna ( dfdata [ 'Cabin' ]) . astype ( 'int32' ) #Embarked dfEmbarked = pd . get_dummies ( dfdata [ 'Embarked' ], dummy_na = True ) dfEmbarked . columns = [ 'Embarked_' + str ( x ) for x in dfEmbarked . columns ] dfresult = pd . concat ([ dfresult , dfEmbarked ], axis = 1 ) return ( dfresult ) x_train = preprocessing ( dftrain_raw ) y_train = dftrain_raw [ 'Survived' ] . values x_test = preprocessing ( dftest_raw ) y_test = dftest_raw [ 'Survived' ] . values print ( \"x_train.shape =\" , x_train . shape ) print ( \"x_test.shape =\" , x_test . shape ) x_train.shape = (712, 15) x_test.shape = (179, 15)","title":"1. Data Preparation"},{"location":"english/Chapter1/Chapter1-1/#2-model-definition","text":"Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . Here we take the simplest way: sequential modeling using function Sequential() . tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 20 , activation = 'relu' , input_shape = ( 15 ,))) model . add ( layers . Dense ( 10 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 20) 320 _________________________________________________________________ dense_1 (Dense) (None, 10) 210 _________________________________________________________________ dense_2 (Dense) (None, 1) 11 ================================================================= Total params: 541 Trainable params: 541 Non-trainable params: 0 _________________________________________________________________","title":"2. Model Definition"},{"location":"english/Chapter1/Chapter1-1/#3-model-training","text":"There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we introduce the simplist way: using internal function fit. # Use binary cross entropy loss function for binary classification model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ]) history = model . fit ( x_train , y_train , batch_size = 64 , epochs = 30 , validation_split = 0.2 #Split part of the training data for validation ) Train on 569 samples, validate on 143 samples Epoch 1/30 569/569 [==============================] - 1s 2ms/sample - loss: 3.5841 - AUC: 0.4079 - val_loss: 3.4429 - val_AUC: 0.4129 Epoch 2/30 569/569 [==============================] - 0s 102us/sample - loss: 2.6093 - AUC: 0.3967 - val_loss: 2.4886 - val_AUC: 0.4139 Epoch 3/30 569/569 [==============================] - 0s 68us/sample - loss: 1.8375 - AUC: 0.4003 - val_loss: 1.7383 - val_AUC: 0.4223 Epoch 4/30 569/569 [==============================] - 0s 83us/sample - loss: 1.2545 - AUC: 0.4390 - val_loss: 1.1936 - val_AUC: 0.4765 Epoch 5/30 569/569 [==============================] - ETA: 0s - loss: 1.4435 - AUC: 0.375 - 0s 90us/sample - loss: 0.9141 - AUC: 0.5192 - val_loss: 0.8274 - val_AUC: 0.5584 Epoch 6/30 569/569 [==============================] - 0s 110us/sample - loss: 0.7052 - AUC: 0.6290 - val_loss: 0.6596 - val_AUC: 0.6880 Epoch 7/30 569/569 [==============================] - 0s 90us/sample - loss: 0.6410 - AUC: 0.7086 - val_loss: 0.6519 - val_AUC: 0.6845 Epoch 8/30 569/569 [==============================] - 0s 93us/sample - loss: 0.6246 - AUC: 0.7080 - val_loss: 0.6480 - val_AUC: 0.6846 Epoch 9/30 569/569 [==============================] - 0s 73us/sample - loss: 0.6088 - AUC: 0.7113 - val_loss: 0.6497 - val_AUC: 0.6838 Epoch 10/30 569/569 [==============================] - 0s 79us/sample - loss: 0.6051 - AUC: 0.7117 - val_loss: 0.6454 - val_AUC: 0.6873 Epoch 11/30 569/569 [==============================] - 0s 96us/sample - loss: 0.5972 - AUC: 0.7218 - val_loss: 0.6369 - val_AUC: 0.6888 Epoch 12/30 569/569 [==============================] - 0s 92us/sample - loss: 0.5918 - AUC: 0.7294 - val_loss: 0.6330 - val_AUC: 0.6908 Epoch 13/30 569/569 [==============================] - 0s 75us/sample - loss: 0.5864 - AUC: 0.7363 - val_loss: 0.6281 - val_AUC: 0.6948 Epoch 14/30 569/569 [==============================] - 0s 104us/sample - loss: 0.5832 - AUC: 0.7426 - val_loss: 0.6240 - val_AUC: 0.7030 Epoch 15/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5777 - AUC: 0.7507 - val_loss: 0.6200 - val_AUC: 0.7066 Epoch 16/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5726 - AUC: 0.7569 - val_loss: 0.6155 - val_AUC: 0.7132 Epoch 17/30 569/569 [==============================] - 0s 99us/sample - loss: 0.5674 - AUC: 0.7643 - val_loss: 0.6070 - val_AUC: 0.7255 Epoch 18/30 569/569 [==============================] - 0s 97us/sample - loss: 0.5631 - AUC: 0.7721 - val_loss: 0.6061 - val_AUC: 0.7305 Epoch 19/30 569/569 [==============================] - 0s 73us/sample - loss: 0.5580 - AUC: 0.7792 - val_loss: 0.6027 - val_AUC: 0.7332 Epoch 20/30 569/569 [==============================] - 0s 85us/sample - loss: 0.5533 - AUC: 0.7861 - val_loss: 0.5997 - val_AUC: 0.7366 Epoch 21/30 569/569 [==============================] - 0s 87us/sample - loss: 0.5497 - AUC: 0.7926 - val_loss: 0.5961 - val_AUC: 0.7433 Epoch 22/30 569/569 [==============================] - 0s 101us/sample - loss: 0.5454 - AUC: 0.7987 - val_loss: 0.5943 - val_AUC: 0.7438 Epoch 23/30 569/569 [==============================] - 0s 100us/sample - loss: 0.5398 - AUC: 0.8057 - val_loss: 0.5926 - val_AUC: 0.7492 Epoch 24/30 569/569 [==============================] - 0s 79us/sample - loss: 0.5328 - AUC: 0.8122 - val_loss: 0.5912 - val_AUC: 0.7493 Epoch 25/30 569/569 [==============================] - 0s 86us/sample - loss: 0.5283 - AUC: 0.8147 - val_loss: 0.5902 - val_AUC: 0.7509 Epoch 26/30 569/569 [==============================] - 0s 67us/sample - loss: 0.5246 - AUC: 0.8196 - val_loss: 0.5845 - val_AUC: 0.7552 Epoch 27/30 569/569 [==============================] - 0s 72us/sample - loss: 0.5205 - AUC: 0.8271 - val_loss: 0.5837 - val_AUC: 0.7584 Epoch 28/30 569/569 [==============================] - 0s 74us/sample - loss: 0.5144 - AUC: 0.8302 - val_loss: 0.5848 - val_AUC: 0.7561 Epoch 29/30 569/569 [==============================] - 0s 77us/sample - loss: 0.5099 - AUC: 0.8326 - val_loss: 0.5809 - val_AUC: 0.7583 Epoch 30/30 569/569 [==============================] - 0s 80us/sample - loss: 0.5071 - AUC: 0.8349 - val_loss: 0.5816 - val_AUC: 0.7605","title":"3. Model Training"},{"location":"english/Chapter1/Chapter1-1/#4-model-evaluation","text":"First, we evaluate the model performance on the training and validation datasets. % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"AUC\" ) Let's take a look at the performance on the testing dataset. model . evaluate ( x = x_test , y = y_test ) [0.5191367897907448, 0.8122605]","title":"4. Model Evaluation"},{"location":"english/Chapter1/Chapter1-1/#5-model-application","text":"#Predict the possiblities model . predict ( x_test [ 0 : 10 ]) #model(tf.constant(x_test[0:10].values,dtype = tf.float32)) #Identical way array([[0.26501188], [0.40970832], [0.44285864], [0.78408605], [0.47650957], [0.43849158], [0.27426785], [0.5962582 ], [0.59476686], [0.17882936]], dtype=float32) #Predict the classes model . predict_classes ( x_test [ 0 : 10 ]) array([[0], [0], [0], [1], [0], [0], [0], [1], [1], [0]], dtype=int32)","title":"5. Model Application"},{"location":"english/Chapter1/Chapter1-1/#6-model-saving","text":"The trained model could be saved through either the way of Keras or the way of original TensorFlow. The former only allows using Python to retrieve the model, while the latter allows cross-platform deployment. The latter way is recommended to save the model. (1) Model Saving with Keras # Saving model structure and parameters model . save ( '../../data/keras_model.h5' ) del model #Deleting current model # Identical to the previous one model = models . load_model ( '../../data/keras_model.h5' ) model . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] # Saving the model structure json_str = model . to_json () # Retrieving the model structure model_json = models . model_from_json ( json_str ) # Saving the weights of the model model . save_weights ( '../../data/keras_model_weight.h5' ) # Retrieving the model structure model_json = models . model_from_json ( json_str ) model_json . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'AUC' ] ) # Load the weights model_json . load_weights ( '../../data/keras_model_weight.h5' ) model_json . evaluate ( x_test , y_test ) [0.5191367897907448, 0.8122605] (2) Model Saving with Original Way of TensorFlow # Saving the weights, this way only save the tensors of the weights model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # Saving model structure and parameters to a file, so the model allows cross-platform deployment model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( x_test , y_test ) [0.5191365896656527, 0.8122605] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6. Model Saving"},{"location":"english/Chapter1/Chapter1-2/","text":"1-2 Example: Modeling Procedure for Images # 1. Data Preparation # The cifar2 dataset is a sub-set of cifar10, which only contains two classes: airplane and automobile. Each class contains 5000 images for training and 1000 images for testing. The goal for this task is to train a model to classify images as airplane or automobile. The files of cifar2 are organized as below: There are two ways of image preparation in TensorFlow. The first one is constructing the image data generator using ImageDataGenerator in tf.keras. The second one is constructing data pipeline using tf.data.Dataset and several methods in tf.image The former is simpler and is demonstrated in this article (in Chinese). The latter is the original method of TensorFlow, which is more flexible with possible better performance with proper usage. Below is the introduction to the second method. import tensorflow as tf from tensorflow.keras import datasets , layers , models BATCH_SIZE = 100 def load_image ( img_path , size = ( 32 , 32 )): label = tf . constant ( 1 , tf . int8 ) if tf . strings . regex_full_match ( img_path , \".*automobile.*\" ) \\ else tf . constant ( 0 , tf . int8 ) img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #In jpeg format img = tf . image . resize ( img , size ) / 255.0 return ( img , label ) #Parallel pre-processing using num_parallel_calls and caching data with prefetch function to improve the performance ds_train = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . Dataset . list_files ( \"../../data/cifar2/test/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) % matplotlib inline % config InlineBackend . figure_format = 'svg' #Checking part of the samples from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i ,( img , label ) in enumerate ( ds_train . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () for x , y in ds_train . take ( 1 ): print ( x . shape , y . shape ) (100, 32, 32, 3) (100,) 2. Model Definition # Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . Here we use API functions for modeling. tf . keras . backend . clear_session () #Clearing the session inputs = layers . Input ( shape = ( 32 , 32 , 3 )) x = layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ))( inputs ) x = layers . MaxPool2D ()( x ) x = layers . Conv2D ( 64 , kernel_size = ( 5 , 5 ))( x ) x = layers . MaxPool2D ()( x ) x = layers . Dropout ( rate = 0.1 )( x ) x = layers . Flatten ()( x ) x = layers . Dense ( 32 , activation = 'relu' )( x ) outputs = layers . Dense ( 1 , activation = 'sigmoid' )( x ) model = models . Model ( inputs = inputs , outputs = outputs ) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 32, 32, 3)] 0 _________________________________________________________________ conv2d (Conv2D) (None, 30, 30, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 15, 15, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 11, 11, 64) 51264 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ dropout (Dropout) (None, 5, 5, 64) 0 _________________________________________________________________ flatten (Flatten) (None, 1600) 0 _________________________________________________________________ dense (Dense) (None, 32) 51232 _________________________________________________________________ dense_1 (Dense) (None, 1) 33 ================================================================= Total params: 103,425 Trainable params: 103,425 Non-trainable params: 0 _________________________________________________________________ 3. Model Training # There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we introduce the simplist way: using internal function fit. import datetime import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## We recommend using pathlib under Python3 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ), loss = tf . keras . losses . binary_crossentropy , metrics = [ \"accuracy\" ] ) history = model . fit ( ds_train , epochs = 10 , validation_data = ds_test , callbacks = [ tensorboard_callback ], workers = 4 ) Train for 100 steps, validate for 20 steps Epoch 1/10 100/100 [==============================] - 16s 156ms/step - loss: 0.4830 - accuracy: 0.7697 - val_loss: 0.3396 - val_accuracy: 0.8475 Epoch 2/10 100/100 [==============================] - 14s 142ms/step - loss: 0.3437 - accuracy: 0.8469 - val_loss: 0.2997 - val_accuracy: 0.8680 Epoch 3/10 100/100 [==============================] - 13s 131ms/step - loss: 0.2871 - accuracy: 0.8777 - val_loss: 0.2390 - val_accuracy: 0.9015 Epoch 4/10 100/100 [==============================] - 12s 117ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.2005 - val_accuracy: 0.9195 Epoch 5/10 100/100 [==============================] - 13s 130ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9180 Epoch 6/10 100/100 [==============================] - 14s 136ms/step - loss: 0.1737 - accuracy: 0.9323 - val_loss: 0.1723 - val_accuracy: 0.9275 Epoch 7/10 100/100 [==============================] - 14s 139ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1670 - val_accuracy: 0.9310 Epoch 8/10 100/100 [==============================] - 13s 134ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9340 Epoch 9/10 100/100 [==============================] - 14s 137ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1581 - val_accuracy: 0.9340 Epoch 10/10 100/100 [==============================] - 14s 142ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9345 4. Model Evaluation # % load_ext tensorboard #%tensorboard --logdir ../../data/keras_model from tensorboard import notebook notebook . list () #Checking model in tensorboard notebook . start ( \"--logdir ../../data/keras_model\" ) import pandas as pd dfhistory = pd . DataFrame ( history . history ) dfhistory . index = range ( 1 , len ( dfhistory ) + 1 ) dfhistory . index . name = 'epoch' dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"accuracy\" ) #Evaluating data using model.evaluate function val_loss , val_accuracy = model . evaluate ( ds_test , workers = 4 ) print ( val_loss , val_accuracy ) 0.16139143370091916 0.9345 5. Model Application # We can use model.predict(ds_test) for prediction. We can also use model.predict_on_batch(x_test) to predict a batch of data. model . predict ( ds_test ) array([[9.9996173e-01], [9.5104784e-01], [2.8648047e-04], ..., [1.1484033e-03], [3.5589080e-02], [9.8537153e-01]], dtype=float32) for x , y in ds_test . take ( 1 ): print ( model . predict_on_batch ( x [ 0 : 20 ])) tf.Tensor( [[3.8065155e-05] [8.8236779e-01] [9.1433197e-01] [9.9921846e-01] [6.4052093e-01] [4.9970779e-03] [2.6735585e-04] [9.9842811e-01] [7.9198682e-01] [7.4823302e-01] [8.7208226e-03] [9.3951421e-03] [9.9790359e-01] [9.9998581e-01] [2.1642199e-05] [1.7915063e-02] [2.5839690e-02] [9.7538447e-01] [9.7393811e-01] [9.7333014e-01]], shape=(20, 1), dtype=float32) 6. Model Saving # We recommend model saving with the original way of TensorFlow. # Saving the weights, this way only save the tensors of the weights model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # Saving model structure and parameters to a file, so the model allows cross-platform deployment model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( ds_test ) [0.16139124035835267, 0.9345] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"1-2 Example: Modeling Procedure for Images"},{"location":"english/Chapter1/Chapter1-2/#1-2-example-modeling-procedure-for-images","text":"","title":"1-2 Example: Modeling Procedure for Images"},{"location":"english/Chapter1/Chapter1-2/#1-data-preparation","text":"The cifar2 dataset is a sub-set of cifar10, which only contains two classes: airplane and automobile. Each class contains 5000 images for training and 1000 images for testing. The goal for this task is to train a model to classify images as airplane or automobile. The files of cifar2 are organized as below: There are two ways of image preparation in TensorFlow. The first one is constructing the image data generator using ImageDataGenerator in tf.keras. The second one is constructing data pipeline using tf.data.Dataset and several methods in tf.image The former is simpler and is demonstrated in this article (in Chinese). The latter is the original method of TensorFlow, which is more flexible with possible better performance with proper usage. Below is the introduction to the second method. import tensorflow as tf from tensorflow.keras import datasets , layers , models BATCH_SIZE = 100 def load_image ( img_path , size = ( 32 , 32 )): label = tf . constant ( 1 , tf . int8 ) if tf . strings . regex_full_match ( img_path , \".*automobile.*\" ) \\ else tf . constant ( 0 , tf . int8 ) img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #In jpeg format img = tf . image . resize ( img , size ) / 255.0 return ( img , label ) #Parallel pre-processing using num_parallel_calls and caching data with prefetch function to improve the performance ds_train = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . Dataset . list_files ( \"../../data/cifar2/test/*/*.jpg\" ) \\ . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) % matplotlib inline % config InlineBackend . figure_format = 'svg' #Checking part of the samples from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i ,( img , label ) in enumerate ( ds_train . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () for x , y in ds_train . take ( 1 ): print ( x . shape , y . shape ) (100, 32, 32, 3) (100,)","title":"1. Data Preparation"},{"location":"english/Chapter1/Chapter1-2/#2-model-definition","text":"Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . Here we use API functions for modeling. tf . keras . backend . clear_session () #Clearing the session inputs = layers . Input ( shape = ( 32 , 32 , 3 )) x = layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ))( inputs ) x = layers . MaxPool2D ()( x ) x = layers . Conv2D ( 64 , kernel_size = ( 5 , 5 ))( x ) x = layers . MaxPool2D ()( x ) x = layers . Dropout ( rate = 0.1 )( x ) x = layers . Flatten ()( x ) x = layers . Dense ( 32 , activation = 'relu' )( x ) outputs = layers . Dense ( 1 , activation = 'sigmoid' )( x ) model = models . Model ( inputs = inputs , outputs = outputs ) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 32, 32, 3)] 0 _________________________________________________________________ conv2d (Conv2D) (None, 30, 30, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 15, 15, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 11, 11, 64) 51264 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ dropout (Dropout) (None, 5, 5, 64) 0 _________________________________________________________________ flatten (Flatten) (None, 1600) 0 _________________________________________________________________ dense (Dense) (None, 32) 51232 _________________________________________________________________ dense_1 (Dense) (None, 1) 33 ================================================================= Total params: 103,425 Trainable params: 103,425 Non-trainable params: 0 _________________________________________________________________","title":"2. Model Definition"},{"location":"english/Chapter1/Chapter1-2/#3-model-training","text":"There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we introduce the simplist way: using internal function fit. import datetime import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## We recommend using pathlib under Python3 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ), loss = tf . keras . losses . binary_crossentropy , metrics = [ \"accuracy\" ] ) history = model . fit ( ds_train , epochs = 10 , validation_data = ds_test , callbacks = [ tensorboard_callback ], workers = 4 ) Train for 100 steps, validate for 20 steps Epoch 1/10 100/100 [==============================] - 16s 156ms/step - loss: 0.4830 - accuracy: 0.7697 - val_loss: 0.3396 - val_accuracy: 0.8475 Epoch 2/10 100/100 [==============================] - 14s 142ms/step - loss: 0.3437 - accuracy: 0.8469 - val_loss: 0.2997 - val_accuracy: 0.8680 Epoch 3/10 100/100 [==============================] - 13s 131ms/step - loss: 0.2871 - accuracy: 0.8777 - val_loss: 0.2390 - val_accuracy: 0.9015 Epoch 4/10 100/100 [==============================] - 12s 117ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.2005 - val_accuracy: 0.9195 Epoch 5/10 100/100 [==============================] - 13s 130ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9180 Epoch 6/10 100/100 [==============================] - 14s 136ms/step - loss: 0.1737 - accuracy: 0.9323 - val_loss: 0.1723 - val_accuracy: 0.9275 Epoch 7/10 100/100 [==============================] - 14s 139ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1670 - val_accuracy: 0.9310 Epoch 8/10 100/100 [==============================] - 13s 134ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9340 Epoch 9/10 100/100 [==============================] - 14s 137ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1581 - val_accuracy: 0.9340 Epoch 10/10 100/100 [==============================] - 14s 142ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9345","title":"3. Model Training"},{"location":"english/Chapter1/Chapter1-2/#4-model-evaluation","text":"% load_ext tensorboard #%tensorboard --logdir ../../data/keras_model from tensorboard import notebook notebook . list () #Checking model in tensorboard notebook . start ( \"--logdir ../../data/keras_model\" ) import pandas as pd dfhistory = pd . DataFrame ( history . history ) dfhistory . index = range ( 1 , len ( dfhistory ) + 1 ) dfhistory . index . name = 'epoch' dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"loss\" ) plot_metric ( history , \"accuracy\" ) #Evaluating data using model.evaluate function val_loss , val_accuracy = model . evaluate ( ds_test , workers = 4 ) print ( val_loss , val_accuracy ) 0.16139143370091916 0.9345","title":"4. Model Evaluation"},{"location":"english/Chapter1/Chapter1-2/#5-model-application","text":"We can use model.predict(ds_test) for prediction. We can also use model.predict_on_batch(x_test) to predict a batch of data. model . predict ( ds_test ) array([[9.9996173e-01], [9.5104784e-01], [2.8648047e-04], ..., [1.1484033e-03], [3.5589080e-02], [9.8537153e-01]], dtype=float32) for x , y in ds_test . take ( 1 ): print ( model . predict_on_batch ( x [ 0 : 20 ])) tf.Tensor( [[3.8065155e-05] [8.8236779e-01] [9.1433197e-01] [9.9921846e-01] [6.4052093e-01] [4.9970779e-03] [2.6735585e-04] [9.9842811e-01] [7.9198682e-01] [7.4823302e-01] [8.7208226e-03] [9.3951421e-03] [9.9790359e-01] [9.9998581e-01] [2.1642199e-05] [1.7915063e-02] [2.5839690e-02] [9.7538447e-01] [9.7393811e-01] [9.7333014e-01]], shape=(20, 1), dtype=float32)","title":"5. Model Application"},{"location":"english/Chapter1/Chapter1-2/#6-model-saving","text":"We recommend model saving with the original way of TensorFlow. # Saving the weights, this way only save the tensors of the weights model . save_weights ( '../../data/tf_model_weights.ckpt' , save_format = \"tf\" ) # Saving model structure and parameters to a file, so the model allows cross-platform deployment model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . evaluate ( ds_test ) [0.16139124035835267, 0.9345] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6. Model Saving"},{"location":"english/Chapter1/Chapter1-3/","text":"1-3 Example: Modeling Procedure for Texts # 1. Data Preparation # The purpose of the imdb dataset is to predict the sentiment label according to the movie reviews. There are 20000 text reviews in the training dataset and 5000 in the testing dataset, with half positive and half negative, respectively. The pre-processing of the text dataset is a little bit complex, which includes word division (for Chinese only, not relevant to this demonstration), dictionary construction, encoding, sequence filling, and data pipeline construction, etc. There are two popular mothods of text preparation in TensorFlow. The first one is constructing the text data generator using Tokenizer in tf.keras.preprocessing , together with tf.keras.utils.Sequence . The second one is using tf.data.Dataset , together with the pre-processing layer tf.keras.layers.experimental.preprocessing.TextVectorization . The former is more complex and is demonstrated here . The latter is the original method of TensorFlow, which is simpler. Below is the introduction to the second method. import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , preprocessing , optimizers , losses , metrics from tensorflow.keras.layers.experimental.preprocessing import TextVectorization import re , string train_data_path = \"../../data/imdb/train.csv\" test_data_path = \"../../data/imdb/test.csv\" MAX_WORDS = 10000 # Consider the 10000 words with the highest frequency of appearance MAX_LEN = 200 # For each sample, preserve the first 200 words BATCH_SIZE = 20 #Constructing data pipeline def split_line ( line ): arr = tf . strings . split ( line , \" \\t \" ) label = tf . expand_dims ( tf . cast ( tf . strings . to_number ( arr [ 0 ]), tf . int32 ), axis = 0 ) text = tf . expand_dims ( arr [ 1 ], axis = 0 ) return ( text , label ) ds_train_raw = tf . data . TextLineDataset ( filenames = [ train_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test_raw = tf . data . TextLineDataset ( filenames = [ test_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) #Constructing dictionary def clean_text ( text ): lowercase = tf . strings . lower ( text ) stripped_html = tf . strings . regex_replace ( lowercase , '<br />' , ' ' ) cleaned_punctuation = tf . strings . regex_replace ( stripped_html , '[ %s ]' % re . escape ( string . punctuation ), '' ) return cleaned_punctuation vectorize_layer = TextVectorization ( standardize = clean_text , split = 'whitespace' , max_tokens = MAX_WORDS - 1 , #Leave one item for the placeholder output_mode = 'int' , output_sequence_length = MAX_LEN ) ds_text = ds_train_raw . map ( lambda text , label : text ) vectorize_layer . adapt ( ds_text ) print ( vectorize_layer . get_vocabulary ()[ 0 : 100 ]) #Word encoding ds_train = ds_train_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = ds_test_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) [b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters'] 2. Model Definition # Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . In this example, we use customized modeling by inheriting base class Model . # Actually, modeling with sequential() or API functions should be priorized. tf . keras . backend . clear_session () class CnnModel ( models . Model ): def __init__ ( self ): super ( CnnModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN ) self . conv_1 = layers . Conv1D ( 16 , kernel_size = 5 , name = \"conv_1\" , activation = \"relu\" ) self . pool_1 = layers . MaxPool1D ( name = \"pool_1\" ) self . conv_2 = layers . Conv1D ( 128 , kernel_size = 2 , name = \"conv_2\" , activation = \"relu\" ) self . pool_2 = layers . MaxPool1D ( name = \"pool_2\" ) self . flatten = layers . Flatten () self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( CnnModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . conv_1 ( x ) x = self . pool_1 ( x ) x = self . conv_2 ( x ) x = self . pool_2 ( x ) x = self . flatten ( x ) x = self . dense ( x ) return ( x ) # To show Output Shape def summary ( self ): x_input = layers . Input ( shape = MAX_LEN ) output = self . call ( x_input ) model = tf . keras . Model ( inputs = x_input , outputs = output ) model . summary () model = CnnModel () model . build ( input_shape = ( None , MAX_LEN )) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 200)] 0 _________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 _________________________________________________________________ conv_1 (Conv1D) (None, 196, 16) 576 _________________________________________________________________ pool_1 (MaxPooling1D) (None, 98, 16) 0 _________________________________________________________________ conv_2 (Conv1D) (None, 97, 128) 4224 _________________________________________________________________ pool_2 (MaxPooling1D) (None, 48, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6144) 0 _________________________________________________________________ dense (Dense) (None, 1) 6145 ================================================================= Total params: 80,945 Trainable params: 80,945 Non-trainable params: 0 _________________________________________________________________ 3. Model Training # There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we use the customized training loop. # Time Stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) optimizer = optimizers . Nadam () loss_func = losses . BinaryCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features , training = False ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) #The logs template should be modified according to metric logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , epochs = 6 ) ================================================================================13:54:08 Epoch=1,Loss:0.442317516,Accuracy:0.7695,Valid Loss:0.323672801,Valid Accuracy:0.8614 ================================================================================13:54:20 Epoch=2,Loss:0.245737702,Accuracy:0.90215,Valid Loss:0.356488883,Valid Accuracy:0.8554 ================================================================================13:54:32 Epoch=3,Loss:0.17360799,Accuracy:0.93455,Valid Loss:0.361132562,Valid Accuracy:0.8674 ================================================================================13:54:44 Epoch=4,Loss:0.113476314,Accuracy:0.95975,Valid Loss:0.483677238,Valid Accuracy:0.856 ================================================================================13:54:57 Epoch=5,Loss:0.0698405355,Accuracy:0.9768,Valid Loss:0.607856631,Valid Accuracy:0.857 ================================================================================13:55:15 Epoch=6,Loss:0.0366807655,Accuracy:0.98825,Valid Loss:0.745884955,Valid Accuracy:0.854 4. Model Evaluation # The model trained by the customized looping is not compiled, so the method model.evaluate(ds_valid) can not be applied directly. def evaluate_model ( model , ds_valid ): for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Valid Loss: {} ,Valid Accuracy: {} ' tf . print ( tf . strings . format ( logs ,( valid_loss . result (), valid_metric . result ()))) valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () evaluate_model ( model , ds_test ) Valid Loss:0.745884418,Valid Accuracy:0.854 5. Model Application # Below are the available methods: model.predict(ds_test) model(x_test) model.call(x_test) model.predict_on_batch(x_test) We recommend the method model.predict(ds_test) since it can be applied to both Dataset and Tensor. model . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) for x_test , _ in ds_test . take ( 1 ): print ( model ( x_test )) #Indentical expressions: #print(model.call(x_test)) #print(model.predict_on_batch(x_test)) tf.Tensor( [[7.8648227e-01] [9.9999011e-01] [9.9944776e-01] [3.7153201e-09] [9.4462049e-01] [2.3522753e-04] [1.2044354e-04] [9.3752089e-07] [9.9996352e-01] [9.3435925e-01] [9.8746723e-01] [9.9908626e-01] [4.1563155e-08] [4.1808244e-03] [8.0184749e-05] [8.3910513e-01] [3.5167937e-05] [7.2113985e-01] [4.5228912e-03] [9.9942589e-01]], shape=(20, 1), dtype=float32) 6. Model Saving # Model saving with the original way of TensorFlow is recommended. model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"1-3 Example: Modeling Procedure for Texts"},{"location":"english/Chapter1/Chapter1-3/#1-3-example-modeling-procedure-for-texts","text":"","title":"1-3 Example: Modeling Procedure for Texts"},{"location":"english/Chapter1/Chapter1-3/#1-data-preparation","text":"The purpose of the imdb dataset is to predict the sentiment label according to the movie reviews. There are 20000 text reviews in the training dataset and 5000 in the testing dataset, with half positive and half negative, respectively. The pre-processing of the text dataset is a little bit complex, which includes word division (for Chinese only, not relevant to this demonstration), dictionary construction, encoding, sequence filling, and data pipeline construction, etc. There are two popular mothods of text preparation in TensorFlow. The first one is constructing the text data generator using Tokenizer in tf.keras.preprocessing , together with tf.keras.utils.Sequence . The second one is using tf.data.Dataset , together with the pre-processing layer tf.keras.layers.experimental.preprocessing.TextVectorization . The former is more complex and is demonstrated here . The latter is the original method of TensorFlow, which is simpler. Below is the introduction to the second method. import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , preprocessing , optimizers , losses , metrics from tensorflow.keras.layers.experimental.preprocessing import TextVectorization import re , string train_data_path = \"../../data/imdb/train.csv\" test_data_path = \"../../data/imdb/test.csv\" MAX_WORDS = 10000 # Consider the 10000 words with the highest frequency of appearance MAX_LEN = 200 # For each sample, preserve the first 200 words BATCH_SIZE = 20 #Constructing data pipeline def split_line ( line ): arr = tf . strings . split ( line , \" \\t \" ) label = tf . expand_dims ( tf . cast ( tf . strings . to_number ( arr [ 0 ]), tf . int32 ), axis = 0 ) text = tf . expand_dims ( arr [ 1 ], axis = 0 ) return ( text , label ) ds_train_raw = tf . data . TextLineDataset ( filenames = [ train_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test_raw = tf . data . TextLineDataset ( filenames = [ test_data_path ]) \\ . map ( split_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) #Constructing dictionary def clean_text ( text ): lowercase = tf . strings . lower ( text ) stripped_html = tf . strings . regex_replace ( lowercase , '<br />' , ' ' ) cleaned_punctuation = tf . strings . regex_replace ( stripped_html , '[ %s ]' % re . escape ( string . punctuation ), '' ) return cleaned_punctuation vectorize_layer = TextVectorization ( standardize = clean_text , split = 'whitespace' , max_tokens = MAX_WORDS - 1 , #Leave one item for the placeholder output_mode = 'int' , output_sequence_length = MAX_LEN ) ds_text = ds_train_raw . map ( lambda text , label : text ) vectorize_layer . adapt ( ds_text ) print ( vectorize_layer . get_vocabulary ()[ 0 : 100 ]) #Word encoding ds_train = ds_train_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = ds_test_raw . map ( lambda text , label :( vectorize_layer ( text ), label )) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) [b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters']","title":"1. Data Preparation"},{"location":"english/Chapter1/Chapter1-3/#2-model-definition","text":"Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . In this example, we use customized modeling by inheriting base class Model . # Actually, modeling with sequential() or API functions should be priorized. tf . keras . backend . clear_session () class CnnModel ( models . Model ): def __init__ ( self ): super ( CnnModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN ) self . conv_1 = layers . Conv1D ( 16 , kernel_size = 5 , name = \"conv_1\" , activation = \"relu\" ) self . pool_1 = layers . MaxPool1D ( name = \"pool_1\" ) self . conv_2 = layers . Conv1D ( 128 , kernel_size = 2 , name = \"conv_2\" , activation = \"relu\" ) self . pool_2 = layers . MaxPool1D ( name = \"pool_2\" ) self . flatten = layers . Flatten () self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( CnnModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . conv_1 ( x ) x = self . pool_1 ( x ) x = self . conv_2 ( x ) x = self . pool_2 ( x ) x = self . flatten ( x ) x = self . dense ( x ) return ( x ) # To show Output Shape def summary ( self ): x_input = layers . Input ( shape = MAX_LEN ) output = self . call ( x_input ) model = tf . keras . Model ( inputs = x_input , outputs = output ) model . summary () model = CnnModel () model . build ( input_shape = ( None , MAX_LEN )) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 200)] 0 _________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 _________________________________________________________________ conv_1 (Conv1D) (None, 196, 16) 576 _________________________________________________________________ pool_1 (MaxPooling1D) (None, 98, 16) 0 _________________________________________________________________ conv_2 (Conv1D) (None, 97, 128) 4224 _________________________________________________________________ pool_2 (MaxPooling1D) (None, 48, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6144) 0 _________________________________________________________________ dense (Dense) (None, 1) 6145 ================================================================= Total params: 80,945 Trainable params: 80,945 Non-trainable params: 0 _________________________________________________________________","title":"2. Model Definition"},{"location":"english/Chapter1/Chapter1-3/#3-model-training","text":"There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we use the customized training loop. # Time Stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) optimizer = optimizers . Nadam () loss_func = losses . BinaryCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features , training = False ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) #The logs template should be modified according to metric logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , epochs = 6 ) ================================================================================13:54:08 Epoch=1,Loss:0.442317516,Accuracy:0.7695,Valid Loss:0.323672801,Valid Accuracy:0.8614 ================================================================================13:54:20 Epoch=2,Loss:0.245737702,Accuracy:0.90215,Valid Loss:0.356488883,Valid Accuracy:0.8554 ================================================================================13:54:32 Epoch=3,Loss:0.17360799,Accuracy:0.93455,Valid Loss:0.361132562,Valid Accuracy:0.8674 ================================================================================13:54:44 Epoch=4,Loss:0.113476314,Accuracy:0.95975,Valid Loss:0.483677238,Valid Accuracy:0.856 ================================================================================13:54:57 Epoch=5,Loss:0.0698405355,Accuracy:0.9768,Valid Loss:0.607856631,Valid Accuracy:0.857 ================================================================================13:55:15 Epoch=6,Loss:0.0366807655,Accuracy:0.98825,Valid Loss:0.745884955,Valid Accuracy:0.854","title":"3. Model Training"},{"location":"english/Chapter1/Chapter1-3/#4-model-evaluation","text":"The model trained by the customized looping is not compiled, so the method model.evaluate(ds_valid) can not be applied directly. def evaluate_model ( model , ds_valid ): for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Valid Loss: {} ,Valid Accuracy: {} ' tf . print ( tf . strings . format ( logs ,( valid_loss . result (), valid_metric . result ()))) valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () evaluate_model ( model , ds_test ) Valid Loss:0.745884418,Valid Accuracy:0.854","title":"4. Model Evaluation"},{"location":"english/Chapter1/Chapter1-3/#5-model-application","text":"Below are the available methods: model.predict(ds_test) model(x_test) model.call(x_test) model.predict_on_batch(x_test) We recommend the method model.predict(ds_test) since it can be applied to both Dataset and Tensor. model . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) for x_test , _ in ds_test . take ( 1 ): print ( model ( x_test )) #Indentical expressions: #print(model.call(x_test)) #print(model.predict_on_batch(x_test)) tf.Tensor( [[7.8648227e-01] [9.9999011e-01] [9.9944776e-01] [3.7153201e-09] [9.4462049e-01] [2.3522753e-04] [1.2044354e-04] [9.3752089e-07] [9.9996352e-01] [9.3435925e-01] [9.8746723e-01] [9.9908626e-01] [4.1563155e-08] [4.1808244e-03] [8.0184749e-05] [8.3910513e-01] [3.5167937e-05] [7.2113985e-01] [4.5228912e-03] [9.9942589e-01]], shape=(20, 1), dtype=float32)","title":"5. Model Application"},{"location":"english/Chapter1/Chapter1-3/#6-model-saving","text":"Model saving with the original way of TensorFlow is recommended. model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' ) model_loaded . predict ( ds_test ) array([[0.7864823 ], [0.9999901 ], [0.99944776], ..., [0.8498302 ], [0.13382755], [1. ]], dtype=float32) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6. Model Saving"},{"location":"english/Chapter1/Chapter1-4/","text":"1-4 Example: Modeling Procedure for Temporal Sequences # The COVID-19 has been lasting for over three months (Note from the translator: until April, 2020) in China and significantly affected the ordinary life. The impacts could be on the incomes, emotions, psychologies, and weights. So how long this pandemic is going to last, and when will we be free again? This example is about predicting the time of COVID-19 termination in China using RNN model established by TensorFlow 2. 1. Data Preparation # The dataset is extracted from \"tushare\". The details of the data acquisition is here (in Chinese) . import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , callbacks % matplotlib inline % config InlineBackend . figure_format = 'svg' df = pd . read_csv ( \"../../data/covid-19.csv\" , sep = \" \\t \" ) df . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdata = df . set_index ( \"date\" ) dfdiff = dfdata . diff ( periods = 1 ) . dropna () dfdiff = dfdiff . reset_index ( \"date\" ) dfdiff . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdiff = dfdiff . drop ( \"date\" , axis = 1 ) . astype ( \"float32\" ) #Use the data of an eight-day window priorier of the date we are investigating as input for prediction WINDOW_SIZE = 8 def batch_dataset ( dataset ): dataset_batched = dataset . batch ( WINDOW_SIZE , drop_remainder = True ) return dataset_batched ds_data = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values , dtype = tf . float32 )) \\ . window ( WINDOW_SIZE , shift = 1 ) . flat_map ( batch_dataset ) ds_label = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values [ WINDOW_SIZE :], dtype = tf . float32 )) #We put all data into one batch for better efficiency since the data volume is small. ds_train = tf . data . Dataset . zip (( ds_data , ds_label )) . batch ( 38 ) . cache () 2. Model Definition # Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . Here we use functional API for modeling. #We design the following block since the daily increment of confirmed, discharged and deceased cases are equal or larger than zero. class Block ( layers . Layer ): def __init__ ( self , ** kwargs ): super ( Block , self ) . __init__ ( ** kwargs ) def call ( self , x_input , x ): x_out = tf . maximum (( 1 + x ) * x_input [:, - 1 ,:], 0.0 ) return x_out def get_config ( self ): config = super ( Block , self ) . get_config () return config tf . keras . backend . clear_session () x_input = layers . Input ( shape = ( None , 3 ), dtype = tf . float32 ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x_input ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , input_shape = ( None , 3 ))( x ) x = layers . Dense ( 3 )( x ) #We design the following block since the daily increment of confirmed, discharged and deseased cases are equal or larger than zero. #x = tf.maximum((1+x)*x_input[:,-1,:],0.0) x = Block ()( x_input , x ) model = models . Model ( inputs = [ x_input ], outputs = [ x ]) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, None, 3)] 0 _________________________________________________________________ lstm (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_1 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_2 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_3 (LSTM) (None, 3) 84 _________________________________________________________________ dense (Dense) (None, 3) 12 _________________________________________________________________ block (Block) (None, 3) 0 ================================================================= Total params: 348 Trainable params: 348 Non-trainable params: 0 _________________________________________________________________ 3. Model Training # There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we use the simplist way: using internal function fit. Note: The parameter adjustment of RNN is more difficult comparing to other types of neural network. We need to try various learning rate to achieve a satisfying result. #Customized loss function, consider the ratio between square error and the prediction class MSPE ( losses . Loss ): def call ( self , y_true , y_pred ): err_percent = ( y_true - y_pred ) ** 2 / ( tf . maximum ( y_true ** 2 , 1e-7 )) mean_err_percent = tf . reduce_mean ( err_percent ) return mean_err_percent def get_config ( self ): config = super ( MSPE , self ) . get_config () return config import os import datetime optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.01 ) model . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## We recommend using pathlib under Python3 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tb_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) #Half the learning rate if loss is not improved after 100 epoches lr_callback = tf . keras . callbacks . ReduceLROnPlateau ( monitor = \"loss\" , factor = 0.5 , patience = 100 ) #Stop training when loss is not improved after 200 epoches stop_callback = tf . keras . callbacks . EarlyStopping ( monitor = \"loss\" , patience = 200 ) callbacks_list = [ tb_callback , lr_callback , stop_callback ] history = model . fit ( ds_train , epochs = 500 , callbacks = callbacks_list ) Epoch 371/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1184 Epoch 372/500 1/1 [==============================] - 0s 64ms/step - loss: 0.1177 Epoch 373/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1169 Epoch 374/500 1/1 [==============================] - 0s 50ms/step - loss: 0.1161 Epoch 375/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1154 Epoch 376/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1147 Epoch 377/500 1/1 [==============================] - 0s 62ms/step - loss: 0.1140 Epoch 378/500 1/1 [==============================] - 0s 93ms/step - loss: 0.1133 Epoch 379/500 1/1 [==============================] - 0s 85ms/step - loss: 0.1126 Epoch 380/500 1/1 [==============================] - 0s 68ms/step - loss: 0.1119 Epoch 381/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1113 Epoch 382/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1107 Epoch 383/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1100 Epoch 384/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1094 Epoch 385/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1088 Epoch 386/500 1/1 [==============================] - 0s 74ms/step - loss: 0.1082 Epoch 387/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1077 Epoch 388/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1071 Epoch 389/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1066 Epoch 390/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1060 Epoch 391/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1055 Epoch 392/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1050 Epoch 393/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1045 Epoch 394/500 1/1 [==============================] - 0s 65ms/step - loss: 0.1040 Epoch 395/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1035 Epoch 396/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1031 Epoch 397/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1026 Epoch 398/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1022 Epoch 399/500 1/1 [==============================] - 0s 57ms/step - loss: 0.1017 Epoch 400/500 1/1 [==============================] - 0s 63ms/step - loss: 0.1013 Epoch 401/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1009 Epoch 402/500 1/1 [==============================] - 0s 53ms/step - loss: 0.1005 Epoch 403/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1001 Epoch 404/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0997 Epoch 405/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0993 Epoch 406/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0990 Epoch 407/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0986 Epoch 408/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0982 Epoch 409/500 1/1 [==============================] - 0s 67ms/step - loss: 0.0979 Epoch 410/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0976 Epoch 411/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0972 Epoch 412/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0969 Epoch 413/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0966 Epoch 414/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0963 Epoch 415/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0960 Epoch 416/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0957 Epoch 417/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0954 Epoch 418/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0951 Epoch 419/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0948 Epoch 420/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0946 Epoch 421/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0943 Epoch 422/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0941 Epoch 423/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0938 Epoch 424/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0936 Epoch 425/500 1/1 [==============================] - 0s 100ms/step - loss: 0.0933 Epoch 426/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0931 Epoch 427/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0929 Epoch 428/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0926 Epoch 429/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0924 Epoch 430/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0922 Epoch 431/500 1/1 [==============================] - 0s 75ms/step - loss: 0.0920 Epoch 432/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0918 Epoch 433/500 1/1 [==============================] - 0s 77ms/step - loss: 0.0916 Epoch 434/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0914 Epoch 435/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0912 Epoch 436/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0911 Epoch 437/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0909 Epoch 438/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0907 Epoch 439/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0905 Epoch 440/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0904 Epoch 441/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0902 Epoch 442/500 1/1 [==============================] - 0s 73ms/step - loss: 0.0901 Epoch 443/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0899 Epoch 444/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0898 Epoch 445/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0896 Epoch 446/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0895 Epoch 447/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0893 Epoch 448/500 1/1 [==============================] - 0s 64ms/step - loss: 0.0892 Epoch 449/500 1/1 [==============================] - 0s 70ms/step - loss: 0.0891 Epoch 450/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0889 Epoch 451/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0888 Epoch 452/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0887 Epoch 453/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0886 Epoch 454/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0885 Epoch 455/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0883 Epoch 456/500 1/1 [==============================] - 0s 71ms/step - loss: 0.0882 Epoch 457/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0881 Epoch 458/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0880 Epoch 459/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 460/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0878 Epoch 461/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0878 Epoch 462/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 463/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0879 Epoch 464/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0888 Epoch 465/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0875 Epoch 466/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0873 Epoch 467/500 1/1 [==============================] - 0s 49ms/step - loss: 0.0872 Epoch 468/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0872 Epoch 469/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 470/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 471/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0870 Epoch 472/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0871 Epoch 473/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0869 Epoch 474/500 1/1 [==============================] - 0s 61ms/step - loss: 0.0870 Epoch 475/500 1/1 [==============================] - 0s 47ms/step - loss: 0.0868 Epoch 476/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0868 Epoch 477/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0866 Epoch 478/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0867 Epoch 479/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0865 Epoch 480/500 1/1 [==============================] - 0s 65ms/step - loss: 0.0866 Epoch 481/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0864 Epoch 482/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0865 Epoch 483/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0863 Epoch 484/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0864 Epoch 485/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0862 Epoch 486/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0863 Epoch 487/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0861 Epoch 488/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0862 Epoch 489/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0860 Epoch 490/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0861 Epoch 491/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 492/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 493/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 494/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 495/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0858 Epoch 496/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0859 Epoch 497/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0857 Epoch 498/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0858 Epoch 499/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0857 Epoch 500/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0858 4. Model Evaluation # Model evaluation usually needs both evaluation and testing sets. We only have very few data in this case so we only visualize the changes of loss function during iteration. % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . title ( 'Training ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric ]) plt . show () plot_metric ( history , \"loss\" ) 5. Model Application # We predict the time of the end of COVID-19 here, i.e. the date when the daily increment of new confirmed cases = 0. #This \"dfresult\" is used to record the current and predicted data dfresult = dfdiff [[ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ]] . copy () dfresult . tail () #Predicting the daily increment of the new confirmed cases of the next 100 days; add this result into dfresult for i in range ( 100 ): arr_predict = model . predict ( tf . constant ( tf . expand_dims ( dfresult . values [ - 38 :,:], axis = 0 ))) dfpredict = pd . DataFrame ( tf . cast ( tf . floor ( arr_predict ), tf . float32 ) . numpy (), columns = dfresult . columns ) dfresult = dfresult . append ( dfpredict , ignore_index = True ) dfresult . query ( \"confirmed_num==0\" ) . head () # From Day 55 the daily increment of the new confirmed cases reduced to zero. Since Day 45 is corresponding to March 10, the daily increment of the news confirmed cases will reduce to 0 in Manch 20. # Note: this prediction is TOO optimistic dfresult . query ( \"cured_num==0\" ) . head () # The daily increment of the discharged (cured) cases will reduce to 0 in Day 164, which is about 4 months after March 10 (i.e. July 10) all the patients will be discharged. # Note: this prediction is TOO pessimistic and problematic: the total sum of the daily increment of discharged cases is larger than cumulated confirmed cases. dfresult . query ( \"dead_num==0\" ) . head () # The daily increment of the deceased will be reduced to 0 from Day 60, which is March 25, 2020 # Note: This prediction is relatively reasonable. 6. Model Saving # Model saving with the original way of TensorFlow is recommended. model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' , compile = False ) optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ) model_loaded . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) model_loaded . predict ( ds_train ) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"1-4 Example: Modeling Procedure for Temporal Sequences"},{"location":"english/Chapter1/Chapter1-4/#1-4-example-modeling-procedure-for-temporal-sequences","text":"The COVID-19 has been lasting for over three months (Note from the translator: until April, 2020) in China and significantly affected the ordinary life. The impacts could be on the incomes, emotions, psychologies, and weights. So how long this pandemic is going to last, and when will we be free again? This example is about predicting the time of COVID-19 termination in China using RNN model established by TensorFlow 2.","title":"1-4 Example: Modeling Procedure for Temporal Sequences"},{"location":"english/Chapter1/Chapter1-4/#1-data-preparation","text":"The dataset is extracted from \"tushare\". The details of the data acquisition is here (in Chinese) . import numpy as np import pandas as pd import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , callbacks % matplotlib inline % config InlineBackend . figure_format = 'svg' df = pd . read_csv ( \"../../data/covid-19.csv\" , sep = \" \\t \" ) df . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdata = df . set_index ( \"date\" ) dfdiff = dfdata . diff ( periods = 1 ) . dropna () dfdiff = dfdiff . reset_index ( \"date\" ) dfdiff . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdiff = dfdiff . drop ( \"date\" , axis = 1 ) . astype ( \"float32\" ) #Use the data of an eight-day window priorier of the date we are investigating as input for prediction WINDOW_SIZE = 8 def batch_dataset ( dataset ): dataset_batched = dataset . batch ( WINDOW_SIZE , drop_remainder = True ) return dataset_batched ds_data = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values , dtype = tf . float32 )) \\ . window ( WINDOW_SIZE , shift = 1 ) . flat_map ( batch_dataset ) ds_label = tf . data . Dataset . from_tensor_slices ( tf . constant ( dfdiff . values [ WINDOW_SIZE :], dtype = tf . float32 )) #We put all data into one batch for better efficiency since the data volume is small. ds_train = tf . data . Dataset . zip (( ds_data , ds_label )) . batch ( 38 ) . cache ()","title":"1. Data Preparation"},{"location":"english/Chapter1/Chapter1-4/#2-model-definition","text":"Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model . Here we use functional API for modeling. #We design the following block since the daily increment of confirmed, discharged and deceased cases are equal or larger than zero. class Block ( layers . Layer ): def __init__ ( self , ** kwargs ): super ( Block , self ) . __init__ ( ** kwargs ) def call ( self , x_input , x ): x_out = tf . maximum (( 1 + x ) * x_input [:, - 1 ,:], 0.0 ) return x_out def get_config ( self ): config = super ( Block , self ) . get_config () return config tf . keras . backend . clear_session () x_input = layers . Input ( shape = ( None , 3 ), dtype = tf . float32 ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x_input ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , return_sequences = True , input_shape = ( None , 3 ))( x ) x = layers . LSTM ( 3 , input_shape = ( None , 3 ))( x ) x = layers . Dense ( 3 )( x ) #We design the following block since the daily increment of confirmed, discharged and deseased cases are equal or larger than zero. #x = tf.maximum((1+x)*x_input[:,-1,:],0.0) x = Block ()( x_input , x ) model = models . Model ( inputs = [ x_input ], outputs = [ x ]) model . summary () Model: \"model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, None, 3)] 0 _________________________________________________________________ lstm (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_1 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_2 (LSTM) (None, None, 3) 84 _________________________________________________________________ lstm_3 (LSTM) (None, 3) 84 _________________________________________________________________ dense (Dense) (None, 3) 12 _________________________________________________________________ block (Block) (None, 3) 0 ================================================================= Total params: 348 Trainable params: 348 Non-trainable params: 0 _________________________________________________________________","title":"2. Model Definition"},{"location":"english/Chapter1/Chapter1-4/#3-model-training","text":"There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we use the simplist way: using internal function fit. Note: The parameter adjustment of RNN is more difficult comparing to other types of neural network. We need to try various learning rate to achieve a satisfying result. #Customized loss function, consider the ratio between square error and the prediction class MSPE ( losses . Loss ): def call ( self , y_true , y_pred ): err_percent = ( y_true - y_pred ) ** 2 / ( tf . maximum ( y_true ** 2 , 1e-7 )) mean_err_percent = tf . reduce_mean ( err_percent ) return mean_err_percent def get_config ( self ): config = super ( MSPE , self ) . get_config () return config import os import datetime optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.01 ) model . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## We recommend using pathlib under Python3 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) tb_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) #Half the learning rate if loss is not improved after 100 epoches lr_callback = tf . keras . callbacks . ReduceLROnPlateau ( monitor = \"loss\" , factor = 0.5 , patience = 100 ) #Stop training when loss is not improved after 200 epoches stop_callback = tf . keras . callbacks . EarlyStopping ( monitor = \"loss\" , patience = 200 ) callbacks_list = [ tb_callback , lr_callback , stop_callback ] history = model . fit ( ds_train , epochs = 500 , callbacks = callbacks_list ) Epoch 371/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1184 Epoch 372/500 1/1 [==============================] - 0s 64ms/step - loss: 0.1177 Epoch 373/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1169 Epoch 374/500 1/1 [==============================] - 0s 50ms/step - loss: 0.1161 Epoch 375/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1154 Epoch 376/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1147 Epoch 377/500 1/1 [==============================] - 0s 62ms/step - loss: 0.1140 Epoch 378/500 1/1 [==============================] - 0s 93ms/step - loss: 0.1133 Epoch 379/500 1/1 [==============================] - 0s 85ms/step - loss: 0.1126 Epoch 380/500 1/1 [==============================] - 0s 68ms/step - loss: 0.1119 Epoch 381/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1113 Epoch 382/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1107 Epoch 383/500 1/1 [==============================] - 0s 55ms/step - loss: 0.1100 Epoch 384/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1094 Epoch 385/500 1/1 [==============================] - 0s 54ms/step - loss: 0.1088 Epoch 386/500 1/1 [==============================] - 0s 74ms/step - loss: 0.1082 Epoch 387/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1077 Epoch 388/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1071 Epoch 389/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1066 Epoch 390/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1060 Epoch 391/500 1/1 [==============================] - 0s 61ms/step - loss: 0.1055 Epoch 392/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1050 Epoch 393/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1045 Epoch 394/500 1/1 [==============================] - 0s 65ms/step - loss: 0.1040 Epoch 395/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1035 Epoch 396/500 1/1 [==============================] - 0s 52ms/step - loss: 0.1031 Epoch 397/500 1/1 [==============================] - 0s 58ms/step - loss: 0.1026 Epoch 398/500 1/1 [==============================] - 0s 60ms/step - loss: 0.1022 Epoch 399/500 1/1 [==============================] - 0s 57ms/step - loss: 0.1017 Epoch 400/500 1/1 [==============================] - 0s 63ms/step - loss: 0.1013 Epoch 401/500 1/1 [==============================] - 0s 59ms/step - loss: 0.1009 Epoch 402/500 1/1 [==============================] - 0s 53ms/step - loss: 0.1005 Epoch 403/500 1/1 [==============================] - 0s 56ms/step - loss: 0.1001 Epoch 404/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0997 Epoch 405/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0993 Epoch 406/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0990 Epoch 407/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0986 Epoch 408/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0982 Epoch 409/500 1/1 [==============================] - 0s 67ms/step - loss: 0.0979 Epoch 410/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0976 Epoch 411/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0972 Epoch 412/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0969 Epoch 413/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0966 Epoch 414/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0963 Epoch 415/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0960 Epoch 416/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0957 Epoch 417/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0954 Epoch 418/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0951 Epoch 419/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0948 Epoch 420/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0946 Epoch 421/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0943 Epoch 422/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0941 Epoch 423/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0938 Epoch 424/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0936 Epoch 425/500 1/1 [==============================] - 0s 100ms/step - loss: 0.0933 Epoch 426/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0931 Epoch 427/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0929 Epoch 428/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0926 Epoch 429/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0924 Epoch 430/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0922 Epoch 431/500 1/1 [==============================] - 0s 75ms/step - loss: 0.0920 Epoch 432/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0918 Epoch 433/500 1/1 [==============================] - 0s 77ms/step - loss: 0.0916 Epoch 434/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0914 Epoch 435/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0912 Epoch 436/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0911 Epoch 437/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0909 Epoch 438/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0907 Epoch 439/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0905 Epoch 440/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0904 Epoch 441/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0902 Epoch 442/500 1/1 [==============================] - 0s 73ms/step - loss: 0.0901 Epoch 443/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0899 Epoch 444/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0898 Epoch 445/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0896 Epoch 446/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0895 Epoch 447/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0893 Epoch 448/500 1/1 [==============================] - 0s 64ms/step - loss: 0.0892 Epoch 449/500 1/1 [==============================] - 0s 70ms/step - loss: 0.0891 Epoch 450/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0889 Epoch 451/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0888 Epoch 452/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0887 Epoch 453/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0886 Epoch 454/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0885 Epoch 455/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0883 Epoch 456/500 1/1 [==============================] - 0s 71ms/step - loss: 0.0882 Epoch 457/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0881 Epoch 458/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0880 Epoch 459/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 460/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0878 Epoch 461/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0878 Epoch 462/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0879 Epoch 463/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0879 Epoch 464/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0888 Epoch 465/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0875 Epoch 466/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0873 Epoch 467/500 1/1 [==============================] - 0s 49ms/step - loss: 0.0872 Epoch 468/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0872 Epoch 469/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 470/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0871 Epoch 471/500 1/1 [==============================] - 0s 59ms/step - loss: 0.0870 Epoch 472/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0871 Epoch 473/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0869 Epoch 474/500 1/1 [==============================] - 0s 61ms/step - loss: 0.0870 Epoch 475/500 1/1 [==============================] - 0s 47ms/step - loss: 0.0868 Epoch 476/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0868 Epoch 477/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0866 Epoch 478/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0867 Epoch 479/500 1/1 [==============================] - 0s 60ms/step - loss: 0.0865 Epoch 480/500 1/1 [==============================] - 0s 65ms/step - loss: 0.0866 Epoch 481/500 1/1 [==============================] - 0s 58ms/step - loss: 0.0864 Epoch 482/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0865 Epoch 483/500 1/1 [==============================] - 0s 53ms/step - loss: 0.0863 Epoch 484/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0864 Epoch 485/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0862 Epoch 486/500 1/1 [==============================] - 0s 55ms/step - loss: 0.0863 Epoch 487/500 1/1 [==============================] - 0s 52ms/step - loss: 0.0861 Epoch 488/500 1/1 [==============================] - 0s 68ms/step - loss: 0.0862 Epoch 489/500 1/1 [==============================] - 0s 62ms/step - loss: 0.0860 Epoch 490/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0861 Epoch 491/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 492/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 493/500 1/1 [==============================] - 0s 51ms/step - loss: 0.0859 Epoch 494/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0860 Epoch 495/500 1/1 [==============================] - 0s 50ms/step - loss: 0.0858 Epoch 496/500 1/1 [==============================] - 0s 69ms/step - loss: 0.0859 Epoch 497/500 1/1 [==============================] - 0s 63ms/step - loss: 0.0857 Epoch 498/500 1/1 [==============================] - 0s 56ms/step - loss: 0.0858 Epoch 499/500 1/1 [==============================] - 0s 54ms/step - loss: 0.0857 Epoch 500/500 1/1 [==============================] - 0s 57ms/step - loss: 0.0858","title":"3. Model Training"},{"location":"english/Chapter1/Chapter1-4/#4-model-evaluation","text":"Model evaluation usually needs both evaluation and testing sets. We only have very few data in this case so we only visualize the changes of loss function during iteration. % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . title ( 'Training ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric ]) plt . show () plot_metric ( history , \"loss\" )","title":"4. Model Evaluation"},{"location":"english/Chapter1/Chapter1-4/#5-model-application","text":"We predict the time of the end of COVID-19 here, i.e. the date when the daily increment of new confirmed cases = 0. #This \"dfresult\" is used to record the current and predicted data dfresult = dfdiff [[ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ]] . copy () dfresult . tail () #Predicting the daily increment of the new confirmed cases of the next 100 days; add this result into dfresult for i in range ( 100 ): arr_predict = model . predict ( tf . constant ( tf . expand_dims ( dfresult . values [ - 38 :,:], axis = 0 ))) dfpredict = pd . DataFrame ( tf . cast ( tf . floor ( arr_predict ), tf . float32 ) . numpy (), columns = dfresult . columns ) dfresult = dfresult . append ( dfpredict , ignore_index = True ) dfresult . query ( \"confirmed_num==0\" ) . head () # From Day 55 the daily increment of the new confirmed cases reduced to zero. Since Day 45 is corresponding to March 10, the daily increment of the news confirmed cases will reduce to 0 in Manch 20. # Note: this prediction is TOO optimistic dfresult . query ( \"cured_num==0\" ) . head () # The daily increment of the discharged (cured) cases will reduce to 0 in Day 164, which is about 4 months after March 10 (i.e. July 10) all the patients will be discharged. # Note: this prediction is TOO pessimistic and problematic: the total sum of the daily increment of discharged cases is larger than cumulated confirmed cases. dfresult . query ( \"dead_num==0\" ) . head () # The daily increment of the deceased will be reduced to 0 from Day 60, which is March 25, 2020 # Note: This prediction is relatively reasonable.","title":"5. Model Application"},{"location":"english/Chapter1/Chapter1-4/#6-model-saving","text":"Model saving with the original way of TensorFlow is recommended. model . save ( '../../data/tf_model_savedmodel' , save_format = \"tf\" ) print ( 'export saved model.' ) model_loaded = tf . keras . models . load_model ( '../../data/tf_model_savedmodel' , compile = False ) optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ) model_loaded . compile ( optimizer = optimizer , loss = MSPE ( name = \"MSPE\" )) model_loaded . predict ( ds_train ) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6. Model Saving"},{"location":"english/Chapter2/","text":"Chapter 2: Key Concepts of TensorFlow # TensorFlow\u2122 is a open-sourced library using data flow graphs for numerical calculation. Each node in the graph represents a mathematical operation, and each edge represents the multi-dimensional array (i.e. tensor) connecting nodes. The flexibility of the architecture allows cross-platform computation , e.g. one or multiple CPUs (or GPUs) on PC, server, mobile devices, etc. TensorFlow was initially developed by Google Brain for researches in machine learning and deep neural networks , however its universality allows the popularity in the application of other fields of computing . Advantages of TensorFlow: Flexibility: Supporting low-level numerical calculation and C++ customized operators.computing. Transportability: Available from Server to PC to mobile devices, and compatible with CPU, GPU and TPU Distributed computation: Allows distributed parallel computation and designating calculation devices for specific operator \"High buildings rise from the ground\", and TensorFlow also has its base, which are the key concepts of tensor, graph and automatic differenciate. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegant Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 2: Key Concepts of TensorFlow"},{"location":"english/Chapter2/#chapter-2-key-concepts-of-tensorflow","text":"TensorFlow\u2122 is a open-sourced library using data flow graphs for numerical calculation. Each node in the graph represents a mathematical operation, and each edge represents the multi-dimensional array (i.e. tensor) connecting nodes. The flexibility of the architecture allows cross-platform computation , e.g. one or multiple CPUs (or GPUs) on PC, server, mobile devices, etc. TensorFlow was initially developed by Google Brain for researches in machine learning and deep neural networks , however its universality allows the popularity in the application of other fields of computing . Advantages of TensorFlow: Flexibility: Supporting low-level numerical calculation and C++ customized operators.computing. Transportability: Available from Server to PC to mobile devices, and compatible with CPU, GPU and TPU Distributed computation: Allows distributed parallel computation and designating calculation devices for specific operator \"High buildings rise from the ground\", and TensorFlow also has its base, which are the key concepts of tensor, graph and automatic differenciate. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegant Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 2: Key Concepts of TensorFlow"},{"location":"english/Chapter2/Chapter2-1/","text":"2-1 Data Structure # Program = Data Structure + Algorithm TensorFlow Program = Data Structure of Tensor + Algorithm in Graph Tensor and graph are key concepts of TensorFlow. The fundamental data structure in TensorFlow is Tensor, which is multi-dimentional array. Tensor is similar with the array in numpy. There are two types of tensor accoring to the behavior: constant and variable. The value of constant cannot be re-assigned in the graph, while variable can be re-assigned through operators such as assign . 1. Constant Tensor # The data type of tensor is basically corresponding to numpy.array . import numpy as np import tensorflow as tf i = tf . constant ( 1 ) # tf.int32 type constant l = tf . constant ( 1 , dtype = tf . int64 ) # tf.int64 type constant f = tf . constant ( 1.23 ) #tf.float32 type constant d = tf . constant ( 3.14 , dtype = tf . double ) # tf.double type constant s = tf . constant ( \"hello world\" ) # tf.string type constant b = tf . constant ( True ) #tf.bool type constant print ( tf . int64 == np . int64 ) print ( tf . bool == np . bool ) print ( tf . double == np . float64 ) print ( tf . string == np . unicode ) # tf.string type is not equal to np.unicode type True True True False Each data type can be represented by tensor in different rank. Scalars are tensors with rank = 0, arrays are with rank = 1, matrix are with rank = 2 Colorful image has three channels (RGB), which can be represented as a tensor with rank = 3. There is a temporal dimension for video so it could be represented as a rank 4 tensor. An intuitive way to understand: the number of the square brackets equals to the rank of the tensor. scalar = tf . constant ( True ) #A scalar is a rank 0 tensor print ( tf . rank ( scalar )) print ( scalar . numpy () . ndim ) # tf.rank equals to the ndim function in numpy tf.Tensor(0, shape=(), dtype=int32) 0 vector = tf . constant ([ 1.0 , 2.0 , 3.0 , 4.0 ]) #A vector is a rank 1 tensor print ( tf . rank ( vector )) print ( np . ndim ( vector . numpy ())) tf.Tensor(1, shape=(), dtype=int32) 1 matrix = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) #A matrix is a rank 2 tensor print ( tf . rank ( matrix ) . numpy ()) print ( np . ndim ( matrix )) 2 2 tensor3 = tf . constant ([[[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]],[[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]]) # A rank 3 tensor print ( tensor3 ) print ( tf . rank ( tensor3 )) tf.Tensor( [[[1. 2.] [3. 4.]] [[5. 6.] [7. 8.]]], shape=(2, 2, 2), dtype=float32) tf.Tensor(3, shape=(), dtype=int32) tensor4 = tf . constant ([[[[ 1.0 , 1.0 ],[ 2.0 , 2.0 ]],[[ 3.0 , 3.0 ],[ 4.0 , 4.0 ]]], [[[ 5.0 , 5.0 ],[ 6.0 , 6.0 ]],[[ 7.0 , 7.0 ],[ 8.0 , 8.0 ]]]]) # A rank 4 tensor print ( tensor4 ) print ( tf . rank ( tensor4 )) tf.Tensor( [[[[1. 1.] [2. 2.]] [[3. 3.] [4. 4.]]] [[[5. 5.] [6. 6.]] [[7. 7.] [8. 8.]]]], shape=(2, 2, 2, 2), dtype=float32) tf.Tensor(4, shape=(), dtype=int32) We use tf.cast to change the data type of the tensors. The method numpy() is for converting the data type from tensor to numpy array. The method shape is for checking up the size of tensor. h = tf . constant ([ 123 , 456 ], dtype = tf . int32 ) f = tf . cast ( h , tf . float32 ) print ( h . dtype , f . dtype ) <dtype: 'int32'> <dtype: 'float32'> y = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) print ( y . numpy ()) #Convert to np.array print ( y . shape ) [[1. 2.] [3. 4.]] (2, 2) u = tf . constant ( u \"Hello World\" ) print ( u . numpy ()) print ( u . numpy () . decode ( \"utf-8\" )) b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xe4\\xb8\\x96\\xe7\\x95\\x8c' Hello World 2. Variable Tensor # The trainable parameters in the models are usually defined as variables. # The value of a constant is NOT changeable. Re-assignment creates a new space in the memory. c = tf . constant ([ 1.0 , 2.0 ]) print ( c ) print ( id ( c )) c = c + tf . constant ([ 1.0 , 1.0 ]) print ( c ) print ( id ( c )) tf.Tensor([1. 2.], shape=(2,), dtype=float32) 5276289568 tf.Tensor([2. 3.], shape=(2,), dtype=float32) 5276290240 # The value of a variable is changeable through re-assigning methods such as assign, assign_add, etc. v = tf . Variable ([ 1.0 , 2.0 ], name = \"v\" ) print ( v ) print ( id ( v )) v . assign_add ([ 1.0 , 1.0 ]) print ( v ) print ( id ( v )) <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)> 5276259888 <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)> 5276259888 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2-1 Data Structure"},{"location":"english/Chapter2/Chapter2-1/#2-1-data-structure","text":"Program = Data Structure + Algorithm TensorFlow Program = Data Structure of Tensor + Algorithm in Graph Tensor and graph are key concepts of TensorFlow. The fundamental data structure in TensorFlow is Tensor, which is multi-dimentional array. Tensor is similar with the array in numpy. There are two types of tensor accoring to the behavior: constant and variable. The value of constant cannot be re-assigned in the graph, while variable can be re-assigned through operators such as assign .","title":"2-1 Data Structure"},{"location":"english/Chapter2/Chapter2-1/#1-constant-tensor","text":"The data type of tensor is basically corresponding to numpy.array . import numpy as np import tensorflow as tf i = tf . constant ( 1 ) # tf.int32 type constant l = tf . constant ( 1 , dtype = tf . int64 ) # tf.int64 type constant f = tf . constant ( 1.23 ) #tf.float32 type constant d = tf . constant ( 3.14 , dtype = tf . double ) # tf.double type constant s = tf . constant ( \"hello world\" ) # tf.string type constant b = tf . constant ( True ) #tf.bool type constant print ( tf . int64 == np . int64 ) print ( tf . bool == np . bool ) print ( tf . double == np . float64 ) print ( tf . string == np . unicode ) # tf.string type is not equal to np.unicode type True True True False Each data type can be represented by tensor in different rank. Scalars are tensors with rank = 0, arrays are with rank = 1, matrix are with rank = 2 Colorful image has three channels (RGB), which can be represented as a tensor with rank = 3. There is a temporal dimension for video so it could be represented as a rank 4 tensor. An intuitive way to understand: the number of the square brackets equals to the rank of the tensor. scalar = tf . constant ( True ) #A scalar is a rank 0 tensor print ( tf . rank ( scalar )) print ( scalar . numpy () . ndim ) # tf.rank equals to the ndim function in numpy tf.Tensor(0, shape=(), dtype=int32) 0 vector = tf . constant ([ 1.0 , 2.0 , 3.0 , 4.0 ]) #A vector is a rank 1 tensor print ( tf . rank ( vector )) print ( np . ndim ( vector . numpy ())) tf.Tensor(1, shape=(), dtype=int32) 1 matrix = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) #A matrix is a rank 2 tensor print ( tf . rank ( matrix ) . numpy ()) print ( np . ndim ( matrix )) 2 2 tensor3 = tf . constant ([[[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]],[[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]]) # A rank 3 tensor print ( tensor3 ) print ( tf . rank ( tensor3 )) tf.Tensor( [[[1. 2.] [3. 4.]] [[5. 6.] [7. 8.]]], shape=(2, 2, 2), dtype=float32) tf.Tensor(3, shape=(), dtype=int32) tensor4 = tf . constant ([[[[ 1.0 , 1.0 ],[ 2.0 , 2.0 ]],[[ 3.0 , 3.0 ],[ 4.0 , 4.0 ]]], [[[ 5.0 , 5.0 ],[ 6.0 , 6.0 ]],[[ 7.0 , 7.0 ],[ 8.0 , 8.0 ]]]]) # A rank 4 tensor print ( tensor4 ) print ( tf . rank ( tensor4 )) tf.Tensor( [[[[1. 1.] [2. 2.]] [[3. 3.] [4. 4.]]] [[[5. 5.] [6. 6.]] [[7. 7.] [8. 8.]]]], shape=(2, 2, 2, 2), dtype=float32) tf.Tensor(4, shape=(), dtype=int32) We use tf.cast to change the data type of the tensors. The method numpy() is for converting the data type from tensor to numpy array. The method shape is for checking up the size of tensor. h = tf . constant ([ 123 , 456 ], dtype = tf . int32 ) f = tf . cast ( h , tf . float32 ) print ( h . dtype , f . dtype ) <dtype: 'int32'> <dtype: 'float32'> y = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) print ( y . numpy ()) #Convert to np.array print ( y . shape ) [[1. 2.] [3. 4.]] (2, 2) u = tf . constant ( u \"Hello World\" ) print ( u . numpy ()) print ( u . numpy () . decode ( \"utf-8\" )) b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xe4\\xb8\\x96\\xe7\\x95\\x8c' Hello World","title":"1. Constant Tensor"},{"location":"english/Chapter2/Chapter2-1/#2-variable-tensor","text":"The trainable parameters in the models are usually defined as variables. # The value of a constant is NOT changeable. Re-assignment creates a new space in the memory. c = tf . constant ([ 1.0 , 2.0 ]) print ( c ) print ( id ( c )) c = c + tf . constant ([ 1.0 , 1.0 ]) print ( c ) print ( id ( c )) tf.Tensor([1. 2.], shape=(2,), dtype=float32) 5276289568 tf.Tensor([2. 3.], shape=(2,), dtype=float32) 5276290240 # The value of a variable is changeable through re-assigning methods such as assign, assign_add, etc. v = tf . Variable ([ 1.0 , 2.0 ], name = \"v\" ) print ( v ) print ( id ( v )) v . assign_add ([ 1.0 , 1.0 ]) print ( v ) print ( id ( v )) <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)> 5276259888 <tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)> 5276259888 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Variable Tensor"},{"location":"english/Chapter2/Chapter2-2/","text":"2-2 Three Types of Graph # There are three types of graph: static, dynamic, and Autograph. TensorFlow 1.X used static graph, which firstly creating the graph by various operators and then open a Session to execute the graph. For TensorFlow 2.X, dynamic graph is used. The operator will be added to the invisible default graph and executed instantaneously after its usage; there is no need to create a Session . Using dynamic graph (i.e. Eager Execution) is convenient for debugging, as it improves performance of TensorFlow code just as original Python code, with possibilities of log output and flow control, etc. The drawback of dynamic graph is a relatively lower execution efficiency comparing to static graph. This is because multiple times of communication between the Python thread and the C++ thread of TensorFlow Kernel is required for dynamic graph, while the static graph is executed almost all on the TensorFlow kernel using C++ code with higher efficiency. What's more, the static graph optimizes the computation, reducing the steps that are not relevant to the result. It is possible to use the decorator @tf.function to construct code by converting normal Python function to TensorFlow graph. Executing this function is identical to executing Session in TensorFlow 1.X. This method, which uses decorator @tf.function to create static graph, is called Autograph. 1. Introduction to Graph # The graph consists of nodes and edges. The node represent operator, while the edge represents the dependencies between the operators. The solid edge (line) represents the dependency with data (tensor) transmission. The dotted edge (line) represents the dependency of control, i.e. the order of execution. 2. The Static Graph # In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session . Example of Static Graph in TensorFlow 1.X import tensorflow as tf #Defining the graph g = tf . Graph () with g . as_default (): #The object of the placeholder will be designated during the execution of the Session x = tf . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . string_join ([ x , y ], name = 'join' , separator = ' ' ) #Executing the graph with tf . Session ( graph = g ) as sess : print ( sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" })) The Static Graph in TensorFlow2.0 as a memorial In order to be compatible to the old versions, TensorFlow 2.X supports the TensorFlow 1.X styled static graph in the sub-module tf.compat.v1 . This is just for memorial and we do NOT recommend this way. import tensorflow as tf g = tf . compat . v1 . Graph () with g . as_default (): x = tf . compat . v1 . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . compat . v1 . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . strings . join ([ x , y ], name = \"join\" , separator = \" \" ) with tf . compat . v1 . Session ( graph = g ) as sess : # fetches is similar to the returning value from a function, while the placeholders in feed_dict is the input argument list to this function result = sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" }) print ( result ) b'hello world' 3. The Dynamic Graph # TensorFlow 2.X uses the dynamic graph and Autograph. In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session . However, the definition and execution is no more distinguishable for dynamic graph. It executes immediatly after definition and that's the reason why it is called \"Eager Excution\". # The construction of the graph takes place at every operator, and the graph execution is immediately following each construction. x = tf . constant ( \"hello\" ) y = tf . constant ( \"world\" ) z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) hello world # The input/output of the dynamic graph could be packaged as a function def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string) 4. Autograph in TensorFlow 2.X # The dynamic graph has a relatively lower efficiency in execution. We can use the decorator @tf.function to convert the original Python functions into the static graph as TensorFlow 1.X\u3002 In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session . In TensorFlow 2.X, the two steps for Autographs are: defining the function with a decorator '@tf.function' and calling this function. The is no need to use Session , so the syntax is as smooth as that of original Python. In reality, we will debug with the dynamic graph, and shift to Autograph using decorator @tf.function for the code requires higher efficiency of execution. There are certain rules of implementing @tf.function , which will be introduced in the following chapters. import tensorflow as tf # Use Autograph to construct the static graph @tf . function def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string) import datetime # Create logdir import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## We recommend using pathlib under Python3 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) writer = tf . summary . create_file_writer ( logdir ) # Start tracing on Autograph tf . summary . trace_on ( graph = True , profiler = True ) # Execute Autograph result = strjoin ( \"hello\" , \"world\" ) # Write the graph info into the log with writer . as_default (): tf . summary . trace_export ( name = \"autograph\" , step = 0 , profiler_outdir = logdir ) # Magic command to launch tensorboard in jupyter % load_ext tensorboard # Launch tensorboard % tensorboard -- logdir ../../ data / autograph / Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2-2 Three Types of Graph"},{"location":"english/Chapter2/Chapter2-2/#2-2-three-types-of-graph","text":"There are three types of graph: static, dynamic, and Autograph. TensorFlow 1.X used static graph, which firstly creating the graph by various operators and then open a Session to execute the graph. For TensorFlow 2.X, dynamic graph is used. The operator will be added to the invisible default graph and executed instantaneously after its usage; there is no need to create a Session . Using dynamic graph (i.e. Eager Execution) is convenient for debugging, as it improves performance of TensorFlow code just as original Python code, with possibilities of log output and flow control, etc. The drawback of dynamic graph is a relatively lower execution efficiency comparing to static graph. This is because multiple times of communication between the Python thread and the C++ thread of TensorFlow Kernel is required for dynamic graph, while the static graph is executed almost all on the TensorFlow kernel using C++ code with higher efficiency. What's more, the static graph optimizes the computation, reducing the steps that are not relevant to the result. It is possible to use the decorator @tf.function to construct code by converting normal Python function to TensorFlow graph. Executing this function is identical to executing Session in TensorFlow 1.X. This method, which uses decorator @tf.function to create static graph, is called Autograph.","title":"2-2 Three Types of Graph"},{"location":"english/Chapter2/Chapter2-2/#1-introduction-to-graph","text":"The graph consists of nodes and edges. The node represent operator, while the edge represents the dependencies between the operators. The solid edge (line) represents the dependency with data (tensor) transmission. The dotted edge (line) represents the dependency of control, i.e. the order of execution.","title":"1. Introduction to Graph"},{"location":"english/Chapter2/Chapter2-2/#2-the-static-graph","text":"In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session . Example of Static Graph in TensorFlow 1.X import tensorflow as tf #Defining the graph g = tf . Graph () with g . as_default (): #The object of the placeholder will be designated during the execution of the Session x = tf . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . string_join ([ x , y ], name = 'join' , separator = ' ' ) #Executing the graph with tf . Session ( graph = g ) as sess : print ( sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" })) The Static Graph in TensorFlow2.0 as a memorial In order to be compatible to the old versions, TensorFlow 2.X supports the TensorFlow 1.X styled static graph in the sub-module tf.compat.v1 . This is just for memorial and we do NOT recommend this way. import tensorflow as tf g = tf . compat . v1 . Graph () with g . as_default (): x = tf . compat . v1 . placeholder ( name = 'x' , shape = [], dtype = tf . string ) y = tf . compat . v1 . placeholder ( name = 'y' , shape = [], dtype = tf . string ) z = tf . strings . join ([ x , y ], name = \"join\" , separator = \" \" ) with tf . compat . v1 . Session ( graph = g ) as sess : # fetches is similar to the returning value from a function, while the placeholders in feed_dict is the input argument list to this function result = sess . run ( fetches = z , feed_dict = { x : \"hello\" , y : \"world\" }) print ( result ) b'hello world'","title":"2. The Static Graph"},{"location":"english/Chapter2/Chapter2-2/#3-the-dynamic-graph","text":"TensorFlow 2.X uses the dynamic graph and Autograph. In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session . However, the definition and execution is no more distinguishable for dynamic graph. It executes immediatly after definition and that's the reason why it is called \"Eager Excution\". # The construction of the graph takes place at every operator, and the graph execution is immediately following each construction. x = tf . constant ( \"hello\" ) y = tf . constant ( \"world\" ) z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) hello world # The input/output of the dynamic graph could be packaged as a function def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string)","title":"3. The Dynamic Graph"},{"location":"english/Chapter2/Chapter2-2/#4-autograph-in-tensorflow-2x","text":"The dynamic graph has a relatively lower efficiency in execution. We can use the decorator @tf.function to convert the original Python functions into the static graph as TensorFlow 1.X\u3002 In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session . In TensorFlow 2.X, the two steps for Autographs are: defining the function with a decorator '@tf.function' and calling this function. The is no need to use Session , so the syntax is as smooth as that of original Python. In reality, we will debug with the dynamic graph, and shift to Autograph using decorator @tf.function for the code requires higher efficiency of execution. There are certain rules of implementing @tf.function , which will be introduced in the following chapters. import tensorflow as tf # Use Autograph to construct the static graph @tf . function def strjoin ( x , y ): z = tf . strings . join ([ x , y ], separator = \" \" ) tf . print ( z ) return z result = strjoin ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) print ( result ) hello world tf.Tensor(b'hello world', shape=(), dtype=string) import datetime # Create logdir import os stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = os . path . join ( 'data' , 'autograph' , stamp ) ## We recommend using pathlib under Python3 # from pathlib import Path # stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # logdir = str(Path('../../data/autograph/' + stamp)) writer = tf . summary . create_file_writer ( logdir ) # Start tracing on Autograph tf . summary . trace_on ( graph = True , profiler = True ) # Execute Autograph result = strjoin ( \"hello\" , \"world\" ) # Write the graph info into the log with writer . as_default (): tf . summary . trace_export ( name = \"autograph\" , step = 0 , profiler_outdir = logdir ) # Magic command to launch tensorboard in jupyter % load_ext tensorboard # Launch tensorboard % tensorboard -- logdir ../../ data / autograph / Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4. Autograph in TensorFlow 2.X"},{"location":"english/Chapter2/Chapter2-3/","text":"2-3 Automatic Differentiate # The neural networks relies on back propagations to calculate gradients and update the parameters in the network. Gradient calculation is complicated which is easy to incur mistakes. The framework of deeplearning helps us to calculate gradient automatically. tf.GradientTape is usually used to record forward calculation in Tensorflow, and reverse this \"tape\" to obtain the gradient. This is the automatic differentiate in TensorFlow. 1. Calculate the Derivative Using the Gradient Tape # import tensorflow as tf import numpy as np # Calculate the derivative of f(x) = a*x**2 + b*x + c x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) print ( dy_dx ) tf.Tensor(-2.0, shape=(), dtype=float32) # Use watch to calculate derivatives of the constant tensor with tf . GradientTape () as tape : tape . watch ([ a , b , c ]) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx , dy_da , dy_db , dy_dc = tape . gradient ( y ,[ x , a , b , c ]) print ( dy_da ) print ( dy_dc ) tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32) # Calculate the second order derivative with tf . GradientTape () as tape2 : with tf . GradientTape () as tape1 : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape1 . gradient ( y , x ) dy2_dx2 = tape2 . gradient ( dy_dx , x ) print ( dy2_dx2 ) tf.Tensor(2.0, shape=(), dtype=float32) # Use it in the autograph @tf . function def f ( x ): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) # Convert the type of the variable to tf.float32 x = tf . cast ( x , tf . float32 ) with tf . GradientTape () as tape : tape . watch ( x ) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) return (( dy_dx , y )) tf . print ( f ( tf . constant ( 0.0 ))) tf . print ( f ( tf . constant ( 1.0 ))) (-2, 1) (0, 0) 2. Calculate the Minimal Value Through the Gradient Tape and the Optimizer # # Calculate the minimal value of f(x) = a*x**2 + b*x + c # Use optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) tf . print ( \"y =\" , y , \"; x =\" , x ) y = 0 ; x = 0.999998569 # Calculate the minimal value off(x) = a*x**2 + b*x + c # Use optimizer.minimize # This optimizer.minimize is identical to calculating gradient using tape, then call apply_gradient x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) #Note that f() has no argument def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): optimizer . minimize ( f ,[ x ]) tf . print ( \"y =\" , f (), \"; x =\" , x ) y = 0 ; x = 0.999998569 # Calculate minimal value in Autograph # Use optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) for _ in tf . range ( 1000 ): #Note that we should use tf.range(1000) instead of range(1000) when using Autograph with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( minimizef ()) tf . print ( x ) 0 0.999998569 # Calculate minimal value in Autograph # Use optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) return ( f ()) tf . print ( train ( 1000 )) tf . print ( x ) 0 0.999998569 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2-3 Automatic Differentiate"},{"location":"english/Chapter2/Chapter2-3/#2-3-automatic-differentiate","text":"The neural networks relies on back propagations to calculate gradients and update the parameters in the network. Gradient calculation is complicated which is easy to incur mistakes. The framework of deeplearning helps us to calculate gradient automatically. tf.GradientTape is usually used to record forward calculation in Tensorflow, and reverse this \"tape\" to obtain the gradient. This is the automatic differentiate in TensorFlow.","title":"2-3 Automatic Differentiate"},{"location":"english/Chapter2/Chapter2-3/#1-calculate-the-derivative-using-the-gradient-tape","text":"import tensorflow as tf import numpy as np # Calculate the derivative of f(x) = a*x**2 + b*x + c x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) print ( dy_dx ) tf.Tensor(-2.0, shape=(), dtype=float32) # Use watch to calculate derivatives of the constant tensor with tf . GradientTape () as tape : tape . watch ([ a , b , c ]) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx , dy_da , dy_db , dy_dc = tape . gradient ( y ,[ x , a , b , c ]) print ( dy_da ) print ( dy_dc ) tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32) # Calculate the second order derivative with tf . GradientTape () as tape2 : with tf . GradientTape () as tape1 : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape1 . gradient ( y , x ) dy2_dx2 = tape2 . gradient ( dy_dx , x ) print ( dy2_dx2 ) tf.Tensor(2.0, shape=(), dtype=float32) # Use it in the autograph @tf . function def f ( x ): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) # Convert the type of the variable to tf.float32 x = tf . cast ( x , tf . float32 ) with tf . GradientTape () as tape : tape . watch ( x ) y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) return (( dy_dx , y )) tf . print ( f ( tf . constant ( 0.0 ))) tf . print ( f ( tf . constant ( 1.0 ))) (-2, 1) (0, 0)","title":"1. Calculate the Derivative Using the Gradient Tape"},{"location":"english/Chapter2/Chapter2-3/#2-calculate-the-minimal-value-through-the-gradient-tape-and-the-optimizer","text":"# Calculate the minimal value of f(x) = a*x**2 + b*x + c # Use optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) tf . print ( \"y =\" , y , \"; x =\" , x ) y = 0 ; x = 0.999998569 # Calculate the minimal value off(x) = a*x**2 + b*x + c # Use optimizer.minimize # This optimizer.minimize is identical to calculating gradient using tape, then call apply_gradient x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) #Note that f() has no argument def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for _ in range ( 1000 ): optimizer . minimize ( f ,[ x ]) tf . print ( \"y =\" , f (), \"; x =\" , x ) y = 0 ; x = 0.999998569 # Calculate minimal value in Autograph # Use optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) for _ in tf . range ( 1000 ): #Note that we should use tf.range(1000) instead of range(1000) when using Autograph with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( minimizef ()) tf . print ( x ) 0 0.999998569 # Calculate minimal value in Autograph # Use optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) return ( f ()) tf . print ( train ( 1000 )) tf . print ( x ) 0 0.999998569 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Calculate the Minimal Value Through the Gradient Tape and the Optimizer"},{"location":"english/Chapter3/","text":"Chapter 3: Hierarchy of TensorFlow # We are going to introduce five levels of TensorFlow in this chapter: Hardware Level, Kernel Level, Low-level API, Mid-level API, High-level API. We demonstrate the differences in model implementation at different API levels with two examples: a linear regression model and a DNN binary classification model. From lower to higher, there are five levels in TensorFlow hierarchy. The bottom one is hardware level. TensorFlow supports adding CPU, GPU or TPU to the resource pool of computing. The second level is the kernel implementing C++. These kernels are able to run on distributed cross platforms. The third level contains operators in written in Python, which provides low-level API instructions that packaging C++ kernels, including tensor operation, graph, automatic differentiate, etc. For example: tf.Variable , tf.constant , tf.function , tf.GradientTape , tf.nn.softmax ... If we compare a model to a house, then these third level APIs are the bricks. The fourth level contains model components implemented in Python. They provide packaging to the low-level API functions, including model layers, loss functions, optimizers, data pipelines, feature columns, etc. For example: tf.keras.layers , tf.keras.losses , tf.keras.metrics , tf.keras.optimizers , tf.data.DataSet , tf.feature_column ... If we compare a model to a house, then these fourth level APIs are the walls. The fifth level contains well-designed models implemented in Python. Most of them are high-level APIs packaged by OOP, typically are the class interfaces for tf.keras.models . If we compare a model to a house, then these fifth level APIs are the houses themselves. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 3: Hierarchy of TensorFlow"},{"location":"english/Chapter3/#chapter-3-hierarchy-of-tensorflow","text":"We are going to introduce five levels of TensorFlow in this chapter: Hardware Level, Kernel Level, Low-level API, Mid-level API, High-level API. We demonstrate the differences in model implementation at different API levels with two examples: a linear regression model and a DNN binary classification model. From lower to higher, there are five levels in TensorFlow hierarchy. The bottom one is hardware level. TensorFlow supports adding CPU, GPU or TPU to the resource pool of computing. The second level is the kernel implementing C++. These kernels are able to run on distributed cross platforms. The third level contains operators in written in Python, which provides low-level API instructions that packaging C++ kernels, including tensor operation, graph, automatic differentiate, etc. For example: tf.Variable , tf.constant , tf.function , tf.GradientTape , tf.nn.softmax ... If we compare a model to a house, then these third level APIs are the bricks. The fourth level contains model components implemented in Python. They provide packaging to the low-level API functions, including model layers, loss functions, optimizers, data pipelines, feature columns, etc. For example: tf.keras.layers , tf.keras.losses , tf.keras.metrics , tf.keras.optimizers , tf.data.DataSet , tf.feature_column ... If we compare a model to a house, then these fourth level APIs are the walls. The fifth level contains well-designed models implemented in Python. Most of them are high-level APIs packaged by OOP, typically are the class interfaces for tf.keras.models . If we compare a model to a house, then these fifth level APIs are the houses themselves. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 3: Hierarchy of TensorFlow"},{"location":"english/Chapter3/Chapter3-1/","text":"3-1 Low-level API: Demonstration # The examples below use low-level APIs in TensorFlow to implement a linear regression model and a DNN binary classification model. Low-level API includes tensor operation, graph and automatic differentiates. import tensorflow as tf # Time Stamp @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) 1. Linear Regression Model # (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf # Number of samples n = 400 # Generating the datasets X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise # Data Visualization % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # Creating generator of data pipeline def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) # Randomized reading order of the samples for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # Testing the data pipeline batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 2.6161194 0.11071014] [ 9.79207 -0.70180416] [ 9.792343 6.9149055 ] [-2.4186516 -9.375019 ] [ 9.83749 -3.4637213 ] [ 7.3953056 4.374569 ] [-0.14686584 -0.28063297] [ 0.49001217 -9.739792 ]], shape=(8, 2), dtype=float32) tf.Tensor( [[ 9.334667 ] [22.058844 ] [ 3.0695205] [26.736238 ] [35.292133 ] [ 4.2943544] [ 1.6713585] [34.826904 ]], shape=(8, 1), dtype=float32) (b) Model Definition w = tf . Variable ( tf . random . normal ( w0 . shape )) b = tf . Variable ( tf . zeros_like ( b0 , dtype = tf . float32 )) # Defining Model class LinearRegression : # Forward propagation def __call__ ( self , x ): return x @w + b # Loss function def loss_func ( self , y_true , y_pred ): return tf . reduce_mean (( y_true - y_pred ) ** 2 / 2 ) model = LinearRegression () \u00a9 Model Training # Debug in dynamic graph def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # Back propagation to calculate the gradients dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # Updating parameters using gradient descending method w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss # Test the results of train_step batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) train_step ( model , features , labels ) <tf.Tensor: shape=(), dtype=float32, numpy=211.09982> def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:35:56 epoch = 50 loss = 1.78806472 w = [[1.97554708] [-2.97719598]] b = [[2.60692883]] ================================================================================16:36:00 epoch = 100 loss = 2.64588404 w = [[1.97319281] [-2.97810626]] b = [[2.95525956]] ================================================================================16:36:04 epoch = 150 loss = 1.42576694 w = [[1.96466208] [-2.98337793]] b = [[3.00264144]] ================================================================================16:36:08 epoch = 200 loss = 1.68992615 w = [[1.97718477] [-2.983814]] b = [[3.01013041]] ## Accelerate using Autograph to transform the dynamic graph into static @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # Back propagation to calculate the gradients dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # Updating parameters using gradient descending method w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:36:35 epoch = 50 loss = 0.894210339 w = [[1.96927285] [-2.98914337]] b = [[3.00987792]] ================================================================================16:36:36 epoch = 100 loss = 1.58621466 w = [[1.97566223] [-2.98550248]] b = [[3.00998402]] ================================================================================16:36:37 epoch = 150 loss = 2.2695992 w = [[1.96664226] [-2.99248481]] b = [[3.01028705]] ================================================================================16:36:38 epoch = 200 loss = 1.90848124 w = [[1.98000824] [-2.98888135]] b = [[3.01085401]] # Visualizing the results % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 2. DNN Binary Classification Model # (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf % matplotlib inline % config InlineBackend . figure_format = 'svg' # Number of the positive/negative samples n_positive , n_negative = 2000 , 2000 # Generating the positive samples with a distribution on a smaller ring r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) # Generating the negative samples with a distribution on a larger ring r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) # Assembling all samples X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) # Visualizing the data plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # Create the generator of the data pipeline def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) # Randomizing the reading order of the samples for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # Testing data pipeline batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 0.03732629 3.5783494 ] [ 0.542919 5.035079 ] [ 5.860281 -2.4476354 ] [ 0.63657564 3.194231 ] [-3.5072308 2.5578873 ] [-2.4109735 -3.6621518 ] [ 4.0975413 -2.4172943 ] [ 1.9393908 -6.782317 ] [-4.7453732 -0.5176727 ] [-1.4057113 -7.9775257 ]], shape=(10, 2), dtype=float32) tf.Tensor( [[1.] [1.] [0.] [1.] [1.] [1.] [1.] [0.] [1.] [0.]], shape=(10, 1), dtype=float32) (b) Model Definition Here the tf.Module is used for organizing the parameters in the model. You may refer to the last section of Chapter 4 ( AutoGraph and tf.Module ) for more details of tf.Module . class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . w1 = tf . Variable ( tf . random . truncated_normal ([ 2 , 4 ]), dtype = tf . float32 ) self . b1 = tf . Variable ( tf . zeros ([ 1 , 4 ]), dtype = tf . float32 ) self . w2 = tf . Variable ( tf . random . truncated_normal ([ 4 , 8 ]), dtype = tf . float32 ) self . b2 = tf . Variable ( tf . zeros ([ 1 , 8 ]), dtype = tf . float32 ) self . w3 = tf . Variable ( tf . random . truncated_normal ([ 8 , 1 ]), dtype = tf . float32 ) self . b3 = tf . Variable ( tf . zeros ([ 1 , 1 ]), dtype = tf . float32 ) # Forward propagation @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = tf . nn . relu ( x @self . w1 + self . b1 ) x = tf . nn . relu ( x @self . w2 + self . b2 ) y = tf . nn . sigmoid ( x @self . w3 + self . b3 ) return y # Loss function (binary cross entropy) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def loss_func ( self , y_true , y_pred ): # Limiting the prediction between 1e-7 and 1 - 1e-7 to avoid the error at log(0) eps = 1e-7 y_pred = tf . clip_by_value ( y_pred , eps , 1.0 - eps ) bce = - y_true * tf . math . log ( y_pred ) - ( 1 - y_true ) * tf . math . log ( 1 - y_pred ) return tf . reduce_mean ( bce ) # Metric (Accuracy) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def metric_func ( self , y_true , y_pred ): y_pred = tf . where ( y_pred > 0.5 , tf . ones_like ( y_pred , dtype = tf . float32 ), tf . zeros_like ( y_pred , dtype = tf . float32 )) acc = tf . reduce_mean ( 1 - tf . abs ( y_true - y_pred )) return acc model = DNNModel () # Testing the structure of model batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) predictions = model ( features ) loss = model . loss_func ( labels , predictions ) metric = model . metric_func ( labels , predictions ) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.76568353 init metric 0.6 print ( len ( model . trainable_variables )) 6 \u00a9 Model Training ## Transform to static graph for acceleration using Autograph @tf . function def train_step ( model , features , labels ): # Forward propagation to calculate the loss with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # Backward propagation to calculate the gradients grads = tape . gradient ( loss , model . trainable_variables ) # Applying gradient descending for p , dloss_dp in zip ( model . trainable_variables , grads ): p . assign ( p - 0.001 * dloss_dp ) # Calculate metric metric = model . metric_func ( labels , predictions ) return loss , metric def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 100 ): loss , metric = train_step ( model , features , labels ) if epoch % 100 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 600 ) ================================================================================16:47:35 epoch = 100 loss = 0.567795336 accuracy = 0.71 ================================================================================16:47:39 epoch = 200 loss = 0.50955683 accuracy = 0.77 ================================================================================16:47:43 epoch = 300 loss = 0.421476126 accuracy = 0.84 ================================================================================16:47:47 epoch = 400 loss = 0.330618203 accuracy = 0.9 ================================================================================16:47:51 epoch = 500 loss = 0.308296859 accuracy = 0.89 ================================================================================16:47:55 epoch = 600 loss = 0.279367268 accuracy = 0.96 # Visualizing the results fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3-1 Low-level API: Demonstration"},{"location":"english/Chapter3/Chapter3-1/#3-1-low-level-api-demonstration","text":"The examples below use low-level APIs in TensorFlow to implement a linear regression model and a DNN binary classification model. Low-level API includes tensor operation, graph and automatic differentiates. import tensorflow as tf # Time Stamp @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"3-1 Low-level API: Demonstration"},{"location":"english/Chapter3/Chapter3-1/#1-linear-regression-model","text":"(a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf # Number of samples n = 400 # Generating the datasets X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise # Data Visualization % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # Creating generator of data pipeline def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) # Randomized reading order of the samples for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # Testing the data pipeline batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 2.6161194 0.11071014] [ 9.79207 -0.70180416] [ 9.792343 6.9149055 ] [-2.4186516 -9.375019 ] [ 9.83749 -3.4637213 ] [ 7.3953056 4.374569 ] [-0.14686584 -0.28063297] [ 0.49001217 -9.739792 ]], shape=(8, 2), dtype=float32) tf.Tensor( [[ 9.334667 ] [22.058844 ] [ 3.0695205] [26.736238 ] [35.292133 ] [ 4.2943544] [ 1.6713585] [34.826904 ]], shape=(8, 1), dtype=float32) (b) Model Definition w = tf . Variable ( tf . random . normal ( w0 . shape )) b = tf . Variable ( tf . zeros_like ( b0 , dtype = tf . float32 )) # Defining Model class LinearRegression : # Forward propagation def __call__ ( self , x ): return x @w + b # Loss function def loss_func ( self , y_true , y_pred ): return tf . reduce_mean (( y_true - y_pred ) ** 2 / 2 ) model = LinearRegression () \u00a9 Model Training # Debug in dynamic graph def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # Back propagation to calculate the gradients dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # Updating parameters using gradient descending method w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss # Test the results of train_step batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) train_step ( model , features , labels ) <tf.Tensor: shape=(), dtype=float32, numpy=211.09982> def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:35:56 epoch = 50 loss = 1.78806472 w = [[1.97554708] [-2.97719598]] b = [[2.60692883]] ================================================================================16:36:00 epoch = 100 loss = 2.64588404 w = [[1.97319281] [-2.97810626]] b = [[2.95525956]] ================================================================================16:36:04 epoch = 150 loss = 1.42576694 w = [[1.96466208] [-2.98337793]] b = [[3.00264144]] ================================================================================16:36:08 epoch = 200 loss = 1.68992615 w = [[1.97718477] [-2.983814]] b = [[3.01013041]] ## Accelerate using Autograph to transform the dynamic graph into static @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # Back propagation to calculate the gradients dloss_dw , dloss_db = tape . gradient ( loss ,[ w , b ]) # Updating parameters using gradient descending method w . assign ( w - 0.001 * dloss_dw ) b . assign ( b - 0.001 * dloss_db ) return loss def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , w ) tf . print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================16:36:35 epoch = 50 loss = 0.894210339 w = [[1.96927285] [-2.98914337]] b = [[3.00987792]] ================================================================================16:36:36 epoch = 100 loss = 1.58621466 w = [[1.97566223] [-2.98550248]] b = [[3.00998402]] ================================================================================16:36:37 epoch = 150 loss = 2.2695992 w = [[1.96664226] [-2.99248481]] b = [[3.01028705]] ================================================================================16:36:38 epoch = 200 loss = 1.90848124 w = [[1.98000824] [-2.98888135]] b = [[3.01085401]] # Visualizing the results % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"1. Linear Regression Model"},{"location":"english/Chapter3/Chapter3-1/#2-dnn-binary-classification-model","text":"(a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf % matplotlib inline % config InlineBackend . figure_format = 'svg' # Number of the positive/negative samples n_positive , n_negative = 2000 , 2000 # Generating the positive samples with a distribution on a smaller ring r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) # Generating the negative samples with a distribution on a larger ring r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) # Assembling all samples X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) # Visualizing the data plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # Create the generator of the data pipeline def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) # Randomizing the reading order of the samples for i in range ( 0 , num_examples , batch_size ): indexs = indices [ i : min ( i + batch_size , num_examples )] yield tf . gather ( features , indexs ), tf . gather ( labels , indexs ) # Testing data pipeline batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tf.Tensor( [[ 0.03732629 3.5783494 ] [ 0.542919 5.035079 ] [ 5.860281 -2.4476354 ] [ 0.63657564 3.194231 ] [-3.5072308 2.5578873 ] [-2.4109735 -3.6621518 ] [ 4.0975413 -2.4172943 ] [ 1.9393908 -6.782317 ] [-4.7453732 -0.5176727 ] [-1.4057113 -7.9775257 ]], shape=(10, 2), dtype=float32) tf.Tensor( [[1.] [1.] [0.] [1.] [1.] [1.] [1.] [0.] [1.] [0.]], shape=(10, 1), dtype=float32) (b) Model Definition Here the tf.Module is used for organizing the parameters in the model. You may refer to the last section of Chapter 4 ( AutoGraph and tf.Module ) for more details of tf.Module . class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . w1 = tf . Variable ( tf . random . truncated_normal ([ 2 , 4 ]), dtype = tf . float32 ) self . b1 = tf . Variable ( tf . zeros ([ 1 , 4 ]), dtype = tf . float32 ) self . w2 = tf . Variable ( tf . random . truncated_normal ([ 4 , 8 ]), dtype = tf . float32 ) self . b2 = tf . Variable ( tf . zeros ([ 1 , 8 ]), dtype = tf . float32 ) self . w3 = tf . Variable ( tf . random . truncated_normal ([ 8 , 1 ]), dtype = tf . float32 ) self . b3 = tf . Variable ( tf . zeros ([ 1 , 1 ]), dtype = tf . float32 ) # Forward propagation @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = tf . nn . relu ( x @self . w1 + self . b1 ) x = tf . nn . relu ( x @self . w2 + self . b2 ) y = tf . nn . sigmoid ( x @self . w3 + self . b3 ) return y # Loss function (binary cross entropy) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def loss_func ( self , y_true , y_pred ): # Limiting the prediction between 1e-7 and 1 - 1e-7 to avoid the error at log(0) eps = 1e-7 y_pred = tf . clip_by_value ( y_pred , eps , 1.0 - eps ) bce = - y_true * tf . math . log ( y_pred ) - ( 1 - y_true ) * tf . math . log ( 1 - y_pred ) return tf . reduce_mean ( bce ) # Metric (Accuracy) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 ), tf . TensorSpec ( shape = [ None , 1 ], dtype = tf . float32 )]) def metric_func ( self , y_true , y_pred ): y_pred = tf . where ( y_pred > 0.5 , tf . ones_like ( y_pred , dtype = tf . float32 ), tf . zeros_like ( y_pred , dtype = tf . float32 )) acc = tf . reduce_mean ( 1 - tf . abs ( y_true - y_pred )) return acc model = DNNModel () # Testing the structure of model batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) predictions = model ( features ) loss = model . loss_func ( labels , predictions ) metric = model . metric_func ( labels , predictions ) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.76568353 init metric 0.6 print ( len ( model . trainable_variables )) 6 \u00a9 Model Training ## Transform to static graph for acceleration using Autograph @tf . function def train_step ( model , features , labels ): # Forward propagation to calculate the loss with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( labels , predictions ) # Backward propagation to calculate the gradients grads = tape . gradient ( loss , model . trainable_variables ) # Applying gradient descending for p , dloss_dp in zip ( model . trainable_variables , grads ): p . assign ( p - 0.001 * dloss_dp ) # Calculate metric metric = model . metric_func ( labels , predictions ) return loss , metric def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 100 ): loss , metric = train_step ( model , features , labels ) if epoch % 100 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 600 ) ================================================================================16:47:35 epoch = 100 loss = 0.567795336 accuracy = 0.71 ================================================================================16:47:39 epoch = 200 loss = 0.50955683 accuracy = 0.77 ================================================================================16:47:43 epoch = 300 loss = 0.421476126 accuracy = 0.84 ================================================================================16:47:47 epoch = 400 loss = 0.330618203 accuracy = 0.9 ================================================================================16:47:51 epoch = 500 loss = 0.308296859 accuracy = 0.89 ================================================================================16:47:55 epoch = 600 loss = 0.279367268 accuracy = 0.96 # Visualizing the results fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. DNN Binary Classification Model"},{"location":"english/Chapter3/Chapter3-2/","text":"3-2 Mid-level API: Demonstration # The examples below use mid-level APIs in TensorFlow to implement a linear regression model and a DNN binary classification model. Mid-level API includes model layers, loss functions, optimizers, data pipelines, feature columns, etc. import tensorflow as tf # Time stamp @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) 1. Linear Regression Model # (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers # Number of sample n = 400 # Generating the datasets X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise # Data Visualization % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # Creating generator of data pipeline ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 100 ) . batch ( 10 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) (b) Model Definition model = layers . Dense ( units = 1 ) model . build ( input_shape = ( 2 ,)) #Creating variables using the build method model . loss_func = losses . mean_squared_error model . optimizer = optimizers . SGD ( learning_rate = 0.001 ) \u00a9 Model Training # Accelerate using Autograph to transform the dynamic graph into static @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . variables ) model . optimizer . apply_gradients ( zip ( grads , model . variables )) return loss # Testing the results of train_step features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss = tf . constant ( 0.0 ) for features , labels in ds : loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , model . variables [ 0 ]) tf . print ( \"b =\" , model . variables [ 1 ]) train_model ( model , epochs = 200 ) ================================================================================17:01:48 epoch = 50 loss = 2.56481647 w = [[1.99355531] [-2.99061537]] b = [3.09484935] ================================================================================17:01:51 epoch = 100 loss = 5.96198225 w = [[1.98028314] [-2.96975136]] b = [3.09501529] ================================================================================17:01:54 epoch = 150 loss = 4.79625702 w = [[2.00056171] [-2.98774862]] b = [3.09567738] ================================================================================17:01:58 epoch = 200 loss = 8.26704407 w = [[2.00282311] [-2.99300027]] b = [3.09406662] # Visualizing the results % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 2. DNN Binary Classification Model # (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' ## Number of the positive/negative samples n_positive , n_negative = 2000 , 2000 # Generating the positive samples with a distribution on a smaller ring r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) # Generating the negative samples with a distribution on a larger ring r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) # Assembling all samples X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) # Visualizing the data plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # Create pipeline for the input data ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 4000 ) . batch ( 100 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) (b) Model Definition class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . dense1 = layers . Dense ( 4 , activation = \"relu\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" ) # Forward propagation @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . loss_func = losses . binary_crossentropy model . metric_func = metrics . binary_accuracy model . optimizer = optimizers . Adam ( learning_rate = 0.001 ) # Testing the structure of model ( features , labels ) = next ( ds . as_numpy_iterator ()) predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.13653195 init metric 0.5 \u00a9 Model Training # Transform to static graph for acceleration using Autograph @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . trainable_variables ) model . optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) return loss , metric # Testing the result of train_step features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) (<tf.Tensor: shape=(), dtype=float32, numpy=1.2033114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.47>) @tf . function def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss , metric = tf . constant ( 0.0 ), tf . constant ( 0.0 ) for features , labels in ds : loss , metric = train_step ( model , features , labels ) if epoch % 10 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 60 ) ================================================================================17:07:36 epoch = 10 loss = 0.556449413 accuracy = 0.79 ================================================================================17:07:38 epoch = 20 loss = 0.439187407 accuracy = 0.86 ================================================================================17:07:40 epoch = 30 loss = 0.259921253 accuracy = 0.95 ================================================================================17:07:42 epoch = 40 loss = 0.244920313 accuracy = 0.9 ================================================================================17:07:43 epoch = 50 loss = 0.19839409 accuracy = 0.92 ================================================================================17:07:45 epoch = 60 loss = 0.126151696 accuracy = 0.95 # Visualizing the results fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3-2 Mid-level API: Demonstration"},{"location":"english/Chapter3/Chapter3-2/#3-2-mid-level-api-demonstration","text":"The examples below use mid-level APIs in TensorFlow to implement a linear regression model and a DNN binary classification model. Mid-level API includes model layers, loss functions, optimizers, data pipelines, feature columns, etc. import tensorflow as tf # Time stamp @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"3-2 Mid-level API: Demonstration"},{"location":"english/Chapter3/Chapter3-2/#1-linear-regression-model","text":"(a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers # Number of sample n = 400 # Generating the datasets X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise # Data Visualization % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # Creating generator of data pipeline ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 100 ) . batch ( 10 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) (b) Model Definition model = layers . Dense ( units = 1 ) model . build ( input_shape = ( 2 ,)) #Creating variables using the build method model . loss_func = losses . mean_squared_error model . optimizer = optimizers . SGD ( learning_rate = 0.001 ) \u00a9 Model Training # Accelerate using Autograph to transform the dynamic graph into static @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . variables ) model . optimizer . apply_gradients ( zip ( grads , model . variables )) return loss # Testing the results of train_step features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss = tf . constant ( 0.0 ) for features , labels in ds : loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss ) tf . print ( \"w =\" , model . variables [ 0 ]) tf . print ( \"b =\" , model . variables [ 1 ]) train_model ( model , epochs = 200 ) ================================================================================17:01:48 epoch = 50 loss = 2.56481647 w = [[1.99355531] [-2.99061537]] b = [3.09484935] ================================================================================17:01:51 epoch = 100 loss = 5.96198225 w = [[1.98028314] [-2.96975136]] b = [3.09501529] ================================================================================17:01:54 epoch = 150 loss = 4.79625702 w = [[2.00056171] [-2.98774862]] b = [3.09567738] ================================================================================17:01:58 epoch = 200 loss = 8.26704407 w = [[2.00282311] [-2.99300027]] b = [3.09406662] # Visualizing the results % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"1. Linear Regression Model"},{"location":"english/Chapter3/Chapter3-2/#2-dnn-binary-classification-model","text":"(a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' ## Number of the positive/negative samples n_positive , n_negative = 2000 , 2000 # Generating the positive samples with a distribution on a smaller ring r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) # Generating the negative samples with a distribution on a larger ring r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) # Assembling all samples X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) # Visualizing the data plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # Create pipeline for the input data ds = tf . data . Dataset . from_tensor_slices (( X , Y )) \\ . shuffle ( buffer_size = 4000 ) . batch ( 100 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) (b) Model Definition class DNNModel ( tf . Module ): def __init__ ( self , name = None ): super ( DNNModel , self ) . __init__ ( name = name ) self . dense1 = layers . Dense ( 4 , activation = \"relu\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" ) # Forward propagation @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def __call__ ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . loss_func = losses . binary_crossentropy model . metric_func = metrics . binary_accuracy model . optimizer = optimizers . Adam ( learning_rate = 0.001 ) # Testing the structure of model ( features , labels ) = next ( ds . as_numpy_iterator ()) predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) tf . print ( \"init loss:\" , loss ) tf . print ( \"init metric\" , metric ) init loss: 1.13653195 init metric 0.5 \u00a9 Model Training # Transform to static graph for acceleration using Autograph @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = model . loss_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) grads = tape . gradient ( loss , model . trainable_variables ) model . optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) metric = model . metric_func ( tf . reshape ( labels ,[ - 1 ]), tf . reshape ( predictions ,[ - 1 ])) return loss , metric # Testing the result of train_step features , labels = next ( ds . as_numpy_iterator ()) train_step ( model , features , labels ) (<tf.Tensor: shape=(), dtype=float32, numpy=1.2033114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.47>) @tf . function def train_model ( model , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): loss , metric = tf . constant ( 0.0 ), tf . constant ( 0.0 ) for features , labels in ds : loss , metric = train_step ( model , features , labels ) if epoch % 10 == 0 : printbar () tf . print ( \"epoch =\" , epoch , \"loss = \" , loss , \"accuracy = \" , metric ) train_model ( model , epochs = 60 ) ================================================================================17:07:36 epoch = 10 loss = 0.556449413 accuracy = 0.79 ================================================================================17:07:38 epoch = 20 loss = 0.439187407 accuracy = 0.86 ================================================================================17:07:40 epoch = 30 loss = 0.259921253 accuracy = 0.95 ================================================================================17:07:42 epoch = 40 loss = 0.244920313 accuracy = 0.9 ================================================================================17:07:43 epoch = 50 loss = 0.19839409 accuracy = 0.92 ================================================================================17:07:45 epoch = 60 loss = 0.126151696 accuracy = 0.95 # Visualizing the results fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. DNN Binary Classification Model"},{"location":"english/Chapter3/Chapter3-3/","text":"3-3 High-level API: Demonstration # The examples below use high-level APIs in TensorFlow to implement a linear regression model and a DNN binary classification model. Typically, the high-level APIs are providing the class interfaces for tf.keras.models . There are three ways of modeling using APIs of Keras: sequential modeling using Sequential function, arbitrary modeling using API functions, and customized modeling by inheriting base class Model . Here we are demonstrating using Sequential function and customized modeling by inheriting base class Model , respectively. import tensorflow as tf # Time stamp @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring ) 1. Linear Regression Model # In this example, we used Sequential function to construct the model sequentially and use the pre-defined method model.fit for training (for the beginners). (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , optimizers # Number of sample n = 400 # Generating the datasets X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise # Data Visualization % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () (b) Model Definition tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 1 , input_shape = ( 2 ,))) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 \u00a9 Model Training ### Training using method fit model . compile ( optimizer = \"adam\" , loss = \"mse\" , metrics = [ \"mae\" ]) model . fit ( X , Y , batch_size = 10 , epochs = 200 ) tf . print ( \"w = \" , model . layers [ 0 ] . kernel ) tf . print ( \"b = \" , model . layers [ 0 ] . bias ) Epoch 197/200 400/400 [==============================] - 0s 190us/sample - loss: 4.3977 - mae: 1.7129 Epoch 198/200 400/400 [==============================] - 0s 172us/sample - loss: 4.3918 - mae: 1.7117 Epoch 199/200 400/400 [==============================] - 0s 134us/sample - loss: 4.3861 - mae: 1.7106 Epoch 200/200 400/400 [==============================] - 0s 166us/sample - loss: 4.3786 - mae: 1.7092 w = [[1.99339032] [-3.00866461]] b = [2.67018795] # Visualizing the results % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 2. DNN Binary Classification Model # This example demonstrates the customized model using the child class inherited from the base class Model , and use a customized loop for training (for the experts). (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' # Number of the positive/negative samples n_positive , n_negative = 2000 , 2000 # Generating the positive samples with a distribution on a smaller ring r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) # Generating the negative samples with a distribution on a larger ring r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) # Assembling all samples X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) # Shuffling the samples data = tf . concat ([ X , Y ], axis = 1 ) data = tf . random . shuffle ( data ) X = data [:,: 2 ] Y = data [:, 2 :] # Visualizing the data plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds_train = tf . data . Dataset . from_tensor_slices (( X [ 0 : n * 3 // 4 ,:], Y [ 0 : n * 3 // 4 ,:])) \\ . shuffle ( buffer_size = 1000 ) . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () ds_valid = tf . data . Dataset . from_tensor_slices (( X [ n * 3 // 4 :,:], Y [ n * 3 // 4 :,:])) \\ . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () (b) Model Definition tf . keras . backend . clear_session () class DNNModel ( models . Model ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () def build ( self , input_shape ): self . dense1 = layers . Dense ( 4 , activation = \"relu\" , name = \"dense1\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" , name = \"dense2\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" , name = \"dense3\" ) super ( DNNModel , self ) . build ( input_shape ) # Forward propagation @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def call ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . build ( input_shape = ( None , 2 )) model . summary () Model: \"dnn_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense1 (Dense) multiple 12 _________________________________________________________________ dense2 (Dense) multiple 40 _________________________________________________________________ dense3 (Dense) multiple 9 ================================================================= Total params: 61 Trainable params: 61 Non-trainable params: 0 _________________________________________________________________ \u00a9 Model Training ### Customizing the training loop optimizer = optimizers . Adam ( learning_rate = 0.01 ) loss_func = tf . keras . losses . BinaryCrossentropy () train_loss = tf . keras . metrics . Mean ( name = 'train_loss' ) train_metric = tf . keras . metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = tf . keras . metrics . Mean ( name = 'valid_loss' ) valid_metric = tf . keras . metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = loss_func ( labels , predictions ) grads = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 100 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_valid , 1000 ) ================================================================================17:35:02 Epoch=100,Loss:0.194088802,Accuracy:0.923064,Valid Loss:0.215538561,Valid Accuracy:0.904368 ================================================================================17:35:22 Epoch=200,Loss:0.151239693,Accuracy:0.93768847,Valid Loss:0.181166962,Valid Accuracy:0.920664132 ================================================================================17:35:43 Epoch=300,Loss:0.134556711,Accuracy:0.944247484,Valid Loss:0.171530813,Valid Accuracy:0.926396072 ================================================================================17:36:04 Epoch=400,Loss:0.125722557,Accuracy:0.949172914,Valid Loss:0.16731061,Valid Accuracy:0.929318547 ================================================================================17:36:24 Epoch=500,Loss:0.120216407,Accuracy:0.952525079,Valid Loss:0.164817035,Valid Accuracy:0.931044817 ================================================================================17:36:44 Epoch=600,Loss:0.116434008,Accuracy:0.954830289,Valid Loss:0.163089141,Valid Accuracy:0.932202339 ================================================================================17:37:05 Epoch=700,Loss:0.113658346,Accuracy:0.956433,Valid Loss:0.161804497,Valid Accuracy:0.933092058 ================================================================================17:37:25 Epoch=800,Loss:0.111522928,Accuracy:0.957467675,Valid Loss:0.160796657,Valid Accuracy:0.93379426 ================================================================================17:37:46 Epoch=900,Loss:0.109816991,Accuracy:0.958205402,Valid Loss:0.159987748,Valid Accuracy:0.934343576 ================================================================================17:38:06 Epoch=1000,Loss:0.10841465,Accuracy:0.958805501,Valid Loss:0.159325734,Valid Accuracy:0.934785843 # Visualizing the results fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3-3 High-level API: Demonstration"},{"location":"english/Chapter3/Chapter3-3/#3-3-high-level-api-demonstration","text":"The examples below use high-level APIs in TensorFlow to implement a linear regression model and a DNN binary classification model. Typically, the high-level APIs are providing the class interfaces for tf.keras.models . There are three ways of modeling using APIs of Keras: sequential modeling using Sequential function, arbitrary modeling using API functions, and customized modeling by inheriting base class Model . Here we are demonstrating using Sequential function and customized modeling by inheriting base class Model , respectively. import tensorflow as tf # Time stamp @tf . function def printbar (): today_ts = tf . timestamp () % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 + timestring )","title":"3-3 High-level API: Demonstration"},{"location":"english/Chapter3/Chapter3-3/#1-linear-regression-model","text":"In this example, we used Sequential function to construct the model sequentially and use the pre-defined method model.fit for training (for the beginners). (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics , optimizers # Number of sample n = 400 # Generating the datasets X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 3.0 ]]) b0 = tf . constant ([[ 3.0 ]]) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise # Data Visualization % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" ) plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" ) plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () (b) Model Definition tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 1 , input_shape = ( 2 ,))) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 \u00a9 Model Training ### Training using method fit model . compile ( optimizer = \"adam\" , loss = \"mse\" , metrics = [ \"mae\" ]) model . fit ( X , Y , batch_size = 10 , epochs = 200 ) tf . print ( \"w = \" , model . layers [ 0 ] . kernel ) tf . print ( \"b = \" , model . layers [ 0 ] . bias ) Epoch 197/200 400/400 [==============================] - 0s 190us/sample - loss: 4.3977 - mae: 1.7129 Epoch 198/200 400/400 [==============================] - 0s 172us/sample - loss: 4.3918 - mae: 1.7117 Epoch 199/200 400/400 [==============================] - 0s 134us/sample - loss: 4.3861 - mae: 1.7106 Epoch 200/200 400/400 [==============================] - 0s 166us/sample - loss: 4.3786 - mae: 1.7092 w = [[1.99339032] [-3.00866461]] b = [2.67018795] # Visualizing the results % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . variables plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"1. Linear Regression Model"},{"location":"english/Chapter3/Chapter3-3/#2-dnn-binary-classification-model","text":"This example demonstrates the customized model using the child class inherited from the base class Model , and use a customized loop for training (for the experts). (a) Data Preparation import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , losses , metrics , optimizers % matplotlib inline % config InlineBackend . figure_format = 'svg' # Number of the positive/negative samples n_positive , n_negative = 2000 , 2000 # Generating the positive samples with a distribution on a smaller ring r_p = 5.0 + tf . random . truncated_normal ([ n_positive , 1 ], 0.0 , 1.0 ) theta_p = tf . random . uniform ([ n_positive , 1 ], 0.0 , 2 * np . pi ) Xp = tf . concat ([ r_p * tf . cos ( theta_p ), r_p * tf . sin ( theta_p )], axis = 1 ) Yp = tf . ones_like ( r_p ) # Generating the negative samples with a distribution on a larger ring r_n = 8.0 + tf . random . truncated_normal ([ n_negative , 1 ], 0.0 , 1.0 ) theta_n = tf . random . uniform ([ n_negative , 1 ], 0.0 , 2 * np . pi ) Xn = tf . concat ([ r_n * tf . cos ( theta_n ), r_n * tf . sin ( theta_n )], axis = 1 ) Yn = tf . zeros_like ( r_n ) # Assembling all samples X = tf . concat ([ Xp , Xn ], axis = 0 ) Y = tf . concat ([ Yp , Yn ], axis = 0 ) # Shuffling the samples data = tf . concat ([ X , Y ], axis = 1 ) data = tf . random . shuffle ( data ) X = data [:,: 2 ] Y = data [:, 2 :] # Visualizing the data plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds_train = tf . data . Dataset . from_tensor_slices (( X [ 0 : n * 3 // 4 ,:], Y [ 0 : n * 3 // 4 ,:])) \\ . shuffle ( buffer_size = 1000 ) . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () ds_valid = tf . data . Dataset . from_tensor_slices (( X [ n * 3 // 4 :,:], Y [ n * 3 // 4 :,:])) \\ . batch ( 20 ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) \\ . cache () (b) Model Definition tf . keras . backend . clear_session () class DNNModel ( models . Model ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () def build ( self , input_shape ): self . dense1 = layers . Dense ( 4 , activation = \"relu\" , name = \"dense1\" ) self . dense2 = layers . Dense ( 8 , activation = \"relu\" , name = \"dense2\" ) self . dense3 = layers . Dense ( 1 , activation = \"sigmoid\" , name = \"dense3\" ) super ( DNNModel , self ) . build ( input_shape ) # Forward propagation @tf . function ( input_signature = [ tf . TensorSpec ( shape = [ None , 2 ], dtype = tf . float32 )]) def call ( self , x ): x = self . dense1 ( x ) x = self . dense2 ( x ) y = self . dense3 ( x ) return y model = DNNModel () model . build ( input_shape = ( None , 2 )) model . summary () Model: \"dnn_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense1 (Dense) multiple 12 _________________________________________________________________ dense2 (Dense) multiple 40 _________________________________________________________________ dense3 (Dense) multiple 9 ================================================================= Total params: 61 Trainable params: 61 Non-trainable params: 0 _________________________________________________________________ \u00a9 Model Training ### Customizing the training loop optimizer = optimizers . Adam ( learning_rate = 0.01 ) loss_func = tf . keras . losses . BinaryCrossentropy () train_loss = tf . keras . metrics . Mean ( name = 'train_loss' ) train_metric = tf . keras . metrics . BinaryAccuracy ( name = 'train_accuracy' ) valid_loss = tf . keras . metrics . Mean ( name = 'valid_loss' ) valid_metric = tf . keras . metrics . BinaryAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features ) loss = loss_func ( labels , predictions ) grads = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 100 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_valid , 1000 ) ================================================================================17:35:02 Epoch=100,Loss:0.194088802,Accuracy:0.923064,Valid Loss:0.215538561,Valid Accuracy:0.904368 ================================================================================17:35:22 Epoch=200,Loss:0.151239693,Accuracy:0.93768847,Valid Loss:0.181166962,Valid Accuracy:0.920664132 ================================================================================17:35:43 Epoch=300,Loss:0.134556711,Accuracy:0.944247484,Valid Loss:0.171530813,Valid Accuracy:0.926396072 ================================================================================17:36:04 Epoch=400,Loss:0.125722557,Accuracy:0.949172914,Valid Loss:0.16731061,Valid Accuracy:0.929318547 ================================================================================17:36:24 Epoch=500,Loss:0.120216407,Accuracy:0.952525079,Valid Loss:0.164817035,Valid Accuracy:0.931044817 ================================================================================17:36:44 Epoch=600,Loss:0.116434008,Accuracy:0.954830289,Valid Loss:0.163089141,Valid Accuracy:0.932202339 ================================================================================17:37:05 Epoch=700,Loss:0.113658346,Accuracy:0.956433,Valid Loss:0.161804497,Valid Accuracy:0.933092058 ================================================================================17:37:25 Epoch=800,Loss:0.111522928,Accuracy:0.957467675,Valid Loss:0.160796657,Valid Accuracy:0.93379426 ================================================================================17:37:46 Epoch=900,Loss:0.109816991,Accuracy:0.958205402,Valid Loss:0.159987748,Valid Accuracy:0.934343576 ================================================================================17:38:06 Epoch=1000,Loss:0.10841465,Accuracy:0.958805501,Valid Loss:0.159325734,Valid Accuracy:0.934785843 # Visualizing the results fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) ax1 . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) >= 0.5 ), axis = 0 ) Xn_pred = tf . boolean_mask ( X , tf . squeeze ( model ( X ) < 0.5 ), axis = 0 ) ax2 . scatter ( Xp_pred [:, 0 ] . numpy (), Xp_pred [:, 1 ] . numpy (), c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ] . numpy (), Xn_pred [:, 1 ] . numpy (), c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. DNN Binary Classification Model"},{"location":"english/Chapter4/","text":"Chapter 4: Low-level API in TensorFlow # Low-level API of TensorFlow includes tensor operation, graph, automatic differentiate, etc. If we compare a model to a house, then these low-level APIs are the bricks. We may use TensorFlow as the enhanced numpy through these low-level APIs. TensorFlow provides a more complete set of methods comparing to numpy. These methods have higher executiing efficiency and could be further accelerated by GPU if necessary. We gave an intuitive introduction to the low-level API in the previous sections, and we will emphasize the introduction on the tensor operation and Autograph. Tensor operation can be devided into two sub-categories: the structural operation and the mathematical operation. The structural operation includes tensor creation, indexing and slicing, dimension transformation, combining & splitting, etc. The mathematical operation includes scalar operation, vector operation, and matrix operation. We will also introduce the broadcasting mechanism of tensor operation. For the part of Autograph, we will cover its suggested rules, its mechanisms Autograph and tf.Module . Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegant Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 4: Low-level API in TensorFlow"},{"location":"english/Chapter4/#chapter-4-low-level-api-in-tensorflow","text":"Low-level API of TensorFlow includes tensor operation, graph, automatic differentiate, etc. If we compare a model to a house, then these low-level APIs are the bricks. We may use TensorFlow as the enhanced numpy through these low-level APIs. TensorFlow provides a more complete set of methods comparing to numpy. These methods have higher executiing efficiency and could be further accelerated by GPU if necessary. We gave an intuitive introduction to the low-level API in the previous sections, and we will emphasize the introduction on the tensor operation and Autograph. Tensor operation can be devided into two sub-categories: the structural operation and the mathematical operation. The structural operation includes tensor creation, indexing and slicing, dimension transformation, combining & splitting, etc. The mathematical operation includes scalar operation, vector operation, and matrix operation. We will also introduce the broadcasting mechanism of tensor operation. For the part of Autograph, we will cover its suggested rules, its mechanisms Autograph and tf.Module . Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegant Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to reply \u52a0\u7fa4(join group) in the WeChat official account to join the group chat with the other readers.","title":"Chapter 4: Low-level API in TensorFlow"},{"location":"english/Chapter4/Chapter4-1/","text":"4-1 Structural Operations of the Tensor # Tensor operation includes structural operation and mathematical operation. The structural operation includes tensor creation, index slicing, dimension transform, combining & splitting, etc. The mathematical operation includes scalar operation, vector operation, and matrix operation. We will also introduce the broadcasting mechanism of tensor operation. This section is about the structural operation of tensor. 1. Creating Tensor # Tensor creation is similar to array creation in numpy. import tensorflow as tf import numpy as np a = tf . constant ([ 1 , 2 , 3 ], dtype = tf . float32 ) tf . print ( a ) [1 2 3] b = tf . range ( 1 , 10 , delta = 2 ) tf . print ( b ) [1 3 5 7 9] c = tf . linspace ( 0.0 , 2 * 3.14 , 100 ) tf . print ( c ) [0 0.0634343475 0.126868695 ... 6.15313148 6.21656609 6.28] d = tf . zeros ([ 3 , 3 ]) tf . print ( d ) [[0 0 0] [0 0 0] [0 0 0]] a = tf . ones ([ 3 , 3 ]) b = tf . zeros_like ( a , dtype = tf . float32 ) tf . print ( a ) tf . print ( b ) [[1 1 1] [1 1 1] [1 1 1]] [[0 0 0] [0 0 0] [0 0 0]] b = tf . fill ([ 3 , 2 ], 5 ) tf . print ( b ) [[5 5] [5 5] [5 5]] # Random numbers with uniform distribution tf . random . set_seed ( 1.0 ) a = tf . random . uniform ([ 5 ], minval = 0 , maxval = 10 ) tf . print ( a ) [1.65130854 9.01481247 6.30974197 4.34546089 2.9193902] # Random numbers with normal distribution b = tf . random . normal ([ 3 , 3 ], mean = 0.0 , stddev = 1.0 ) tf . print ( b ) [[0.403087884 -1.0880208 -0.0630953535] [1.33655667 0.711760104 -0.489286453] [-0.764221311 -1.03724861 -1.25193381]] # Random numbers with normal distribution and truncate within the range 2X standard deviation c = tf . random . truncated_normal (( 5 , 5 ), mean = 0.0 , stddev = 1.0 , dtype = tf . float32 ) tf . print ( c ) [[-0.457012236 -0.406867266 0.728577733 -0.892977774 -0.369404584] [0.323488563 1.19383323 0.888299048 1.25985599 -1.95951891] [-0.202244401 0.294496894 -0.468728036 1.29494202 1.48142183] [0.0810953453 1.63843894 0.556645 0.977199793 -1.17777884] [1.67368948 0.0647980496 -0.705142677 -0.281972528 0.126546144]] # Special matrix I = tf . eye ( 3 , 3 ) # Identity matrix tf . print ( I ) tf . print ( \" \" ) t = tf . linalg . diag ([ 1 , 2 , 3 ]) # Diagonal matrix tf . print ( t ) [[1 0 0] [0 1 0] [0 0 1]] [[1 0 0] [0 2 0] [0 0 3]] 2. Indexing and Slicing # The indexing and slicing of tensor is the same as numpy, and slicing supports default parameters and ellipsis. Data type of tf.Variable supports indexing and slicing to modify values of certain elements. For referencing a continuous portion of a tensor, tf.slice is recommended. On the other hand, for the irregular slicing shape, tf.gather , tf.gather_nd , tf.boolean_mask are recommended. The method tf.boolean_mask is powerful, it functions as both tf.gather and tf.gather_nd , and supports boolean indexing. For the purpose of creating a new tensor through modifying certain elements in an existing tensor, tf.where and tf.scatter_nd can be used. tf . random . set_seed ( 3 ) t = tf . random . uniform ([ 5 , 5 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( t ) [[4 7 4 2 9] [9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2] [3 7 0 0 3]] # Row 0 tf . print ( t [ 0 ]) [4 7 4 2 9] # Last row tf . print ( t [ - 1 ]) [3 7 0 0 3] # Row 1 Column 3 tf . print ( t [ 1 , 3 ]) tf . print ( t [ 1 ][ 3 ]) 4 4 # From row 1 to row 3 tf . print ( t [ 1 : 4 ,:]) tf . print ( tf . slice ( t ,[ 1 , 0 ],[ 3 , 5 ])) #tf.slice(input,begin_vector,size_vector) [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] # From row 1 to the last row, and from column 0 to the last but one with an increment of 2 tf . print ( t [ 1 : 4 ,: 4 : 2 ]) [[9 2] [7 7] [9 9]] # Variable supports modifying elements through indexing and slicing x = tf . Variable ([[ 1 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) x [ 1 ,:] . assign ( tf . constant ([ 0.0 , 0.0 ])) tf . print ( x ) [[1 2] [0 0]] a = tf . random . uniform ([ 3 , 3 , 3 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( a ) [[[7 3 9] [9 0 7] [9 6 7]] [[1 3 3] [0 8 1] [3 1 0]] [[4 0 6] [6 2 2] [7 9 5]]] # Ellipsis represents multiple colons tf . print ( a [ ... , 1 ]) # This is equal to tf . print ( a [:,:, 1 ]) [[3 0 6] [3 8 1] [0 2 9]] [[3 0 6] [3 8 1] [0 2 9]] The examples above are regular slicing; for irregular slicing, tf.gather , tf.gather_nd , tf.boolean_mask can be used. Here is an example of student's grade records. There are 4 classes, 10 students in each class, and 7 courses for each student, which could be represented as a tensor with a dimension of 4\u00d710\u00d77. scores = tf . random . uniform (( 4 , 10 , 7 ), minval = 0 , maxval = 100 , dtype = tf . int32 ) tf . print ( scores ) [[[52 82 66 ... 17 86 14] [8 36 94 ... 13 78 41] [77 53 51 ... 22 91 56] ... [11 19 26 ... 89 86 68] [60 72 0 ... 11 26 15] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [83 36 31 ... 75 38 85] [54 26 67 ... 60 68 98] ... [20 5 18 ... 32 45 3] [72 52 81 ... 88 41 20] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [78 71 54 ... 43 98 81] [21 66 53 ... 97 75 77] ... [6 74 3 ... 53 65 43] [98 36 72 ... 33 36 81] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [35 8 82 ... 11 59 97] [44 6 99 ... 81 60 27] ... [76 26 35 ... 51 8 17] [33 52 53 ... 78 37 31] [71 27 44 ... 0 52 16]]] # Extract all the grades of the 0th, 5th and 9th students in each class. p = tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] # Extract the grades of the 1st, 3rd and 6th courses of the 0th, 5th and 9th students in each class. q = tf . gather ( tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ),[ 1 , 3 , 6 ], axis = 2 ) tf . print ( q ) [[[82 55 14] [80 46 96] [99 58 74]] [[73 48 81] [10 38 92] [21 86 90]] [[80 57 60] [12 34 25] [78 71 21]] [[57 75 3] [41 47 13] [27 96 16]]] # Extract all the grades of the 0th student in the 0th class, the 4th student in the 2nd class, and the 6th student in the 3rd class. # Then length of the parameter indices equals to the number of samples, and the each element of indices is the coordinate of each sample. s = tf . gather_nd ( scores , indices = [( 0 , 0 ),( 2 , 4 ),( 3 , 6 )]) s <tf.Tensor: shape=(3, 7), dtype=int32, numpy= array([[52, 82, 66, 55, 17, 86, 14], [99, 94, 46, 70, 1, 63, 41], [46, 83, 70, 80, 90, 85, 17]], dtype=int32)> The function of tf.gather and tf.gather_nd as shown above could be achieved through tf.boolean_mask . # Extract all the grades of the 0th, 5th and 9th students in each class. p = tf . boolean_mask ( scores ,[ True , False , False , False , False , True , False , False , False , True ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] # Extract all the grades of the 0th student in the 0th class, the 4th student in the 2nd class, and the 6th student in the 3rd class. s = tf . boolean_mask ( scores , [[ True , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , True , False , False , False , False , False ], [ False , False , False , False , False , False , True , False , False , False ]]) tf . print ( s ) [[52 82 66 ... 17 86 14] [99 94 46 ... 1 63 41] [46 83 70 ... 90 85 17]] # Boolean indexing using tf.boolean_mask # Find all elements that are less than 0 in the matrix c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) tf . print ( c , \" \\n \" ) tf . print ( tf . boolean_mask ( c , c < 0 ), \" \\n \" ) tf . print ( c [ c < 0 ]) # This is the syntactic sugar of boolean_mask for boolean indexing. [[-1 1 -1] [2 2 -2] [3 -3 3]] [-1 -1 -2 -3] [-1 -1 -2 -3] The methods shown above are able to extract part of the elements in the tensor, but are not able to create new tensors through modification of these elements. The method tf.where and tf.scatter_nd should be used for this purpose. tf.where is the tensor version of if ; on the other hand, this method is able to find the coordinate of all the elements that statisfy certain conditions. tf.scatter_nd works in an opposite way to the method tf.gather_nd . The latter collects the elements according to the given coordinate, while the former inserts values on the given positions in an all-zero tensor with a known shape. # Find elements that are less than 0, create a new tensor by replacing these elements with np.nan. # tf.where is similar to np.where, which is the \"if\" for the tensors c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) d = tf . where ( c < 0 , tf . fill ( c . shape , np . nan ), c ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[nan, 1., nan], [ 2., 2., nan], [ 3., nan, 3.]], dtype=float32)> # The method where returns all the coordinates that satisfy the condition if there is only one argument indices = tf . where ( c < 0 ) indices <tf.Tensor: shape=(4, 2), dtype=int64, numpy= array([[0, 0], [0, 2], [1, 2], [2, 1]])> # Create a new tensor by replacing the value of two tensor elements located at [0,0] [2,1] as 0. d = c - tf . scatter_nd ([[ 0 , 0 ],[ 2 , 1 ]],[ c [ 0 , 0 ], c [ 2 , 1 ]], c . shape ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[ 0., 1., -1.], [ 2., 2., -2.], [ 3., 0., 3.]], dtype=float32)> # The method scatter_nd functions inversly to gather_nd # This method can be used to insert values on the given positions in an all-zero tensor with a known shape. indices = tf . where ( c < 0 ) tf . scatter_nd ( indices , tf . gather_nd ( c , indices ), c . shape ) <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[-1., 0., -1.], [ 0., 0., -2.], [ 0., -3., 0.]], dtype=float32)> 3. Dimension Transform # The functions that are related to dimension transform include tf.reshape , tf.squeeze , tf.expand_dims , tf.transpose . tf.reshape is used to alter the shape of the tensor. tf.squeeze is used to reduce the number of dimensions. tf.expand_dims is used to increase the number of dimensions. tf.transpose is used to exchange the order of the dimensions. tf.reshape changes the shape of the tensor, but will not change the order of elements stored in the memory, thus this operation is extremely fast and reversible. a = tf . random . uniform ( shape = [ 1 , 3 , 3 , 2 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) tf . print ( a ) TensorShape([1, 3, 3, 2]) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] # Reshape into (3,6) b = tf . reshape ( a ,[ 3 , 6 ]) tf . print ( b . shape ) tf . print ( b ) TensorShape([3, 6]) [[135 178 26 116 29 224] [179 219 153 209 111 215] [39 7 138 129 59 205]] # Reshape back to (1,3,3,2) c = tf . reshape ( b ,[ 1 , 3 , 3 , 2 ]) tf . print ( c ) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] When there is only one element on a certain dimension, tf.squeeze eliminates this dimension. It won't change the order of the stored elements in the memory, which is similar to tf.reshape . The elements in a tensor is stored linearly, usually the adjacent elements in the same dimension use adjacent physical addresses. s = tf . squeeze ( a ) tf . print ( s . shape ) tf . print ( s ) TensorShape([3, 3, 2]) [[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]] d = tf . expand_dims ( s , axis = 0 ) # Insert an extra dimension to the 0th dim with length = 1 d <tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy= array([[[[135, 178], [ 26, 116], [ 29, 224]], [[179, 219], [153, 209], [111, 215]], [[ 39, 7], [138, 129], [ 59, 205]]]], dtype=int32)> tf.transpose swaps the dimensions in the tensor; unlike tf.shape , it will change the order of the elements in the memory. tf.transpose is usually used for converting image format of storage. # Batch,Height,Width,Channel a = tf . random . uniform ( shape = [ 100 , 600 , 600 , 4 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) # Transform to the order as Channel,Height,Width,Batch s = tf . transpose ( a , perm = [ 3 , 1 , 2 , 0 ]) tf . print ( s . shape ) TensorShape([100, 600, 600, 4]) TensorShape([4, 600, 600, 100]) 4. Combining and Splitting # We can use tf.concat and tf.stack methods to combine multiple tensors, and use tf.split to split a tensor into multiple ones, which are similar as those in numpy. tf.concat is slightly different to tf.stack : tf.concat is concatination and does not increase the number of dimensions, while tf.stack is stacking and increases the number of dimensions. a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) tf . concat ([ a , b , c ], axis = 0 ) <tf.Tensor: shape=(6, 2), dtype=float32, numpy= array([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]], dtype=float32)> tf . concat ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 6), dtype=float32, numpy= array([[ 1., 2., 5., 6., 9., 10.], [ 3., 4., 7., 8., 11., 12.]], dtype=float32)> tf . stack ([ a , b , c ]) <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 3., 4.]], [[ 5., 6.], [ 7., 8.]], [[ 9., 10.], [11., 12.]]], dtype=float32)> tf . stack ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 5., 6.], [ 9., 10.]], [[ 3., 4.], [ 7., 8.], [11., 12.]]], dtype=float32)> a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) c = tf . concat ([ a , b , c ], axis = 0 ) tf.split is the inverse of tf.concat . It allows even splitting with given number of portions, or uneven splitting with given size of each portion. #tf.split(value,num_or_size_splits,axis) tf . split ( c , 3 , axis = 0 ) # Even splitting with given number of portions [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] tf . split ( c ,[ 2 , 2 , 2 ], axis = 0 ) # Splitting with given size of each portion. [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4-1 Structural Operations of the Tensor"},{"location":"english/Chapter4/Chapter4-1/#4-1-structural-operations-of-the-tensor","text":"Tensor operation includes structural operation and mathematical operation. The structural operation includes tensor creation, index slicing, dimension transform, combining & splitting, etc. The mathematical operation includes scalar operation, vector operation, and matrix operation. We will also introduce the broadcasting mechanism of tensor operation. This section is about the structural operation of tensor.","title":"4-1 Structural Operations of the Tensor"},{"location":"english/Chapter4/Chapter4-1/#1-creating-tensor","text":"Tensor creation is similar to array creation in numpy. import tensorflow as tf import numpy as np a = tf . constant ([ 1 , 2 , 3 ], dtype = tf . float32 ) tf . print ( a ) [1 2 3] b = tf . range ( 1 , 10 , delta = 2 ) tf . print ( b ) [1 3 5 7 9] c = tf . linspace ( 0.0 , 2 * 3.14 , 100 ) tf . print ( c ) [0 0.0634343475 0.126868695 ... 6.15313148 6.21656609 6.28] d = tf . zeros ([ 3 , 3 ]) tf . print ( d ) [[0 0 0] [0 0 0] [0 0 0]] a = tf . ones ([ 3 , 3 ]) b = tf . zeros_like ( a , dtype = tf . float32 ) tf . print ( a ) tf . print ( b ) [[1 1 1] [1 1 1] [1 1 1]] [[0 0 0] [0 0 0] [0 0 0]] b = tf . fill ([ 3 , 2 ], 5 ) tf . print ( b ) [[5 5] [5 5] [5 5]] # Random numbers with uniform distribution tf . random . set_seed ( 1.0 ) a = tf . random . uniform ([ 5 ], minval = 0 , maxval = 10 ) tf . print ( a ) [1.65130854 9.01481247 6.30974197 4.34546089 2.9193902] # Random numbers with normal distribution b = tf . random . normal ([ 3 , 3 ], mean = 0.0 , stddev = 1.0 ) tf . print ( b ) [[0.403087884 -1.0880208 -0.0630953535] [1.33655667 0.711760104 -0.489286453] [-0.764221311 -1.03724861 -1.25193381]] # Random numbers with normal distribution and truncate within the range 2X standard deviation c = tf . random . truncated_normal (( 5 , 5 ), mean = 0.0 , stddev = 1.0 , dtype = tf . float32 ) tf . print ( c ) [[-0.457012236 -0.406867266 0.728577733 -0.892977774 -0.369404584] [0.323488563 1.19383323 0.888299048 1.25985599 -1.95951891] [-0.202244401 0.294496894 -0.468728036 1.29494202 1.48142183] [0.0810953453 1.63843894 0.556645 0.977199793 -1.17777884] [1.67368948 0.0647980496 -0.705142677 -0.281972528 0.126546144]] # Special matrix I = tf . eye ( 3 , 3 ) # Identity matrix tf . print ( I ) tf . print ( \" \" ) t = tf . linalg . diag ([ 1 , 2 , 3 ]) # Diagonal matrix tf . print ( t ) [[1 0 0] [0 1 0] [0 0 1]] [[1 0 0] [0 2 0] [0 0 3]]","title":"1. Creating Tensor"},{"location":"english/Chapter4/Chapter4-1/#2-indexing-and-slicing","text":"The indexing and slicing of tensor is the same as numpy, and slicing supports default parameters and ellipsis. Data type of tf.Variable supports indexing and slicing to modify values of certain elements. For referencing a continuous portion of a tensor, tf.slice is recommended. On the other hand, for the irregular slicing shape, tf.gather , tf.gather_nd , tf.boolean_mask are recommended. The method tf.boolean_mask is powerful, it functions as both tf.gather and tf.gather_nd , and supports boolean indexing. For the purpose of creating a new tensor through modifying certain elements in an existing tensor, tf.where and tf.scatter_nd can be used. tf . random . set_seed ( 3 ) t = tf . random . uniform ([ 5 , 5 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( t ) [[4 7 4 2 9] [9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2] [3 7 0 0 3]] # Row 0 tf . print ( t [ 0 ]) [4 7 4 2 9] # Last row tf . print ( t [ - 1 ]) [3 7 0 0 3] # Row 1 Column 3 tf . print ( t [ 1 , 3 ]) tf . print ( t [ 1 ][ 3 ]) 4 4 # From row 1 to row 3 tf . print ( t [ 1 : 4 ,:]) tf . print ( tf . slice ( t ,[ 1 , 0 ],[ 3 , 5 ])) #tf.slice(input,begin_vector,size_vector) [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] [[9 1 2 4 7] [7 2 7 4 0] [9 6 9 7 2]] # From row 1 to the last row, and from column 0 to the last but one with an increment of 2 tf . print ( t [ 1 : 4 ,: 4 : 2 ]) [[9 2] [7 7] [9 9]] # Variable supports modifying elements through indexing and slicing x = tf . Variable ([[ 1 , 2 ],[ 3 , 4 ]], dtype = tf . float32 ) x [ 1 ,:] . assign ( tf . constant ([ 0.0 , 0.0 ])) tf . print ( x ) [[1 2] [0 0]] a = tf . random . uniform ([ 3 , 3 , 3 ], minval = 0 , maxval = 10 , dtype = tf . int32 ) tf . print ( a ) [[[7 3 9] [9 0 7] [9 6 7]] [[1 3 3] [0 8 1] [3 1 0]] [[4 0 6] [6 2 2] [7 9 5]]] # Ellipsis represents multiple colons tf . print ( a [ ... , 1 ]) # This is equal to tf . print ( a [:,:, 1 ]) [[3 0 6] [3 8 1] [0 2 9]] [[3 0 6] [3 8 1] [0 2 9]] The examples above are regular slicing; for irregular slicing, tf.gather , tf.gather_nd , tf.boolean_mask can be used. Here is an example of student's grade records. There are 4 classes, 10 students in each class, and 7 courses for each student, which could be represented as a tensor with a dimension of 4\u00d710\u00d77. scores = tf . random . uniform (( 4 , 10 , 7 ), minval = 0 , maxval = 100 , dtype = tf . int32 ) tf . print ( scores ) [[[52 82 66 ... 17 86 14] [8 36 94 ... 13 78 41] [77 53 51 ... 22 91 56] ... [11 19 26 ... 89 86 68] [60 72 0 ... 11 26 15] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [83 36 31 ... 75 38 85] [54 26 67 ... 60 68 98] ... [20 5 18 ... 32 45 3] [72 52 81 ... 88 41 20] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [78 71 54 ... 43 98 81] [21 66 53 ... 97 75 77] ... [6 74 3 ... 53 65 43] [98 36 72 ... 33 36 81] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [35 8 82 ... 11 59 97] [44 6 99 ... 81 60 27] ... [76 26 35 ... 51 8 17] [33 52 53 ... 78 37 31] [71 27 44 ... 0 52 16]]] # Extract all the grades of the 0th, 5th and 9th students in each class. p = tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] # Extract the grades of the 1st, 3rd and 6th courses of the 0th, 5th and 9th students in each class. q = tf . gather ( tf . gather ( scores ,[ 0 , 5 , 9 ], axis = 1 ),[ 1 , 3 , 6 ], axis = 2 ) tf . print ( q ) [[[82 55 14] [80 46 96] [99 58 74]] [[73 48 81] [10 38 92] [21 86 90]] [[80 57 60] [12 34 25] [78 71 21]] [[57 75 3] [41 47 13] [27 96 16]]] # Extract all the grades of the 0th student in the 0th class, the 4th student in the 2nd class, and the 6th student in the 3rd class. # Then length of the parameter indices equals to the number of samples, and the each element of indices is the coordinate of each sample. s = tf . gather_nd ( scores , indices = [( 0 , 0 ),( 2 , 4 ),( 3 , 6 )]) s <tf.Tensor: shape=(3, 7), dtype=int32, numpy= array([[52, 82, 66, 55, 17, 86, 14], [99, 94, 46, 70, 1, 63, 41], [46, 83, 70, 80, 90, 85, 17]], dtype=int32)> The function of tf.gather and tf.gather_nd as shown above could be achieved through tf.boolean_mask . # Extract all the grades of the 0th, 5th and 9th students in each class. p = tf . boolean_mask ( scores ,[ True , False , False , False , False , True , False , False , False , True ], axis = 1 ) tf . print ( p ) [[[52 82 66 ... 17 86 14] [24 80 70 ... 72 63 96] [24 99 38 ... 97 44 74]] [[79 73 73 ... 35 3 81] [46 10 94 ... 23 18 92] [0 21 89 ... 53 10 90]] [[52 80 22 ... 29 25 60] [19 12 23 ... 87 86 25] [61 78 70 ... 7 59 21]] [[56 57 45 ... 23 15 3] [6 41 79 ... 97 43 13] [71 27 44 ... 0 52 16]]] # Extract all the grades of the 0th student in the 0th class, the 4th student in the 2nd class, and the 6th student in the 3rd class. s = tf . boolean_mask ( scores , [[ True , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , False , False , False , False , False , False ], [ False , False , False , False , True , False , False , False , False , False ], [ False , False , False , False , False , False , True , False , False , False ]]) tf . print ( s ) [[52 82 66 ... 17 86 14] [99 94 46 ... 1 63 41] [46 83 70 ... 90 85 17]] # Boolean indexing using tf.boolean_mask # Find all elements that are less than 0 in the matrix c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) tf . print ( c , \" \\n \" ) tf . print ( tf . boolean_mask ( c , c < 0 ), \" \\n \" ) tf . print ( c [ c < 0 ]) # This is the syntactic sugar of boolean_mask for boolean indexing. [[-1 1 -1] [2 2 -2] [3 -3 3]] [-1 -1 -2 -3] [-1 -1 -2 -3] The methods shown above are able to extract part of the elements in the tensor, but are not able to create new tensors through modification of these elements. The method tf.where and tf.scatter_nd should be used for this purpose. tf.where is the tensor version of if ; on the other hand, this method is able to find the coordinate of all the elements that statisfy certain conditions. tf.scatter_nd works in an opposite way to the method tf.gather_nd . The latter collects the elements according to the given coordinate, while the former inserts values on the given positions in an all-zero tensor with a known shape. # Find elements that are less than 0, create a new tensor by replacing these elements with np.nan. # tf.where is similar to np.where, which is the \"if\" for the tensors c = tf . constant ([[ - 1 , 1 , - 1 ],[ 2 , 2 , - 2 ],[ 3 , - 3 , 3 ]], dtype = tf . float32 ) d = tf . where ( c < 0 , tf . fill ( c . shape , np . nan ), c ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[nan, 1., nan], [ 2., 2., nan], [ 3., nan, 3.]], dtype=float32)> # The method where returns all the coordinates that satisfy the condition if there is only one argument indices = tf . where ( c < 0 ) indices <tf.Tensor: shape=(4, 2), dtype=int64, numpy= array([[0, 0], [0, 2], [1, 2], [2, 1]])> # Create a new tensor by replacing the value of two tensor elements located at [0,0] [2,1] as 0. d = c - tf . scatter_nd ([[ 0 , 0 ],[ 2 , 1 ]],[ c [ 0 , 0 ], c [ 2 , 1 ]], c . shape ) d <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[ 0., 1., -1.], [ 2., 2., -2.], [ 3., 0., 3.]], dtype=float32)> # The method scatter_nd functions inversly to gather_nd # This method can be used to insert values on the given positions in an all-zero tensor with a known shape. indices = tf . where ( c < 0 ) tf . scatter_nd ( indices , tf . gather_nd ( c , indices ), c . shape ) <tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[-1., 0., -1.], [ 0., 0., -2.], [ 0., -3., 0.]], dtype=float32)>","title":"2. Indexing and Slicing"},{"location":"english/Chapter4/Chapter4-1/#3-dimension-transform","text":"The functions that are related to dimension transform include tf.reshape , tf.squeeze , tf.expand_dims , tf.transpose . tf.reshape is used to alter the shape of the tensor. tf.squeeze is used to reduce the number of dimensions. tf.expand_dims is used to increase the number of dimensions. tf.transpose is used to exchange the order of the dimensions. tf.reshape changes the shape of the tensor, but will not change the order of elements stored in the memory, thus this operation is extremely fast and reversible. a = tf . random . uniform ( shape = [ 1 , 3 , 3 , 2 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) tf . print ( a ) TensorShape([1, 3, 3, 2]) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] # Reshape into (3,6) b = tf . reshape ( a ,[ 3 , 6 ]) tf . print ( b . shape ) tf . print ( b ) TensorShape([3, 6]) [[135 178 26 116 29 224] [179 219 153 209 111 215] [39 7 138 129 59 205]] # Reshape back to (1,3,3,2) c = tf . reshape ( b ,[ 1 , 3 , 3 , 2 ]) tf . print ( c ) [[[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]]] When there is only one element on a certain dimension, tf.squeeze eliminates this dimension. It won't change the order of the stored elements in the memory, which is similar to tf.reshape . The elements in a tensor is stored linearly, usually the adjacent elements in the same dimension use adjacent physical addresses. s = tf . squeeze ( a ) tf . print ( s . shape ) tf . print ( s ) TensorShape([3, 3, 2]) [[[135 178] [26 116] [29 224]] [[179 219] [153 209] [111 215]] [[39 7] [138 129] [59 205]]] d = tf . expand_dims ( s , axis = 0 ) # Insert an extra dimension to the 0th dim with length = 1 d <tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy= array([[[[135, 178], [ 26, 116], [ 29, 224]], [[179, 219], [153, 209], [111, 215]], [[ 39, 7], [138, 129], [ 59, 205]]]], dtype=int32)> tf.transpose swaps the dimensions in the tensor; unlike tf.shape , it will change the order of the elements in the memory. tf.transpose is usually used for converting image format of storage. # Batch,Height,Width,Channel a = tf . random . uniform ( shape = [ 100 , 600 , 600 , 4 ], minval = 0 , maxval = 255 , dtype = tf . int32 ) tf . print ( a . shape ) # Transform to the order as Channel,Height,Width,Batch s = tf . transpose ( a , perm = [ 3 , 1 , 2 , 0 ]) tf . print ( s . shape ) TensorShape([100, 600, 600, 4]) TensorShape([4, 600, 600, 100])","title":"3. Dimension Transform"},{"location":"english/Chapter4/Chapter4-1/#4-combining-and-splitting","text":"We can use tf.concat and tf.stack methods to combine multiple tensors, and use tf.split to split a tensor into multiple ones, which are similar as those in numpy. tf.concat is slightly different to tf.stack : tf.concat is concatination and does not increase the number of dimensions, while tf.stack is stacking and increases the number of dimensions. a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) tf . concat ([ a , b , c ], axis = 0 ) <tf.Tensor: shape=(6, 2), dtype=float32, numpy= array([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]], dtype=float32)> tf . concat ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 6), dtype=float32, numpy= array([[ 1., 2., 5., 6., 9., 10.], [ 3., 4., 7., 8., 11., 12.]], dtype=float32)> tf . stack ([ a , b , c ]) <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 3., 4.]], [[ 5., 6.], [ 7., 8.]], [[ 9., 10.], [11., 12.]]], dtype=float32)> tf . stack ([ a , b , c ], axis = 1 ) <tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy= array([[[ 1., 2.], [ 5., 6.], [ 9., 10.]], [[ 3., 4.], [ 7., 8.], [11., 12.]]], dtype=float32)> a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = tf . constant ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) c = tf . concat ([ a , b , c ], axis = 0 ) tf.split is the inverse of tf.concat . It allows even splitting with given number of portions, or uneven splitting with given size of each portion. #tf.split(value,num_or_size_splits,axis) tf . split ( c , 3 , axis = 0 ) # Even splitting with given number of portions [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] tf . split ( c ,[ 2 , 2 , 2 ], axis = 0 ) # Splitting with given size of each portion. [<tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[5., 6.], [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 9., 10.], [11., 12.]], dtype=float32)>] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4. Combining and Splitting"},{"location":"english/Chapter4/Chapter4-2/","text":"4-2 Mathematical Operations of the Tensor # Tensor operation includes structural operation and mathematical operation. The structural operation includes tensor creation, index slicing, dimension transform, combining & splitting, etc. The mathematical operation includes scalar operation, vector operation, and matrix operation. We will also introduce the broadcasting mechanism of tensor operation. This section is about the mathematical operation of tensor. 1. Scalar Operation # The mathematical operation includes scalar operation, vector operation, and matrix operation. The scalar operation includes add, subtract, multiply, divide, power, and trigonometric functions, exponential functions, log functions, and logical comparison, etc. The scalar operation is an element-by-element operation. Some of the scalar operators are overloaded from the normal mathematical operators and support broadcasting similar as numpy. Most scalar operators are under the module tf.math . import tensorflow as tf import numpy as np a = tf . constant ([[ 1.0 , 2 ],[ - 3 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6 ],[ 7.0 , 8.0 ]]) a + b # Operator overloading <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 6., 8.], [ 4., 12.]], dtype=float32)> a - b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ -4., -4.], [-10., -4.]], dtype=float32)> a * b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 5., 12.], [-21., 32.]], dtype=float32)> a / b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0.2 , 0.33333334], [-0.42857143, 0.5 ]], dtype=float32)> a ** 2 <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 1., 4.], [ 9., 16.]], dtype=float32)> a ** ( 0.5 ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a % 3 # Reloading of mod operator, identical to: m = tf.math.mod(a,3) <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)> a // 3 # Divid and round towards negative infinity <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0., 0.], [-1., 1.]], dtype=float32)> ( a >= 2 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, True]])> ( a >= 2 ) & ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, False]])> ( a >= 2 ) | ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[ True, True], [ True, True]])> a == 5 #tf.equal(a,5) <tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])> tf . sqrt ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a = tf . constant ([ 1.0 , 8.0 ]) b = tf . constant ([ 5.0 , 6.0 ]) c = tf . constant ([ 6.0 , 7.0 ]) tf . add_n ([ a , b , c ]) <tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)> tf . print ( tf . maximum ( a , b )) [5 8] tf . print ( tf . minimum ( a , b )) [1 6] # clip value x = tf . constant ([ 0.9 , - 0.8 , 100.0 , - 20.0 , 0.7 ]) y = tf . clip_by_value ( x , clip_value_min =- 1 , clip_value_max = 1 ) z = tf . clip_by_norm ( x , clip_norm = 3 ) tf . print ( y ) tf . print ( z ) [0.9 -0.8 1 -1 0.7] [0.0264732055 -0.0235317405 2.94146752 -0.588293493 0.0205902718] 2. Vector Operation # Vector operation manipulate along one specific axis. It projects one vector to a scalar or another vector. Many names of vector operator starts with \"reduce\". # Vector \"reduce\" a = tf . range ( 1 , 10 ) tf . print ( tf . reduce_sum ( a )) tf . print ( tf . reduce_mean ( a )) tf . print ( tf . reduce_max ( a )) tf . print ( tf . reduce_min ( a )) tf . print ( tf . reduce_prod ( a )) 45 5 9 1 362880 # \"reduce\" along the specific dimension b = tf . reshape ( a ,( 3 , 3 )) tf . print ( tf . reduce_sum ( b , axis = 1 , keepdims = True )) tf . print ( tf . reduce_sum ( b , axis = 0 , keepdims = True )) [[6] [15] [24]] [[12 15 18]] # \"reduce\" for bool type p = tf . constant ([ True , False , False ]) q = tf . constant ([ False , False , True ]) tf . print ( tf . reduce_all ( p )) tf . print ( tf . reduce_any ( q )) 0 1 # Implement tf.reduce_sum using tf.foldr s = tf . foldr ( lambda a , b : a + b , tf . range ( 10 )) tf . print ( s ) 45 # Cumulative sum a = tf . range ( 1 , 10 ) tf . print ( tf . math . cumsum ( a )) tf . print ( tf . math . cumprod ( a )) [1 3 6 ... 28 36 45] [1 2 6 ... 5040 40320 362880] # Index of max and min values in the arguments a = tf . range ( 1 , 10 ) tf . print ( tf . argmax ( a )) tf . print ( tf . argmin ( a )) 8 0 # Sort the elements in the tensor using tf.math.top_k a = tf . constant ([ 1 , 3 , 7 , 5 , 4 , 8 ]) values , indices = tf . math . top_k ( a , 3 , sorted = True ) tf . print ( values ) tf . print ( indices ) # tf.math.top_k is able to implement KNN algorithm in TensorFlow [8 7 5] [5 2 3] 3. Matrix Operation # Matrix must be two-dimensional. Something such as tf.constant([1,2,3]) is not a matrix. Matrix operation includes matrix multiply, transpose, inverse, trace, norm, determinant, eigenvalue, decomposition, etc. Most of the matrix operations are in the tf.linalg except for some popular operations. # Matrix multiplication a = tf . constant ([[ 1 , 2 ],[ 3 , 4 ]]) b = tf . constant ([[ 2 , 0 ],[ 0 , 2 ]]) a @b # Identical to tf.matmul(a,b) <tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[2, 4], [6, 8]], dtype=int32)> # Matrix transpose a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . transpose ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 3.], [2., 4.]], dtype=float32)> # Matrix inverse, must be in type of tf.float32 or tf.double a = tf . constant ([[ 1.0 , 2 ],[ 3.0 , 4 ]], dtype = tf . float32 ) tf . linalg . inv ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[-2.0000002 , 1.0000001 ], [ 1.5000001 , -0.50000006]], dtype=float32)> # Matrix trace a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . trace ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.0> # Matrix norm a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . norm ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.477226> # Determinant a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . det ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=-2.0> # Eigenvalues a = tf . constant ([[ 1.0 , 2 ],[ 5 , 4 ]]) tf . linalg . eigvals ( a ) <tf.Tensor: shape=(2,), dtype=complex64, numpy=array([-0.99999994+0.j, 5.9999995 +0.j], dtype=complex64)> # QR decomposition a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]], dtype = tf . float32 ) q , r = tf . linalg . qr ( a ) tf . print ( q ) tf . print ( r ) tf . print ( q @r ) [[-0.316227794 -0.948683321] [-0.948683321 0.316227734]] [[-3.1622777 -4.4271884] [0 -0.632455349]] [[1.00000012 1.99999976] [3 4]] # SVD decomposition a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ],[ 5.0 , 6.0 ]], dtype = tf . float32 ) s , u , v = tf . linalg . svd ( a ) tf . print ( u , \" \\n \" ) tf . print ( s , \" \\n \" ) tf . print ( v , \" \\n \" ) tf . print ( u @tf . linalg . diag ( s ) @tf . transpose ( v )) # SVD decomposition is used for dimension reduction in PCA [[0.229847744 -0.88346082] [0.524744868 -0.240782902] [0.819642067 0.401896209]] [9.52551842 0.51429987] [[0.619629562 0.784894466] [0.784894466 -0.619629562]] [[1.00000119 2] [3.00000095 4.00000048] [5.00000143 6.00000095]] 4. Broadcasting Mechanism # The rules of broadcasting in TensorFlow is the same as numpy: If two tensors are different in rank, expand the tensor with lower rank. If two tensors has the same length along certain dimension, or one of the tensors has length 1 along certain dimension, then these two tensors are compatible along this dimension. Two tensors that are compatible along all dimensions are able to broadcast. After broadcasting, the length of each dimension equals to the larger one among two tensors. When a tensor has length = 1 along any dimension while the length of corresponding dimension of the other tensor > 1, in the broadcast result, this only element is jusk like been duplicated along this dimension. tf.broadcast_to expand the dimension of tensor explicitly. a = tf . constant ([ 1 , 2 , 3 ]) b = tf . constant ([[ 0 , 0 , 0 ],[ 1 , 1 , 1 ],[ 2 , 2 , 2 ]]) b + a # Identical to b + tf.broadcast_to(a,b.shape) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [2, 3, 4], [3, 4, 5]], dtype=int32)> tf . broadcast_to ( a , b . shape ) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [1, 2, 3], [1, 2, 3]], dtype=int32)> # Shape after broadcasting using static shape, requires arguments in TensorShape type tf . broadcast_static_shape ( a . shape , b . shape ) TensorShape([3, 3]) # Shape after broadcasting using dynamic shape, requires arguments in Tensor type c = tf . constant ([ 1 , 2 , 3 ]) d = tf . constant ([[ 1 ],[ 2 ],[ 3 ]]) tf . broadcast_dynamic_shape ( tf . shape ( c ), tf . shape ( d )) <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)> # Results of broadcasting c + d # Identical to tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3]) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[2, 3, 4], [3, 4, 5], [4, 5, 6]], dtype=int32)> Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4-2 Mathematical Operations of the Tensor"},{"location":"english/Chapter4/Chapter4-2/#4-2-mathematical-operations-of-the-tensor","text":"Tensor operation includes structural operation and mathematical operation. The structural operation includes tensor creation, index slicing, dimension transform, combining & splitting, etc. The mathematical operation includes scalar operation, vector operation, and matrix operation. We will also introduce the broadcasting mechanism of tensor operation. This section is about the mathematical operation of tensor.","title":"4-2 Mathematical Operations of the Tensor"},{"location":"english/Chapter4/Chapter4-2/#1-scalar-operation","text":"The mathematical operation includes scalar operation, vector operation, and matrix operation. The scalar operation includes add, subtract, multiply, divide, power, and trigonometric functions, exponential functions, log functions, and logical comparison, etc. The scalar operation is an element-by-element operation. Some of the scalar operators are overloaded from the normal mathematical operators and support broadcasting similar as numpy. Most scalar operators are under the module tf.math . import tensorflow as tf import numpy as np a = tf . constant ([[ 1.0 , 2 ],[ - 3 , 4.0 ]]) b = tf . constant ([[ 5.0 , 6 ],[ 7.0 , 8.0 ]]) a + b # Operator overloading <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 6., 8.], [ 4., 12.]], dtype=float32)> a - b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ -4., -4.], [-10., -4.]], dtype=float32)> a * b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 5., 12.], [-21., 32.]], dtype=float32)> a / b <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0.2 , 0.33333334], [-0.42857143, 0.5 ]], dtype=float32)> a ** 2 <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 1., 4.], [ 9., 16.]], dtype=float32)> a ** ( 0.5 ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a % 3 # Reloading of mod operator, identical to: m = tf.math.mod(a,3) <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)> a // 3 # Divid and round towards negative infinity <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[ 0., 0.], [-1., 1.]], dtype=float32)> ( a >= 2 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, True]])> ( a >= 2 ) & ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[False, True], [False, False]])> ( a >= 2 ) | ( a <= 3 ) <tf.Tensor: shape=(2, 2), dtype=bool, numpy= array([[ True, True], [ True, True]])> a == 5 #tf.equal(a,5) <tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])> tf . sqrt ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 1.4142135], [ nan, 2. ]], dtype=float32)> a = tf . constant ([ 1.0 , 8.0 ]) b = tf . constant ([ 5.0 , 6.0 ]) c = tf . constant ([ 6.0 , 7.0 ]) tf . add_n ([ a , b , c ]) <tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)> tf . print ( tf . maximum ( a , b )) [5 8] tf . print ( tf . minimum ( a , b )) [1 6] # clip value x = tf . constant ([ 0.9 , - 0.8 , 100.0 , - 20.0 , 0.7 ]) y = tf . clip_by_value ( x , clip_value_min =- 1 , clip_value_max = 1 ) z = tf . clip_by_norm ( x , clip_norm = 3 ) tf . print ( y ) tf . print ( z ) [0.9 -0.8 1 -1 0.7] [0.0264732055 -0.0235317405 2.94146752 -0.588293493 0.0205902718]","title":"1. Scalar Operation"},{"location":"english/Chapter4/Chapter4-2/#2-vector-operation","text":"Vector operation manipulate along one specific axis. It projects one vector to a scalar or another vector. Many names of vector operator starts with \"reduce\". # Vector \"reduce\" a = tf . range ( 1 , 10 ) tf . print ( tf . reduce_sum ( a )) tf . print ( tf . reduce_mean ( a )) tf . print ( tf . reduce_max ( a )) tf . print ( tf . reduce_min ( a )) tf . print ( tf . reduce_prod ( a )) 45 5 9 1 362880 # \"reduce\" along the specific dimension b = tf . reshape ( a ,( 3 , 3 )) tf . print ( tf . reduce_sum ( b , axis = 1 , keepdims = True )) tf . print ( tf . reduce_sum ( b , axis = 0 , keepdims = True )) [[6] [15] [24]] [[12 15 18]] # \"reduce\" for bool type p = tf . constant ([ True , False , False ]) q = tf . constant ([ False , False , True ]) tf . print ( tf . reduce_all ( p )) tf . print ( tf . reduce_any ( q )) 0 1 # Implement tf.reduce_sum using tf.foldr s = tf . foldr ( lambda a , b : a + b , tf . range ( 10 )) tf . print ( s ) 45 # Cumulative sum a = tf . range ( 1 , 10 ) tf . print ( tf . math . cumsum ( a )) tf . print ( tf . math . cumprod ( a )) [1 3 6 ... 28 36 45] [1 2 6 ... 5040 40320 362880] # Index of max and min values in the arguments a = tf . range ( 1 , 10 ) tf . print ( tf . argmax ( a )) tf . print ( tf . argmin ( a )) 8 0 # Sort the elements in the tensor using tf.math.top_k a = tf . constant ([ 1 , 3 , 7 , 5 , 4 , 8 ]) values , indices = tf . math . top_k ( a , 3 , sorted = True ) tf . print ( values ) tf . print ( indices ) # tf.math.top_k is able to implement KNN algorithm in TensorFlow [8 7 5] [5 2 3]","title":"2. Vector Operation"},{"location":"english/Chapter4/Chapter4-2/#3-matrix-operation","text":"Matrix must be two-dimensional. Something such as tf.constant([1,2,3]) is not a matrix. Matrix operation includes matrix multiply, transpose, inverse, trace, norm, determinant, eigenvalue, decomposition, etc. Most of the matrix operations are in the tf.linalg except for some popular operations. # Matrix multiplication a = tf . constant ([[ 1 , 2 ],[ 3 , 4 ]]) b = tf . constant ([[ 2 , 0 ],[ 0 , 2 ]]) a @b # Identical to tf.matmul(a,b) <tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[2, 4], [6, 8]], dtype=int32)> # Matrix transpose a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . transpose ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1., 3.], [2., 4.]], dtype=float32)> # Matrix inverse, must be in type of tf.float32 or tf.double a = tf . constant ([[ 1.0 , 2 ],[ 3.0 , 4 ]], dtype = tf . float32 ) tf . linalg . inv ( a ) <tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[-2.0000002 , 1.0000001 ], [ 1.5000001 , -0.50000006]], dtype=float32)> # Matrix trace a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . trace ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.0> # Matrix norm a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . norm ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=5.477226> # Determinant a = tf . constant ([[ 1.0 , 2 ],[ 3 , 4 ]]) tf . linalg . det ( a ) <tf.Tensor: shape=(), dtype=float32, numpy=-2.0> # Eigenvalues a = tf . constant ([[ 1.0 , 2 ],[ 5 , 4 ]]) tf . linalg . eigvals ( a ) <tf.Tensor: shape=(2,), dtype=complex64, numpy=array([-0.99999994+0.j, 5.9999995 +0.j], dtype=complex64)> # QR decomposition a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]], dtype = tf . float32 ) q , r = tf . linalg . qr ( a ) tf . print ( q ) tf . print ( r ) tf . print ( q @r ) [[-0.316227794 -0.948683321] [-0.948683321 0.316227734]] [[-3.1622777 -4.4271884] [0 -0.632455349]] [[1.00000012 1.99999976] [3 4]] # SVD decomposition a = tf . constant ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ],[ 5.0 , 6.0 ]], dtype = tf . float32 ) s , u , v = tf . linalg . svd ( a ) tf . print ( u , \" \\n \" ) tf . print ( s , \" \\n \" ) tf . print ( v , \" \\n \" ) tf . print ( u @tf . linalg . diag ( s ) @tf . transpose ( v )) # SVD decomposition is used for dimension reduction in PCA [[0.229847744 -0.88346082] [0.524744868 -0.240782902] [0.819642067 0.401896209]] [9.52551842 0.51429987] [[0.619629562 0.784894466] [0.784894466 -0.619629562]] [[1.00000119 2] [3.00000095 4.00000048] [5.00000143 6.00000095]]","title":"3. Matrix Operation"},{"location":"english/Chapter4/Chapter4-2/#4-broadcasting-mechanism","text":"The rules of broadcasting in TensorFlow is the same as numpy: If two tensors are different in rank, expand the tensor with lower rank. If two tensors has the same length along certain dimension, or one of the tensors has length 1 along certain dimension, then these two tensors are compatible along this dimension. Two tensors that are compatible along all dimensions are able to broadcast. After broadcasting, the length of each dimension equals to the larger one among two tensors. When a tensor has length = 1 along any dimension while the length of corresponding dimension of the other tensor > 1, in the broadcast result, this only element is jusk like been duplicated along this dimension. tf.broadcast_to expand the dimension of tensor explicitly. a = tf . constant ([ 1 , 2 , 3 ]) b = tf . constant ([[ 0 , 0 , 0 ],[ 1 , 1 , 1 ],[ 2 , 2 , 2 ]]) b + a # Identical to b + tf.broadcast_to(a,b.shape) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [2, 3, 4], [3, 4, 5]], dtype=int32)> tf . broadcast_to ( a , b . shape ) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[1, 2, 3], [1, 2, 3], [1, 2, 3]], dtype=int32)> # Shape after broadcasting using static shape, requires arguments in TensorShape type tf . broadcast_static_shape ( a . shape , b . shape ) TensorShape([3, 3]) # Shape after broadcasting using dynamic shape, requires arguments in Tensor type c = tf . constant ([ 1 , 2 , 3 ]) d = tf . constant ([[ 1 ],[ 2 ],[ 3 ]]) tf . broadcast_dynamic_shape ( tf . shape ( c ), tf . shape ( d )) <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)> # Results of broadcasting c + d # Identical to tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3]) <tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[2, 3, 4], [3, 4, 5], [4, 5, 6]], dtype=int32)> Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4. Broadcasting Mechanism"},{"location":"english/Chapter4/Chapter4-3/","text":"4-3 Rules of Using the AutoGraph # There are three ways of constructing graph: static, dynamic and Autograph. TensorFlow 2.X uses dynamic graph and Autograph. Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution. Static graph has high efficiency in execution, but more difficult for debugging. Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies. There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results. We are going to introduce the coding rules of Autograph and its mechanism of converting into static graph, together with introduction about how to construct Autograph using tf.Module . This section introduce the coding rules of using Autograph. We will introduce the mechanisms of Autograph in next section and explain the logic behind the rules there. 1. Summarization of the Coding Rules of Autograph # We should use the TensorFlow-defined functions to be decorated by @tf.function as much as possible, instead of those Python functions. For instance, tf.print should be used instead of print ; tf.range should be used instead of range ; tf.constant(True) should be used instead of True . Avoid defining tf.Variable inside the decorator @tf.function . Functions that are decorated by @tf.function cannot modify the struct data types variables outside the function such as Python list, dictionary, etc. 2. Explanations to the Autograph Coding Rules # 2.1 We should use the TensorFlow-defined functions to be decorated by @tf.function as much as possible, instead of those Python functions. import numpy as np import tensorflow as tf @tf . function def np_random (): a = np . random . randn ( 3 , 3 ) tf . print ( a ) @tf . function def tf_random (): a = tf . random . normal (( 3 , 3 )) tf . print ( a ) # Same results after each execution of np_random np_random () np_random () array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) # New random numbers are generated after each execution of tf_random tf_random () tf_random () [[-1.38956189 -0.394843668 0.420657277] [2.87235498 -1.33740318 -0.533843279] [0.918233037 0.118598573 -0.399486482]] [[-0.858178258 1.67509317 0.511889517] [-0.545829177 -2.20118237 -0.968222201] [0.733958483 -0.61904633 0.77440238]] 2.2 Avoid defining tf.Variable inside the decorator @tf.function . # Avoid defining tf.Variable inside the decorator @tf.function. x = tf . Variable ( 1.0 , dtype = tf . float32 ) @tf . function def outer_var (): x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) outer_var () outer_var () @tf . function def inner_var (): x = tf . Variable ( 1.0 , dtype = tf . float32 ) x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) # Error after execution #inner_var() #inner_var() --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-12-c95a7c3c1ddd> in <module> 7 8 # Error after execution ----> 9 inner_var() 10 inner_var() ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds) 566 xla_context.Exit() 567 else: --> 568 result = self._call(*args, **kwds) 569 570 if tracing_count == self._get_tracing_count(): ...... ValueError: tf.function-decorated function tried to create variables on non-first call. 2.3 Functions that are decorated by @tf.function cannot modify the struct data types variables outside the function such as Python list, dictionary, etc. tensor_list = [] #@tf.function # Autograph will result in something unexpected if executing this line def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>] tensor_list = [] @tf . function # Autograph will result in something unexpected if executing this line def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor 'x:0' shape=() dtype=float32>] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4-3 Rules of Using the AutoGraph"},{"location":"english/Chapter4/Chapter4-3/#4-3-rules-of-using-the-autograph","text":"There are three ways of constructing graph: static, dynamic and Autograph. TensorFlow 2.X uses dynamic graph and Autograph. Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution. Static graph has high efficiency in execution, but more difficult for debugging. Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies. There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results. We are going to introduce the coding rules of Autograph and its mechanism of converting into static graph, together with introduction about how to construct Autograph using tf.Module . This section introduce the coding rules of using Autograph. We will introduce the mechanisms of Autograph in next section and explain the logic behind the rules there.","title":"4-3 Rules of Using the AutoGraph"},{"location":"english/Chapter4/Chapter4-3/#1-summarization-of-the-coding-rules-of-autograph","text":"We should use the TensorFlow-defined functions to be decorated by @tf.function as much as possible, instead of those Python functions. For instance, tf.print should be used instead of print ; tf.range should be used instead of range ; tf.constant(True) should be used instead of True . Avoid defining tf.Variable inside the decorator @tf.function . Functions that are decorated by @tf.function cannot modify the struct data types variables outside the function such as Python list, dictionary, etc.","title":"1. Summarization of the Coding Rules of Autograph"},{"location":"english/Chapter4/Chapter4-3/#2-explanations-to-the-autograph-coding-rules","text":"2.1 We should use the TensorFlow-defined functions to be decorated by @tf.function as much as possible, instead of those Python functions. import numpy as np import tensorflow as tf @tf . function def np_random (): a = np . random . randn ( 3 , 3 ) tf . print ( a ) @tf . function def tf_random (): a = tf . random . normal (( 3 , 3 )) tf . print ( a ) # Same results after each execution of np_random np_random () np_random () array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) array([[ 0.22619201, -0.4550123 , -0.42587565], [ 0.05429906, 0.2312667 , -1.44819738], [ 0.36571796, 1.45578986, -1.05348983]]) # New random numbers are generated after each execution of tf_random tf_random () tf_random () [[-1.38956189 -0.394843668 0.420657277] [2.87235498 -1.33740318 -0.533843279] [0.918233037 0.118598573 -0.399486482]] [[-0.858178258 1.67509317 0.511889517] [-0.545829177 -2.20118237 -0.968222201] [0.733958483 -0.61904633 0.77440238]] 2.2 Avoid defining tf.Variable inside the decorator @tf.function . # Avoid defining tf.Variable inside the decorator @tf.function. x = tf . Variable ( 1.0 , dtype = tf . float32 ) @tf . function def outer_var (): x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) outer_var () outer_var () @tf . function def inner_var (): x = tf . Variable ( 1.0 , dtype = tf . float32 ) x . assign_add ( 1.0 ) tf . print ( x ) return ( x ) # Error after execution #inner_var() #inner_var() --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-12-c95a7c3c1ddd> in <module> 7 8 # Error after execution ----> 9 inner_var() 10 inner_var() ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds) 566 xla_context.Exit() 567 else: --> 568 result = self._call(*args, **kwds) 569 570 if tracing_count == self._get_tracing_count(): ...... ValueError: tf.function-decorated function tried to create variables on non-first call. 2.3 Functions that are decorated by @tf.function cannot modify the struct data types variables outside the function such as Python list, dictionary, etc. tensor_list = [] #@tf.function # Autograph will result in something unexpected if executing this line def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>] tensor_list = [] @tf . function # Autograph will result in something unexpected if executing this line def append_tensor ( x ): tensor_list . append ( x ) return tensor_list append_tensor ( tf . constant ( 5.0 )) append_tensor ( tf . constant ( 6.0 )) print ( tensor_list ) [<tf.Tensor 'x:0' shape=() dtype=float32>] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Explanations to the Autograph Coding Rules"},{"location":"english/Chapter4/Chapter4-4/","text":"4-4 Mechanisms of the AutoGraph # There are three ways of constructing graph: static, dynamic and Autograph. TensorFlow 2.X uses dynamic graph and Autograph. Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution. Static graph has high efficiency in execution, but more difficult for debugging. Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies. There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results. We are going to introduce the coding rules of Autograph and its mechanism of converting into static graph, together with introduction about how to construct Autograph using tf.Module . The coding rules of Autograph was introduced in the last section. Here we introduce the mechanisms of Autograph. 1. Mechanisms of Autograph # What happens when we define a function using decorator @tf.function ? Consider the following code. import tensorflow as tf import numpy as np @tf . function ( autograph = True ) def myadd ( a , b ): for i in tf . range ( 3 ): tf . print ( i ) c = a + b print ( \"tracing\" ) return c Nothing happens except a function signature is recorded in the stack of Python. What happens when this function decorated by @tf.function is called? Consider the following code. myadd ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) tracing 0 1 2 There are two incidents: First, the graph is created. A static graph is created. The Python code inside this function is executed, the tensor type of each variable is determined, and the operator is added to the graph according to the order of execution. During this period, if the argument autograph=True (default) is setted, convertting of the controlling flow in Python to the one inside TensorFlow graph will happen. The majority of the work are: replacing if to tf.cond operator; replacing while and for looping to tf.while_loop ; when necessary, add tf.control_dependencies to specify the dependencies of executing orders. This is identical to the following expressions in TensorFlow 1.X: g = tf . Graph () with g . as_default (): a = tf . placeholder ( shape = [], dtype = tf . string ) b = tf . placeholder ( shape = [], dtype = tf . string ) cond = lambda i : i < tf . constant ( 3 ) def body ( i ): tf . print ( i ) return ( i + 1 ) loop = tf . while_loop ( cond , body , loop_vars = [ 0 ]) loop with tf . control_dependencies ( loop ): c = tf . strings . join ([ a , b ]) print ( \"tracing\" ) The second incident is the execution of the graph. This is identical to the following expressions in TensorFlow 1.X: with tf . Session ( graph = g ) as sess : sess . run ( c , feed_dict = { a : tf . constant ( \"hello\" ), b : tf . constant ( \"world\" )}) So the result for the first step comes first: A string \"tracing\" printed by the standard I/O stream of Python. And next is the result of the second step: A string \"1, 2, 3\" printed by the standard I/O stream of TensorFlow. What is going to happen when we call this function again with the same types of the input arguments? Consider the following code. myadd ( tf . constant ( \"good\" ), tf . constant ( \"morning\" )) 0 1 2 Only one thing happens: execution of the graph, which is the second step mentioned above. So the string \"traicing\" doesn't appear. What is going to happen when we call this function again with some different types of the input arguments? Consider the following code. myadd ( tf . constant ( 1 ), tf . constant ( 2 )) tracing 0 1 2 Since the data type of the argument has been changed, the previously created graph cannot be used again. Two more tasks to be done: create new graph and execute it. The result of the first step will be observed again, i.e. a string \"tracing\" printed by the standard I/O stream of Python. And next is the result of the second step: A string \"1, 2, 3\" printed by the standard I/O stream of TensorFlow. Note: if the data type of the argument is not Tensor in the original definition of this function, then the graph will be re-created each time after calling this function. The demonstrated code below re-creates graph every time, so it is recommended to use Tensor type as the arguments when calling the function decorated by @tf.function . myadd ( \"hello\" , \"world\" ) myadd ( \"good\" , \"morning\" ) tracing 0 1 2 tracing 0 1 2 2. Scrutinize the Coding Rules of Autograph Again # We can have a better understanding to the three rules of coding of Autograph after knowing the mechanisms above. 1, We should use the TensorFlow-defined functions to be decorated by @tf.function as much as possible, instead of those Python functions. For instance, tf.print should be used instead of print . Explanations: Python functions are only used during the stage of creating static graph. The Python functions are not able to be embedded into the static graph, so these Python functions are not calculated during the calling after the graph creation; in contrast, TensorFlow functions are able to be embedded into the graph. Using Python functions is causing unmatched outputs between the \"eager execution\" before the decoration by @tf.function and the \"execution of static graph\" after the decoration by @tf.function . 2\uff0cAvoid defining tf.Variable inside the decorator @tf.function . Explanations: The defined tf.Variable will be re-created every time when calling the function during the \"eager execution\" stage. However, this re-creation of tf.Variable only takes place at the first step, i.e. tracing Python code to create the graph, which is introducing unmatched outputs between the \"eager execution\" before the decoration by @tf.function and the \"execution of static graph\" after the decoration by @tf.function . In fact, TensorFlow throws error in most of such cases. 3\uff0cFunctions that are decorated by @tf.function cannot modify the variables outside the function with the data types such as Python list, dictionary, etc. Explanations: Static graph is executed in the TensorFlow kernels, which are compiled from C++ code, thus the list and dictionary in Python are not able to be embedded into the graph. These data types can only be read during the stage of graph creating and cannot be modified during the graph execution. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4-4 Mechanisms of the AutoGraph"},{"location":"english/Chapter4/Chapter4-4/#4-4-mechanisms-of-the-autograph","text":"There are three ways of constructing graph: static, dynamic and Autograph. TensorFlow 2.X uses dynamic graph and Autograph. Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution. Static graph has high efficiency in execution, but more difficult for debugging. Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies. There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results. We are going to introduce the coding rules of Autograph and its mechanism of converting into static graph, together with introduction about how to construct Autograph using tf.Module . The coding rules of Autograph was introduced in the last section. Here we introduce the mechanisms of Autograph.","title":"4-4 Mechanisms of the AutoGraph"},{"location":"english/Chapter4/Chapter4-4/#1-mechanisms-of-autograph","text":"What happens when we define a function using decorator @tf.function ? Consider the following code. import tensorflow as tf import numpy as np @tf . function ( autograph = True ) def myadd ( a , b ): for i in tf . range ( 3 ): tf . print ( i ) c = a + b print ( \"tracing\" ) return c Nothing happens except a function signature is recorded in the stack of Python. What happens when this function decorated by @tf.function is called? Consider the following code. myadd ( tf . constant ( \"hello\" ), tf . constant ( \"world\" )) tracing 0 1 2 There are two incidents: First, the graph is created. A static graph is created. The Python code inside this function is executed, the tensor type of each variable is determined, and the operator is added to the graph according to the order of execution. During this period, if the argument autograph=True (default) is setted, convertting of the controlling flow in Python to the one inside TensorFlow graph will happen. The majority of the work are: replacing if to tf.cond operator; replacing while and for looping to tf.while_loop ; when necessary, add tf.control_dependencies to specify the dependencies of executing orders. This is identical to the following expressions in TensorFlow 1.X: g = tf . Graph () with g . as_default (): a = tf . placeholder ( shape = [], dtype = tf . string ) b = tf . placeholder ( shape = [], dtype = tf . string ) cond = lambda i : i < tf . constant ( 3 ) def body ( i ): tf . print ( i ) return ( i + 1 ) loop = tf . while_loop ( cond , body , loop_vars = [ 0 ]) loop with tf . control_dependencies ( loop ): c = tf . strings . join ([ a , b ]) print ( \"tracing\" ) The second incident is the execution of the graph. This is identical to the following expressions in TensorFlow 1.X: with tf . Session ( graph = g ) as sess : sess . run ( c , feed_dict = { a : tf . constant ( \"hello\" ), b : tf . constant ( \"world\" )}) So the result for the first step comes first: A string \"tracing\" printed by the standard I/O stream of Python. And next is the result of the second step: A string \"1, 2, 3\" printed by the standard I/O stream of TensorFlow. What is going to happen when we call this function again with the same types of the input arguments? Consider the following code. myadd ( tf . constant ( \"good\" ), tf . constant ( \"morning\" )) 0 1 2 Only one thing happens: execution of the graph, which is the second step mentioned above. So the string \"traicing\" doesn't appear. What is going to happen when we call this function again with some different types of the input arguments? Consider the following code. myadd ( tf . constant ( 1 ), tf . constant ( 2 )) tracing 0 1 2 Since the data type of the argument has been changed, the previously created graph cannot be used again. Two more tasks to be done: create new graph and execute it. The result of the first step will be observed again, i.e. a string \"tracing\" printed by the standard I/O stream of Python. And next is the result of the second step: A string \"1, 2, 3\" printed by the standard I/O stream of TensorFlow. Note: if the data type of the argument is not Tensor in the original definition of this function, then the graph will be re-created each time after calling this function. The demonstrated code below re-creates graph every time, so it is recommended to use Tensor type as the arguments when calling the function decorated by @tf.function . myadd ( \"hello\" , \"world\" ) myadd ( \"good\" , \"morning\" ) tracing 0 1 2 tracing 0 1 2","title":"1. Mechanisms of Autograph"},{"location":"english/Chapter4/Chapter4-4/#2-scrutinize-the-coding-rules-of-autograph-again","text":"We can have a better understanding to the three rules of coding of Autograph after knowing the mechanisms above. 1, We should use the TensorFlow-defined functions to be decorated by @tf.function as much as possible, instead of those Python functions. For instance, tf.print should be used instead of print . Explanations: Python functions are only used during the stage of creating static graph. The Python functions are not able to be embedded into the static graph, so these Python functions are not calculated during the calling after the graph creation; in contrast, TensorFlow functions are able to be embedded into the graph. Using Python functions is causing unmatched outputs between the \"eager execution\" before the decoration by @tf.function and the \"execution of static graph\" after the decoration by @tf.function . 2\uff0cAvoid defining tf.Variable inside the decorator @tf.function . Explanations: The defined tf.Variable will be re-created every time when calling the function during the \"eager execution\" stage. However, this re-creation of tf.Variable only takes place at the first step, i.e. tracing Python code to create the graph, which is introducing unmatched outputs between the \"eager execution\" before the decoration by @tf.function and the \"execution of static graph\" after the decoration by @tf.function . In fact, TensorFlow throws error in most of such cases. 3\uff0cFunctions that are decorated by @tf.function cannot modify the variables outside the function with the data types such as Python list, dictionary, etc. Explanations: Static graph is executed in the TensorFlow kernels, which are compiled from C++ code, thus the list and dictionary in Python are not able to be embedded into the graph. These data types can only be read during the stage of graph creating and cannot be modified during the graph execution. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Scrutinize the Coding Rules of Autograph Again"},{"location":"english/Chapter4/Chapter4-5/","text":"4-5 AutoGraph and tf.Module # There are three ways of constructing graph: static, dynamic and Autograph. TensorFlow 2.X uses dynamic graph and Autograph. Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution. Static graph has high efficiency in execution, but more difficult for debugging. Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies. There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results. The coding rules and the mechanisms of Autograph were introduced in the last sections. In this section, we introduce constructing Autograph using tf.Module . 1. Introduction to Autograph and tf.Module # We mentioned that the definition of tf.Variable should be avoided inside the decorator @tf.function . However, it would seem to be a imperfect leaked package if we define tf.Variable outside the function, since the function has outside dependency. One of the simple solutions is: defining a class and place the definition of tf.Variable inside the initial method, and leave the other methods/implementation elsewhere. After such an ingenious operation, it is so naturally as if the chronic constipation was cured by the best laxative. The surprise is that TensorFlow providing us a base class tf.Module to get the above naturally. What's more, It is supposed to be inherited for constructing child classes to manage variables and other Module conveniently. And the most important that it allows us to save model through tf.saved_model and achieve cross-platform deployment. What a surprise! In fact, tf.keras.models.Model , tf.keras.layers.Layer are both inherited from tf.Module . They provides the management to the variables and the referred sub-modules. We are able to develop arbitrary learning model (not only neural network) and implement cross-platform deployment through the packaging provided by tf.Module and the low-level APIs in TensorFlow. 2. Packaging Autograph Using tf.Module # We define a simple function\u3002 import tensorflow as tf x = tf . Variable ( 1.0 , dtype = tf . float32 ) # Use input_signature to limit the signature type of the input tensors with shape and dtype inside the decorator tf.function @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def add_print ( a ): x . assign_add ( a ) tf . print ( x ) return ( x ) add_print ( tf . constant ( 3.0 )) #add_print(tf.constant(3)) # Error: argument inconsistent with the tensor signature. 4 Package using tf.Module . class DemoModule ( tf . Module ): def __init__ ( self , init_value = tf . constant ( 0.0 ), name = None ): super ( DemoModule , self ) . __init__ ( name = name ) with self . name_scope : # Identical to: with tf.name_scope(\"demo_module\") self . x = tf . Variable ( init_value , dtype = tf . float32 , trainable = True ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( self , a ): with self . name_scope : self . x . assign_add ( a ) tf . print ( self . x ) return ( self . x ) # Execute demo = DemoModule ( init_value = tf . constant ( 1.0 )) result = demo . addprint ( tf . constant ( 5.0 )) 6 # Browse all variables and trainable variables in the module print ( demo . variables ) print ( demo . trainable_variables ) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) # Browse all sub-modules demo . submodules # Save the model using tf.saved_model and specify the method of cross-platform deployment. tf . saved_model . save ( demo , \"../../data/demo/1\" , signatures = { \"serving_default\" : demo . addprint }) # Load the modle demo2 = tf . saved_model . load ( \"../../data/demo/1\" ) demo2 . addprint ( tf . constant ( 5.0 )) 11 # Check the info of the model file. The info in the red rectangulars could be used during the deployment and the cross-platform usage. ! saved_model_cli show -- dir ../../ data / demo / 1 -- all Check the graph in tensorboard, the module will be added with name demo_module , showing the hierarchy of the graph. import datetime # Creating log stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = '../../data/demomodule/ %s ' % stamp writer = tf . summary . create_file_writer ( logdir ) # Start tracing of the Autograph tf . summary . trace_on ( graph = True , profiler = True ) # Execute the Autograph demo = DemoModule ( init_value = tf . constant ( 0.0 )) result = demo . addprint ( tf . constant ( 5.0 )) # Write the info of the graph into the log with writer . as_default (): tf . summary . trace_export ( name = \"demomodule\" , step = 0 , profiler_outdir = logdir ) # Magic command to launch tensorboard in jupyter % reload_ext tensorboard from tensorboard import notebook notebook . list () notebook . start ( \"--logdir ../../data/demomodule/\" ) Besides using the child class of tf.Module , it is also possible to package through adding attribute to tf.Module . mymodule = tf . Module () mymodule . x = tf . Variable ( 0.0 ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( a ): mymodule . x . assign_add ( a ) tf . print ( mymodule . x ) return ( mymodule . x ) mymodule . addprint = addprint mymodule . addprint ( tf . constant ( 1.0 )) . numpy () 1.0 print ( mymodule . variables ) (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>,) # Save model using tf.saved_model tf . saved_model . save ( mymodule , \"../../data/mymodule\" , signatures = { \"serving_default\" : mymodule . addprint }) # Load the model mymodule2 = tf . saved_model . load ( \"../../data/mymodule\" ) mymodule2 . addprint ( tf . constant ( 5.0 )) INFO:tensorflow:Assets written to: ../../data/mymodule/assets 5 3. tf.Module and tf.keras.Model \uff0c tf.keras.layers.Layer # The models and the layers in tf.keras are implemented through inheriting tf.Module . Both of them are able to manage variables and sub-modules. import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics print ( issubclass ( tf . keras . Model , tf . Module )) print ( issubclass ( tf . keras . layers . Layer , tf . Module )) print ( issubclass ( tf . keras . Model , tf . keras . layers . Layer )) True True True tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 4 , input_shape = ( 10 ,))) model . add ( layers . Dense ( 2 )) model . add ( layers . Dense ( 1 )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 4) 44 _________________________________________________________________ dense_1 (Dense) (None, 2) 10 _________________________________________________________________ dense_2 (Dense) (None, 1) 3 ================================================================= Total params: 57 Trainable params: 57 Non-trainable params: 0 _________________________________________________________________ model . variables [<tf.Variable 'dense/kernel:0' shape=(10, 4) dtype=float32, numpy= array([[-0.06741005, 0.45534766, 0.5190817 , -0.01806331], [-0.14258742, -0.49711505, 0.26030976, 0.18607801], [-0.62806034, 0.5327399 , 0.42206633, 0.29201728], [-0.16602087, -0.18901917, 0.55159235, -0.01091868], [ 0.04533798, 0.326845 , -0.582667 , 0.19431782], [ 0.6494713 , -0.16174704, 0.4062966 , 0.48760796], [ 0.58400524, -0.6280886 , -0.11265379, -0.6438277 ], [ 0.26642334, 0.49275804, 0.20793378, -0.43889117], [ 0.4092741 , 0.09871006, -0.2073121 , 0.26047975], [ 0.43910992, 0.00199282, -0.07711256, -0.27966842]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . layers [ 0 ] . trainable = False # Freeze the variables in layer 0, make it untrainable. model . trainable_variables [<tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . submodules (<tensorflow.python.keras.engine.input_layer.InputLayer at 0x144d8c080>, <tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>) model . layers [<tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>] print ( model . name ) print ( model . name_scope ()) sequential sequential Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4-5 AutoGraph and tf.Module"},{"location":"english/Chapter4/Chapter4-5/#4-5-autograph-and-tfmodule","text":"There are three ways of constructing graph: static, dynamic and Autograph. TensorFlow 2.X uses dynamic graph and Autograph. Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution. Static graph has high efficiency in execution, but more difficult for debugging. Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies. There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results. The coding rules and the mechanisms of Autograph were introduced in the last sections. In this section, we introduce constructing Autograph using tf.Module .","title":"4-5 AutoGraph and tf.Module"},{"location":"english/Chapter4/Chapter4-5/#1-introduction-to-autograph-and-tfmodule","text":"We mentioned that the definition of tf.Variable should be avoided inside the decorator @tf.function . However, it would seem to be a imperfect leaked package if we define tf.Variable outside the function, since the function has outside dependency. One of the simple solutions is: defining a class and place the definition of tf.Variable inside the initial method, and leave the other methods/implementation elsewhere. After such an ingenious operation, it is so naturally as if the chronic constipation was cured by the best laxative. The surprise is that TensorFlow providing us a base class tf.Module to get the above naturally. What's more, It is supposed to be inherited for constructing child classes to manage variables and other Module conveniently. And the most important that it allows us to save model through tf.saved_model and achieve cross-platform deployment. What a surprise! In fact, tf.keras.models.Model , tf.keras.layers.Layer are both inherited from tf.Module . They provides the management to the variables and the referred sub-modules. We are able to develop arbitrary learning model (not only neural network) and implement cross-platform deployment through the packaging provided by tf.Module and the low-level APIs in TensorFlow.","title":"1. Introduction to Autograph and tf.Module"},{"location":"english/Chapter4/Chapter4-5/#2-packaging-autograph-using-tfmodule","text":"We define a simple function\u3002 import tensorflow as tf x = tf . Variable ( 1.0 , dtype = tf . float32 ) # Use input_signature to limit the signature type of the input tensors with shape and dtype inside the decorator tf.function @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def add_print ( a ): x . assign_add ( a ) tf . print ( x ) return ( x ) add_print ( tf . constant ( 3.0 )) #add_print(tf.constant(3)) # Error: argument inconsistent with the tensor signature. 4 Package using tf.Module . class DemoModule ( tf . Module ): def __init__ ( self , init_value = tf . constant ( 0.0 ), name = None ): super ( DemoModule , self ) . __init__ ( name = name ) with self . name_scope : # Identical to: with tf.name_scope(\"demo_module\") self . x = tf . Variable ( init_value , dtype = tf . float32 , trainable = True ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( self , a ): with self . name_scope : self . x . assign_add ( a ) tf . print ( self . x ) return ( self . x ) # Execute demo = DemoModule ( init_value = tf . constant ( 1.0 )) result = demo . addprint ( tf . constant ( 5.0 )) 6 # Browse all variables and trainable variables in the module print ( demo . variables ) print ( demo . trainable_variables ) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) (<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,) # Browse all sub-modules demo . submodules # Save the model using tf.saved_model and specify the method of cross-platform deployment. tf . saved_model . save ( demo , \"../../data/demo/1\" , signatures = { \"serving_default\" : demo . addprint }) # Load the modle demo2 = tf . saved_model . load ( \"../../data/demo/1\" ) demo2 . addprint ( tf . constant ( 5.0 )) 11 # Check the info of the model file. The info in the red rectangulars could be used during the deployment and the cross-platform usage. ! saved_model_cli show -- dir ../../ data / demo / 1 -- all Check the graph in tensorboard, the module will be added with name demo_module , showing the hierarchy of the graph. import datetime # Creating log stamp = datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) logdir = '../../data/demomodule/ %s ' % stamp writer = tf . summary . create_file_writer ( logdir ) # Start tracing of the Autograph tf . summary . trace_on ( graph = True , profiler = True ) # Execute the Autograph demo = DemoModule ( init_value = tf . constant ( 0.0 )) result = demo . addprint ( tf . constant ( 5.0 )) # Write the info of the graph into the log with writer . as_default (): tf . summary . trace_export ( name = \"demomodule\" , step = 0 , profiler_outdir = logdir ) # Magic command to launch tensorboard in jupyter % reload_ext tensorboard from tensorboard import notebook notebook . list () notebook . start ( \"--logdir ../../data/demomodule/\" ) Besides using the child class of tf.Module , it is also possible to package through adding attribute to tf.Module . mymodule = tf . Module () mymodule . x = tf . Variable ( 0.0 ) @tf . function ( input_signature = [ tf . TensorSpec ( shape = [], dtype = tf . float32 )]) def addprint ( a ): mymodule . x . assign_add ( a ) tf . print ( mymodule . x ) return ( mymodule . x ) mymodule . addprint = addprint mymodule . addprint ( tf . constant ( 1.0 )) . numpy () 1.0 print ( mymodule . variables ) (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>,) # Save model using tf.saved_model tf . saved_model . save ( mymodule , \"../../data/mymodule\" , signatures = { \"serving_default\" : mymodule . addprint }) # Load the model mymodule2 = tf . saved_model . load ( \"../../data/mymodule\" ) mymodule2 . addprint ( tf . constant ( 5.0 )) INFO:tensorflow:Assets written to: ../../data/mymodule/assets 5","title":"2. Packaging Autograph Using tf.Module"},{"location":"english/Chapter4/Chapter4-5/#3-tfmodule-and-tfkerasmodeltfkeraslayerslayer","text":"The models and the layers in tf.keras are implemented through inheriting tf.Module . Both of them are able to manage variables and sub-modules. import tensorflow as tf from tensorflow.keras import models , layers , losses , metrics print ( issubclass ( tf . keras . Model , tf . Module )) print ( issubclass ( tf . keras . layers . Layer , tf . Module )) print ( issubclass ( tf . keras . Model , tf . keras . layers . Layer )) True True True tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 4 , input_shape = ( 10 ,))) model . add ( layers . Dense ( 2 )) model . add ( layers . Dense ( 1 )) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 4) 44 _________________________________________________________________ dense_1 (Dense) (None, 2) 10 _________________________________________________________________ dense_2 (Dense) (None, 1) 3 ================================================================= Total params: 57 Trainable params: 57 Non-trainable params: 0 _________________________________________________________________ model . variables [<tf.Variable 'dense/kernel:0' shape=(10, 4) dtype=float32, numpy= array([[-0.06741005, 0.45534766, 0.5190817 , -0.01806331], [-0.14258742, -0.49711505, 0.26030976, 0.18607801], [-0.62806034, 0.5327399 , 0.42206633, 0.29201728], [-0.16602087, -0.18901917, 0.55159235, -0.01091868], [ 0.04533798, 0.326845 , -0.582667 , 0.19431782], [ 0.6494713 , -0.16174704, 0.4062966 , 0.48760796], [ 0.58400524, -0.6280886 , -0.11265379, -0.6438277 ], [ 0.26642334, 0.49275804, 0.20793378, -0.43889117], [ 0.4092741 , 0.09871006, -0.2073121 , 0.26047975], [ 0.43910992, 0.00199282, -0.07711256, -0.27966842]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . layers [ 0 ] . trainable = False # Freeze the variables in layer 0, make it untrainable. model . trainable_variables [<tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy= array([[ 0.5022683 , -0.0507431 ], [-0.61540484, 0.9369011 ], [-0.14412141, -0.54607415], [ 0.2027781 , -0.4651153 ]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy= array([[-0.244825 ], [-1.2101456]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>] model . submodules (<tensorflow.python.keras.engine.input_layer.InputLayer at 0x144d8c080>, <tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>) model . layers [<tensorflow.python.keras.layers.core.Dense at 0x144daada0>, <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>, <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>] print ( model . name ) print ( model . name_scope ()) sequential sequential Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. tf.Module and tf.keras.Model\uff0ctf.keras.layers.Layer"},{"location":"english/Chapter5/","text":"Chapter 5: Mid-level API in TensorFlow # Mid-level API in TensorFlow includes: Data pipeline (tf.data) Feature column (tf.feature_column) Activation function (tf.nn) Model layer (tf.keras.layers) Loss function (tf.keras.losses) Evaluation function (tf.keras.metrics) Optimizer (tf.keras.optimizers) Callback function (tf.keras.callbacks) If we compare a model to a house, then these fourth level APIs are the walls. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"Chapter 5: Mid-level API in TensorFlow"},{"location":"english/Chapter5/#chapter-5-mid-level-api-in-tensorflow","text":"Mid-level API in TensorFlow includes: Data pipeline (tf.data) Feature column (tf.feature_column) Activation function (tf.nn) Model layer (tf.keras.layers) Loss function (tf.keras.losses) Evaluation function (tf.keras.metrics) Optimizer (tf.keras.optimizers) Callback function (tf.keras.callbacks) If we compare a model to a house, then these fourth level APIs are the walls. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"Chapter 5: Mid-level API in TensorFlow"},{"location":"english/Chapter5/Chapter5-1/","text":"5-1 Dataset # All the data could be read into memory for training to maximize the efficiency, if the volume of training data is small (e.g. < 1 GB) However, if the data volume is huge (e.g. > 10 GB) which is not possible to load everything into the memory, they should be devided into batches before reading. The API tf.data constructs input data pipeline to help manage huge volume of data with various formats and conversions. 1. Constructing Data Pipeline # Data pipeline could be constructed through following methods: numpy array, pandas DataFrame, Python generator, csv file, text file, file path, tfrecords file. Among these methods, the most popular ones are: numpy array, pandas DataFrame and file path. The drawback of using tfrecords file to construct data pipelines is its complication, since it requires: (a) construct tf.Example from samples; (b) compress tf.Example into string and write it to tfrecords file; \u00a9 when using these data, the tfrecords file have to be read and analyzed into tf.Example . On the other hand, the advantage of using tfrecords files is its small volume after compression, its convenient sharing through the Internet, and the fast speed of loading. 1.1 Constructing Data Pipeline through Numpy Array # Constructing Data Pipeline through Numpy Array import tensorflow as tf import numpy as np from sklearn import datasets iris = datasets . load_iris () ds1 = tf . data . Dataset . from_tensor_slices (( iris [ \"data\" ], iris [ \"target\" ])) for features , label in ds1 . take ( 5 ): print ( features , label ) tf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.9 3. 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([5. 3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) 1.2 Constructing Data Pipeline through Pandas DataFrame # Constructing Data Pipeline through Pandas DataFrame import tensorflow as tf from sklearn import datasets import pandas as pd iris = datasets . load_iris () dfiris = pd . DataFrame ( iris [ \"data\" ], columns = iris . feature_names ) ds2 = tf . data . Dataset . from_tensor_slices (( dfiris . to_dict ( \"list\" ), iris [ \"target\" ])) for features , label in ds2 . take ( 3 ): print ( features , label ) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) 1.3 Constructing Data Pipeline through Python generator # Constructing Data Pipeline through Python generator import tensorflow as tf from matplotlib import pyplot as plt from tensorflow.keras.preprocessing.image import ImageDataGenerator # Defining a generator to read image from a folder image_generator = ImageDataGenerator ( rescale = 1.0 / 255 ) . flow_from_directory ( \"../../data/cifar2/test/\" , target_size = ( 32 , 32 ), batch_size = 20 , class_mode = 'binary' ) classdict = image_generator . class_indices print ( classdict ) def generator (): for features , label in image_generator : yield ( features , label ) ds3 = tf . data . Dataset . from_generator ( generator , output_types = ( tf . float32 , tf . int32 )) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds3 . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 1.4 Constructing Data Pipeline through csv file # Constructing Data Pipeline through csv file ds4 = tf . data . experimental . make_csv_dataset ( file_pattern = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ], batch_size = 3 , label_name = \"Survived\" , na_value = \"\" , num_epochs = 1 , ignore_errors = True ) for data , label in ds4 . take ( 2 ): print ( data , label ) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([540, 58, 764], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 1], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Frolicher, Miss. Hedwig Margaritha', b'Novel, Mr. Mansouer', b'Carter, Mrs. William Ernest (Lucile Polk)'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'female', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([22. , 28.5, 36. ], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 2], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'13568', b'2697', b'113760'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 49.5 , 7.2292, 120. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'B39', b'', b'B96 B98'], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'C', b'C', b'S'], dtype=object)>)]) tf.Tensor([1 0 1], shape=(3,), dtype=int32) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([845, 66, 390], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 2], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Culumovic, Mr. Jeso', b'Moubarek, Master. Gerios', b'Lehmann, Miss. Bertha'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([17., 0., 17.], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'315090', b'2661', b'SC 1748'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8.6625, 15.2458, 12. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'', b'', b''], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'C', b'C'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32) 1.5 Constructing Data Pipeline through text file # Constructing Data Pipeline through text file ds5 = tf . data . TextLineDataset ( filenames = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ] ) . skip ( 1 ) # Omitting the header on the first line for line in ds5 . take ( 5 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) tf.Tensor(b'687,0,3,\"Panula, Mr. Jaako Arnold\",male,14.0,4,1,3101295,39.6875,,S', shape=(), dtype=string) 1.6 Constructing Data Pipeline through file path ds6 = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) for file in ds6 . take ( 5 ): print ( file ) tf.Tensor(b'../../data/cifar2/train/automobile/1263.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/2837.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/4264.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/4241.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/192.jpg', shape=(), dtype=string) from matplotlib import pyplot as plt def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) # Note that we are using jpeg format img = tf . image . resize ( img , size ) return ( img , label ) % matplotlib inline % config InlineBackend . figure_format = 'svg' for i ,( img , label ) in enumerate ( ds6 . map ( load_image ) . take ( 2 )): plt . figure ( i ) plt . imshow (( img / 255.0 ) . numpy ()) plt . title ( \"label = %d \" % label ) plt . xticks ([]) plt . yticks ([]) 1.7 Constructing Data Pipeline through tfrecords file import os import numpy as np # inpath is the original data path; outpath: output path of the TFRecord file def create_tfrecords ( inpath , outpath ): writer = tf . io . TFRecordWriter ( outpath ) dirs = os . listdir ( inpath ) for index , name in enumerate ( dirs ): class_path = inpath + \"/\" + name + \"/\" for img_name in os . listdir ( class_path ): img_path = class_path + img_name img = tf . io . read_file ( img_path ) #img = tf.image.decode_image(img) #img = tf.image.encode_jpeg(img) # Use jpeg format for all the compressions example = tf . train . Example ( features = tf . train . Features ( feature = { 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = [ index ])), 'img_raw' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ img . numpy ()])) })) writer . write ( example . SerializeToString ()) writer . close () create_tfrecords ( \"../../data/cifar2/test/\" , \"../../data/cifar2_test.tfrecords/\" ) from matplotlib import pyplot as plt def parse_example ( proto ): description = { 'img_raw' : tf . io . FixedLenFeature ([], tf . string ), 'label' : tf . io . FixedLenFeature ([], tf . int64 )} example = tf . io . parse_single_example ( proto , description ) img = tf . image . decode_jpeg ( example [ \"img_raw\" ]) # Note that we are using jpeg format img = tf . image . resize ( img , ( 32 , 32 )) label = example [ \"label\" ] return ( img , label ) ds7 = tf . data . TFRecordDataset ( \"../../data/cifar2_test.tfrecords\" ) . map ( parse_example ) . shuffle ( 3000 ) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds7 . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow (( img / 255.0 ) . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 2. Applying Data Conversion # Dataset is very flexible in the application of data structure. Essentially it is a sequence with elements in various data types, such as tensor, list, dictionary and Dataset. Dataset contains many functions of data conversion. map : projecting the conversion function to every element in the dataset. flat_map : projecting the conversion function to every element in the dataset, and flatten the embedded Dataset. interleave : similar as flat_map but interleaves the data from different sources. filter : filter certain elements. zip : zipping two Datasets with the same length. concatenate : concatenating two Datasets. reduce : executing operation of reducing. batch : constructing batches and release one batch each time; there will be one more rank comparing to the original data; the inverse operation is unbatch . padded_batch : constructing batches, similar as batch , but can achieve padded shape. window : constructing sliding window, and return Dataset of Dataset. shuffle : shuffling the order of the data. repeat : repeat the data certain times; if no argument is specified, repeat data with infinitive times. shard : sampling the elements starting from a certain position with fixed distance. take : sampling the first few elements from a certain position. #map: projecting the conversion function to every element in the dataset. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_map = ds . map ( lambda x : tf . strings . split ( x , \" \" )) for x in ds_map : print ( x ) tf.Tensor([b'hello' b'world'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'China'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'Beijing'], shape=(2,), dtype=string) #flat_map: projecting the conversion function to every element in the dataset, and flatten the embedded Dataset. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_flatmap = ds . flat_map ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_flatmap : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) # interleave: similar as `flat_map` but interleaves the data from different sources. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_interleave = ds . interleave ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_interleave : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) #filter: filter certain elements. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) # Find the element with letter'a' or 'B' ds_filter = ds . filter ( lambda x : tf . strings . regex_full_match ( x , \".*[a|B].*\" )) for x in ds_filter : print ( x ) tf.Tensor(b'hello China', shape=(), dtype=string) tf.Tensor(b'hello Beijing', shape=(), dtype=string) #zip: zipping two Datasets with the same length. ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds3 = tf . data . Dataset . range ( 6 , 9 ) ds_zip = tf . data . Dataset . zip (( ds1 , ds2 , ds3 )) for x , y , z in ds_zip : print ( x . numpy (), y . numpy (), z . numpy ()) 0 3 6 1 4 7 2 5 8 #condatenate: concatenating two Datasets. ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds_concat = tf . data . Dataset . concatenate ( ds1 , ds2 ) for x in ds_concat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) #reduce: executing operation of reducing. ds = tf . data . Dataset . from_tensor_slices ([ 1 , 2 , 3 , 4 , 5.0 ]) result = ds . reduce ( 0.0 , lambda x , y : tf . add ( x , y )) result <tf.Tensor: shape=(), dtype=float32, numpy=15.0> #batch: constructing batches and release one batch each time; there will be one more rank comparing to the original data; the inverse operation is `unbatch`. ds = tf . data . Dataset . range ( 12 ) ds_batch = ds . batch ( 4 ) for x in ds_batch : print ( x ) tf.Tensor([0 1 2 3], shape=(4,), dtype=int64) tf.Tensor([4 5 6 7], shape=(4,), dtype=int64) tf.Tensor([ 8 9 10 11], shape=(4,), dtype=int64) #padded_batch: constructing batches, similar as `batch`, but can achieve padded shape. elements = [[ 1 , 2 ],[ 3 , 4 , 5 ],[ 6 , 7 ],[ 8 ]] ds = tf . data . Dataset . from_generator ( lambda : iter ( elements ), tf . int32 ) ds_padded_batch = ds . padded_batch ( 2 , padded_shapes = [ 4 ,]) for x in ds_padded_batch : print ( x ) tf.Tensor( [[1 2 0 0] [3 4 5 0]], shape=(2, 4), dtype=int32) tf.Tensor( [[6 7 0 0] [8 0 0 0]], shape=(2, 4), dtype=int32) #window: constructing sliding window, and return Dataset of Dataset. ds = tf . data . Dataset . range ( 12 ) # window returns Dataset of Dataset, which could be flattened by flat_map ds_window = ds . window ( 3 , shift = 1 ) . flat_map ( lambda x : x . batch ( 3 , drop_remainder = True )) for x in ds_window : print ( x ) tf.Tensor([0 1 2], shape=(3,), dtype=int64) tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([2 3 4], shape=(3,), dtype=int64) tf.Tensor([3 4 5], shape=(3,), dtype=int64) tf.Tensor([4 5 6], shape=(3,), dtype=int64) tf.Tensor([5 6 7], shape=(3,), dtype=int64) tf.Tensor([6 7 8], shape=(3,), dtype=int64) tf.Tensor([7 8 9], shape=(3,), dtype=int64) tf.Tensor([ 8 9 10], shape=(3,), dtype=int64) tf.Tensor([ 9 10 11], shape=(3,), dtype=int64) #shuffle: shuffling the order of the data. ds = tf . data . Dataset . range ( 12 ) ds_shuffle = ds . shuffle ( buffer_size = 5 ) for x in ds_shuffle : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(6, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(11, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(9, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) tf.Tensor(8, shape=(), dtype=int64) #repeat: repeat the data certain times; if no argument is specified, repeat data with infinitive times. ds = tf . data . Dataset . range ( 3 ) ds_repeat = ds . repeat ( 3 ) for x in ds_repeat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) #shard: sampling the elements starting from a certain position with fixed distance. ds = tf . data . Dataset . range ( 12 ) ds_shard = ds . shard ( 3 , index = 1 ) for x in ds_shard : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) #take: sampling the first few elements from a certain position. ds = tf . data . Dataset . range ( 12 ) ds_take = ds . take ( 3 ) list ( ds_take . as_numpy_iterator ()) [0, 1, 2] 3. Enhance the Efficiency of the Pipeline # The training of deep learning model could be lengthy. The consumed time is mainly consists of two parts: data preparation and parameter iteration . The efficiency of parameter iteration is ususlly enhanced by GPU. The efficiency of data preparation could be improved by constructing high-efficiency data pipeline. Below are several suggestions of constructing high-efficiency data pipeline: 1, Paralleling the data preparation and the parameter iteration using method prefetch . 2, Use the method interleave to read data with multi-process and interleave the data from different sources. 3, Set num_parallel_calls during using map , allowing data conversion with multiple process. 4, Apply method cache to cache data into the memory after the first epoch for the case with a small data volume. 5, When converting with map , batch the data first, and then convert each batch with vecterization. 3.1 Paralleling the data preparation and the parameter iteration using method prefetch . import tensorflow as tf # Time stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) import time # Data preparation and parameter iteration is serial as default. # Simulation of data preparation def generator (): for i in range ( 10 ): # Suppose we need 2 seconds for each preparation time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # Simulation of parameter iteration def train_step (): # Suppose we need 1 seconds for each training step time . sleep ( 1 ) # Estimated time of training: 10*2+10*1 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for x in ds : train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) # Use method prefetch to parallel the processes of data preparation and parameter iteration. # Estimated time of training: max(10*2,10*1) = 20s printbar () tf . print ( tf . constant ( \"start training with prefetch...\" )) # tf.data.experimental.AUTOTUNE allows auto-selection of parameters for x in ds . prefetch ( buffer_size = tf . data . experimental . AUTOTUNE ): train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) 3.2 Use the method interleave to read data with multi-process and interleave the data from different sources. ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . flat_map ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 4 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . interleave ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 8 ): print ( line ) tf.Tensor(b'181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S', shape=(), dtype=string) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'405,0,3,\"Oreskovic, Miss. Marija\",female,20.0,0,0,315096,8.6625,,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'635,0,3,\"Skoog, Miss. Mabel\",female,9.0,3,2,347088,27.9,,S', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18.0,1,0,PC 17757,227.525,C62 C64,C', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) 3.3 Set num_parallel_calls during using map , allowing data conversion with multiple process. ds = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #Note: jpeg format here img = tf . image . resize ( img , size ) return ( img , label ) # Conversion with single process printbar () tf . print ( tf . constant ( \"start transformation...\" )) ds_map = ds . map ( load_image ) for _ in ds_map : pass printbar () tf . print ( tf . constant ( \"end transformation...\" )) # Conversion with multi-process printbar () tf . print ( tf . constant ( \"start parallel transformation...\" )) ds_map_parallel = ds . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) for _ in ds_map_parallel : pass printbar () tf . print ( tf . constant ( \"end parallel transformation...\" )) 3.4 Apply method cache to cache data into the memory after the first epoch for the case with a small data volume. import time # Simulation of data preparation def generator (): for i in range ( 5 ): # Suppose we need 2 seconds for each preparation time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # Simulation of parameter iteration\u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): # Suppose we need 1 second for each training step pass # Estimated time for training: (5*2+5*0)*3 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) import time # Simulation of data preparation def generator (): for i in range ( 5 ): # Suppose we need 2 seconds for each preparation time . sleep ( 2 ) yield i # Use the method \"cache\" to cache the data into the memory, only for dataset with small volume. ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) . cache () # Simulation of parameter iteration def train_step (): # Suppose each training step needs 0 second time . sleep ( 0 ) # Estimated time for training: (5*2+5*0)+(5*0+5*0)*2 = 10s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) 3.5 When converting with map , batch the data first, and then convert each batch with vecterization. # Map first, then batch ds = tf . data . Dataset . range ( 100000 ) ds_map_batch = ds . map ( lambda x : x ** 2 ) . batch ( 20 ) printbar () tf . print ( tf . constant ( \"start scalar transformation...\" )) for x in ds_map_batch : pass printbar () tf . print ( tf . constant ( \"end scalar transformation...\" )) # Batch first, then map ds = tf . data . Dataset . range ( 100000 ) ds_batch_map = ds . batch ( 20 ) . map ( lambda x : x ** 2 ) printbar () tf . print ( tf . constant ( \"start vector transformation...\" )) for x in ds_batch_map : pass printbar () tf . print ( tf . constant ( \"end vector transformation...\" )) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-1 Dataset"},{"location":"english/Chapter5/Chapter5-1/#5-1-dataset","text":"All the data could be read into memory for training to maximize the efficiency, if the volume of training data is small (e.g. < 1 GB) However, if the data volume is huge (e.g. > 10 GB) which is not possible to load everything into the memory, they should be devided into batches before reading. The API tf.data constructs input data pipeline to help manage huge volume of data with various formats and conversions.","title":"5-1 Dataset"},{"location":"english/Chapter5/Chapter5-1/#1-constructing-data-pipeline","text":"Data pipeline could be constructed through following methods: numpy array, pandas DataFrame, Python generator, csv file, text file, file path, tfrecords file. Among these methods, the most popular ones are: numpy array, pandas DataFrame and file path. The drawback of using tfrecords file to construct data pipelines is its complication, since it requires: (a) construct tf.Example from samples; (b) compress tf.Example into string and write it to tfrecords file; \u00a9 when using these data, the tfrecords file have to be read and analyzed into tf.Example . On the other hand, the advantage of using tfrecords files is its small volume after compression, its convenient sharing through the Internet, and the fast speed of loading. 1.1 Constructing Data Pipeline through Numpy Array # Constructing Data Pipeline through Numpy Array import tensorflow as tf import numpy as np from sklearn import datasets iris = datasets . load_iris () ds1 = tf . data . Dataset . from_tensor_slices (( iris [ \"data\" ], iris [ \"target\" ])) for features , label in ds1 . take ( 5 ): print ( features , label ) tf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.9 3. 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor([5. 3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64) 1.2 Constructing Data Pipeline through Pandas DataFrame # Constructing Data Pipeline through Pandas DataFrame import tensorflow as tf from sklearn import datasets import pandas as pd iris = datasets . load_iris () dfiris = pd . DataFrame ( iris [ \"data\" ], columns = iris . feature_names ) ds2 = tf . data . Dataset . from_tensor_slices (( dfiris . to_dict ( \"list\" ), iris [ \"target\" ])) for features , label in ds2 . take ( 3 ): print ( features , label ) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) {'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64) 1.3 Constructing Data Pipeline through Python generator # Constructing Data Pipeline through Python generator import tensorflow as tf from matplotlib import pyplot as plt from tensorflow.keras.preprocessing.image import ImageDataGenerator # Defining a generator to read image from a folder image_generator = ImageDataGenerator ( rescale = 1.0 / 255 ) . flow_from_directory ( \"../../data/cifar2/test/\" , target_size = ( 32 , 32 ), batch_size = 20 , class_mode = 'binary' ) classdict = image_generator . class_indices print ( classdict ) def generator (): for features , label in image_generator : yield ( features , label ) ds3 = tf . data . Dataset . from_generator ( generator , output_types = ( tf . float32 , tf . int32 )) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds3 . unbatch () . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 1.4 Constructing Data Pipeline through csv file # Constructing Data Pipeline through csv file ds4 = tf . data . experimental . make_csv_dataset ( file_pattern = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ], batch_size = 3 , label_name = \"Survived\" , na_value = \"\" , num_epochs = 1 , ignore_errors = True ) for data , label in ds4 . take ( 2 ): print ( data , label ) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([540, 58, 764], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 1], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Frolicher, Miss. Hedwig Margaritha', b'Novel, Mr. Mansouer', b'Carter, Mrs. William Ernest (Lucile Polk)'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'female', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([22. , 28.5, 36. ], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 2], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'13568', b'2697', b'113760'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 49.5 , 7.2292, 120. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'B39', b'', b'B96 B98'], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'C', b'C', b'S'], dtype=object)>)]) tf.Tensor([1 0 1], shape=(3,), dtype=int32) OrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([845, 66, 390], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 2], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy= array([b'Culumovic, Mr. Jeso', b'Moubarek, Master. Gerios', b'Lehmann, Miss. Bertha'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([17., 0., 17.], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'315090', b'2661', b'SC 1748'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8.6625, 15.2458, 12. ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'', b'', b''], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'C', b'C'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32) 1.5 Constructing Data Pipeline through text file # Constructing Data Pipeline through text file ds5 = tf . data . TextLineDataset ( filenames = [ \"../../data/titanic/train.csv\" , \"../../data/titanic/test.csv\" ] ) . skip ( 1 ) # Omitting the header on the first line for line in ds5 . take ( 5 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) tf.Tensor(b'687,0,3,\"Panula, Mr. Jaako Arnold\",male,14.0,4,1,3101295,39.6875,,S', shape=(), dtype=string) 1.6 Constructing Data Pipeline through file path ds6 = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) for file in ds6 . take ( 5 ): print ( file ) tf.Tensor(b'../../data/cifar2/train/automobile/1263.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/2837.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/airplane/4264.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/4241.jpg', shape=(), dtype=string) tf.Tensor(b'../../data/cifar2/train/automobile/192.jpg', shape=(), dtype=string) from matplotlib import pyplot as plt def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) # Note that we are using jpeg format img = tf . image . resize ( img , size ) return ( img , label ) % matplotlib inline % config InlineBackend . figure_format = 'svg' for i ,( img , label ) in enumerate ( ds6 . map ( load_image ) . take ( 2 )): plt . figure ( i ) plt . imshow (( img / 255.0 ) . numpy ()) plt . title ( \"label = %d \" % label ) plt . xticks ([]) plt . yticks ([]) 1.7 Constructing Data Pipeline through tfrecords file import os import numpy as np # inpath is the original data path; outpath: output path of the TFRecord file def create_tfrecords ( inpath , outpath ): writer = tf . io . TFRecordWriter ( outpath ) dirs = os . listdir ( inpath ) for index , name in enumerate ( dirs ): class_path = inpath + \"/\" + name + \"/\" for img_name in os . listdir ( class_path ): img_path = class_path + img_name img = tf . io . read_file ( img_path ) #img = tf.image.decode_image(img) #img = tf.image.encode_jpeg(img) # Use jpeg format for all the compressions example = tf . train . Example ( features = tf . train . Features ( feature = { 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = [ index ])), 'img_raw' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ img . numpy ()])) })) writer . write ( example . SerializeToString ()) writer . close () create_tfrecords ( \"../../data/cifar2/test/\" , \"../../data/cifar2_test.tfrecords/\" ) from matplotlib import pyplot as plt def parse_example ( proto ): description = { 'img_raw' : tf . io . FixedLenFeature ([], tf . string ), 'label' : tf . io . FixedLenFeature ([], tf . int64 )} example = tf . io . parse_single_example ( proto , description ) img = tf . image . decode_jpeg ( example [ \"img_raw\" ]) # Note that we are using jpeg format img = tf . image . resize ( img , ( 32 , 32 )) label = example [ \"label\" ] return ( img , label ) ds7 = tf . data . TFRecordDataset ( \"../../data/cifar2_test.tfrecords\" ) . map ( parse_example ) . shuffle ( 3000 ) % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 6 , 6 )) for i ,( img , label ) in enumerate ( ds7 . take ( 9 )): ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow (( img / 255.0 ) . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show ()","title":"1. Constructing Data Pipeline"},{"location":"english/Chapter5/Chapter5-1/#2-applying-data-conversion","text":"Dataset is very flexible in the application of data structure. Essentially it is a sequence with elements in various data types, such as tensor, list, dictionary and Dataset. Dataset contains many functions of data conversion. map : projecting the conversion function to every element in the dataset. flat_map : projecting the conversion function to every element in the dataset, and flatten the embedded Dataset. interleave : similar as flat_map but interleaves the data from different sources. filter : filter certain elements. zip : zipping two Datasets with the same length. concatenate : concatenating two Datasets. reduce : executing operation of reducing. batch : constructing batches and release one batch each time; there will be one more rank comparing to the original data; the inverse operation is unbatch . padded_batch : constructing batches, similar as batch , but can achieve padded shape. window : constructing sliding window, and return Dataset of Dataset. shuffle : shuffling the order of the data. repeat : repeat the data certain times; if no argument is specified, repeat data with infinitive times. shard : sampling the elements starting from a certain position with fixed distance. take : sampling the first few elements from a certain position. #map: projecting the conversion function to every element in the dataset. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_map = ds . map ( lambda x : tf . strings . split ( x , \" \" )) for x in ds_map : print ( x ) tf.Tensor([b'hello' b'world'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'China'], shape=(2,), dtype=string) tf.Tensor([b'hello' b'Beijing'], shape=(2,), dtype=string) #flat_map: projecting the conversion function to every element in the dataset, and flatten the embedded Dataset. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_flatmap = ds . flat_map ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_flatmap : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) # interleave: similar as `flat_map` but interleaves the data from different sources. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) ds_interleave = ds . interleave ( lambda x : tf . data . Dataset . from_tensor_slices ( tf . strings . split ( x , \" \" ))) for x in ds_interleave : print ( x ) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'hello', shape=(), dtype=string) tf.Tensor(b'world', shape=(), dtype=string) tf.Tensor(b'China', shape=(), dtype=string) tf.Tensor(b'Beijing', shape=(), dtype=string) #filter: filter certain elements. ds = tf . data . Dataset . from_tensor_slices ([ \"hello world\" , \"hello China\" , \"hello Beijing\" ]) # Find the element with letter'a' or 'B' ds_filter = ds . filter ( lambda x : tf . strings . regex_full_match ( x , \".*[a|B].*\" )) for x in ds_filter : print ( x ) tf.Tensor(b'hello China', shape=(), dtype=string) tf.Tensor(b'hello Beijing', shape=(), dtype=string) #zip: zipping two Datasets with the same length. ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds3 = tf . data . Dataset . range ( 6 , 9 ) ds_zip = tf . data . Dataset . zip (( ds1 , ds2 , ds3 )) for x , y , z in ds_zip : print ( x . numpy (), y . numpy (), z . numpy ()) 0 3 6 1 4 7 2 5 8 #condatenate: concatenating two Datasets. ds1 = tf . data . Dataset . range ( 0 , 3 ) ds2 = tf . data . Dataset . range ( 3 , 6 ) ds_concat = tf . data . Dataset . concatenate ( ds1 , ds2 ) for x in ds_concat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) #reduce: executing operation of reducing. ds = tf . data . Dataset . from_tensor_slices ([ 1 , 2 , 3 , 4 , 5.0 ]) result = ds . reduce ( 0.0 , lambda x , y : tf . add ( x , y )) result <tf.Tensor: shape=(), dtype=float32, numpy=15.0> #batch: constructing batches and release one batch each time; there will be one more rank comparing to the original data; the inverse operation is `unbatch`. ds = tf . data . Dataset . range ( 12 ) ds_batch = ds . batch ( 4 ) for x in ds_batch : print ( x ) tf.Tensor([0 1 2 3], shape=(4,), dtype=int64) tf.Tensor([4 5 6 7], shape=(4,), dtype=int64) tf.Tensor([ 8 9 10 11], shape=(4,), dtype=int64) #padded_batch: constructing batches, similar as `batch`, but can achieve padded shape. elements = [[ 1 , 2 ],[ 3 , 4 , 5 ],[ 6 , 7 ],[ 8 ]] ds = tf . data . Dataset . from_generator ( lambda : iter ( elements ), tf . int32 ) ds_padded_batch = ds . padded_batch ( 2 , padded_shapes = [ 4 ,]) for x in ds_padded_batch : print ( x ) tf.Tensor( [[1 2 0 0] [3 4 5 0]], shape=(2, 4), dtype=int32) tf.Tensor( [[6 7 0 0] [8 0 0 0]], shape=(2, 4), dtype=int32) #window: constructing sliding window, and return Dataset of Dataset. ds = tf . data . Dataset . range ( 12 ) # window returns Dataset of Dataset, which could be flattened by flat_map ds_window = ds . window ( 3 , shift = 1 ) . flat_map ( lambda x : x . batch ( 3 , drop_remainder = True )) for x in ds_window : print ( x ) tf.Tensor([0 1 2], shape=(3,), dtype=int64) tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([2 3 4], shape=(3,), dtype=int64) tf.Tensor([3 4 5], shape=(3,), dtype=int64) tf.Tensor([4 5 6], shape=(3,), dtype=int64) tf.Tensor([5 6 7], shape=(3,), dtype=int64) tf.Tensor([6 7 8], shape=(3,), dtype=int64) tf.Tensor([7 8 9], shape=(3,), dtype=int64) tf.Tensor([ 8 9 10], shape=(3,), dtype=int64) tf.Tensor([ 9 10 11], shape=(3,), dtype=int64) #shuffle: shuffling the order of the data. ds = tf . data . Dataset . range ( 12 ) ds_shuffle = ds . shuffle ( buffer_size = 5 ) for x in ds_shuffle : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(6, shape=(), dtype=int64) tf.Tensor(5, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(11, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(9, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) tf.Tensor(8, shape=(), dtype=int64) #repeat: repeat the data certain times; if no argument is specified, repeat data with infinitive times. ds = tf . data . Dataset . range ( 3 ) ds_repeat = ds . repeat ( 3 ) for x in ds_repeat : print ( x ) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64) #shard: sampling the elements starting from a certain position with fixed distance. ds = tf . data . Dataset . range ( 12 ) ds_shard = ds . shard ( 3 , index = 1 ) for x in ds_shard : print ( x ) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64) #take: sampling the first few elements from a certain position. ds = tf . data . Dataset . range ( 12 ) ds_take = ds . take ( 3 ) list ( ds_take . as_numpy_iterator ()) [0, 1, 2]","title":"2. Applying Data Conversion"},{"location":"english/Chapter5/Chapter5-1/#3-enhance-the-efficiency-of-the-pipeline","text":"The training of deep learning model could be lengthy. The consumed time is mainly consists of two parts: data preparation and parameter iteration . The efficiency of parameter iteration is ususlly enhanced by GPU. The efficiency of data preparation could be improved by constructing high-efficiency data pipeline. Below are several suggestions of constructing high-efficiency data pipeline: 1, Paralleling the data preparation and the parameter iteration using method prefetch . 2, Use the method interleave to read data with multi-process and interleave the data from different sources. 3, Set num_parallel_calls during using map , allowing data conversion with multiple process. 4, Apply method cache to cache data into the memory after the first epoch for the case with a small data volume. 5, When converting with map , batch the data first, and then convert each batch with vecterization. 3.1 Paralleling the data preparation and the parameter iteration using method prefetch . import tensorflow as tf # Time stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) import time # Data preparation and parameter iteration is serial as default. # Simulation of data preparation def generator (): for i in range ( 10 ): # Suppose we need 2 seconds for each preparation time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # Simulation of parameter iteration def train_step (): # Suppose we need 1 seconds for each training step time . sleep ( 1 ) # Estimated time of training: 10*2+10*1 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for x in ds : train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) # Use method prefetch to parallel the processes of data preparation and parameter iteration. # Estimated time of training: max(10*2,10*1) = 20s printbar () tf . print ( tf . constant ( \"start training with prefetch...\" )) # tf.data.experimental.AUTOTUNE allows auto-selection of parameters for x in ds . prefetch ( buffer_size = tf . data . experimental . AUTOTUNE ): train_step () printbar () tf . print ( tf . constant ( \"end training...\" )) 3.2 Use the method interleave to read data with multi-process and interleave the data from different sources. ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . flat_map ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 4 ): print ( line ) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) ds_files = tf . data . Dataset . list_files ( \"../../data/titanic/*.csv\" ) ds = ds_files . interleave ( lambda x : tf . data . TextLineDataset ( x ) . skip ( 1 )) for line in ds . take ( 8 ): print ( line ) tf.Tensor(b'181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S', shape=(), dtype=string) tf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string) tf.Tensor(b'405,0,3,\"Oreskovic, Miss. Marija\",female,20.0,0,0,315096,8.6625,,S', shape=(), dtype=string) tf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string) tf.Tensor(b'635,0,3,\"Skoog, Miss. Mabel\",female,9.0,3,2,347088,27.9,,S', shape=(), dtype=string) tf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string) tf.Tensor(b'701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18.0,1,0,PC 17757,227.525,C62 C64,C', shape=(), dtype=string) tf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string) 3.3 Set num_parallel_calls during using map , allowing data conversion with multiple process. ds = tf . data . Dataset . list_files ( \"../../data/cifar2/train/*/*.jpg\" ) def load_image ( img_path , size = ( 32 , 32 )): label = 1 if tf . strings . regex_full_match ( img_path , \".*/automobile/.*\" ) else 0 img = tf . io . read_file ( img_path ) img = tf . image . decode_jpeg ( img ) #Note: jpeg format here img = tf . image . resize ( img , size ) return ( img , label ) # Conversion with single process printbar () tf . print ( tf . constant ( \"start transformation...\" )) ds_map = ds . map ( load_image ) for _ in ds_map : pass printbar () tf . print ( tf . constant ( \"end transformation...\" )) # Conversion with multi-process printbar () tf . print ( tf . constant ( \"start parallel transformation...\" )) ds_map_parallel = ds . map ( load_image , num_parallel_calls = tf . data . experimental . AUTOTUNE ) for _ in ds_map_parallel : pass printbar () tf . print ( tf . constant ( \"end parallel transformation...\" )) 3.4 Apply method cache to cache data into the memory after the first epoch for the case with a small data volume. import time # Simulation of data preparation def generator (): for i in range ( 5 ): # Suppose we need 2 seconds for each preparation time . sleep ( 2 ) yield i ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) # Simulation of parameter iteration\u6a21\u62df\u53c2\u6570\u8fed\u4ee3 def train_step (): # Suppose we need 1 second for each training step pass # Estimated time for training: (5*2+5*0)*3 = 30s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) import time # Simulation of data preparation def generator (): for i in range ( 5 ): # Suppose we need 2 seconds for each preparation time . sleep ( 2 ) yield i # Use the method \"cache\" to cache the data into the memory, only for dataset with small volume. ds = tf . data . Dataset . from_generator ( generator , output_types = ( tf . int32 )) . cache () # Simulation of parameter iteration def train_step (): # Suppose each training step needs 0 second time . sleep ( 0 ) # Estimated time for training: (5*2+5*0)+(5*0+5*0)*2 = 10s printbar () tf . print ( tf . constant ( \"start training...\" )) for epoch in tf . range ( 3 ): for x in ds : train_step () printbar () tf . print ( \"epoch =\" , epoch , \" ended\" ) printbar () tf . print ( tf . constant ( \"end training...\" )) 3.5 When converting with map , batch the data first, and then convert each batch with vecterization. # Map first, then batch ds = tf . data . Dataset . range ( 100000 ) ds_map_batch = ds . map ( lambda x : x ** 2 ) . batch ( 20 ) printbar () tf . print ( tf . constant ( \"start scalar transformation...\" )) for x in ds_map_batch : pass printbar () tf . print ( tf . constant ( \"end scalar transformation...\" )) # Batch first, then map ds = tf . data . Dataset . range ( 100000 ) ds_batch_map = ds . batch ( 20 ) . map ( lambda x : x ** 2 ) printbar () tf . print ( tf . constant ( \"start vector transformation...\" )) for x in ds_batch_map : pass printbar () tf . print ( tf . constant ( \"end vector transformation...\" )) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. Enhance the Efficiency of the Pipeline"},{"location":"english/Chapter5/Chapter5-2/","text":"5-2 feature_column # Feature column is usually applied in the feature engineering for the structured data, while rarely used for the image or text date. 1. Introduction about how to use feature column # Feature column is used to converting category features into one-hot encoding, or creating bucketing feature from continuous feature, or generating cross features from multiple features, etc. Before creating feature column, please call the functions in the module tf.feature_column . The nine most frequently used functions in this module are shown in the figure below. All these functions will return a Categorical-Column or a Dense-Column object, but will not return bucketized_column, since the last class is inhereted from the first two classes. Be careful: all the Categorical-Column class have to be converted into Dense-Column class through indicator_column before input to the model. numeric_column , the most frequently used function. bucketized_column , generated from numerical column, listing multiple features from a numerical clumn; it is one-hot encoded. categorical_column_with_identity , one-hot encoded, identical to the case that each bucket is one interger. categorical_column_with_vocabulary_list , one-hot encoded; the dictionary is specified by the list. categorical_column_with_vocabulary_file \uff0c one-hot encoded; the dictionary is specified by the file. categorical_column_with_hash_bucket , used in the case with a large interger or a large dictionary. indicator_column , generated by Categorical-Column; one-hot encoded. embedding_column , generated by Categorical Column; the embedded vector distributed parameter needs learning/training. The recommended dimension of the embedded vector is the fourth root to the number of categories. crossed_column , consists of arbitrary category column except for categorical_column_with_hash_bucket 2. Demonstration of feature column # Here is a complete example that solves Titanic survival problmen using feature column. import datetime import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , models # Printing log def printlog ( info ): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( info + '... \\n\\n ' ) #================================================================================ # 1. Constructing data pipeline #================================================================================ printlog ( \"step1: prepare dataset...\" ) dftrain_raw = pd . read_csv ( \"../../data/titanic/train.csv\" ) dftest_raw = pd . read_csv ( \"../../data/titanic/test.csv\" ) dfraw = pd . concat ([ dftrain_raw , dftest_raw ]) def prepare_dfdata ( dfraw ): dfdata = dfraw . copy () dfdata . columns = [ x . lower () for x in dfdata . columns ] dfdata = dfdata . rename ( columns = { 'survived' : 'label' }) dfdata = dfdata . drop ([ 'passengerid' , 'name' ], axis = 1 ) for col , dtype in dict ( dfdata . dtypes ) . items (): # See if there are missing values. if dfdata [ col ] . hasnans : # Adding signs to the missing columns dfdata [ col + '_nan' ] = pd . isna ( dfdata [ col ]) . astype ( 'int32' ) # Fill if dtype not in [ np . object , np . str , np . unicode ]: dfdata [ col ] . fillna ( dfdata [ col ] . mean (), inplace = True ) else : dfdata [ col ] . fillna ( '' , inplace = True ) return ( dfdata ) dfdata = prepare_dfdata ( dfraw ) dftrain = dfdata . iloc [ 0 : len ( dftrain_raw ),:] dftest = dfdata . iloc [ len ( dftrain_raw ):,:] # Importing data from dataframe def df_to_dataset ( df , shuffle = True , batch_size = 32 ): dfdata = df . copy () if 'label' not in dfdata . columns : ds = tf . data . Dataset . from_tensor_slices ( dfdata . to_dict ( orient = 'list' )) else : labels = dfdata . pop ( 'label' ) ds = tf . data . Dataset . from_tensor_slices (( dfdata . to_dict ( orient = 'list' ), labels )) if shuffle : ds = ds . shuffle ( buffer_size = len ( dfdata )) ds = ds . batch ( batch_size ) return ds ds_train = df_to_dataset ( dftrain ) ds_test = df_to_dataset ( dftest ) #================================================================================ # 2. Defining the feature column #================================================================================ printlog ( \"step2: make feature columns...\" ) feature_columns = [] # Numerical column for col in [ 'age' , 'fare' , 'parch' , 'sibsp' ] + [ c for c in dfdata . columns if c . endswith ( '_nan' )]: feature_columns . append ( tf . feature_column . numeric_column ( col )) # Bucketized column age = tf . feature_column . numeric_column ( 'age' ) age_buckets = tf . feature_column . bucketized_column ( age , boundaries = [ 18 , 25 , 30 , 35 , 40 , 45 , 50 , 55 , 60 , 65 ]) feature_columns . append ( age_buckets ) # Category column # NOTE: all the Categorical-Column class have to be converted into Dense-Column class through `indicator_column` before input to the model. sex = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'sex' , vocabulary_list = [ \"male\" , \"female\" ])) feature_columns . append ( sex ) pclass = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ])) feature_columns . append ( pclass ) ticket = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'ticket' , 3 )) feature_columns . append ( ticket ) embarked = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'embarked' , vocabulary_list = [ 'S' , 'C' , 'B' ])) feature_columns . append ( embarked ) # Embedding column cabin = tf . feature_column . embedding_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'cabin' , 32 ), 2 ) feature_columns . append ( cabin ) # Crossed column pclass_cate = tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ]) crossed_feature = tf . feature_column . indicator_column ( tf . feature_column . crossed_column ([ age_buckets , pclass_cate ], hash_bucket_size = 15 )) feature_columns . append ( crossed_feature ) #================================================================================ # 3. Defining the model #================================================================================ printlog ( \"step3: define model...\" ) tf . keras . backend . clear_session () model = tf . keras . Sequential ([ layers . DenseFeatures ( feature_columns ), # Placing the feature into tf.keras.layers.DenseFeatures layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 1 , activation = 'sigmoid' ) ]) #================================================================================ # 4. Training the model #================================================================================ printlog ( \"step4: train model...\" ) model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' ]) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) #================================================================================ # 5. Evaluating the model #================================================================================ printlog ( \"step5: eval model...\" ) model . summary () % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"accuracy\" ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_features (DenseFeature multiple 64 _________________________________________________________________ dense (Dense) multiple 3008 _________________________________________________________________ dense_1 (Dense) multiple 4160 _________________________________________________________________ dense_2 (Dense) multiple 65 ================================================================= Total params: 7,297 Trainable params: 7,297 Non-trainable params: 0 _________________________________________________________________ Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-2 feature_column"},{"location":"english/Chapter5/Chapter5-2/#5-2-feature_column","text":"Feature column is usually applied in the feature engineering for the structured data, while rarely used for the image or text date.","title":"5-2 feature_column"},{"location":"english/Chapter5/Chapter5-2/#1-introduction-about-how-to-use-feature-column","text":"Feature column is used to converting category features into one-hot encoding, or creating bucketing feature from continuous feature, or generating cross features from multiple features, etc. Before creating feature column, please call the functions in the module tf.feature_column . The nine most frequently used functions in this module are shown in the figure below. All these functions will return a Categorical-Column or a Dense-Column object, but will not return bucketized_column, since the last class is inhereted from the first two classes. Be careful: all the Categorical-Column class have to be converted into Dense-Column class through indicator_column before input to the model. numeric_column , the most frequently used function. bucketized_column , generated from numerical column, listing multiple features from a numerical clumn; it is one-hot encoded. categorical_column_with_identity , one-hot encoded, identical to the case that each bucket is one interger. categorical_column_with_vocabulary_list , one-hot encoded; the dictionary is specified by the list. categorical_column_with_vocabulary_file \uff0c one-hot encoded; the dictionary is specified by the file. categorical_column_with_hash_bucket , used in the case with a large interger or a large dictionary. indicator_column , generated by Categorical-Column; one-hot encoded. embedding_column , generated by Categorical Column; the embedded vector distributed parameter needs learning/training. The recommended dimension of the embedded vector is the fourth root to the number of categories. crossed_column , consists of arbitrary category column except for categorical_column_with_hash_bucket","title":"1. Introduction about how to use feature column"},{"location":"english/Chapter5/Chapter5-2/#2-demonstration-of-feature-column","text":"Here is a complete example that solves Titanic survival problmen using feature column. import datetime import numpy as np import pandas as pd from matplotlib import pyplot as plt import tensorflow as tf from tensorflow.keras import layers , models # Printing log def printlog ( info ): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( info + '... \\n\\n ' ) #================================================================================ # 1. Constructing data pipeline #================================================================================ printlog ( \"step1: prepare dataset...\" ) dftrain_raw = pd . read_csv ( \"../../data/titanic/train.csv\" ) dftest_raw = pd . read_csv ( \"../../data/titanic/test.csv\" ) dfraw = pd . concat ([ dftrain_raw , dftest_raw ]) def prepare_dfdata ( dfraw ): dfdata = dfraw . copy () dfdata . columns = [ x . lower () for x in dfdata . columns ] dfdata = dfdata . rename ( columns = { 'survived' : 'label' }) dfdata = dfdata . drop ([ 'passengerid' , 'name' ], axis = 1 ) for col , dtype in dict ( dfdata . dtypes ) . items (): # See if there are missing values. if dfdata [ col ] . hasnans : # Adding signs to the missing columns dfdata [ col + '_nan' ] = pd . isna ( dfdata [ col ]) . astype ( 'int32' ) # Fill if dtype not in [ np . object , np . str , np . unicode ]: dfdata [ col ] . fillna ( dfdata [ col ] . mean (), inplace = True ) else : dfdata [ col ] . fillna ( '' , inplace = True ) return ( dfdata ) dfdata = prepare_dfdata ( dfraw ) dftrain = dfdata . iloc [ 0 : len ( dftrain_raw ),:] dftest = dfdata . iloc [ len ( dftrain_raw ):,:] # Importing data from dataframe def df_to_dataset ( df , shuffle = True , batch_size = 32 ): dfdata = df . copy () if 'label' not in dfdata . columns : ds = tf . data . Dataset . from_tensor_slices ( dfdata . to_dict ( orient = 'list' )) else : labels = dfdata . pop ( 'label' ) ds = tf . data . Dataset . from_tensor_slices (( dfdata . to_dict ( orient = 'list' ), labels )) if shuffle : ds = ds . shuffle ( buffer_size = len ( dfdata )) ds = ds . batch ( batch_size ) return ds ds_train = df_to_dataset ( dftrain ) ds_test = df_to_dataset ( dftest ) #================================================================================ # 2. Defining the feature column #================================================================================ printlog ( \"step2: make feature columns...\" ) feature_columns = [] # Numerical column for col in [ 'age' , 'fare' , 'parch' , 'sibsp' ] + [ c for c in dfdata . columns if c . endswith ( '_nan' )]: feature_columns . append ( tf . feature_column . numeric_column ( col )) # Bucketized column age = tf . feature_column . numeric_column ( 'age' ) age_buckets = tf . feature_column . bucketized_column ( age , boundaries = [ 18 , 25 , 30 , 35 , 40 , 45 , 50 , 55 , 60 , 65 ]) feature_columns . append ( age_buckets ) # Category column # NOTE: all the Categorical-Column class have to be converted into Dense-Column class through `indicator_column` before input to the model. sex = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'sex' , vocabulary_list = [ \"male\" , \"female\" ])) feature_columns . append ( sex ) pclass = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ])) feature_columns . append ( pclass ) ticket = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'ticket' , 3 )) feature_columns . append ( ticket ) embarked = tf . feature_column . indicator_column ( tf . feature_column . categorical_column_with_vocabulary_list ( key = 'embarked' , vocabulary_list = [ 'S' , 'C' , 'B' ])) feature_columns . append ( embarked ) # Embedding column cabin = tf . feature_column . embedding_column ( tf . feature_column . categorical_column_with_hash_bucket ( 'cabin' , 32 ), 2 ) feature_columns . append ( cabin ) # Crossed column pclass_cate = tf . feature_column . categorical_column_with_vocabulary_list ( key = 'pclass' , vocabulary_list = [ 1 , 2 , 3 ]) crossed_feature = tf . feature_column . indicator_column ( tf . feature_column . crossed_column ([ age_buckets , pclass_cate ], hash_bucket_size = 15 )) feature_columns . append ( crossed_feature ) #================================================================================ # 3. Defining the model #================================================================================ printlog ( \"step3: define model...\" ) tf . keras . backend . clear_session () model = tf . keras . Sequential ([ layers . DenseFeatures ( feature_columns ), # Placing the feature into tf.keras.layers.DenseFeatures layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 64 , activation = 'relu' ), layers . Dense ( 1 , activation = 'sigmoid' ) ]) #================================================================================ # 4. Training the model #================================================================================ printlog ( \"step4: train model...\" ) model . compile ( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' ]) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) #================================================================================ # 5. Evaluating the model #================================================================================ printlog ( \"step5: eval model...\" ) model . summary () % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"accuracy\" ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_features (DenseFeature multiple 64 _________________________________________________________________ dense (Dense) multiple 3008 _________________________________________________________________ dense_1 (Dense) multiple 4160 _________________________________________________________________ dense_2 (Dense) multiple 65 ================================================================= Total params: 7,297 Trainable params: 7,297 Non-trainable params: 0 _________________________________________________________________ Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Demonstration of feature column"},{"location":"english/Chapter5/Chapter5-3/","text":"5-3 activation # Activation function plays a key role in deep learning. It introduces the nonlinearity that enables the neural network to fit arbitrary complicated functions. The neural network, no matter how complicated the structure is, is still a linear transformation which cannot fit the nonlinear functions without the activation function. For the time being, the most popular activation function is relu , but there are some new functions such as swish , GELU , claiming a better performance over relu . Here are two review papers to the activation function (in Chinese). \u300a\u4e00\u6587\u6982\u89c8\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b \u300a\u4eceReLU\u5230GELU,\u4e00\u6587\u6982\u89c8\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b 1. The most popular activation functions # tf.nn.sigmoid : Compressing real number between 0 to 1, usually used in the output layer for binary classification; the main drawbacks are vanishing gradient, high computing complexity, and the non-zero center of the output. tf.nn.softmax : Extended version of sigmoid for multiple categories, usually used in the output layer for multiple classifications. tf.nn.tanh \uff1aCompressing real number between -1 to 1, expectation of the output is zero; the main drawbacks are vanishing gradient and high computing complexity. tf.nn.relu \uff1aLinear rectified unit, the most popular activation function, usually used in the hidden layer; the main drawbacks are non-zero center of the output and vanishing gradient for the inputs < 0 (dying relu). tf.nn.leaky_relu \uff1aImproved ReLU, resolving the dying ReLU problem. tf.nn.elu \uff1aExponential linear unit, which is an improvement to the ReLU, alleviate the dying ReLU problem. tf.nn.selu \uff1aScaled exponential linear unit, which is able to normalize the neural network automatically if the weights are initialized through tf.keras.initializers.lecun_normal . No gradient exploding/vanishing problems, but need to apply together with AlphaDropout (an alternation of Dropout). tf.nn.swish \uff1aSelf-gated activation function, a research product form Google. The literature prove that it brings slight improvement comparing to ReLU. gelu \uff1aGaussian error linear unit, which has the best performance in Transformer; however tf.nn hasn't implemented it. 2. Implementing activation functions in the models # There are two ways of implementing activation functions in Keras models: specifying through the activation parameter in certain layers, or adding activation layer layers.Activation explicitly. import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 32 , input_shape = ( None , 16 ), activation = tf . nn . relu )) # Specifying through the activation parameter model . add ( layers . Dense ( 10 )) model . add ( layers . Activation ( tf . nn . softmax )) # adding `layers.Activation` explicitly. model . summary () Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-3 activation"},{"location":"english/Chapter5/Chapter5-3/#5-3-activation","text":"Activation function plays a key role in deep learning. It introduces the nonlinearity that enables the neural network to fit arbitrary complicated functions. The neural network, no matter how complicated the structure is, is still a linear transformation which cannot fit the nonlinear functions without the activation function. For the time being, the most popular activation function is relu , but there are some new functions such as swish , GELU , claiming a better performance over relu . Here are two review papers to the activation function (in Chinese). \u300a\u4e00\u6587\u6982\u89c8\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b \u300a\u4eceReLU\u5230GELU,\u4e00\u6587\u6982\u89c8\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u300b","title":"5-3 activation"},{"location":"english/Chapter5/Chapter5-3/#1-the-most-popular-activation-functions","text":"tf.nn.sigmoid : Compressing real number between 0 to 1, usually used in the output layer for binary classification; the main drawbacks are vanishing gradient, high computing complexity, and the non-zero center of the output. tf.nn.softmax : Extended version of sigmoid for multiple categories, usually used in the output layer for multiple classifications. tf.nn.tanh \uff1aCompressing real number between -1 to 1, expectation of the output is zero; the main drawbacks are vanishing gradient and high computing complexity. tf.nn.relu \uff1aLinear rectified unit, the most popular activation function, usually used in the hidden layer; the main drawbacks are non-zero center of the output and vanishing gradient for the inputs < 0 (dying relu). tf.nn.leaky_relu \uff1aImproved ReLU, resolving the dying ReLU problem. tf.nn.elu \uff1aExponential linear unit, which is an improvement to the ReLU, alleviate the dying ReLU problem. tf.nn.selu \uff1aScaled exponential linear unit, which is able to normalize the neural network automatically if the weights are initialized through tf.keras.initializers.lecun_normal . No gradient exploding/vanishing problems, but need to apply together with AlphaDropout (an alternation of Dropout). tf.nn.swish \uff1aSelf-gated activation function, a research product form Google. The literature prove that it brings slight improvement comparing to ReLU. gelu \uff1aGaussian error linear unit, which has the best performance in Transformer; however tf.nn hasn't implemented it.","title":"1. The most popular activation functions"},{"location":"english/Chapter5/Chapter5-3/#2-implementing-activation-functions-in-the-models","text":"There are two ways of implementing activation functions in Keras models: specifying through the activation parameter in certain layers, or adding activation layer layers.Activation explicitly. import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 32 , input_shape = ( None , 16 ), activation = tf . nn . relu )) # Specifying through the activation parameter model . add ( layers . Dense ( 10 )) model . add ( layers . Activation ( tf . nn . softmax )) # adding `layers.Activation` explicitly. model . summary () Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Implementing activation functions in the models"},{"location":"english/Chapter5/Chapter5-4/","text":"5-4 layers # The deep learning model usually consists of various layers. tf.keras.layers contains a large amount of models with various functions, such as: layers.Dense , layers.Flatten , layers.Input , layers.DenseFeature , layers.Dropout layers.Conv2D , layers.MaxPooling2D , layers.Conv1D layers.Embedding , layers.GRU , layers.LSTM , layers.Bidirectional , etc. In case these pre-defined layers are insufficient for modeling, the users are able to write anonymous layer tf.keras.Lambda or write customized layer through inheriting tf.keras.layers.Layer . Note that tf.keras.Lambda is only for the layers without any trainable parameter. 1. Pre-defined Layer # Here are the introductions for the most popular layers. Fundamental layers Dense: Densely connected layer. # of parameters = # of features of the input layer \u00d7 # of weight + # of bias. Activation: Activation function layer. Usually placed after the Dense layer for specify the activation function in the Dense layer. Dropout: Dropout layer. Setting the inputs as zero randomly during the training stage, which is a method of regularization. BatchNormalization:Layer for batch normalization. It scale and translate the batches into stable mean and standad deviation through linear transformation. This lead to the model adaptive to the various distribution of the input, which is mild regularization that accelerates training. This layer is usually applied before the activation function. SpatialDropout2D:Spatial dropout layer. Setting the whole feature map into zero with certain possibilities during training, which is a regularization to avoid high correlation between feature maps. Input:Input layer. Usually it is the first layer when modelling through functional API. DenseFeature:Layer that provides connection to the feature columns, which is used to accept a list of feature columns and generate a densely connected layer. Flatten:Flatten layer, used for flattening multi-dimensional tensor into one-dimension. Reshape:Reshape layer, reform the shape of the input tensor. Concatenate:Concatenating layer to link multiple tensors along the specific dimension. Add: Adding layer. Subtract: Subtracting layer. Maximum: Layer for maximum value. Minimum: Layer for minimum value. Layers for the convoelutional network. Conv1D : Layer of 1D convolution, ususlly for text. # of parameters = # of input channels \u00d7 # of kernel size (e.g. 3) \u00d7 # of kernels. Conv2D : Layer of 2D convolution, ususlly for image. # of parameters = # of input channels \u00d7 # of kernel size (e.g. 3\u00d73) \u00d7 # of kernels. Conv3D : Layer of 3D convolution, ususlly for video. # of parameters = # of input channels \u00d7 # of kernel size (e.g. 3\u00d73\u00d73) \u00d7 # of kernels. SeparableConv2D : Depthwise 2D separable covolution. Unlike the traditional convolution, separable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. # of parameters = # of input channels \u00d7 size of convolutional kernel + # of input channels \u00d7 1 \u00d7 1 \u00d7 # of output channels. Usually, depthwise separable convolution has a much smaller number of parameters with a better performance. DepthwiseConv2D : Depthwise 2D convolution. Depthwise convolutions consists in performing just the first step in a depthwise separable convolution (which acts on each input channel separately). Usually the # of input and output channels are the same, but can be altered through the depth_multiplier argument to control how many output channels are generated per input channel in the depthwise step. # of output channles = # of input channles \u00d7 depth_multiplier. # of parameters = # of input channels \u00d7 size of kernel \u00d7 depth_multiplier . Conv2DTranspose :2D Transposed convolution layer (sometimes called Deconvolution), but this is not the inverse operation of convolution. When the kernal maintains the same as convolution, and given the input size the same as the output size of convolution, then the output size of the transposed convolution is the same as the input size of convolution. LocallyConnected2D : Locally-connected layer for 2D inputs. This layer works similarly to the Conv2D layer, except that weights are unshared, thus has much more parameters than Conv2D . MaxPooling2D : 2D max pooling layer, also called down-sampling layer. This layer is for reducing dimension without any trainable prameter. AveragePooling2D : 2D average pooling layer. GlobalMaxPool2D : Global max pooling layer. Only one value preserved for each channel, usually used between convolution layer and fully connected layer, which is a substitution of Flatten . GlobalAvgPool2D : Global average pooling layer. Only one value preserved for each channel. Recursive network related layers Embedding : Embedding layer, provides an encoding with higher efficiency than one-hot for discrete features. It is usually used for projecting input words into dense vectors. Training is required for the parameters in the embedding layer. LSTM : Long Short-Term Memory layer, which is the most popular layer for the recursive network. It contains carry track and is composed of a cell, an input gate, an output gate and a forget gate, which significantly alleviate the problem of gradient vanishing and thus applicable for the problem of long-term dependency. All the middle results could be observed when the patameter return_sequences is set as True ; in the opposite case only the final result is returned. GRU : Gated Recursive Unit Layer, a simplified version of LSTM without carry track, thus has less parameters and could be trained faster. SimpleRNN : Simple Recursive Neural Network layer. It is not popular due to the problem of gradient vanishing, which made it inapplicable to the long-dependence. ConvLSTM2D : Convolutional LSTM layer. Has similar structure to LSTM but the conversion operation to both input and status are convolution. Bidirectional : Bi-directional wrapper for RNNs, for wrapping layers (such as LSTM and GRU) into bi-directional RNN, enhancing the capability of feature extraction. RNN : Base class of RNN. It accepts an RNN cell or a list of RNN cells, and iterate on the sequence to convert the input as an RNN through the calling of tf.keras.backend.rnn function. LSTMCell : LSTM cell. Unlike iterating across the whole sequence as LSTM , it only iterate once on the sequence. It would be more intuitive to understand the LSTM equals to LSTMCell wrapped by the base layer RNN . GRUCell : GRU cell. Unlike iterating across the whole sequence as GRU , it only iterate once on the sequence. SimpleRNNCell : SimpleRNN cell. Unlike iterating across the whole sequence as SimpleRNN , it only iterate once on the sequence. AbstractRNNCell : Abstract RNN Cell. It allows user to customize RNN cell through inheritance and subsequently construct the RNN layer through wrapping these RNN cells by RNN base layer. Attention : Dot-product attention layer, a.k.a. Luong-style attention, for constructing attention model. AdditiveAttention : Additive attention layer, a.k.a. Bahdanau-style attention, for constructing attention model. TimeDistributed : Time distributed wrapper, allows applying Dense , Conv2D to each time segment. 2. Customized Model Layer # It is recommended to use Lambda layer for customized model layer without trainable parameter. For the customized model layer with trainable parameters, it is recommended to inherite from the base class Layer . We only need to define forward propagation for Lambda layer since there is no trainable parameter, thus it is easier in application comparing to the inheritance from base class Layer . The forward propagation of Lambda layer could be expressed using lambda function or keyword def in Python. import tensorflow as tf from tensorflow.keras import layers , models , regularizers mypower = layers . Lambda ( lambda x : tf . math . pow ( x , 2 )) mypower ( tf . range ( 5 )) <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0, 1, 4, 9, 16], dtype=int32)> Inheriting from Layer needs re-implementation of the initialization, build and call methods. Here is an example of simplified linear layer, which is similar to Dense . class Linear ( layers . Layer ): def __init__ ( self , units = 32 , ** kwargs ): super ( Linear , self ) . __init__ ( ** kwargs ) self . units = units # The trainable parameters are defined in build method def build ( self , input_shape ): self . w = self . add_weight ( \"w\" , shape = ( input_shape [ - 1 ], self . units ), initializer = 'random_normal' , trainable = True ) # Parameter named \"w\" is compulsory or an error will be thrown out self . b = self . add_weight ( \"b\" , shape = ( self . units ,), initializer = 'random_normal' , trainable = True ) super ( Linear , self ) . build ( input_shape ) # Identical to self.built = True # The logic of forward propagation is defined in call method, and is called by __call__ method @tf . function def call ( self , inputs ): return tf . matmul ( inputs , self . w ) + self . b # Use customized get-config method to save the model as h5 format, specifically for the model composed through Functional API with customized Layer def get_config ( self ): config = super ( Linear , self ) . get_config () config . update ({ 'units' : self . units }) return config linear = Linear ( units = 8 ) print ( linear . built ) # Specify input_shape, call build method; the 0th dimension is for the number of samples, should be filled with None. linear . build ( input_shape = ( None , 16 )) print ( linear . built ) False True linear = Linear ( units = 8 ) print ( linear . built ) linear . build ( input_shape = ( None , 16 )) print ( linear . compute_output_shape ( input_shape = ( None , 16 ))) False (None, 8) linear = Linear ( units = 16 ) print ( linear . built ) # If built = False, the __call__ method will call \"build\" method first, then call \"call\" method linear ( tf . random . uniform (( 100 , 64 ))) print ( linear . built ) config = linear . get_config () print ( config ) False True {'name': 'linear_3', 'trainable': True, 'dtype': 'float32', 'units': 16} tf . keras . backend . clear_session () model = models . Sequential () # Note: the input_shape here will be modified by the model, so we don't have to fill None in the dimension representing the number of samples. model . add ( Linear ( units = 1 , input_shape = ( 2 ,))) print ( \"model.input_shape: \" , model . input_shape ) print ( \"model.output_shape: \" , model . output_shape ) model . summary () model.input_shape: (None, 2) model.output_shape: (None, 1) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= linear (Linear) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 _________________________________________________________________ model . compile ( optimizer = \"sgd\" , loss = \"mse\" , metrics = [ \"mae\" ]) print ( model . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # Save as h5 formatted model model . save ( \"../../data/linear_model.h5\" , save_format = \"h5\" ) model_loaded_keras = tf . keras . models . load_model ( \"../../data/linear_model.h5\" , custom_objects = { \"Linear\" : Linear }) print ( model_loaded_keras . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # Save as tf formatted model model . save ( \"../../data/linear_model\" , save_format = \"tf\" ) model_loaded_tf = tf . keras . models . load_model ( \"../../data/linear_model\" ) print ( model_loaded_tf . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) [[-0.04092304] [-0.06150477]] [[-0.04092304] [-0.06150477]] INFO:tensorflow:Assets written to: ../../data/linear_model/assets [[-0.04092304] [-0.06150477]] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-4 layers"},{"location":"english/Chapter5/Chapter5-4/#5-4-layers","text":"The deep learning model usually consists of various layers. tf.keras.layers contains a large amount of models with various functions, such as: layers.Dense , layers.Flatten , layers.Input , layers.DenseFeature , layers.Dropout layers.Conv2D , layers.MaxPooling2D , layers.Conv1D layers.Embedding , layers.GRU , layers.LSTM , layers.Bidirectional , etc. In case these pre-defined layers are insufficient for modeling, the users are able to write anonymous layer tf.keras.Lambda or write customized layer through inheriting tf.keras.layers.Layer . Note that tf.keras.Lambda is only for the layers without any trainable parameter.","title":"5-4 layers"},{"location":"english/Chapter5/Chapter5-4/#1-pre-defined-layer","text":"Here are the introductions for the most popular layers. Fundamental layers Dense: Densely connected layer. # of parameters = # of features of the input layer \u00d7 # of weight + # of bias. Activation: Activation function layer. Usually placed after the Dense layer for specify the activation function in the Dense layer. Dropout: Dropout layer. Setting the inputs as zero randomly during the training stage, which is a method of regularization. BatchNormalization:Layer for batch normalization. It scale and translate the batches into stable mean and standad deviation through linear transformation. This lead to the model adaptive to the various distribution of the input, which is mild regularization that accelerates training. This layer is usually applied before the activation function. SpatialDropout2D:Spatial dropout layer. Setting the whole feature map into zero with certain possibilities during training, which is a regularization to avoid high correlation between feature maps. Input:Input layer. Usually it is the first layer when modelling through functional API. DenseFeature:Layer that provides connection to the feature columns, which is used to accept a list of feature columns and generate a densely connected layer. Flatten:Flatten layer, used for flattening multi-dimensional tensor into one-dimension. Reshape:Reshape layer, reform the shape of the input tensor. Concatenate:Concatenating layer to link multiple tensors along the specific dimension. Add: Adding layer. Subtract: Subtracting layer. Maximum: Layer for maximum value. Minimum: Layer for minimum value. Layers for the convoelutional network. Conv1D : Layer of 1D convolution, ususlly for text. # of parameters = # of input channels \u00d7 # of kernel size (e.g. 3) \u00d7 # of kernels. Conv2D : Layer of 2D convolution, ususlly for image. # of parameters = # of input channels \u00d7 # of kernel size (e.g. 3\u00d73) \u00d7 # of kernels. Conv3D : Layer of 3D convolution, ususlly for video. # of parameters = # of input channels \u00d7 # of kernel size (e.g. 3\u00d73\u00d73) \u00d7 # of kernels. SeparableConv2D : Depthwise 2D separable covolution. Unlike the traditional convolution, separable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. # of parameters = # of input channels \u00d7 size of convolutional kernel + # of input channels \u00d7 1 \u00d7 1 \u00d7 # of output channels. Usually, depthwise separable convolution has a much smaller number of parameters with a better performance. DepthwiseConv2D : Depthwise 2D convolution. Depthwise convolutions consists in performing just the first step in a depthwise separable convolution (which acts on each input channel separately). Usually the # of input and output channels are the same, but can be altered through the depth_multiplier argument to control how many output channels are generated per input channel in the depthwise step. # of output channles = # of input channles \u00d7 depth_multiplier. # of parameters = # of input channels \u00d7 size of kernel \u00d7 depth_multiplier . Conv2DTranspose :2D Transposed convolution layer (sometimes called Deconvolution), but this is not the inverse operation of convolution. When the kernal maintains the same as convolution, and given the input size the same as the output size of convolution, then the output size of the transposed convolution is the same as the input size of convolution. LocallyConnected2D : Locally-connected layer for 2D inputs. This layer works similarly to the Conv2D layer, except that weights are unshared, thus has much more parameters than Conv2D . MaxPooling2D : 2D max pooling layer, also called down-sampling layer. This layer is for reducing dimension without any trainable prameter. AveragePooling2D : 2D average pooling layer. GlobalMaxPool2D : Global max pooling layer. Only one value preserved for each channel, usually used between convolution layer and fully connected layer, which is a substitution of Flatten . GlobalAvgPool2D : Global average pooling layer. Only one value preserved for each channel. Recursive network related layers Embedding : Embedding layer, provides an encoding with higher efficiency than one-hot for discrete features. It is usually used for projecting input words into dense vectors. Training is required for the parameters in the embedding layer. LSTM : Long Short-Term Memory layer, which is the most popular layer for the recursive network. It contains carry track and is composed of a cell, an input gate, an output gate and a forget gate, which significantly alleviate the problem of gradient vanishing and thus applicable for the problem of long-term dependency. All the middle results could be observed when the patameter return_sequences is set as True ; in the opposite case only the final result is returned. GRU : Gated Recursive Unit Layer, a simplified version of LSTM without carry track, thus has less parameters and could be trained faster. SimpleRNN : Simple Recursive Neural Network layer. It is not popular due to the problem of gradient vanishing, which made it inapplicable to the long-dependence. ConvLSTM2D : Convolutional LSTM layer. Has similar structure to LSTM but the conversion operation to both input and status are convolution. Bidirectional : Bi-directional wrapper for RNNs, for wrapping layers (such as LSTM and GRU) into bi-directional RNN, enhancing the capability of feature extraction. RNN : Base class of RNN. It accepts an RNN cell or a list of RNN cells, and iterate on the sequence to convert the input as an RNN through the calling of tf.keras.backend.rnn function. LSTMCell : LSTM cell. Unlike iterating across the whole sequence as LSTM , it only iterate once on the sequence. It would be more intuitive to understand the LSTM equals to LSTMCell wrapped by the base layer RNN . GRUCell : GRU cell. Unlike iterating across the whole sequence as GRU , it only iterate once on the sequence. SimpleRNNCell : SimpleRNN cell. Unlike iterating across the whole sequence as SimpleRNN , it only iterate once on the sequence. AbstractRNNCell : Abstract RNN Cell. It allows user to customize RNN cell through inheritance and subsequently construct the RNN layer through wrapping these RNN cells by RNN base layer. Attention : Dot-product attention layer, a.k.a. Luong-style attention, for constructing attention model. AdditiveAttention : Additive attention layer, a.k.a. Bahdanau-style attention, for constructing attention model. TimeDistributed : Time distributed wrapper, allows applying Dense , Conv2D to each time segment.","title":"1. Pre-defined Layer"},{"location":"english/Chapter5/Chapter5-4/#2-customized-model-layer","text":"It is recommended to use Lambda layer for customized model layer without trainable parameter. For the customized model layer with trainable parameters, it is recommended to inherite from the base class Layer . We only need to define forward propagation for Lambda layer since there is no trainable parameter, thus it is easier in application comparing to the inheritance from base class Layer . The forward propagation of Lambda layer could be expressed using lambda function or keyword def in Python. import tensorflow as tf from tensorflow.keras import layers , models , regularizers mypower = layers . Lambda ( lambda x : tf . math . pow ( x , 2 )) mypower ( tf . range ( 5 )) <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0, 1, 4, 9, 16], dtype=int32)> Inheriting from Layer needs re-implementation of the initialization, build and call methods. Here is an example of simplified linear layer, which is similar to Dense . class Linear ( layers . Layer ): def __init__ ( self , units = 32 , ** kwargs ): super ( Linear , self ) . __init__ ( ** kwargs ) self . units = units # The trainable parameters are defined in build method def build ( self , input_shape ): self . w = self . add_weight ( \"w\" , shape = ( input_shape [ - 1 ], self . units ), initializer = 'random_normal' , trainable = True ) # Parameter named \"w\" is compulsory or an error will be thrown out self . b = self . add_weight ( \"b\" , shape = ( self . units ,), initializer = 'random_normal' , trainable = True ) super ( Linear , self ) . build ( input_shape ) # Identical to self.built = True # The logic of forward propagation is defined in call method, and is called by __call__ method @tf . function def call ( self , inputs ): return tf . matmul ( inputs , self . w ) + self . b # Use customized get-config method to save the model as h5 format, specifically for the model composed through Functional API with customized Layer def get_config ( self ): config = super ( Linear , self ) . get_config () config . update ({ 'units' : self . units }) return config linear = Linear ( units = 8 ) print ( linear . built ) # Specify input_shape, call build method; the 0th dimension is for the number of samples, should be filled with None. linear . build ( input_shape = ( None , 16 )) print ( linear . built ) False True linear = Linear ( units = 8 ) print ( linear . built ) linear . build ( input_shape = ( None , 16 )) print ( linear . compute_output_shape ( input_shape = ( None , 16 ))) False (None, 8) linear = Linear ( units = 16 ) print ( linear . built ) # If built = False, the __call__ method will call \"build\" method first, then call \"call\" method linear ( tf . random . uniform (( 100 , 64 ))) print ( linear . built ) config = linear . get_config () print ( config ) False True {'name': 'linear_3', 'trainable': True, 'dtype': 'float32', 'units': 16} tf . keras . backend . clear_session () model = models . Sequential () # Note: the input_shape here will be modified by the model, so we don't have to fill None in the dimension representing the number of samples. model . add ( Linear ( units = 1 , input_shape = ( 2 ,))) print ( \"model.input_shape: \" , model . input_shape ) print ( \"model.output_shape: \" , model . output_shape ) model . summary () model.input_shape: (None, 2) model.output_shape: (None, 1) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= linear (Linear) (None, 1) 3 ================================================================= Total params: 3 Trainable params: 3 Non-trainable params: 0 _________________________________________________________________ model . compile ( optimizer = \"sgd\" , loss = \"mse\" , metrics = [ \"mae\" ]) print ( model . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # Save as h5 formatted model model . save ( \"../../data/linear_model.h5\" , save_format = \"h5\" ) model_loaded_keras = tf . keras . models . load_model ( \"../../data/linear_model.h5\" , custom_objects = { \"Linear\" : Linear }) print ( model_loaded_keras . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) # Save as tf formatted model model . save ( \"../../data/linear_model\" , save_format = \"tf\" ) model_loaded_tf = tf . keras . models . load_model ( \"../../data/linear_model\" ) print ( model_loaded_tf . predict ( tf . constant ([[ 3.0 , 2.0 ],[ 4.0 , 5.0 ]]))) [[-0.04092304] [-0.06150477]] [[-0.04092304] [-0.06150477]] INFO:tensorflow:Assets written to: ../../data/linear_model/assets [[-0.04092304] [-0.06150477]] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Customized Model Layer"},{"location":"english/Chapter5/Chapter5-5/","text":"5-5 losses # In general, the target function in supervised learning consists of loss function and regularization term. (Target = Loss + Regularization) For the keras model, the regularization term of the target function is usually designated in each layer, such as using kernel_regularizer and bias_regularizer parameters in Dense layer to sepecify using l1 or l2 norm. On the other hand, kernel_constraint and bias_constraint parameters can limit the range of the weights, which is also a method of regularization. Loss function is designated during the compilation of the model. For the regression models, the most popular loss function is the mean squared error mean_squared_error . For binary classification model, the most popular loss function is binary cross entropy binary_crossentropy . For multiple classification model, when the labels are one-hot encoded, we should use categorical cross entropy categorical_crossentropy as loss function; for the category with ordinal encoding, the sparse categorical cross entropy sparse_categorical_crossentropy should be used as the loss funcion. We may define customized loss function when necessary. The customzed loss function requires two tensors y_true and y_pred as input,and it output a scalar as the value of the caluclated loss function. import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , regularizers , constraints 1. Loss Function and Regularization Term # tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 64 , input_dim = 64 , kernel_regularizer = regularizers . l2 ( 0.01 ), activity_regularizer = regularizers . l1 ( 0.01 ), kernel_constraint = constraints . MaxNorm ( max_value = 2 , axis = 0 ))) model . add ( layers . Dense ( 10 , kernel_regularizer = regularizers . l1_l2 ( 0.01 , 0.01 ), activation = \"sigmoid\" )) model . compile ( optimizer = \"rmsprop\" , loss = \"binary_crossentropy\" , metrics = [ \"AUC\" ]) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 64) 4160 _________________________________________________________________ dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 4,810 Trainable params: 4,810 Non-trainable params: 0 _________________________________________________________________ 2. Pre-defined Loss Function # There are two types of implementation of the pre-defined loss function: class-type or function-type. e.g. CategoricalCrossentropy and categorical_crossentropy are both categorical cross entropy; the former is the implementation by class, and the latter is the by function. The most frequently used pre-defined loss functions are: mean_squared_error (Mean Squared Error, for regression, dubbed as \"mse\", class-type and function-type implementations are MeanSquaredError and MSE , respectively) mean_absolute_error (Mean Absolute Error, for regression, dubbed as \"mae\", class-type and function-type implementations are MeanAbsoluteError and MAE , respectively) mean_absolute_percentage_error (Mean Absolute Percentage Error, for regression dubed as \"mape\", class-type and function-type implementations are MeanAbsolutePercentageError and MAPE , respectively) Huber (Huber Loss\uff0cfor regression, performance is between \"mse\" and \"mae\", robust to outliers, thus has advantages comparint to \"mse\"; implemented only in class) binary_crossentropy (Binary Cross Entropy, for binary classification; the class-type implementation is BinaryCrossentropy ) categorical_crossentropy (Categorical Cross Entropy, for multiple classification, requires one-hot encoding for the label; the class-type implementation is CategoricalCrossentropy ) sparse_categorical_crossentropy (Sparse Categorical Cross Entropy, used for multiple classification, requires ordinal encoding; the class-type implementation is SparseCategoricalCrossentropy ) hinge (Hinge loss function, for binary classification, famous for the application as loss function in Support Vector Machine (SVM); the class-type implementation is Hinge ) kld (Kullback-Leibler divergence loss, usually used as the loss function in the expectation maximization (EM) algorithm; it is a measurement of the difference between two probability distributions. The class-type and function-type implementations are KLDivergence and KLD , respectively) cosine_similarity (Cosine similarity, for multiple classification; the class-type implementation is CosineSimilarity ) 3. Customized Loss Function # The customzed loss function requires two tensors y_true and y_pred as input,and it output a scalar as the value of the caluclated loss function. It is also possible to customize loss function through inheriting from the base class tf.keras.losses.Loss and rewrite the call method to implement the calculation of loss. Here is an example of customized implementation to the Focal Loss, which is an improvement of binary_crossentropy loss function. Focal Loss results better comparing to the binary cross entropy, given the condition of unbalanced category and many easy samples in training data. It has two adjustable parameters\uff0calpha and gamma. The aim of alpha is to decay the weight of negative samples\uff0cand gamma to decay the weight of the easy samples. So the model will then focal its weight on the positive samples and hard samples. This is why the loss is called focal loss. You may refer to the following article for details of this topic: Understand Focal Loss and GHM in 5 minutes def focal_loss ( gamma = 2. , alpha = 0.75 ): def focal_loss_fixed ( y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * alpha + ( 1 - y_true ) * ( 1 - alpha ) modulating_factor = tf . pow ( 1.0 - p_t , gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss return focal_loss_fixed class FocalLoss ( losses . Loss ): def __init__ ( self , gamma = 2.0 , alpha = 0.75 , name = \"focal_loss\" ): self . gamma = gamma self . alpha = alpha def call ( self , y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * self . alpha + ( 1 - y_true ) * ( 1 - self . alpha ) modulating_factor = tf . pow ( 1.0 - p_t , self . gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-5 losses"},{"location":"english/Chapter5/Chapter5-5/#5-5-losses","text":"In general, the target function in supervised learning consists of loss function and regularization term. (Target = Loss + Regularization) For the keras model, the regularization term of the target function is usually designated in each layer, such as using kernel_regularizer and bias_regularizer parameters in Dense layer to sepecify using l1 or l2 norm. On the other hand, kernel_constraint and bias_constraint parameters can limit the range of the weights, which is also a method of regularization. Loss function is designated during the compilation of the model. For the regression models, the most popular loss function is the mean squared error mean_squared_error . For binary classification model, the most popular loss function is binary cross entropy binary_crossentropy . For multiple classification model, when the labels are one-hot encoded, we should use categorical cross entropy categorical_crossentropy as loss function; for the category with ordinal encoding, the sparse categorical cross entropy sparse_categorical_crossentropy should be used as the loss funcion. We may define customized loss function when necessary. The customzed loss function requires two tensors y_true and y_pred as input,and it output a scalar as the value of the caluclated loss function. import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , regularizers , constraints","title":"5-5 losses"},{"location":"english/Chapter5/Chapter5-5/#1-loss-function-and-regularization-term","text":"tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Dense ( 64 , input_dim = 64 , kernel_regularizer = regularizers . l2 ( 0.01 ), activity_regularizer = regularizers . l1 ( 0.01 ), kernel_constraint = constraints . MaxNorm ( max_value = 2 , axis = 0 ))) model . add ( layers . Dense ( 10 , kernel_regularizer = regularizers . l1_l2 ( 0.01 , 0.01 ), activation = \"sigmoid\" )) model . compile ( optimizer = \"rmsprop\" , loss = \"binary_crossentropy\" , metrics = [ \"AUC\" ]) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 64) 4160 _________________________________________________________________ dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 4,810 Trainable params: 4,810 Non-trainable params: 0 _________________________________________________________________","title":"1. Loss Function and Regularization Term"},{"location":"english/Chapter5/Chapter5-5/#2-pre-defined-loss-function","text":"There are two types of implementation of the pre-defined loss function: class-type or function-type. e.g. CategoricalCrossentropy and categorical_crossentropy are both categorical cross entropy; the former is the implementation by class, and the latter is the by function. The most frequently used pre-defined loss functions are: mean_squared_error (Mean Squared Error, for regression, dubbed as \"mse\", class-type and function-type implementations are MeanSquaredError and MSE , respectively) mean_absolute_error (Mean Absolute Error, for regression, dubbed as \"mae\", class-type and function-type implementations are MeanAbsoluteError and MAE , respectively) mean_absolute_percentage_error (Mean Absolute Percentage Error, for regression dubed as \"mape\", class-type and function-type implementations are MeanAbsolutePercentageError and MAPE , respectively) Huber (Huber Loss\uff0cfor regression, performance is between \"mse\" and \"mae\", robust to outliers, thus has advantages comparint to \"mse\"; implemented only in class) binary_crossentropy (Binary Cross Entropy, for binary classification; the class-type implementation is BinaryCrossentropy ) categorical_crossentropy (Categorical Cross Entropy, for multiple classification, requires one-hot encoding for the label; the class-type implementation is CategoricalCrossentropy ) sparse_categorical_crossentropy (Sparse Categorical Cross Entropy, used for multiple classification, requires ordinal encoding; the class-type implementation is SparseCategoricalCrossentropy ) hinge (Hinge loss function, for binary classification, famous for the application as loss function in Support Vector Machine (SVM); the class-type implementation is Hinge ) kld (Kullback-Leibler divergence loss, usually used as the loss function in the expectation maximization (EM) algorithm; it is a measurement of the difference between two probability distributions. The class-type and function-type implementations are KLDivergence and KLD , respectively) cosine_similarity (Cosine similarity, for multiple classification; the class-type implementation is CosineSimilarity )","title":"2. Pre-defined Loss Function"},{"location":"english/Chapter5/Chapter5-5/#3-customized-loss-function","text":"The customzed loss function requires two tensors y_true and y_pred as input,and it output a scalar as the value of the caluclated loss function. It is also possible to customize loss function through inheriting from the base class tf.keras.losses.Loss and rewrite the call method to implement the calculation of loss. Here is an example of customized implementation to the Focal Loss, which is an improvement of binary_crossentropy loss function. Focal Loss results better comparing to the binary cross entropy, given the condition of unbalanced category and many easy samples in training data. It has two adjustable parameters\uff0calpha and gamma. The aim of alpha is to decay the weight of negative samples\uff0cand gamma to decay the weight of the easy samples. So the model will then focal its weight on the positive samples and hard samples. This is why the loss is called focal loss. You may refer to the following article for details of this topic: Understand Focal Loss and GHM in 5 minutes def focal_loss ( gamma = 2. , alpha = 0.75 ): def focal_loss_fixed ( y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * alpha + ( 1 - y_true ) * ( 1 - alpha ) modulating_factor = tf . pow ( 1.0 - p_t , gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss return focal_loss_fixed class FocalLoss ( losses . Loss ): def __init__ ( self , gamma = 2.0 , alpha = 0.75 , name = \"focal_loss\" ): self . gamma = gamma self . alpha = alpha def call ( self , y_true , y_pred ): bce = tf . losses . binary_crossentropy ( y_true , y_pred ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * self . alpha + ( 1 - y_true ) * ( 1 - self . alpha ) modulating_factor = tf . pow ( 1.0 - p_t , self . gamma ) loss = tf . reduce_sum ( alpha_factor * modulating_factor * bce , axis = - 1 ) return loss Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. Customized Loss Function"},{"location":"english/Chapter5/Chapter5-6/","text":"5-6 metrics # Besides being used as optimization target during training, loss function also acts as an evaluation remark of model performance. However, in general, the performance of the model is evaluated using other terms. This is evaluation metrics. Loss function could be used as metrics. MAE , MSE , CategoricalCrossentropy are several most common metrics. However, metrics is not necessarily able to act as loss function, such as AUC , Accuracy , Precision . This is because metrics is not required to be continuously differentiable, while this is a general requirement for the loss function. Multiple metrics could be specified through list during the compilation of the model. Metrics could be customized if necessary. The customzed metrics requires two tensors y_true and y_pred as input,and it output a scalar as the value of the caluclated metrics. It is also possible to customize metrics through inheriting from the base class tf.keras.metrics.Metric and rewrite the init , update_state , and result methods to implement the calculation of metrics. Usually the training are performed batch by batch, while metrics could be calculated only after a whole epoch, thus the class-type metrics is more popular. We need to write initialization method to create the necessary middle variables (they are related to the resulting metrics), write the update_state method to update the states of these middle variables after each batch, and write the result method for the final output. If the metrics is written as a function, it is only possible to use the avaraged metrics among all the batches in the epoch as the overal metrics. This usually deviates from the result calculated by all training steps in the epoch. 1. Most Frequently Used Pre-defined Metrics # MeanSquaredError (Mean Squared Error, used for regression, dubbed as \"MSE\", function name mse ) MeanAbsoluteError (Mean Absolute Error, used for regression, dubbed as \"MAE\", function name mae ) MeanAbsolutePercentageError (Mean Absolute Percentage Error, used for regression, dubbed as \"MAPE\", function name mape ) RootMeanSquaredError (Root-Mean-Squared-Error, used for regression.) Accuracy (Accuracy\uff0cused for classification, could be represented as a string \"Accuracy\"; Accuracy=(TP+TN)/(TP+TN+FP+FN); requires ordinal encoding for the inputs y_true and y_pred .) Precision (Precision, used for binary classification;; Precision = TP/(TP+FP)) Recall (Recalling rate, used for binary classification; Recall = TP/(TP+FN)) TruePositives (True positives, used for binary classification.) TrueNegatives (True negatives, used for binary classification.) FalsePositives (False positives, used for binary classification.) FalseNegatives (False negatives, used for binary classification.) AUC (Area Under the Curve, represents the area under the ROC curve (TPR vs FPR); it is used for binary classification. An intuitive explanation: pick a positive sample and a negative sample, AUC is the possibility that the prediction of positive sample larger than the prediction of the negative sample.) CategoricalAccuracy (Catigorical Accuracy, same as Accuracy except requiring one-hot encoding for the input label y_true .) SparseCategoricalAccuracy (Sparse Categorical Accuracy, same as Accuracy except requiring ordinal encoding for the label y_true.) MeanIoU (Intersection-Over-Union, ususally for image segmentation.) TopKCategoricalAccuracy (TopK accuracy for multiple classification, requires one-hot encoding for the input label y_true) SparseTopKCategoricalAccuracy (TopK accuracy for multiple classification, requires ordinary encoding for the input label y_true) Mean (Mean value) Sum (Summation) 2. Customized Metrics # Here we use the K-S (Kolmogorov-Smirnov) statistic, which is frequently used in financial risk management, as an example for the customized metrics. K-S statistic is used for binary classification problem; KS = max(TPR - FPR), where TPR = TP / (TP + FN), FPR = FP / (FP + TN) TPR curve is the cumulative distribution function (CDF) of the positive samples, while FPR curve is the CDF of the negative samples. K-S statistic is the maximum of the difference between the CDF of positive and negative samples. import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics # Customized metrics defined by function @tf . function def ks ( y_true , y_pred ): y_true = tf . reshape ( y_true ,( - 1 ,)) y_pred = tf . reshape ( y_pred ,( - 1 ,)) length = tf . shape ( y_true )[ 0 ] t = tf . math . top_k ( y_pred , k = length , sorted = False ) y_pred_sorted = tf . gather ( y_pred , t . indices ) y_true_sorted = tf . gather ( y_true , t . indices ) cum_positive_ratio = tf . truediv ( tf . cumsum ( y_true_sorted ), tf . reduce_sum ( y_true_sorted )) cum_negative_ratio = tf . truediv ( tf . cumsum ( 1 - y_true_sorted ), tf . reduce_sum ( 1 - y_true_sorted )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ],[ 0.7 ], [ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) tf . print ( ks ( y_true , y_pred )) 0.625 # Customized metrics defined by class class KS ( metrics . Metric ): def __init__ ( self , name = \"ks\" , ** kwargs ): super ( KS , self ) . __init__ ( name = name , ** kwargs ) self . true_positives = self . add_weight ( name = \"tp\" , shape = ( 101 ,), initializer = \"zeros\" ) self . false_positives = self . add_weight ( name = \"fp\" , shape = ( 101 ,), initializer = \"zeros\" ) @tf . function def update_state ( self , y_true , y_pred ): y_true = tf . cast ( tf . reshape ( y_true ,( - 1 ,)), tf . bool ) y_pred = tf . cast ( 100 * tf . reshape ( y_pred ,( - 1 ,)), tf . int32 ) for i in tf . range ( 0 , tf . shape ( y_true )[ 0 ]): if y_true [ i ]: self . true_positives [ y_pred [ i ]] . assign ( self . true_positives [ y_pred [ i ]] + 1.0 ) else : self . false_positives [ y_pred [ i ]] . assign ( self . false_positives [ y_pred [ i ]] + 1.0 ) return ( self . true_positives , self . false_positives ) @tf . function def result ( self ): cum_positive_ratio = tf . truediv ( tf . cumsum ( self . true_positives ), tf . reduce_sum ( self . true_positives )) cum_negative_ratio = tf . truediv ( tf . cumsum ( self . false_positives ), tf . reduce_sum ( self . false_positives )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ], [ 0.7 ],[ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) myks = KS () myks . update_state ( y_true , y_pred ) tf . print ( myks . result ()) 0.625 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-6 metrics"},{"location":"english/Chapter5/Chapter5-6/#5-6-metrics","text":"Besides being used as optimization target during training, loss function also acts as an evaluation remark of model performance. However, in general, the performance of the model is evaluated using other terms. This is evaluation metrics. Loss function could be used as metrics. MAE , MSE , CategoricalCrossentropy are several most common metrics. However, metrics is not necessarily able to act as loss function, such as AUC , Accuracy , Precision . This is because metrics is not required to be continuously differentiable, while this is a general requirement for the loss function. Multiple metrics could be specified through list during the compilation of the model. Metrics could be customized if necessary. The customzed metrics requires two tensors y_true and y_pred as input,and it output a scalar as the value of the caluclated metrics. It is also possible to customize metrics through inheriting from the base class tf.keras.metrics.Metric and rewrite the init , update_state , and result methods to implement the calculation of metrics. Usually the training are performed batch by batch, while metrics could be calculated only after a whole epoch, thus the class-type metrics is more popular. We need to write initialization method to create the necessary middle variables (they are related to the resulting metrics), write the update_state method to update the states of these middle variables after each batch, and write the result method for the final output. If the metrics is written as a function, it is only possible to use the avaraged metrics among all the batches in the epoch as the overal metrics. This usually deviates from the result calculated by all training steps in the epoch.","title":"5-6 metrics"},{"location":"english/Chapter5/Chapter5-6/#1-most-frequently-used-pre-defined-metrics","text":"MeanSquaredError (Mean Squared Error, used for regression, dubbed as \"MSE\", function name mse ) MeanAbsoluteError (Mean Absolute Error, used for regression, dubbed as \"MAE\", function name mae ) MeanAbsolutePercentageError (Mean Absolute Percentage Error, used for regression, dubbed as \"MAPE\", function name mape ) RootMeanSquaredError (Root-Mean-Squared-Error, used for regression.) Accuracy (Accuracy\uff0cused for classification, could be represented as a string \"Accuracy\"; Accuracy=(TP+TN)/(TP+TN+FP+FN); requires ordinal encoding for the inputs y_true and y_pred .) Precision (Precision, used for binary classification;; Precision = TP/(TP+FP)) Recall (Recalling rate, used for binary classification; Recall = TP/(TP+FN)) TruePositives (True positives, used for binary classification.) TrueNegatives (True negatives, used for binary classification.) FalsePositives (False positives, used for binary classification.) FalseNegatives (False negatives, used for binary classification.) AUC (Area Under the Curve, represents the area under the ROC curve (TPR vs FPR); it is used for binary classification. An intuitive explanation: pick a positive sample and a negative sample, AUC is the possibility that the prediction of positive sample larger than the prediction of the negative sample.) CategoricalAccuracy (Catigorical Accuracy, same as Accuracy except requiring one-hot encoding for the input label y_true .) SparseCategoricalAccuracy (Sparse Categorical Accuracy, same as Accuracy except requiring ordinal encoding for the label y_true.) MeanIoU (Intersection-Over-Union, ususally for image segmentation.) TopKCategoricalAccuracy (TopK accuracy for multiple classification, requires one-hot encoding for the input label y_true) SparseTopKCategoricalAccuracy (TopK accuracy for multiple classification, requires ordinary encoding for the input label y_true) Mean (Mean value) Sum (Summation)","title":"1. Most Frequently Used Pre-defined Metrics"},{"location":"english/Chapter5/Chapter5-6/#2-customized-metrics","text":"Here we use the K-S (Kolmogorov-Smirnov) statistic, which is frequently used in financial risk management, as an example for the customized metrics. K-S statistic is used for binary classification problem; KS = max(TPR - FPR), where TPR = TP / (TP + FN), FPR = FP / (FP + TN) TPR curve is the cumulative distribution function (CDF) of the positive samples, while FPR curve is the CDF of the negative samples. K-S statistic is the maximum of the difference between the CDF of positive and negative samples. import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics # Customized metrics defined by function @tf . function def ks ( y_true , y_pred ): y_true = tf . reshape ( y_true ,( - 1 ,)) y_pred = tf . reshape ( y_pred ,( - 1 ,)) length = tf . shape ( y_true )[ 0 ] t = tf . math . top_k ( y_pred , k = length , sorted = False ) y_pred_sorted = tf . gather ( y_pred , t . indices ) y_true_sorted = tf . gather ( y_true , t . indices ) cum_positive_ratio = tf . truediv ( tf . cumsum ( y_true_sorted ), tf . reduce_sum ( y_true_sorted )) cum_negative_ratio = tf . truediv ( tf . cumsum ( 1 - y_true_sorted ), tf . reduce_sum ( 1 - y_true_sorted )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ],[ 0.7 ], [ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) tf . print ( ks ( y_true , y_pred )) 0.625 # Customized metrics defined by class class KS ( metrics . Metric ): def __init__ ( self , name = \"ks\" , ** kwargs ): super ( KS , self ) . __init__ ( name = name , ** kwargs ) self . true_positives = self . add_weight ( name = \"tp\" , shape = ( 101 ,), initializer = \"zeros\" ) self . false_positives = self . add_weight ( name = \"fp\" , shape = ( 101 ,), initializer = \"zeros\" ) @tf . function def update_state ( self , y_true , y_pred ): y_true = tf . cast ( tf . reshape ( y_true ,( - 1 ,)), tf . bool ) y_pred = tf . cast ( 100 * tf . reshape ( y_pred ,( - 1 ,)), tf . int32 ) for i in tf . range ( 0 , tf . shape ( y_true )[ 0 ]): if y_true [ i ]: self . true_positives [ y_pred [ i ]] . assign ( self . true_positives [ y_pred [ i ]] + 1.0 ) else : self . false_positives [ y_pred [ i ]] . assign ( self . false_positives [ y_pred [ i ]] + 1.0 ) return ( self . true_positives , self . false_positives ) @tf . function def result ( self ): cum_positive_ratio = tf . truediv ( tf . cumsum ( self . true_positives ), tf . reduce_sum ( self . true_positives )) cum_negative_ratio = tf . truediv ( tf . cumsum ( self . false_positives ), tf . reduce_sum ( self . false_positives )) ks_value = tf . reduce_max ( tf . abs ( cum_positive_ratio - cum_negative_ratio )) return ks_value y_true = tf . constant ([[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 1 ],[ 1 ],[ 1 ],[ 0 ],[ 0 ],[ 0 ],[ 1 ],[ 0 ],[ 1 ],[ 0 ]]) y_pred = tf . constant ([[ 0.6 ],[ 0.1 ],[ 0.4 ],[ 0.5 ],[ 0.7 ],[ 0.7 ], [ 0.7 ],[ 0.4 ],[ 0.4 ],[ 0.5 ],[ 0.8 ],[ 0.3 ],[ 0.5 ],[ 0.3 ]]) myks = KS () myks . update_state ( y_true , y_pred ) tf . print ( myks . result ()) 0.625 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Customized Metrics"},{"location":"english/Chapter5/Chapter5-7/","text":"5-7 optimizers # There is a group of magic cooks in machine learning. Their daily life looks like: They grab some raw material (data), put them into a pot (model), light some fire (optimization algorithm), and wait until the cuisine is ready. However, anyone who has cooking experience knows that fire controlling is the key part. Even using same material with the same recipe, different fire level leads to totally different results: medium well, burnt, or still raw. This theroy on cooking also applies to the machine learning. The choice of the optimization algorithm determines the final performance of the final model. An unsatisfying performance is not necessarily due to the problem of feature or model designing, instead, it might be attributed to the choice of optimization algorithm. The evolution of the optimization algorithm for the deep learning is: SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam You may refer to the following article to for more details \"Understand the differences in optimization algorthms with just one framework: SGD/AdaGrad/Adam\" For the beginners, choosing Adam as the optimizer and using the default parameters will set everything for you. Some researchers who are chaising better metrics for publications could use Adam as the initial optimizer and use SGD later for fine-tuning the parameters for better performance. There are some cutting-edge optimization algorithms claiming a better performance, e.g. LazyAdam, Look-ahead, RAdam, Ranger, etc. 1. How To Use the Optimizer # Optimizer accepts variables and corresponding gradient through apply_gradients method to iterate over the given variables. Another way is using minimize method to optimize the target function iteratively. Another common way is passing the optimizer to the Model of keras, and call model.fit method to optimize the loss function. A variable named optimizer.iterations will be created during optimizer initialization to record the number of iteration. Thus the optimizer should be created outside the decorator @tf.function with the same reason as tf.Variable . import tensorflow as tf import numpy as np # Time stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) # The minimal value of f(x) = a*x**2 + b*x + c # Here we use optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) while tf . constant ( True ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) # Condition of terminating the iteration if tf . abs ( dy_dx ) < tf . constant ( 0.00001 ): break if tf . math . mod ( optimizer . iterations , 100 ) == 0 : printbar () tf . print ( \"step = \" , optimizer . iterations ) tf . print ( \"x = \" , x ) tf . print ( \"\" ) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( \"y =\" , minimizef ()) tf . print ( \"x =\" , x ) # Minimal value of f(x) = a*x**2 + b*x + c # Here we use optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch = 1000 ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) tf . print ( \"epoch = \" , optimizer . iterations ) return ( f ()) train ( 1000 ) tf . print ( \"y = \" , f ()) tf . print ( \"x = \" , x ) # Minimal value of f(x) = a*x**2 + b*x + c # Here we use model.fit tf . keras . backend . clear_session () class FakeModel ( tf . keras . models . Model ): def __init__ ( self , a , b , c ): super ( FakeModel , self ) . __init__ () self . a = a self . b = b self . c = c def build ( self ): self . x = tf . Variable ( 0.0 , name = \"x\" ) self . built = True def call ( self , features ): loss = self . a * ( self . x ) ** 2 + self . b * ( self . x ) + self . c return ( tf . ones_like ( features ) * loss ) def myloss ( y_true , y_pred ): return tf . reduce_mean ( y_pred ) model = FakeModel ( tf . constant ( 1.0 ), tf . constant ( - 2.0 ), tf . constant ( 1.0 )) model . build () model . summary () model . compile ( optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ), loss = myloss ) history = model . fit ( tf . zeros (( 100 , 2 )), tf . ones ( 100 ), batch_size = 1 , epochs = 10 ) # Iterate for 1000 times tf . print ( \"x=\" , model . x ) tf . print ( \"loss=\" , model ( tf . constant ( 0.0 ))) 2. Pre-defined Optimizers # The evolution of the optimization algorithm for the deep learning is: SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam There are corresponding classes in keras.optimizers sub-module as the implementations of these optimizers. SGD , the default parameters is for a pure SGD. For a non-zero parameter momentum , the optimizer changes to SGDM since it considers the first-order momentum. For nesterov = True, the optimizer changes to NAG (Nesterov Accelerated Gradient), which calculates the gradient of the one further step. Adagrad , considers the second-order momentum and equipted with self-adaptive learning rate; the drawback is a slow learning rate at a later stage or early ceasing of learning due to the monotonically desending leanring rate. RMSprop , considers the second-order momentum and equipted with self-adaptive learning rate; improves the Adagrad through exponential smoothing, which only cnosiders the second-order momentum in a given window length. Adadelta , considers the second-order momentum, similar as RMSprop but more complicated with an improved self-adaption. Adam , consider both the first-order and the second-order momentum; it improves RMSprop by including first-order momentum. Nadam , improves Adam by including Nesterov Acceleration. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-7 optimizers"},{"location":"english/Chapter5/Chapter5-7/#5-7-optimizers","text":"There is a group of magic cooks in machine learning. Their daily life looks like: They grab some raw material (data), put them into a pot (model), light some fire (optimization algorithm), and wait until the cuisine is ready. However, anyone who has cooking experience knows that fire controlling is the key part. Even using same material with the same recipe, different fire level leads to totally different results: medium well, burnt, or still raw. This theroy on cooking also applies to the machine learning. The choice of the optimization algorithm determines the final performance of the final model. An unsatisfying performance is not necessarily due to the problem of feature or model designing, instead, it might be attributed to the choice of optimization algorithm. The evolution of the optimization algorithm for the deep learning is: SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam You may refer to the following article to for more details \"Understand the differences in optimization algorthms with just one framework: SGD/AdaGrad/Adam\" For the beginners, choosing Adam as the optimizer and using the default parameters will set everything for you. Some researchers who are chaising better metrics for publications could use Adam as the initial optimizer and use SGD later for fine-tuning the parameters for better performance. There are some cutting-edge optimization algorithms claiming a better performance, e.g. LazyAdam, Look-ahead, RAdam, Ranger, etc.","title":"5-7 optimizers"},{"location":"english/Chapter5/Chapter5-7/#1-how-to-use-the-optimizer","text":"Optimizer accepts variables and corresponding gradient through apply_gradients method to iterate over the given variables. Another way is using minimize method to optimize the target function iteratively. Another common way is passing the optimizer to the Model of keras, and call model.fit method to optimize the loss function. A variable named optimizer.iterations will be created during optimizer initialization to record the number of iteration. Thus the optimizer should be created outside the decorator @tf.function with the same reason as tf.Variable . import tensorflow as tf import numpy as np # Time stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) # The minimal value of f(x) = a*x**2 + b*x + c # Here we use optimizer.apply_gradients x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) @tf . function def minimizef (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) while tf . constant ( True ): with tf . GradientTape () as tape : y = a * tf . pow ( x , 2 ) + b * x + c dy_dx = tape . gradient ( y , x ) optimizer . apply_gradients ( grads_and_vars = [( dy_dx , x )]) # Condition of terminating the iteration if tf . abs ( dy_dx ) < tf . constant ( 0.00001 ): break if tf . math . mod ( optimizer . iterations , 100 ) == 0 : printbar () tf . print ( \"step = \" , optimizer . iterations ) tf . print ( \"x = \" , x ) tf . print ( \"\" ) y = a * tf . pow ( x , 2 ) + b * x + c return y tf . print ( \"y =\" , minimizef ()) tf . print ( \"x =\" , x ) # Minimal value of f(x) = a*x**2 + b*x + c # Here we use optimizer.minimize x = tf . Variable ( 0.0 , name = \"x\" , dtype = tf . float32 ) optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) def f (): a = tf . constant ( 1.0 ) b = tf . constant ( - 2.0 ) c = tf . constant ( 1.0 ) y = a * tf . pow ( x , 2 ) + b * x + c return ( y ) @tf . function def train ( epoch = 1000 ): for _ in tf . range ( epoch ): optimizer . minimize ( f ,[ x ]) tf . print ( \"epoch = \" , optimizer . iterations ) return ( f ()) train ( 1000 ) tf . print ( \"y = \" , f ()) tf . print ( \"x = \" , x ) # Minimal value of f(x) = a*x**2 + b*x + c # Here we use model.fit tf . keras . backend . clear_session () class FakeModel ( tf . keras . models . Model ): def __init__ ( self , a , b , c ): super ( FakeModel , self ) . __init__ () self . a = a self . b = b self . c = c def build ( self ): self . x = tf . Variable ( 0.0 , name = \"x\" ) self . built = True def call ( self , features ): loss = self . a * ( self . x ) ** 2 + self . b * ( self . x ) + self . c return ( tf . ones_like ( features ) * loss ) def myloss ( y_true , y_pred ): return tf . reduce_mean ( y_pred ) model = FakeModel ( tf . constant ( 1.0 ), tf . constant ( - 2.0 ), tf . constant ( 1.0 )) model . build () model . summary () model . compile ( optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ), loss = myloss ) history = model . fit ( tf . zeros (( 100 , 2 )), tf . ones ( 100 ), batch_size = 1 , epochs = 10 ) # Iterate for 1000 times tf . print ( \"x=\" , model . x ) tf . print ( \"loss=\" , model ( tf . constant ( 0.0 )))","title":"1. How To Use the Optimizer"},{"location":"english/Chapter5/Chapter5-7/#2-pre-defined-optimizers","text":"The evolution of the optimization algorithm for the deep learning is: SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam There are corresponding classes in keras.optimizers sub-module as the implementations of these optimizers. SGD , the default parameters is for a pure SGD. For a non-zero parameter momentum , the optimizer changes to SGDM since it considers the first-order momentum. For nesterov = True, the optimizer changes to NAG (Nesterov Accelerated Gradient), which calculates the gradient of the one further step. Adagrad , considers the second-order momentum and equipted with self-adaptive learning rate; the drawback is a slow learning rate at a later stage or early ceasing of learning due to the monotonically desending leanring rate. RMSprop , considers the second-order momentum and equipted with self-adaptive learning rate; improves the Adagrad through exponential smoothing, which only cnosiders the second-order momentum in a given window length. Adadelta , considers the second-order momentum, similar as RMSprop but more complicated with an improved self-adaption. Adam , consider both the first-order and the second-order momentum; it improves RMSprop by including first-order momentum. Nadam , improves Adam by including Nesterov Acceleration. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Pre-defined Optimizers"},{"location":"english/Chapter5/Chapter5-8/","text":"5-8 callbacks # The callbacks in tf.keras is a class, usually specified as a parameter when use model.fit . It provides the extra operations at the starting or the ending of training, each epoch or each batch. These operations include record some log information, change learning rate, early termination of the training, etc. Likewise, this callbacks parameter is also able to be specified for model.evaluate or model.predict , providing extra operations at the starting or the ending of the evaluation, prediction, or each batch. However this method is rarely used. For the most cases, the pre-defined callbacks in the sub-module keras.callbacks are sufficient. It is also possible to define child class inheriting keras.callbacks.Callbacks to customize callbacks if necessary. All the classes of callbacks are inheriting keras.callbacks.Callbacks , which contains two attributes: params and model . params is a dictionary, which records training parameters (e.g. verbosity, batch size, number of epochs, etc.). model is the reference to the current model. What's more, there is an extra argument logs in the certain methods of the callbacks classes, such as on_epoch_begin , on_batch_end . This parameter provides certain information of current epoch or batch and are able to save the computing results. These logs variables are able to transfer among the functions with the same name in these callbacks classes. 1. Pre-defined Callbacks # BaseLogger : it calcuates the mean metrics among all batches for each epoch. For those metrics with middle status in staeful_metrics , it uses the final metrics without calculating mean value for all the batches, and the final mean metrics is added to the variable logs . This callback is automatically applied to every Keras model and is applied first. History : a dictionary that records the metrics of each epoch calculated by BaseLogger and is returned by model.fit . This callback is automatically applied to every Keras model after BaseLogger . EarlyStopping : this callback terminates the training if the monitoring metrics are not significantly increased after certain number of epoches. TensorBoard : this callback saves the visualized log of the Tensorboard. It supports visualization of metrics, graphs and parameters in the model. ModelCheckpoint : this callback saves model after each epoch. ReduceLROnPlateau : this callback reduce the learning rate with certain rate if the monitoring metrics are not significantly increased after certain number of epoches. TerminateOnNaN : terminate the training if loss is NaN. LearningRateScheduler : it controls the learning rate before each epoch with given function between the learning rate lr and epoch. CSVLogger : save logs of each epoch in CSV file. ProgbarLogger : print the logs of each epoch into stardard I/O stream. 2. Customized Callbacks # It is possible to write a simple callback through callbacks.LambdaCallback , or write a complicated callback through inheriting base class callbacks.Callback . Don't hesitate to read the source code to know more details of the callbacks in tf.Keras . import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics , callbacks import tensorflow.keras.backend as K # Example of the simple callback using LambdaCallback import json json_log = open ( '../../data/keras_log.json' , mode = 'wt' , buffering = 1 ) json_logging_callback = callbacks . LambdaCallback ( on_epoch_end = lambda epoch , logs : json_log . write ( json . dumps ( dict ( epoch = epoch , ** logs )) + ' \\n ' ), on_train_end = lambda logs : json_log . close () ) # Example of the complicated callback through base class inheritance. This is the source code of LearningRateScheduler. class LearningRateScheduler ( callbacks . Callback ): def __init__ ( self , schedule , verbose = 0 ): super ( LearningRateScheduler , self ) . __init__ () self . schedule = schedule self . verbose = verbose def on_epoch_begin ( self , epoch , logs = None ): if not hasattr ( self . model . optimizer , 'lr' ): raise ValueError ( 'Optimizer must have a \"lr\" attribute.' ) try : lr = float ( K . get_value ( self . model . optimizer . lr )) lr = self . schedule ( epoch , lr ) except TypeError : # Support for old API for backward compatibility lr = self . schedule ( epoch ) if not isinstance ( lr , ( tf . Tensor , float , np . float32 , np . float64 )): raise ValueError ( 'The output of the \"schedule\" function ' 'should be float.' ) if isinstance ( lr , ops . Tensor ) and not lr . dtype . is_floating : raise ValueError ( 'The dtype of Tensor should be float' ) K . set_value ( self . model . optimizer . lr , K . get_value ( lr )) if self . verbose > 0 : print ( ' \\n Epoch %05d : LearningRateScheduler reducing learning ' 'rate to %s .' % ( epoch + 1 , lr )) def on_epoch_end ( self , epoch , logs = None ): logs = logs or {} logs [ 'lr' ] = K . get_value ( self . model . optimizer . lr ) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5-8 callbacks"},{"location":"english/Chapter5/Chapter5-8/#5-8-callbacks","text":"The callbacks in tf.keras is a class, usually specified as a parameter when use model.fit . It provides the extra operations at the starting or the ending of training, each epoch or each batch. These operations include record some log information, change learning rate, early termination of the training, etc. Likewise, this callbacks parameter is also able to be specified for model.evaluate or model.predict , providing extra operations at the starting or the ending of the evaluation, prediction, or each batch. However this method is rarely used. For the most cases, the pre-defined callbacks in the sub-module keras.callbacks are sufficient. It is also possible to define child class inheriting keras.callbacks.Callbacks to customize callbacks if necessary. All the classes of callbacks are inheriting keras.callbacks.Callbacks , which contains two attributes: params and model . params is a dictionary, which records training parameters (e.g. verbosity, batch size, number of epochs, etc.). model is the reference to the current model. What's more, there is an extra argument logs in the certain methods of the callbacks classes, such as on_epoch_begin , on_batch_end . This parameter provides certain information of current epoch or batch and are able to save the computing results. These logs variables are able to transfer among the functions with the same name in these callbacks classes.","title":"5-8 callbacks"},{"location":"english/Chapter5/Chapter5-8/#1-pre-defined-callbacks","text":"BaseLogger : it calcuates the mean metrics among all batches for each epoch. For those metrics with middle status in staeful_metrics , it uses the final metrics without calculating mean value for all the batches, and the final mean metrics is added to the variable logs . This callback is automatically applied to every Keras model and is applied first. History : a dictionary that records the metrics of each epoch calculated by BaseLogger and is returned by model.fit . This callback is automatically applied to every Keras model after BaseLogger . EarlyStopping : this callback terminates the training if the monitoring metrics are not significantly increased after certain number of epoches. TensorBoard : this callback saves the visualized log of the Tensorboard. It supports visualization of metrics, graphs and parameters in the model. ModelCheckpoint : this callback saves model after each epoch. ReduceLROnPlateau : this callback reduce the learning rate with certain rate if the monitoring metrics are not significantly increased after certain number of epoches. TerminateOnNaN : terminate the training if loss is NaN. LearningRateScheduler : it controls the learning rate before each epoch with given function between the learning rate lr and epoch. CSVLogger : save logs of each epoch in CSV file. ProgbarLogger : print the logs of each epoch into stardard I/O stream.","title":"1. Pre-defined Callbacks"},{"location":"english/Chapter5/Chapter5-8/#2-customized-callbacks","text":"It is possible to write a simple callback through callbacks.LambdaCallback , or write a complicated callback through inheriting base class callbacks.Callback . Don't hesitate to read the source code to know more details of the callbacks in tf.Keras . import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import layers , models , losses , metrics , callbacks import tensorflow.keras.backend as K # Example of the simple callback using LambdaCallback import json json_log = open ( '../../data/keras_log.json' , mode = 'wt' , buffering = 1 ) json_logging_callback = callbacks . LambdaCallback ( on_epoch_end = lambda epoch , logs : json_log . write ( json . dumps ( dict ( epoch = epoch , ** logs )) + ' \\n ' ), on_train_end = lambda logs : json_log . close () ) # Example of the complicated callback through base class inheritance. This is the source code of LearningRateScheduler. class LearningRateScheduler ( callbacks . Callback ): def __init__ ( self , schedule , verbose = 0 ): super ( LearningRateScheduler , self ) . __init__ () self . schedule = schedule self . verbose = verbose def on_epoch_begin ( self , epoch , logs = None ): if not hasattr ( self . model . optimizer , 'lr' ): raise ValueError ( 'Optimizer must have a \"lr\" attribute.' ) try : lr = float ( K . get_value ( self . model . optimizer . lr )) lr = self . schedule ( epoch , lr ) except TypeError : # Support for old API for backward compatibility lr = self . schedule ( epoch ) if not isinstance ( lr , ( tf . Tensor , float , np . float32 , np . float64 )): raise ValueError ( 'The output of the \"schedule\" function ' 'should be float.' ) if isinstance ( lr , ops . Tensor ) and not lr . dtype . is_floating : raise ValueError ( 'The dtype of Tensor should be float' ) K . set_value ( self . model . optimizer . lr , K . get_value ( lr )) if self . verbose > 0 : print ( ' \\n Epoch %05d : LearningRateScheduler reducing learning ' 'rate to %s .' % ( epoch + 1 , lr )) def on_epoch_end ( self , epoch , logs = None ): logs = logs or {} logs [ 'lr' ] = K . get_value ( self . model . optimizer . lr ) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"2. Customized Callbacks"},{"location":"english/Chapter6/","text":"Chapter 6: High-level API in TensorFlow # The high-level API in TensorFlow mainly refers to tensorflow.keras.models . This chapter introduces the following details related to tensorflow.keras.models : Model constructing (using Sequential , functional API, or the child class of Model ) Model training (using pre-defined fit , train_on_batch methods, customized training loops, single GPU training, multiple GPU training, and TPU training) Model deployment (using tensorflow serving for deployment, using spark (scala) for using tensorflow models) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"Chapter 6: High-level API in TensorFlow"},{"location":"english/Chapter6/#chapter-6-high-level-api-in-tensorflow","text":"The high-level API in TensorFlow mainly refers to tensorflow.keras.models . This chapter introduces the following details related to tensorflow.keras.models : Model constructing (using Sequential , functional API, or the child class of Model ) Model training (using pre-defined fit , train_on_batch methods, customized training loops, single GPU training, multiple GPU training, and TPU training) Model deployment (using tensorflow serving for deployment, using spark (scala) for using tensorflow models) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"Chapter 6: High-level API in TensorFlow"},{"location":"english/Chapter6/Chapter6-1/","text":"6-1 Three Ways of Modeling # There are three ways of modeling: using Sequential to construct model with the order of layers, using functional APIs to construct model with arbitrary structure, using child class inheriting from the base class Model . For the models with sequenced structure, Sequential method should be given the highest priority. For the models with nonsequenced structures such as multiple input/output, shared weights, or residual connections, modeling with functional API is recommended. Modeling through child class of Model should be AVOIDED unless with special requirements. This method is flexible, but also fallible. Here are the examples of modeling using the three above-mentioned methods to classify IMDB movie reviews. import numpy as np import pandas as pd import tensorflow as tf from tqdm import tqdm from tensorflow.keras import * train_token_path = \"../../data/imdb/train_token.csv\" test_token_path = \"../../data/imdb/test_token.csv\" MAX_WORDS = 10000 # We will only consider the top 10,000 words in the dataset MAX_LEN = 200 # We will cut reviews after 200 words BATCH_SIZE = 20 # Constructing data pipeline def parse_line ( line ): t = tf . strings . split ( line , \" \\t \" ) label = tf . reshape ( tf . cast ( tf . strings . to_number ( t [ 0 ]), tf . int32 ),( - 1 ,)) features = tf . cast ( tf . strings . to_number ( tf . strings . split ( t [ 1 ], \" \" )), tf . int32 ) return ( features , label ) ds_train = tf . data . TextLineDataset ( filenames = [ train_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . TextLineDataset ( filenames = [ test_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) 1. Modeling Using Sequential # tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 1 , activation = \"sigmoid\" )) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () import datetime baselogger = callbacks . BaseLogger ( stateful_metrics = [ \"AUC\" ]) logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ baselogger , tensorboard_callback ]) % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"AUC\" ) 2. Modeling Using Functional API # tf . keras . backend . clear_session () inputs = layers . Input ( shape = [ MAX_LEN ]) x = layers . Embedding ( MAX_WORDS , 7 )( inputs ) branch1 = layers . SeparableConv1D ( 64 , 3 , activation = \"relu\" )( x ) branch1 = layers . MaxPool1D ( 3 )( branch1 ) branch1 = layers . SeparableConv1D ( 32 , 3 , activation = \"relu\" )( branch1 ) branch1 = layers . GlobalMaxPool1D ()( branch1 ) branch2 = layers . SeparableConv1D ( 64 , 5 , activation = \"relu\" )( x ) branch2 = layers . MaxPool1D ( 5 )( branch2 ) branch2 = layers . SeparableConv1D ( 32 , 5 , activation = \"relu\" )( branch2 ) branch2 = layers . GlobalMaxPool1D ()( branch2 ) branch3 = layers . SeparableConv1D ( 64 , 7 , activation = \"relu\" )( x ) branch3 = layers . MaxPool1D ( 7 )( branch3 ) branch3 = layers . SeparableConv1D ( 32 , 7 , activation = \"relu\" )( branch3 ) branch3 = layers . GlobalMaxPool1D ()( branch3 ) concat = layers . Concatenate ()([ branch1 , branch2 , branch3 ]) outputs = layers . Dense ( 1 , activation = \"sigmoid\" )( concat ) model = models . Model ( inputs = inputs , outputs = outputs ) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 200)] 0 __________________________________________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 input_1[0][0] __________________________________________________________________________________________________ separable_conv1d (SeparableConv (None, 198, 64) 533 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_2 (SeparableCo (None, 196, 64) 547 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_4 (SeparableCo (None, 194, 64) 561 embedding[0][0] __________________________________________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 66, 64) 0 separable_conv1d[0][0] __________________________________________________________________________________________________ max_pooling1d_1 (MaxPooling1D) (None, 39, 64) 0 separable_conv1d_2[0][0] __________________________________________________________________________________________________ max_pooling1d_2 (MaxPooling1D) (None, 27, 64) 0 separable_conv1d_4[0][0] __________________________________________________________________________________________________ separable_conv1d_1 (SeparableCo (None, 64, 32) 2272 max_pooling1d[0][0] __________________________________________________________________________________________________ separable_conv1d_3 (SeparableCo (None, 35, 32) 2400 max_pooling1d_1[0][0] __________________________________________________________________________________________________ separable_conv1d_5 (SeparableCo (None, 21, 32) 2528 max_pooling1d_2[0][0] __________________________________________________________________________________________________ global_max_pooling1d (GlobalMax (None, 32) 0 separable_conv1d_1[0][0] __________________________________________________________________________________________________ global_max_pooling1d_1 (GlobalM (None, 32) 0 separable_conv1d_3[0][0] __________________________________________________________________________________________________ global_max_pooling1d_2 (GlobalM (None, 32) 0 separable_conv1d_5[0][0] __________________________________________________________________________________________________ concatenate (Concatenate) (None, 96) 0 global_max_pooling1d[0][0] global_max_pooling1d_1[0][0] global_max_pooling1d_2[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 1) 97 concatenate[0][0] ================================================================================================== Total params: 78,938 Trainable params: 78,938 Non-trainable params: 0 __________________________________________________________________________________________________ import datetime logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192 Epoch 2/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350 Epoch 3/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363 Epoch 4/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311 Epoch 5/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233 Epoch 6/6 1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138 plot_metric ( history , \"AUC\" ) 3. Customized Modeling Using Child Class of Model # # Define a customized residual module as Layer class ResBlock ( layers . Layer ): def __init__ ( self , kernel_size , ** kwargs ): super ( ResBlock , self ) . __init__ ( ** kwargs ) self . kernel_size = kernel_size def build ( self , input_shape ): self . conv1 = layers . Conv1D ( filters = 64 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv2 = layers . Conv1D ( filters = 32 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv3 = layers . Conv1D ( filters = input_shape [ - 1 ], kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . maxpool = layers . MaxPool1D ( 2 ) super ( ResBlock , self ) . build ( input_shape ) # Identical to self.built = True def call ( self , inputs ): x = self . conv1 ( inputs ) x = self . conv2 ( x ) x = self . conv3 ( x ) x = layers . Add ()([ inputs , x ]) x = self . maxpool ( x ) return x # Need to define get_config method in order to sequentialize the model constructed from the customized Layer by Functional API. def get_config ( self ): config = super ( ResBlock , self ) . get_config () config . update ({ 'kernel_size' : self . kernel_size }) return config # Test ResBlock resblock = ResBlock ( kernel_size = 3 ) resblock . build ( input_shape = ( None , 200 , 7 )) resblock . compute_output_shape ( input_shape = ( None , 200 , 7 )) TensorShape([None, 100, 7]) # Customized model, which could also be implemented by Sequential or Functional API class ImdbModel ( models . Model ): def __init__ ( self ): super ( ImdbModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 ) self . block1 = ResBlock ( 7 ) self . block2 = ResBlock ( 5 ) self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( ImdbModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . block1 ( x ) x = self . block2 ( x ) x = layers . Flatten ()( x ) x = self . dense ( x ) return ( x ) tf . keras . backend . clear_session () model = ImdbModel () model . build ( input_shape = ( None , 200 )) model . summary () model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) Model: \"imdb_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) multiple 70000 _________________________________________________________________ res_block (ResBlock) multiple 19143 _________________________________________________________________ res_block_1 (ResBlock) multiple 13703 _________________________________________________________________ dense (Dense) multiple 351 ================================================================= Total params: 103,197 Trainable params: 103,197 Non-trainable params: 0 _________________________________________________________________ import datetime logdir = \"../tflogs/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286 Epoch 2/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410 Epoch 3/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390 Epoch 4/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292 Epoch 5/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132 Epoch 6/6 1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052 plot_metric ( history , \"AUC\" ) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-1 Three Ways of Modeling"},{"location":"english/Chapter6/Chapter6-1/#6-1-three-ways-of-modeling","text":"There are three ways of modeling: using Sequential to construct model with the order of layers, using functional APIs to construct model with arbitrary structure, using child class inheriting from the base class Model . For the models with sequenced structure, Sequential method should be given the highest priority. For the models with nonsequenced structures such as multiple input/output, shared weights, or residual connections, modeling with functional API is recommended. Modeling through child class of Model should be AVOIDED unless with special requirements. This method is flexible, but also fallible. Here are the examples of modeling using the three above-mentioned methods to classify IMDB movie reviews. import numpy as np import pandas as pd import tensorflow as tf from tqdm import tqdm from tensorflow.keras import * train_token_path = \"../../data/imdb/train_token.csv\" test_token_path = \"../../data/imdb/test_token.csv\" MAX_WORDS = 10000 # We will only consider the top 10,000 words in the dataset MAX_LEN = 200 # We will cut reviews after 200 words BATCH_SIZE = 20 # Constructing data pipeline def parse_line ( line ): t = tf . strings . split ( line , \" \\t \" ) label = tf . reshape ( tf . cast ( tf . strings . to_number ( t [ 0 ]), tf . int32 ),( - 1 ,)) features = tf . cast ( tf . strings . to_number ( tf . strings . split ( t [ 1 ], \" \" )), tf . int32 ) return ( features , label ) ds_train = tf . data . TextLineDataset ( filenames = [ train_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) ds_test = tf . data . TextLineDataset ( filenames = [ test_token_path ]) \\ . map ( parse_line , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE )","title":"6-1 Three Ways of Modeling"},{"location":"english/Chapter6/Chapter6-1/#1-modeling-using-sequential","text":"tf . keras . backend . clear_session () model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 1 , activation = \"sigmoid\" )) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () import datetime baselogger = callbacks . BaseLogger ( stateful_metrics = [ \"AUC\" ]) logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ baselogger , tensorboard_callback ]) % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( history , metric ): train_metrics = history . history [ metric ] val_metrics = history . history [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( history , \"AUC\" )","title":"1. Modeling Using Sequential"},{"location":"english/Chapter6/Chapter6-1/#2-modeling-using-functional-api","text":"tf . keras . backend . clear_session () inputs = layers . Input ( shape = [ MAX_LEN ]) x = layers . Embedding ( MAX_WORDS , 7 )( inputs ) branch1 = layers . SeparableConv1D ( 64 , 3 , activation = \"relu\" )( x ) branch1 = layers . MaxPool1D ( 3 )( branch1 ) branch1 = layers . SeparableConv1D ( 32 , 3 , activation = \"relu\" )( branch1 ) branch1 = layers . GlobalMaxPool1D ()( branch1 ) branch2 = layers . SeparableConv1D ( 64 , 5 , activation = \"relu\" )( x ) branch2 = layers . MaxPool1D ( 5 )( branch2 ) branch2 = layers . SeparableConv1D ( 32 , 5 , activation = \"relu\" )( branch2 ) branch2 = layers . GlobalMaxPool1D ()( branch2 ) branch3 = layers . SeparableConv1D ( 64 , 7 , activation = \"relu\" )( x ) branch3 = layers . MaxPool1D ( 7 )( branch3 ) branch3 = layers . SeparableConv1D ( 32 , 7 , activation = \"relu\" )( branch3 ) branch3 = layers . GlobalMaxPool1D ()( branch3 ) concat = layers . Concatenate ()([ branch1 , branch2 , branch3 ]) outputs = layers . Dense ( 1 , activation = \"sigmoid\" )( concat ) model = models . Model ( inputs = inputs , outputs = outputs ) model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) model . summary () Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 200)] 0 __________________________________________________________________________________________________ embedding (Embedding) (None, 200, 7) 70000 input_1[0][0] __________________________________________________________________________________________________ separable_conv1d (SeparableConv (None, 198, 64) 533 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_2 (SeparableCo (None, 196, 64) 547 embedding[0][0] __________________________________________________________________________________________________ separable_conv1d_4 (SeparableCo (None, 194, 64) 561 embedding[0][0] __________________________________________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 66, 64) 0 separable_conv1d[0][0] __________________________________________________________________________________________________ max_pooling1d_1 (MaxPooling1D) (None, 39, 64) 0 separable_conv1d_2[0][0] __________________________________________________________________________________________________ max_pooling1d_2 (MaxPooling1D) (None, 27, 64) 0 separable_conv1d_4[0][0] __________________________________________________________________________________________________ separable_conv1d_1 (SeparableCo (None, 64, 32) 2272 max_pooling1d[0][0] __________________________________________________________________________________________________ separable_conv1d_3 (SeparableCo (None, 35, 32) 2400 max_pooling1d_1[0][0] __________________________________________________________________________________________________ separable_conv1d_5 (SeparableCo (None, 21, 32) 2528 max_pooling1d_2[0][0] __________________________________________________________________________________________________ global_max_pooling1d (GlobalMax (None, 32) 0 separable_conv1d_1[0][0] __________________________________________________________________________________________________ global_max_pooling1d_1 (GlobalM (None, 32) 0 separable_conv1d_3[0][0] __________________________________________________________________________________________________ global_max_pooling1d_2 (GlobalM (None, 32) 0 separable_conv1d_5[0][0] __________________________________________________________________________________________________ concatenate (Concatenate) (None, 96) 0 global_max_pooling1d[0][0] global_max_pooling1d_1[0][0] global_max_pooling1d_2[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 1) 97 concatenate[0][0] ================================================================================================== Total params: 78,938 Trainable params: 78,938 Non-trainable params: 0 __________________________________________________________________________________________________ import datetime logdir = \"../../data/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192 Epoch 2/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350 Epoch 3/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363 Epoch 4/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311 Epoch 5/6 1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233 Epoch 6/6 1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138 plot_metric ( history , \"AUC\" )","title":"2. Modeling Using Functional API"},{"location":"english/Chapter6/Chapter6-1/#3-customized-modeling-using-child-class-of-model","text":"# Define a customized residual module as Layer class ResBlock ( layers . Layer ): def __init__ ( self , kernel_size , ** kwargs ): super ( ResBlock , self ) . __init__ ( ** kwargs ) self . kernel_size = kernel_size def build ( self , input_shape ): self . conv1 = layers . Conv1D ( filters = 64 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv2 = layers . Conv1D ( filters = 32 , kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . conv3 = layers . Conv1D ( filters = input_shape [ - 1 ], kernel_size = self . kernel_size , activation = \"relu\" , padding = \"same\" ) self . maxpool = layers . MaxPool1D ( 2 ) super ( ResBlock , self ) . build ( input_shape ) # Identical to self.built = True def call ( self , inputs ): x = self . conv1 ( inputs ) x = self . conv2 ( x ) x = self . conv3 ( x ) x = layers . Add ()([ inputs , x ]) x = self . maxpool ( x ) return x # Need to define get_config method in order to sequentialize the model constructed from the customized Layer by Functional API. def get_config ( self ): config = super ( ResBlock , self ) . get_config () config . update ({ 'kernel_size' : self . kernel_size }) return config # Test ResBlock resblock = ResBlock ( kernel_size = 3 ) resblock . build ( input_shape = ( None , 200 , 7 )) resblock . compute_output_shape ( input_shape = ( None , 200 , 7 )) TensorShape([None, 100, 7]) # Customized model, which could also be implemented by Sequential or Functional API class ImdbModel ( models . Model ): def __init__ ( self ): super ( ImdbModel , self ) . __init__ () def build ( self , input_shape ): self . embedding = layers . Embedding ( MAX_WORDS , 7 ) self . block1 = ResBlock ( 7 ) self . block2 = ResBlock ( 5 ) self . dense = layers . Dense ( 1 , activation = \"sigmoid\" ) super ( ImdbModel , self ) . build ( input_shape ) def call ( self , x ): x = self . embedding ( x ) x = self . block1 ( x ) x = self . block2 ( x ) x = layers . Flatten ()( x ) x = self . dense ( x ) return ( x ) tf . keras . backend . clear_session () model = ImdbModel () model . build ( input_shape = ( None , 200 )) model . summary () model . compile ( optimizer = 'Nadam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' , \"AUC\" ]) Model: \"imdb_model\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) multiple 70000 _________________________________________________________________ res_block (ResBlock) multiple 19143 _________________________________________________________________ res_block_1 (ResBlock) multiple 13703 _________________________________________________________________ dense (Dense) multiple 351 ================================================================= Total params: 103,197 Trainable params: 103,197 Non-trainable params: 0 _________________________________________________________________ import datetime logdir = \"../tflogs/keras_model/\" + datetime . datetime . now () . strftime ( \"%Y%m %d -%H%M%S\" ) tensorboard_callback = tf . keras . callbacks . TensorBoard ( logdir , histogram_freq = 1 ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 6 , callbacks = [ tensorboard_callback ]) Epoch 1/6 1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286 Epoch 2/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410 Epoch 3/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390 Epoch 4/6 1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292 Epoch 5/6 1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132 Epoch 6/6 1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052 plot_metric ( history , \"AUC\" ) Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. Customized Modeling Using Child Class of Model"},{"location":"english/Chapter6/Chapter6-2/","text":"6-2 Three Ways of Training # There are three ways of model training: using pre-defined fit method, using pre-defined tran_on_batch method, using customized training loop. Note: fit_generator method is not recommended in tf.keras since it has been merged into fit . import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import * # Time stamps @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () 1. Pre-defined fit method # This is a powerful method, which supports training the data with types of numpy array, tf.data.Dataset and Python generator. This method also supports complicated logical controlling through proper configuration of the callbacks. tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 11s 37ms/step - loss: 2.0231 - sparse_categorical_accuracy: 0.4636 - sparse_top_k_categorical_accuracy: 0.7450 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.7560 Epoch 2/10 281/281 [==============================] - 9s 31ms/step - loss: 1.5079 - sparse_categorical_accuracy: 0.6091 - sparse_top_k_categorical_accuracy: 0.7901 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.6109 - val_sparse_top_k_categorical_accuracy: 0.7792 Epoch 3/10 281/281 [==============================] - 9s 33ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6823 - sparse_top_k_categorical_accuracy: 0.8448 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_top_k_categorical_accuracy: 0.8001 Epoch 4/10 281/281 [==============================] - 9s 33ms/step - loss: 0.9382 - sparse_categorical_accuracy: 0.7543 - sparse_top_k_categorical_accuracy: 0.9075 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.6398 - val_sparse_top_k_categorical_accuracy: 0.8032 Epoch 5/10 281/281 [==============================] - 10s 34ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8255 - sparse_top_k_categorical_accuracy: 0.9513 - val_loss: 1.9426 - val_sparse_categorical_accuracy: 0.6376 - val_sparse_top_k_categorical_accuracy: 0.7956 Epoch 6/10 281/281 [==============================] - 9s 33ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8762 - sparse_top_k_categorical_accuracy: 0.9716 - val_loss: 2.2141 - val_sparse_categorical_accuracy: 0.6291 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 7/10 281/281 [==============================] - 10s 37ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.6264 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 8/10 281/281 [==============================] - 10s 35ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9205 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 2.5366 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7974 Epoch 9/10 281/281 [==============================] - 10s 36ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9299 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 2.6564 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 10/10 281/281 [==============================] - 9s 30ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9334 - sparse_top_k_categorical_accuracy: 0.9947 - val_loss: 2.7365 - val_sparse_categorical_accuracy: 0.6220 - val_sparse_top_k_categorical_accuracy: 0.8005 2. Pre-defined train_on_batch method # This pre-defined method allows fine-controlling to the training procedure for each batch without the callbacks, which is even more flexible than fit method. tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ def train_model ( model , ds_train , ds_valid , epoches ): for epoch in tf . range ( 1 , epoches + 1 ): model . reset_metrics () # Reduce learning rate at the late stage of training. if epoch == 5 : model . optimizer . lr . assign ( model . optimizer . lr / 2.0 ) tf . print ( \"Lowering optimizer Learning Rate... \\n\\n \" ) for x , y in ds_train : train_result = model . train_on_batch ( x , y ) for x , y in ds_valid : valid_result = model . test_on_batch ( x , y , reset_metrics = False ) if epoch % 1 == 0 : printbar () tf . print ( \"epoch = \" , epoch ) print ( \"train:\" , dict ( zip ( model . metrics_names , train_result ))) print ( \"valid:\" , dict ( zip ( model . metrics_names , valid_result ))) print ( \"\" ) train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:09:19 epoch = 1 train: {'loss': 0.82411176, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.8636364} valid: {'loss': 1.9265995, 'sparse_categorical_accuracy': 0.5743544, 'sparse_top_k_categorical_accuracy': 0.75779164} ================================================================================13:09:27 epoch = 2 train: {'loss': 0.6006621, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 1.844159, 'sparse_categorical_accuracy': 0.6126447, 'sparse_top_k_categorical_accuracy': 0.7920748} ================================================================================13:09:35 epoch = 3 train: {'loss': 0.36935613, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 2.163433, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.8045414} ================================================================================13:09:42 epoch = 4 train: {'loss': 0.2304088, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 2.8911984, 'sparse_categorical_accuracy': 0.6344613, 'sparse_top_k_categorical_accuracy': 0.7978629} Lowering optimizer Learning Rate... ================================================================================13:09:51 epoch = 5 train: {'loss': 0.111194365, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 3.6431572, 'sparse_categorical_accuracy': 0.6295637, 'sparse_top_k_categorical_accuracy': 0.7978629} ================================================================================13:09:59 epoch = 6 train: {'loss': 0.07741702, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.074161, 'sparse_categorical_accuracy': 0.6255565, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:07 epoch = 7 train: {'loss': 0.056113098, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.4461513, 'sparse_categorical_accuracy': 0.6273375, 'sparse_top_k_categorical_accuracy': 0.79652715} ================================================================================13:10:17 epoch = 8 train: {'loss': 0.043448802, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.7687583, 'sparse_categorical_accuracy': 0.6224399, 'sparse_top_k_categorical_accuracy': 0.79741764} ================================================================================13:10:26 epoch = 9 train: {'loss': 0.035002146, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.130505, 'sparse_categorical_accuracy': 0.6175423, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:34 epoch = 10 train: {'loss': 0.028303564, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.4559293, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7947462} 3. Customized Training Loop # Re-compilation of the model is not required in the customized training loop, just back-propagate the iterative parameters through the optimizer according to the loss function, which gives us the highest flexibility. tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:12:03 Epoch=1,Loss:2.02051544,Accuracy:0.460253835,Valid Loss:1.75700927,Valid Accuracy:0.536954582 ================================================================================13:12:09 Epoch=2,Loss:1.510795,Accuracy:0.610665798,Valid Loss:1.55349839,Valid Accuracy:0.616206586 ================================================================================13:12:17 Epoch=3,Loss:1.19221532,Accuracy:0.696170092,Valid Loss:1.52315605,Valid Accuracy:0.651380241 ================================================================================13:12:23 Epoch=4,Loss:0.90101546,Accuracy:0.766310394,Valid Loss:1.68327653,Valid Accuracy:0.648263574 ================================================================================13:12:30 Epoch=5,Loss:0.655430496,Accuracy:0.831329346,Valid Loss:1.90872383,Valid Accuracy:0.641139805 ================================================================================13:12:37 Epoch=6,Loss:0.492730737,Accuracy:0.877866864,Valid Loss:2.09966016,Valid Accuracy:0.63223511 ================================================================================13:12:44 Epoch=7,Loss:0.391238362,Accuracy:0.904030263,Valid Loss:2.27431226,Valid Accuracy:0.625111282 ================================================================================13:12:51 Epoch=8,Loss:0.327761739,Accuracy:0.922066331,Valid Loss:2.42568827,Valid Accuracy:0.617542326 ================================================================================13:12:58 Epoch=9,Loss:0.285573095,Accuracy:0.930527747,Valid Loss:2.55942106,Valid Accuracy:0.612644672 ================================================================================13:13:05 Epoch=10,Loss:0.255482465,Accuracy:0.936094403,Valid Loss:2.67789412,Valid Accuracy:0.612199485 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-2 Three Ways of Training"},{"location":"english/Chapter6/Chapter6-2/#6-2-three-ways-of-training","text":"There are three ways of model training: using pre-defined fit method, using pre-defined tran_on_batch method, using customized training loop. Note: fit_generator method is not recommended in tf.keras since it has been merged into fit . import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras import * # Time stamps @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"6-2 Three Ways of Training"},{"location":"english/Chapter6/Chapter6-2/#1-pre-defined-fit-method","text":"This is a powerful method, which supports training the data with types of numpy array, tf.data.Dataset and Python generator. This method also supports complicated logical controlling through proper configuration of the callbacks. tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 11s 37ms/step - loss: 2.0231 - sparse_categorical_accuracy: 0.4636 - sparse_top_k_categorical_accuracy: 0.7450 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.7560 Epoch 2/10 281/281 [==============================] - 9s 31ms/step - loss: 1.5079 - sparse_categorical_accuracy: 0.6091 - sparse_top_k_categorical_accuracy: 0.7901 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.6109 - val_sparse_top_k_categorical_accuracy: 0.7792 Epoch 3/10 281/281 [==============================] - 9s 33ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6823 - sparse_top_k_categorical_accuracy: 0.8448 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_top_k_categorical_accuracy: 0.8001 Epoch 4/10 281/281 [==============================] - 9s 33ms/step - loss: 0.9382 - sparse_categorical_accuracy: 0.7543 - sparse_top_k_categorical_accuracy: 0.9075 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.6398 - val_sparse_top_k_categorical_accuracy: 0.8032 Epoch 5/10 281/281 [==============================] - 10s 34ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8255 - sparse_top_k_categorical_accuracy: 0.9513 - val_loss: 1.9426 - val_sparse_categorical_accuracy: 0.6376 - val_sparse_top_k_categorical_accuracy: 0.7956 Epoch 6/10 281/281 [==============================] - 9s 33ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8762 - sparse_top_k_categorical_accuracy: 0.9716 - val_loss: 2.2141 - val_sparse_categorical_accuracy: 0.6291 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 7/10 281/281 [==============================] - 10s 37ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.6264 - val_sparse_top_k_categorical_accuracy: 0.7947 Epoch 8/10 281/281 [==============================] - 10s 35ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9205 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 2.5366 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7974 Epoch 9/10 281/281 [==============================] - 10s 36ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9299 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 2.6564 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 10/10 281/281 [==============================] - 9s 30ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9334 - sparse_top_k_categorical_accuracy: 0.9947 - val_loss: 2.7365 - val_sparse_categorical_accuracy: 0.6220 - val_sparse_top_k_categorical_accuracy: 0.8005","title":"1. Pre-defined fit method"},{"location":"english/Chapter6/Chapter6-2/#2-pre-defined-train_on_batch-method","text":"This pre-defined method allows fine-controlling to the training procedure for each batch without the callbacks, which is even more flexible than fit method. tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy (), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) model = create_model () model . summary () model = compile_model ( model ) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ def train_model ( model , ds_train , ds_valid , epoches ): for epoch in tf . range ( 1 , epoches + 1 ): model . reset_metrics () # Reduce learning rate at the late stage of training. if epoch == 5 : model . optimizer . lr . assign ( model . optimizer . lr / 2.0 ) tf . print ( \"Lowering optimizer Learning Rate... \\n\\n \" ) for x , y in ds_train : train_result = model . train_on_batch ( x , y ) for x , y in ds_valid : valid_result = model . test_on_batch ( x , y , reset_metrics = False ) if epoch % 1 == 0 : printbar () tf . print ( \"epoch = \" , epoch ) print ( \"train:\" , dict ( zip ( model . metrics_names , train_result ))) print ( \"valid:\" , dict ( zip ( model . metrics_names , valid_result ))) print ( \"\" ) train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:09:19 epoch = 1 train: {'loss': 0.82411176, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.8636364} valid: {'loss': 1.9265995, 'sparse_categorical_accuracy': 0.5743544, 'sparse_top_k_categorical_accuracy': 0.75779164} ================================================================================13:09:27 epoch = 2 train: {'loss': 0.6006621, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 1.844159, 'sparse_categorical_accuracy': 0.6126447, 'sparse_top_k_categorical_accuracy': 0.7920748} ================================================================================13:09:35 epoch = 3 train: {'loss': 0.36935613, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544} valid: {'loss': 2.163433, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.8045414} ================================================================================13:09:42 epoch = 4 train: {'loss': 0.2304088, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 2.8911984, 'sparse_categorical_accuracy': 0.6344613, 'sparse_top_k_categorical_accuracy': 0.7978629} Lowering optimizer Learning Rate... ================================================================================13:09:51 epoch = 5 train: {'loss': 0.111194365, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 3.6431572, 'sparse_categorical_accuracy': 0.6295637, 'sparse_top_k_categorical_accuracy': 0.7978629} ================================================================================13:09:59 epoch = 6 train: {'loss': 0.07741702, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.074161, 'sparse_categorical_accuracy': 0.6255565, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:07 epoch = 7 train: {'loss': 0.056113098, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.4461513, 'sparse_categorical_accuracy': 0.6273375, 'sparse_top_k_categorical_accuracy': 0.79652715} ================================================================================13:10:17 epoch = 8 train: {'loss': 0.043448802, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 4.7687583, 'sparse_categorical_accuracy': 0.6224399, 'sparse_top_k_categorical_accuracy': 0.79741764} ================================================================================13:10:26 epoch = 9 train: {'loss': 0.035002146, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.130505, 'sparse_categorical_accuracy': 0.6175423, 'sparse_top_k_categorical_accuracy': 0.794301} ================================================================================13:10:34 epoch = 10 train: {'loss': 0.028303564, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0} valid: {'loss': 5.4559293, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7947462}","title":"2. Pre-defined train_on_batch method"},{"location":"english/Chapter6/Chapter6-2/#3-customized-training-loop","text":"Re-compilation of the model is not required in the customized training loop, just back-propagate the iterative parameters through the optimizer according to the loss function, which gives us the highest flexibility. tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================13:12:03 Epoch=1,Loss:2.02051544,Accuracy:0.460253835,Valid Loss:1.75700927,Valid Accuracy:0.536954582 ================================================================================13:12:09 Epoch=2,Loss:1.510795,Accuracy:0.610665798,Valid Loss:1.55349839,Valid Accuracy:0.616206586 ================================================================================13:12:17 Epoch=3,Loss:1.19221532,Accuracy:0.696170092,Valid Loss:1.52315605,Valid Accuracy:0.651380241 ================================================================================13:12:23 Epoch=4,Loss:0.90101546,Accuracy:0.766310394,Valid Loss:1.68327653,Valid Accuracy:0.648263574 ================================================================================13:12:30 Epoch=5,Loss:0.655430496,Accuracy:0.831329346,Valid Loss:1.90872383,Valid Accuracy:0.641139805 ================================================================================13:12:37 Epoch=6,Loss:0.492730737,Accuracy:0.877866864,Valid Loss:2.09966016,Valid Accuracy:0.63223511 ================================================================================13:12:44 Epoch=7,Loss:0.391238362,Accuracy:0.904030263,Valid Loss:2.27431226,Valid Accuracy:0.625111282 ================================================================================13:12:51 Epoch=8,Loss:0.327761739,Accuracy:0.922066331,Valid Loss:2.42568827,Valid Accuracy:0.617542326 ================================================================================13:12:58 Epoch=9,Loss:0.285573095,Accuracy:0.930527747,Valid Loss:2.55942106,Valid Accuracy:0.612644672 ================================================================================13:13:05 Epoch=10,Loss:0.255482465,Accuracy:0.936094403,Valid Loss:2.67789412,Valid Accuracy:0.612199485 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. Customized Training Loop"},{"location":"english/Chapter6/Chapter6-3/","text":"6-3 Model Training Using Single GPU # The training procedure of deep learning is usually time consuming. It even takes tens of days for training, and there is no need to mention those take days or hours. The time is mainly consumpted by two stages, data preparation and parameter iteration. We can increase the number of process to alleviate this issue if data preparation takes the majority of time. However, if the majority of time is taken by parameter iteration, we need to use GPU or Google TPU for acceleration. You may refer to this article for further details: \"GPU acceleration for Keras Models - How to Use Free Colab GPUs (in Chinese)\" There is no need to modify source code for switching from CPU to GPU when using the pre-defined fit method or the customized training loops. When GPU is available and the device is not specified, TensorFlow automatically chooses GPU for tensor creating and computing. However, for the case of using shared GPU with multiple users, sucha as using server of the company or the lab, we need to add following code to specify the GPU ID and the GPU memory size that we are going to use, in order to avoid the GPU resources to be occupied by a single user (actually TensorFlow acquires all GPU cors and all GPU memories by default) and allows multiple users perform training on it. In Colab notebook, choose GPU in Edit -> Notebook Settings -> Hardware Accelerator Note: the following code only executes on Colab. You may use the following link for testing (tf_singleGPU, in Chinese) https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * # Time stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring ) 1. GPU Configuration # gpus = tf . config . list_physical_devices ( \"GPU\" ) if gpus : gpu0 = gpus [ 0 ] # Only use GPU 0 when existing multiple GPUs tf . config . experimental . set_memory_growth ( gpu0 , True ) # Set the usage of GPU memory according to needs # The GPU memory usage could also be fixed (e.g. 4GB) #tf.config.experimental.set_virtual_device_configuration(gpu0, # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) tf . config . set_visible_devices ([ gpu0 ], \"GPU\" ) Compare the computing speed between GPU and CPU. printbar () with tf . device ( \"/gpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:01 2.24953778e+11 ================================================================================17:37:01 printbar () with tf . device ( \"/cpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:34 2.24953795e+11 ================================================================================17:37:40 2. Data Preparation # MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () 3. Model Defining # tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ 4. Model Training # optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================17:13:26 Epoch=1,Loss:1.96735072,Accuracy:0.489200622,Valid Loss:1.64124215,Valid Accuracy:0.582813919 ================================================================================17:13:28 Epoch=2,Loss:1.4640888,Accuracy:0.624805152,Valid Loss:1.5559175,Valid Accuracy:0.607747078 ================================================================================17:13:30 Epoch=3,Loss:1.20681274,Accuracy:0.68581605,Valid Loss:1.58494771,Valid Accuracy:0.622439921 ================================================================================17:13:31 Epoch=4,Loss:0.937500894,Accuracy:0.75361836,Valid Loss:1.77466083,Valid Accuracy:0.621994674 ================================================================================17:13:33 Epoch=5,Loss:0.693960547,Accuracy:0.822199941,Valid Loss:2.00267363,Valid Accuracy:0.6197685 ================================================================================17:13:35 Epoch=6,Loss:0.519614,Accuracy:0.870296121,Valid Loss:2.23463202,Valid Accuracy:0.613980412 ================================================================================17:13:37 Epoch=7,Loss:0.408562034,Accuracy:0.901246965,Valid Loss:2.46969271,Valid Accuracy:0.612199485 ================================================================================17:13:39 Epoch=8,Loss:0.339028627,Accuracy:0.920062363,Valid Loss:2.68585229,Valid Accuracy:0.615316093 ================================================================================17:13:41 Epoch=9,Loss:0.293798745,Accuracy:0.92930305,Valid Loss:2.88995624,Valid Accuracy:0.613535166 ================================================================================17:13:43 Epoch=10,Loss:0.263130337,Accuracy:0.936651051,Valid Loss:3.09705234,Valid Accuracy:0.612644672 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-3 Model Training Using Single GPU"},{"location":"english/Chapter6/Chapter6-3/#6-3-model-training-using-single-gpu","text":"The training procedure of deep learning is usually time consuming. It even takes tens of days for training, and there is no need to mention those take days or hours. The time is mainly consumpted by two stages, data preparation and parameter iteration. We can increase the number of process to alleviate this issue if data preparation takes the majority of time. However, if the majority of time is taken by parameter iteration, we need to use GPU or Google TPU for acceleration. You may refer to this article for further details: \"GPU acceleration for Keras Models - How to Use Free Colab GPUs (in Chinese)\" There is no need to modify source code for switching from CPU to GPU when using the pre-defined fit method or the customized training loops. When GPU is available and the device is not specified, TensorFlow automatically chooses GPU for tensor creating and computing. However, for the case of using shared GPU with multiple users, sucha as using server of the company or the lab, we need to add following code to specify the GPU ID and the GPU memory size that we are going to use, in order to avoid the GPU resources to be occupied by a single user (actually TensorFlow acquires all GPU cors and all GPU memories by default) and allows multiple users perform training on it. In Colab notebook, choose GPU in Edit -> Notebook Settings -> Hardware Accelerator Note: the following code only executes on Colab. You may use the following link for testing (tf_singleGPU, in Chinese) https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * # Time stamp @tf . function def printbar (): ts = tf . timestamp () today_ts = ts % ( 24 * 60 * 60 ) hour = tf . cast ( today_ts // 3600 + 8 , tf . int32 ) % tf . constant ( 24 ) minite = tf . cast (( today_ts % 3600 ) // 60 , tf . int32 ) second = tf . cast ( tf . floor ( today_ts % 60 ), tf . int32 ) def timeformat ( m ): if tf . strings . length ( tf . strings . format ( \" {} \" , m )) == 1 : return ( tf . strings . format ( \"0 {} \" , m )) else : return ( tf . strings . format ( \" {} \" , m )) timestring = tf . strings . join ([ timeformat ( hour ), timeformat ( minite ), timeformat ( second )], separator = \":\" ) tf . print ( \"==========\" * 8 , end = \"\" ) tf . print ( timestring )","title":"6-3 Model Training Using Single GPU"},{"location":"english/Chapter6/Chapter6-3/#1-gpu-configuration","text":"gpus = tf . config . list_physical_devices ( \"GPU\" ) if gpus : gpu0 = gpus [ 0 ] # Only use GPU 0 when existing multiple GPUs tf . config . experimental . set_memory_growth ( gpu0 , True ) # Set the usage of GPU memory according to needs # The GPU memory usage could also be fixed (e.g. 4GB) #tf.config.experimental.set_virtual_device_configuration(gpu0, # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) tf . config . set_visible_devices ([ gpu0 ], \"GPU\" ) Compare the computing speed between GPU and CPU. printbar () with tf . device ( \"/gpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:01 2.24953778e+11 ================================================================================17:37:01 printbar () with tf . device ( \"/cpu:0\" ): tf . random . set_seed ( 0 ) a = tf . random . uniform (( 10000 , 100 ), minval = 0 , maxval = 3.0 ) b = tf . random . uniform (( 100 , 100000 ), minval = 0 , maxval = 3.0 ) c = a @b tf . print ( tf . reduce_sum ( tf . reduce_sum ( c , axis = 0 ), axis = 0 )) printbar () ================================================================================17:37:34 2.24953795e+11 ================================================================================17:37:40","title":"1. GPU Configuration"},{"location":"english/Chapter6/Chapter6-3/#2-data-preparation","text":"MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"2. Data Preparation"},{"location":"english/Chapter6/Chapter6-3/#3-model-defining","text":"tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) model = create_model () model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________","title":"3. Model Defining"},{"location":"english/Chapter6/Chapter6-3/#4-model-training","text":"optimizer = optimizers . Nadam () loss_func = losses . SparseCategoricalCrossentropy () train_loss = metrics . Mean ( name = 'train_loss' ) train_metric = metrics . SparseCategoricalAccuracy ( name = 'train_accuracy' ) valid_loss = metrics . Mean ( name = 'valid_loss' ) valid_metric = metrics . SparseCategoricalAccuracy ( name = 'valid_accuracy' ) @tf . function def train_step ( model , features , labels ): with tf . GradientTape () as tape : predictions = model ( features , training = True ) loss = loss_func ( labels , predictions ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables )) train_loss . update_state ( loss ) train_metric . update_state ( labels , predictions ) @tf . function def valid_step ( model , features , labels ): predictions = model ( features ) batch_loss = loss_func ( labels , predictions ) valid_loss . update_state ( batch_loss ) valid_metric . update_state ( labels , predictions ) def train_model ( model , ds_train , ds_valid , epochs ): for epoch in tf . range ( 1 , epochs + 1 ): for features , labels in ds_train : train_step ( model , features , labels ) for features , labels in ds_valid : valid_step ( model , features , labels ) logs = 'Epoch= {} ,Loss: {} ,Accuracy: {} ,Valid Loss: {} ,Valid Accuracy: {} ' if epoch % 1 == 0 : printbar () tf . print ( tf . strings . format ( logs , ( epoch , train_loss . result (), train_metric . result (), valid_loss . result (), valid_metric . result ()))) tf . print ( \"\" ) train_loss . reset_states () valid_loss . reset_states () train_metric . reset_states () valid_metric . reset_states () train_model ( model , ds_train , ds_test , 10 ) ================================================================================17:13:26 Epoch=1,Loss:1.96735072,Accuracy:0.489200622,Valid Loss:1.64124215,Valid Accuracy:0.582813919 ================================================================================17:13:28 Epoch=2,Loss:1.4640888,Accuracy:0.624805152,Valid Loss:1.5559175,Valid Accuracy:0.607747078 ================================================================================17:13:30 Epoch=3,Loss:1.20681274,Accuracy:0.68581605,Valid Loss:1.58494771,Valid Accuracy:0.622439921 ================================================================================17:13:31 Epoch=4,Loss:0.937500894,Accuracy:0.75361836,Valid Loss:1.77466083,Valid Accuracy:0.621994674 ================================================================================17:13:33 Epoch=5,Loss:0.693960547,Accuracy:0.822199941,Valid Loss:2.00267363,Valid Accuracy:0.6197685 ================================================================================17:13:35 Epoch=6,Loss:0.519614,Accuracy:0.870296121,Valid Loss:2.23463202,Valid Accuracy:0.613980412 ================================================================================17:13:37 Epoch=7,Loss:0.408562034,Accuracy:0.901246965,Valid Loss:2.46969271,Valid Accuracy:0.612199485 ================================================================================17:13:39 Epoch=8,Loss:0.339028627,Accuracy:0.920062363,Valid Loss:2.68585229,Valid Accuracy:0.615316093 ================================================================================17:13:41 Epoch=9,Loss:0.293798745,Accuracy:0.92930305,Valid Loss:2.88995624,Valid Accuracy:0.613535166 ================================================================================17:13:43 Epoch=10,Loss:0.263130337,Accuracy:0.936651051,Valid Loss:3.09705234,Valid Accuracy:0.612644672 Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4. Model Training"},{"location":"english/Chapter6/Chapter6-4/","text":"6-4 Model Training Using Multiple GPUs # We recommend using pre-defined fit method for training when using multiple GPU, which only requires two additional lines of code. In Colab notebook, choose GPU in Edit -> Notebook Settings -> Hardware Accelerator Note: the following code only executes on Colab. You may use the following link for testing (tf_multiGPU, in Chinese) https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU- Introduction to MirroredStrategy\uff1a The strategy gives a copy to each of the N computing devices before training. When a batch of training data is received, devide the data into N portions and transfer them into N devices (data parallelism) Each device calculate the local variables (mirrored variables) to calculate the gradient according to the received portion of data. Implement All-reduce operation in parallel computing, exchange the gradient data and calculate summation, allows each device to obtain the gradient sum from all the devices. Update the local variables (mirrored variables) using the gradient sum. Proceed to the next round of training when all the devices updated their local variables (This is a fully synchronized strategy). % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * # Simulate two logical GPUs with one physical GPU gpus = tf . config . experimental . list_physical_devices ( 'GPU' ) if gpus : # Set two logical GPUs for simulation try : tf . config . experimental . set_virtual_device_configuration ( gpus [ 0 ], [ tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 ), tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 )]) logical_gpus = tf . config . experimental . list_logical_devices ( 'GPU' ) print ( len ( gpus ), \"Physical GPU,\" , len ( logical_gpus ), \"Logical GPUs\" ) except RuntimeError as e : print ( e ) 1. Data Preparation # MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () 2. Model Defining # tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) 3. Model Training # # Add the following two lines of code strategy = tf . distribute . MirroredStrategy () with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1') Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). Train for 281 steps, validate for 71 steps Epoch 1/10 INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). 281/281 [==============================] - 15s 53ms/step - loss: 2.0270 - sparse_categorical_accuracy: 0.4653 - sparse_top_k_categorical_accuracy: 0.7481 - val_loss: 1.7517 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7578 Epoch 2/10 281/281 [==============================] - 4s 14ms/step - loss: 1.5206 - sparse_categorical_accuracy: 0.6045 - sparse_top_k_categorical_accuracy: 0.7938 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 3/10 281/281 [==============================] - 4s 14ms/step - loss: 1.2178 - sparse_categorical_accuracy: 0.6843 - sparse_top_k_categorical_accuracy: 0.8547 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6327 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 4/10 281/281 [==============================] - 4s 13ms/step - loss: 0.9127 - sparse_categorical_accuracy: 0.7648 - sparse_top_k_categorical_accuracy: 0.9113 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6296 - val_sparse_top_k_categorical_accuracy: 0.8201 Epoch 5/10 281/281 [==============================] - 4s 14ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.8321 - sparse_top_k_categorical_accuracy: 0.9525 - val_loss: 1.8791 - val_sparse_categorical_accuracy: 0.6158 - val_sparse_top_k_categorical_accuracy: 0.8219 Epoch 6/10 281/281 [==============================] - 4s 14ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9725 - val_loss: 2.1282 - val_sparse_categorical_accuracy: 0.6037 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 7/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.9051 - sparse_top_k_categorical_accuracy: 0.9814 - val_loss: 2.3033 - val_sparse_categorical_accuracy: 0.6046 - val_sparse_top_k_categorical_accuracy: 0.8094 Epoch 8/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9207 - sparse_top_k_categorical_accuracy: 0.9863 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.8099 Epoch 9/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 2.5571 - val_sparse_categorical_accuracy: 0.6020 - val_sparse_top_k_categorical_accuracy: 0.8126 Epoch 10/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9342 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 2.6700 - val_sparse_categorical_accuracy: 0.6077 - val_sparse_top_k_categorical_accuracy: 0.8148 CPU times: user 1min 2s, sys: 8.59 s, total: 1min 10s Wall time: 58.5 s Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-4 Model Training Using Multiple GPUs"},{"location":"english/Chapter6/Chapter6-4/#6-4-model-training-using-multiple-gpus","text":"We recommend using pre-defined fit method for training when using multiple GPU, which only requires two additional lines of code. In Colab notebook, choose GPU in Edit -> Notebook Settings -> Hardware Accelerator Note: the following code only executes on Colab. You may use the following link for testing (tf_multiGPU, in Chinese) https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU- Introduction to MirroredStrategy\uff1a The strategy gives a copy to each of the N computing devices before training. When a batch of training data is received, devide the data into N portions and transfer them into N devices (data parallelism) Each device calculate the local variables (mirrored variables) to calculate the gradient according to the received portion of data. Implement All-reduce operation in parallel computing, exchange the gradient data and calculate summation, allows each device to obtain the gradient sum from all the devices. Update the local variables (mirrored variables) using the gradient sum. Proceed to the next round of training when all the devices updated their local variables (This is a fully synchronized strategy). % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * # Simulate two logical GPUs with one physical GPU gpus = tf . config . experimental . list_physical_devices ( 'GPU' ) if gpus : # Set two logical GPUs for simulation try : tf . config . experimental . set_virtual_device_configuration ( gpus [ 0 ], [ tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 ), tf . config . experimental . VirtualDeviceConfiguration ( memory_limit = 1024 )]) logical_gpus = tf . config . experimental . list_logical_devices ( 'GPU' ) print ( len ( gpus ), \"Physical GPU,\" , len ( logical_gpus ), \"Logical GPUs\" ) except RuntimeError as e : print ( e )","title":"6-4 Model Training Using Multiple GPUs"},{"location":"english/Chapter6/Chapter6-4/#1-data-preparation","text":"MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"1. Data Preparation"},{"location":"english/Chapter6/Chapter6-4/#2-model-defining","text":"tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model )","title":"2. Model Defining"},{"location":"english/Chapter6/Chapter6-4/#3-model-training","text":"# Add the following two lines of code strategy = tf . distribute . MirroredStrategy () with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1') Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). Train for 281 steps, validate for 71 steps Epoch 1/10 INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'). 281/281 [==============================] - 15s 53ms/step - loss: 2.0270 - sparse_categorical_accuracy: 0.4653 - sparse_top_k_categorical_accuracy: 0.7481 - val_loss: 1.7517 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7578 Epoch 2/10 281/281 [==============================] - 4s 14ms/step - loss: 1.5206 - sparse_categorical_accuracy: 0.6045 - sparse_top_k_categorical_accuracy: 0.7938 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.7983 Epoch 3/10 281/281 [==============================] - 4s 14ms/step - loss: 1.2178 - sparse_categorical_accuracy: 0.6843 - sparse_top_k_categorical_accuracy: 0.8547 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6327 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 4/10 281/281 [==============================] - 4s 13ms/step - loss: 0.9127 - sparse_categorical_accuracy: 0.7648 - sparse_top_k_categorical_accuracy: 0.9113 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6296 - val_sparse_top_k_categorical_accuracy: 0.8201 Epoch 5/10 281/281 [==============================] - 4s 14ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.8321 - sparse_top_k_categorical_accuracy: 0.9525 - val_loss: 1.8791 - val_sparse_categorical_accuracy: 0.6158 - val_sparse_top_k_categorical_accuracy: 0.8219 Epoch 6/10 281/281 [==============================] - 4s 14ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9725 - val_loss: 2.1282 - val_sparse_categorical_accuracy: 0.6037 - val_sparse_top_k_categorical_accuracy: 0.8112 Epoch 7/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.9051 - sparse_top_k_categorical_accuracy: 0.9814 - val_loss: 2.3033 - val_sparse_categorical_accuracy: 0.6046 - val_sparse_top_k_categorical_accuracy: 0.8094 Epoch 8/10 281/281 [==============================] - 4s 14ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9207 - sparse_top_k_categorical_accuracy: 0.9863 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.8099 Epoch 9/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 2.5571 - val_sparse_categorical_accuracy: 0.6020 - val_sparse_top_k_categorical_accuracy: 0.8126 Epoch 10/10 281/281 [==============================] - 4s 14ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9342 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 2.6700 - val_sparse_categorical_accuracy: 0.6077 - val_sparse_top_k_categorical_accuracy: 0.8148 CPU times: user 1min 2s, sys: 8.59 s, total: 1min 10s Wall time: 58.5 s Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. Model Training"},{"location":"english/Chapter6/Chapter6-5/","text":"6-5 Model Training Using TPU # It only requires six additional lines of code when training your model using TPU on Google Colab. In Colab notebook, choose TPU in Edit -> Notebook Settings -> Hardware Accelerator. Note: the following code only executes on Colab. You may use the following link for testing (tf_TPU, in Chinese) https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * 1. Data Preparation # MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () 2. Model Defining # tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model ) 3. Model Training # # The above mentioned 6 additional lines of code import os resolver = tf . distribute . cluster_resolver . TPUClusterResolver ( tpu = 'grpc://' + os . environ [ 'COLAB_TPU_ADDR' ]) tf . config . experimental_connect_to_cluster ( resolver ) tf . tpu . experimental . initialize_tpu_system ( resolver ) strategy = tf . distribute . experimental . TPUStrategy ( resolver ) with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Found TPU system: INFO:tensorflow:Found TPU system: INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 12s 43ms/step - loss: 3.4466 - sparse_categorical_accuracy: 0.4332 - sparse_top_k_categorical_accuracy: 0.7180 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.5352 - val_sparse_top_k_categorical_accuracy: 0.7195 Epoch 2/10 281/281 [==============================] - 6s 20ms/step - loss: 3.3251 - sparse_categorical_accuracy: 0.5405 - sparse_top_k_categorical_accuracy: 0.7302 - val_loss: 3.3082 - val_sparse_categorical_accuracy: 0.5463 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 3/10 281/281 [==============================] - 6s 20ms/step - loss: 3.2961 - sparse_categorical_accuracy: 0.5729 - sparse_top_k_categorical_accuracy: 0.7280 - val_loss: 3.3026 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 4/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2751 - sparse_categorical_accuracy: 0.5924 - sparse_top_k_categorical_accuracy: 0.7276 - val_loss: 3.2957 - val_sparse_categorical_accuracy: 0.5543 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 5/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2655 - sparse_categorical_accuracy: 0.6008 - sparse_top_k_categorical_accuracy: 0.7290 - val_loss: 3.3022 - val_sparse_categorical_accuracy: 0.5490 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 6/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2616 - sparse_categorical_accuracy: 0.6041 - sparse_top_k_categorical_accuracy: 0.7295 - val_loss: 3.3015 - val_sparse_categorical_accuracy: 0.5503 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 7/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2595 - sparse_categorical_accuracy: 0.6059 - sparse_top_k_categorical_accuracy: 0.7322 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.5454 - val_sparse_top_k_categorical_accuracy: 0.7266 Epoch 8/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2591 - sparse_categorical_accuracy: 0.6063 - sparse_top_k_categorical_accuracy: 0.7327 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 9/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2588 - sparse_categorical_accuracy: 0.6062 - sparse_top_k_categorical_accuracy: 0.7332 - val_loss: 3.2992 - val_sparse_categorical_accuracy: 0.5521 - val_sparse_top_k_categorical_accuracy: 0.7257 Epoch 10/10 281/281 [==============================] - 5s 18ms/step - loss: 3.2577 - sparse_categorical_accuracy: 0.6073 - sparse_top_k_categorical_accuracy: 0.7363 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.5516 - val_sparse_top_k_categorical_accuracy: 0.7306 CPU times: user 18.9 s, sys: 3.86 s, total: 22.7 s Wall time: 1min 1s Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-5 Model Training Using TPU"},{"location":"english/Chapter6/Chapter6-5/#6-5-model-training-using-tpu","text":"It only requires six additional lines of code when training your model using TPU on Google Colab. In Colab notebook, choose TPU in Edit -> Notebook Settings -> Hardware Accelerator. Note: the following code only executes on Colab. You may use the following link for testing (tf_TPU, in Chinese) https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import *","title":"6-5 Model Training Using TPU"},{"location":"english/Chapter6/Chapter6-5/#1-data-preparation","text":"MAX_LEN = 300 BATCH_SIZE = 32 ( x_train , y_train ),( x_test , y_test ) = datasets . reuters . load_data () x_train = preprocessing . sequence . pad_sequences ( x_train , maxlen = MAX_LEN ) x_test = preprocessing . sequence . pad_sequences ( x_test , maxlen = MAX_LEN ) MAX_WORDS = x_train . max () + 1 CAT_NUM = y_train . max () + 1 ds_train = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache () ds_test = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) \\ . shuffle ( buffer_size = 1000 ) . batch ( BATCH_SIZE ) \\ . prefetch ( tf . data . experimental . AUTOTUNE ) . cache ()","title":"1. Data Preparation"},{"location":"english/Chapter6/Chapter6-5/#2-model-defining","text":"tf . keras . backend . clear_session () def create_model (): model = models . Sequential () model . add ( layers . Embedding ( MAX_WORDS , 7 , input_length = MAX_LEN )) model . add ( layers . Conv1D ( filters = 64 , kernel_size = 5 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Conv1D ( filters = 32 , kernel_size = 3 , activation = \"relu\" )) model . add ( layers . MaxPool1D ( 2 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( CAT_NUM , activation = \"softmax\" )) return ( model ) def compile_model ( model ): model . compile ( optimizer = optimizers . Nadam (), loss = losses . SparseCategoricalCrossentropy ( from_logits = True ), metrics = [ metrics . SparseCategoricalAccuracy (), metrics . SparseTopKCategoricalAccuracy ( 5 )]) return ( model )","title":"2. Model Defining"},{"location":"english/Chapter6/Chapter6-5/#3-model-training","text":"# The above mentioned 6 additional lines of code import os resolver = tf . distribute . cluster_resolver . TPUClusterResolver ( tpu = 'grpc://' + os . environ [ 'COLAB_TPU_ADDR' ]) tf . config . experimental_connect_to_cluster ( resolver ) tf . tpu . experimental . initialize_tpu_system ( resolver ) strategy = tf . distribute . experimental . TPUStrategy ( resolver ) with strategy . scope (): model = create_model () model . summary () model = compile_model ( model ) WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. WARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost. INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470 INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Clearing out eager caches INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Finished initializing TPU system. INFO:tensorflow:Found TPU system: INFO:tensorflow:Found TPU system: INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Cores: 8 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Workers: 1 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Num TPU Cores Per Worker: 8 INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0) Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 300, 7) 216874 _________________________________________________________________ conv1d (Conv1D) (None, 296, 64) 2304 _________________________________________________________________ max_pooling1d (MaxPooling1D) (None, 148, 64) 0 _________________________________________________________________ conv1d_1 (Conv1D) (None, 146, 32) 6176 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 73, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2336) 0 _________________________________________________________________ dense (Dense) (None, 46) 107502 ================================================================= Total params: 332,856 Trainable params: 332,856 Non-trainable params: 0 _________________________________________________________________ history = model . fit ( ds_train , validation_data = ds_test , epochs = 10 ) Train for 281 steps, validate for 71 steps Epoch 1/10 281/281 [==============================] - 12s 43ms/step - loss: 3.4466 - sparse_categorical_accuracy: 0.4332 - sparse_top_k_categorical_accuracy: 0.7180 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.5352 - val_sparse_top_k_categorical_accuracy: 0.7195 Epoch 2/10 281/281 [==============================] - 6s 20ms/step - loss: 3.3251 - sparse_categorical_accuracy: 0.5405 - sparse_top_k_categorical_accuracy: 0.7302 - val_loss: 3.3082 - val_sparse_categorical_accuracy: 0.5463 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 3/10 281/281 [==============================] - 6s 20ms/step - loss: 3.2961 - sparse_categorical_accuracy: 0.5729 - sparse_top_k_categorical_accuracy: 0.7280 - val_loss: 3.3026 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 4/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2751 - sparse_categorical_accuracy: 0.5924 - sparse_top_k_categorical_accuracy: 0.7276 - val_loss: 3.2957 - val_sparse_categorical_accuracy: 0.5543 - val_sparse_top_k_categorical_accuracy: 0.7217 Epoch 5/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2655 - sparse_categorical_accuracy: 0.6008 - sparse_top_k_categorical_accuracy: 0.7290 - val_loss: 3.3022 - val_sparse_categorical_accuracy: 0.5490 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 6/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2616 - sparse_categorical_accuracy: 0.6041 - sparse_top_k_categorical_accuracy: 0.7295 - val_loss: 3.3015 - val_sparse_categorical_accuracy: 0.5503 - val_sparse_top_k_categorical_accuracy: 0.7235 Epoch 7/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2595 - sparse_categorical_accuracy: 0.6059 - sparse_top_k_categorical_accuracy: 0.7322 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.5454 - val_sparse_top_k_categorical_accuracy: 0.7266 Epoch 8/10 281/281 [==============================] - 6s 21ms/step - loss: 3.2591 - sparse_categorical_accuracy: 0.6063 - sparse_top_k_categorical_accuracy: 0.7327 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7231 Epoch 9/10 281/281 [==============================] - 5s 19ms/step - loss: 3.2588 - sparse_categorical_accuracy: 0.6062 - sparse_top_k_categorical_accuracy: 0.7332 - val_loss: 3.2992 - val_sparse_categorical_accuracy: 0.5521 - val_sparse_top_k_categorical_accuracy: 0.7257 Epoch 10/10 281/281 [==============================] - 5s 18ms/step - loss: 3.2577 - sparse_categorical_accuracy: 0.6073 - sparse_top_k_categorical_accuracy: 0.7363 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.5516 - val_sparse_top_k_categorical_accuracy: 0.7306 CPU times: user 18.9 s, sys: 3.86 s, total: 22.7 s Wall time: 1min 1s Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"3. Model Training"},{"location":"english/Chapter6/Chapter6-6/","text":"6-6 Model Deploying Using tensorflow-serving # There are multiple ways to deploy and run the trained models which saved with the original tensorflow format. For example: We can load and run the model in the web browser using javascript through tensorflow-js . We can load and run the TensorFlow model on mobile and embeded devices through tensorflow-lite . We can use tensorflow-serving to load the model that providing network interface API service and to acquire the prediction results from the model through sending network requests in arbitrary programming languages. We can predict using the TensorFlow model in Java or spark (scala) through the TensorFlow for Java port. This section introduces model deploying by tensorflow serving and using spark (scala) to implement the TensorFlow models. 0. Introduction to model deploying by tensorflow serving # The necessary steps of model deploying using tensorflow serving are: (1) Prepare the protobuf model file. (2) Install the tensorflow serving. (3) Start the tensorflow serving service. (4) Send the request to the API service to obtain the prediction. You may use the following link for testing (tf_serving, in Chinese) https://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8 % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import * 1. Prepare the protobuf Model File # Here we train a simple linear regression model with tf.keras and save it as protobuf file. import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## Number of samples n = 800 ## Generating testing dataset X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise ## Modeling tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) # Set the input name as \"inputs\" outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) # Set the output name as \"outputs\" linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## Training with fit method linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## Save the model as pb format export_path = \"../../data/linear_model/\" version = \"1\" # Version could be used for management of further updates linear . save ( export_path + version , save_format = \"tf\" ) # Check the saved model file ! ls { export_path + version } assets saved_model.pb variables # Check the info of the model file ! saved_model_cli show -- dir { export_path + str ( version )} -- all MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs: signature_def['__saved_model_init_op']: The given SavedModel SignatureDef contains the following input(s): The given SavedModel SignatureDef contains the following output(s): outputs['__saved_model_init_op'] tensor_info: dtype: DT_INVALID shape: unknown_rank name: NoOp Method name is: signature_def['serving_default']: The given SavedModel SignatureDef contains the following input(s): inputs['inputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name: serving_default_inputs:0 The given SavedModel SignatureDef contains the following output(s): outputs['outputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 1) name: StatefulPartitionedCall:0 Method name is: tensorflow/serving/predict WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Defined Functions: Function Name: '__call__' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Function Name: '_default_save_signature' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Function Name: 'call_and_return_all_conditional_losses' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None 2. Installing tensorflow serving # Two methods for installing tensorflow serving: Using Docker images, or using apt. Docker image is the simplest way of installation and we recommend it. Docker is a container that provides independent environment for various programs. The companies that are using TensorFlow usually use Docker to install tensorflow serving by operation experts, so the algorithm engineers don't have to worry about the installation. The installation of Docker on different OS are shown below (in Chinese). Windows: https://www.runoob.com/docker/windows-docker-install.html MacOs: https://www.runoob.com/docker/macos-docker-install.html CentOS: https://www.runoob.com/docker/centos-docker-install.html After successful installation of Docker, run the following command to load the tensorflow/serving image. docker pull tensorflow/serving 3. Starting tensorflow serving Service # ! docker run - t -- rm - p 8501 : 8501 \\ - v \"/Users/.../../data/linear_model/\" \\ - e MODEL_NAME = linear_model \\ tensorflow / serving & > server . log 2 >& 1 4. Sending request to the API service # The request could be sent through http function in any kind of the programming languages. We demonstrate request sending using the curl command in Linux and the requests library in Python. ! curl - d '{\"instances\": [1.0, 2.0, 5.0]}' \\ - X POST http : // localhost : 8501 / v1 / models / linear_model : predict { \"predictions\": [[3.06546211], [5.01313448] ] } import json , requests data = json . dumps ({ \"signature_name\" : \"serving_default\" , \"instances\" : [[ 1.0 , 2.0 ], [ 5.0 , 7.0 ]]}) headers = { \"content-type\" : \"application/json\" } json_response = requests . post ( 'http://localhost:8501/v1/models/linear_model:predict' , data = data , headers = headers ) predictions = json . loads ( json_response . text )[ \"predictions\" ] print ( predictions ) [[3.06546211], [6.02843142]] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-6 Model Deploying Using tensorflow-serving"},{"location":"english/Chapter6/Chapter6-6/#6-6-model-deploying-using-tensorflow-serving","text":"There are multiple ways to deploy and run the trained models which saved with the original tensorflow format. For example: We can load and run the model in the web browser using javascript through tensorflow-js . We can load and run the TensorFlow model on mobile and embeded devices through tensorflow-lite . We can use tensorflow-serving to load the model that providing network interface API service and to acquire the prediction results from the model through sending network requests in arbitrary programming languages. We can predict using the TensorFlow model in Java or spark (scala) through the TensorFlow for Java port. This section introduces model deploying by tensorflow serving and using spark (scala) to implement the TensorFlow models.","title":"6-6 Model Deploying Using tensorflow-serving"},{"location":"english/Chapter6/Chapter6-6/#0-introduction-to-model-deploying-by-tensorflow-serving","text":"The necessary steps of model deploying using tensorflow serving are: (1) Prepare the protobuf model file. (2) Install the tensorflow serving. (3) Start the tensorflow serving service. (4) Send the request to the API service to obtain the prediction. You may use the following link for testing (tf_serving, in Chinese) https://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8 % tensorflow_version 2. x import tensorflow as tf print ( tf . __version__ ) from tensorflow.keras import *","title":"0. Introduction to model deploying by tensorflow serving"},{"location":"english/Chapter6/Chapter6-6/#1-prepare-the-protobuf-model-file","text":"Here we train a simple linear regression model with tf.keras and save it as protobuf file. import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## Number of samples n = 800 ## Generating testing dataset X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise ## Modeling tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) # Set the input name as \"inputs\" outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) # Set the output name as \"outputs\" linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## Training with fit method linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## Save the model as pb format export_path = \"../../data/linear_model/\" version = \"1\" # Version could be used for management of further updates linear . save ( export_path + version , save_format = \"tf\" ) # Check the saved model file ! ls { export_path + version } assets saved_model.pb variables # Check the info of the model file ! saved_model_cli show -- dir { export_path + str ( version )} -- all MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs: signature_def['__saved_model_init_op']: The given SavedModel SignatureDef contains the following input(s): The given SavedModel SignatureDef contains the following output(s): outputs['__saved_model_init_op'] tensor_info: dtype: DT_INVALID shape: unknown_rank name: NoOp Method name is: signature_def['serving_default']: The given SavedModel SignatureDef contains the following input(s): inputs['inputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name: serving_default_inputs:0 The given SavedModel SignatureDef contains the following output(s): outputs['outputs'] tensor_info: dtype: DT_FLOAT shape: (-1, 1) name: StatefulPartitionedCall:0 Method name is: tensorflow/serving/predict WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Defined Functions: Function Name: '__call__' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Function Name: '_default_save_signature' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Function Name: 'call_and_return_all_conditional_losses' Option #1 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: True Argument #3 DType: NoneType Value: None Option #2 Callable with: Argument #1 inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs') Argument #2 DType: bool Value: False Argument #3 DType: NoneType Value: None","title":"1. Prepare the protobuf Model File"},{"location":"english/Chapter6/Chapter6-6/#2-installing-tensorflow-serving","text":"Two methods for installing tensorflow serving: Using Docker images, or using apt. Docker image is the simplest way of installation and we recommend it. Docker is a container that provides independent environment for various programs. The companies that are using TensorFlow usually use Docker to install tensorflow serving by operation experts, so the algorithm engineers don't have to worry about the installation. The installation of Docker on different OS are shown below (in Chinese). Windows: https://www.runoob.com/docker/windows-docker-install.html MacOs: https://www.runoob.com/docker/macos-docker-install.html CentOS: https://www.runoob.com/docker/centos-docker-install.html After successful installation of Docker, run the following command to load the tensorflow/serving image. docker pull tensorflow/serving","title":"2. Installing tensorflow serving"},{"location":"english/Chapter6/Chapter6-6/#3-starting-tensorflow-serving-service","text":"! docker run - t -- rm - p 8501 : 8501 \\ - v \"/Users/.../../data/linear_model/\" \\ - e MODEL_NAME = linear_model \\ tensorflow / serving & > server . log 2 >& 1","title":"3. Starting tensorflow serving Service"},{"location":"english/Chapter6/Chapter6-6/#4-sending-request-to-the-api-service","text":"The request could be sent through http function in any kind of the programming languages. We demonstrate request sending using the curl command in Linux and the requests library in Python. ! curl - d '{\"instances\": [1.0, 2.0, 5.0]}' \\ - X POST http : // localhost : 8501 / v1 / models / linear_model : predict { \"predictions\": [[3.06546211], [5.01313448] ] } import json , requests data = json . dumps ({ \"signature_name\" : \"serving_default\" , \"instances\" : [[ 1.0 , 2.0 ], [ 5.0 , 7.0 ]]}) headers = { \"content-type\" : \"application/json\" } json_response = requests . post ( 'http://localhost:8501/v1/models/linear_model:predict' , data = data , headers = headers ) predictions = json . loads ( json_response . text )[ \"predictions\" ] print ( predictions ) [[3.06546211], [6.02843142]] Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"4. Sending request to the API service"},{"location":"english/Chapter6/Chapter6-7/","text":"6-7 Call Tensorflow Model Using spark-scala # This section introduce how to use the trained TensorFlow model to predict in spark. The prerequisite of this section is fundamental knowledge on spark and scala. It is easier to use pyspark, since it only requires loading model with Python on each executor and predict separately. For the consideration of the performance, the spark in scala version is the most popular. The section shows how to use the trained TensorFlow model in spark through TensorFlow for Java. It is possible to predit with the trained TensorFlow model in hundreds of thousands computers using the parallel computing feature of spark. 0 Using TensorFlow model in spark-scala # The necessary steps for predicting with trained TensorFlow model in spark (scala) are: (1) Preparing protobuf model file (2) Create a spark (scala) project, insert jar package dependencies for TensorFlow in java. (3) Loading TensorFlow model on the driver end of spark (scala) project and debug it successfully. (4) Loading TensorFlow model on executor of spark (scala) project through RDD and debug it successfully. (5) Loading TensorFlow model on executor of spark (scala) project through Data and debug it successfully. 1. Preparing protobuf Model File # Here we train a simple linear regression model with tf.keras and save it as protobuf file. import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## Number of samples n = 800 ## Generating testing dataset X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise ## Modeling tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) # Set the input name as \"inputs\" outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) # Set the output name as \"outputs\" linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## Training with fit method linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## Save the model as pb format export_path = \"../../data/linear_model/\" version = \"1\" # Version could be used for management of further updates linear . save ( export_path + version , save_format = \"tf\" ) ! ls { export_path + version } # Check the info of the model file ! saved_model_cli show -- dir { export_path + str ( version )} -- all The model file information marked red could be used later. 2. Create a spark (scala) project, insert jar package dependencies for TensorFlow in java. # Need to add the following jar package dependency if use maven to manage projects. <!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow --> <dependency> <groupId>org.tensorflow</groupId> <artifactId>tensorflow</artifactId> <version>1.15.0</version> </dependency> You may also download the jar package org.tensorflow.tensorflow , together with the depended org.tensorflow.libtensorflow and org.tensorflowlibtensorflow_jni from the following link, then add all of them into the project. https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0 3. Loading TensorFlow model on the driver end of spark (scala) project and debug it successfully. # The following demonstration is run in jupyter notebook. We need to install toree to have it support spark(scala). import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } //Note: the second argument of the load function should be \"serve\"; the related info could be found from the model file. val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\" , \"serve\" ) //Note: for the Java version TensorFlow uses static graph as TensorFlow 1.X, i.e. use `Session`, then explicit data to feed and results to fetch, and finally run it. //Note: multiple feed methods could be used consequetively when we need to feed multiple data. //Note: the input must be in the type of float val sess = bundle . session () val x = tf . Tensor . create ( Array ( Array ( 1.0f , 2.0f ), Array ( 2.0f , 3.0f ))) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) if ( x != null ) x . close () if ( y != null ) y . close () if ( sess != null ) sess . close () if ( bundle != null ) bundle . close () result The output is: Array(Array(3.019596), Array(3.9878292)) 4. Loading TensorFlow model on executor of spark (scala) project through RDD and debug it successfully # Here we transfer the TensorFlow model loaded on the Driver end to each executor through broadcasting, and predict with distributed computing on all the executors. import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } val spark = SparkSession . builder () . appName ( \"TfRDD\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext // Loading model on Driver end val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) // Broadcasting the model to all the executors val broads = sc . broadcast ( bundle ) // Creating dataset val rdd_data = sc . makeRDD ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 6.0f , 7.0f ), Array ( 8.0f , 3.0f ))) // Predicting in batch by using the model through mapPartitions val rdd_result = rdd_data . mapPartitions ( iter => { val arr = iter . toArray val model = broads . value val sess = model . session () val x = tf . Tensor . create ( arr ) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) // Copy the prediction into the Array in type Float with the same shape val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) result . iterator }) rdd_result . take ( 5 ) bundle . close The output is: Array(Array(3.019596), Array(3.9264367), Array(7.8607616), Array(15.974984)) 5. Loading TensorFlow model on executor of spark (scala) project through Data and debug it successfully # The distributed prediction using TensorFlow model could also be implemented on DataFrame data, besides implementing on RDD data in Spark. It could be done through registering the method of prediction as a sparkSQL function. import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } object TfDataFrame extends Serializable { def main ( args : Array [ String ]) : Unit = { val spark = SparkSession . builder () . appName ( \"TfDataFrame\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext import spark.implicits._ val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) val broads = sc . broadcast ( bundle ) // Construct the prediction function and register it as udf of sparkSQL val tfpredict = ( features : WrappedArray [ Float ]) => { val bund = broads . value val sess = bund . session () val x = tf . Tensor . create ( Array ( features . toArray )) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) val y_pred = result ( 0 )( 0 ) y_pred } spark . udf . register ( \"tfpredict\" , tfpredict ) // Creating DataFrame dataset, and put the features into one of the columns val dfdata = sc . parallelize ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 7.0f , 8.0f ))). toDF ( \"features\" ) dfdata . show // Call the sparkSQL predicting function, add a new column as y_preds val dfresult = dfdata . selectExpr ( \"features\" , \"tfpredict(features) as y_preds\" ) dfresult . show bundle . close } } TfDataFrame . main ( Array ()) +----------+ | features| +----------+ |[1.0, 2.0]| |[3.0, 5.0]| |[7.0, 8.0]| +----------+ +----------+---------+ | features| y_preds| +----------+---------+ |[1.0, 2.0]| 3.019596| |[3.0, 5.0]|3.9264367| |[7.0, 8.0]| 8.828995| +----------+---------+ We implemented distributed prediction using a linear regression model (implemented by tf.keras ) using both RDD and DataFrame data structures in spark. It is also possible to use the trained neural networks for distributed prediction through spark with just a slight modifications on this demonstration. Actually the capability of TensorFlow is more than implementing neural networks, the low-level language of graph is able to express all kinds of numerical computation. We are able to implement any kind of machine learning model on TensorFlow 2.0 with these various low-level APIs. It is also possible to export the trained models as files and use it on the distributed system such as spark, which provides huge space of imagination for future applications. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"6-7 Call Tensorflow Model Using spark-scala"},{"location":"english/Chapter6/Chapter6-7/#6-7-call-tensorflow-model-using-spark-scala","text":"This section introduce how to use the trained TensorFlow model to predict in spark. The prerequisite of this section is fundamental knowledge on spark and scala. It is easier to use pyspark, since it only requires loading model with Python on each executor and predict separately. For the consideration of the performance, the spark in scala version is the most popular. The section shows how to use the trained TensorFlow model in spark through TensorFlow for Java. It is possible to predit with the trained TensorFlow model in hundreds of thousands computers using the parallel computing feature of spark.","title":"6-7 Call Tensorflow Model Using spark-scala"},{"location":"english/Chapter6/Chapter6-7/#0-using-tensorflow-model-in-spark-scala","text":"The necessary steps for predicting with trained TensorFlow model in spark (scala) are: (1) Preparing protobuf model file (2) Create a spark (scala) project, insert jar package dependencies for TensorFlow in java. (3) Loading TensorFlow model on the driver end of spark (scala) project and debug it successfully. (4) Loading TensorFlow model on executor of spark (scala) project through RDD and debug it successfully. (5) Loading TensorFlow model on executor of spark (scala) project through Data and debug it successfully.","title":"0 Using TensorFlow model in spark-scala"},{"location":"english/Chapter6/Chapter6-7/#1-preparing-protobuf-model-file","text":"Here we train a simple linear regression model with tf.keras and save it as protobuf file. import tensorflow as tf from tensorflow.keras import models , layers , optimizers ## Number of samples n = 800 ## Generating testing dataset X = tf . random . uniform ([ n , 2 ], minval =- 10 , maxval = 10 ) w0 = tf . constant ([[ 2.0 ],[ - 1.0 ]]) b0 = tf . constant ( 3.0 ) Y = X @w0 + b0 + tf . random . normal ([ n , 1 ], mean = 0.0 , stddev = 2.0 ) # @ is matrix multiplication; adding Gaussian noise ## Modeling tf . keras . backend . clear_session () inputs = layers . Input ( shape = ( 2 ,), name = \"inputs\" ) # Set the input name as \"inputs\" outputs = layers . Dense ( 1 , name = \"outputs\" )( inputs ) # Set the output name as \"outputs\" linear = models . Model ( inputs = inputs , outputs = outputs ) linear . summary () ## Training with fit method linear . compile ( optimizer = \"rmsprop\" , loss = \"mse\" , metrics = [ \"mae\" ]) linear . fit ( X , Y , batch_size = 8 , epochs = 100 ) tf . print ( \"w = \" , linear . layers [ 1 ] . kernel ) tf . print ( \"b = \" , linear . layers [ 1 ] . bias ) ## Save the model as pb format export_path = \"../../data/linear_model/\" version = \"1\" # Version could be used for management of further updates linear . save ( export_path + version , save_format = \"tf\" ) ! ls { export_path + version } # Check the info of the model file ! saved_model_cli show -- dir { export_path + str ( version )} -- all The model file information marked red could be used later.","title":"1. Preparing protobuf Model File"},{"location":"english/Chapter6/Chapter6-7/#2-create-a-spark-scala-project-insert-jar-package-dependencies-for-tensorflow-in-java","text":"Need to add the following jar package dependency if use maven to manage projects. <!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow --> <dependency> <groupId>org.tensorflow</groupId> <artifactId>tensorflow</artifactId> <version>1.15.0</version> </dependency> You may also download the jar package org.tensorflow.tensorflow , together with the depended org.tensorflow.libtensorflow and org.tensorflowlibtensorflow_jni from the following link, then add all of them into the project. https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0","title":"2. Create a spark (scala) project, insert jar package dependencies for TensorFlow in java."},{"location":"english/Chapter6/Chapter6-7/#3-loading-tensorflow-model-on-the-driver-end-of-spark-scala-project-and-debug-it-successfully","text":"The following demonstration is run in jupyter notebook. We need to install toree to have it support spark(scala). import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } //Note: the second argument of the load function should be \"serve\"; the related info could be found from the model file. val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\" , \"serve\" ) //Note: for the Java version TensorFlow uses static graph as TensorFlow 1.X, i.e. use `Session`, then explicit data to feed and results to fetch, and finally run it. //Note: multiple feed methods could be used consequetively when we need to feed multiple data. //Note: the input must be in the type of float val sess = bundle . session () val x = tf . Tensor . create ( Array ( Array ( 1.0f , 2.0f ), Array ( 2.0f , 3.0f ))) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) if ( x != null ) x . close () if ( y != null ) y . close () if ( sess != null ) sess . close () if ( bundle != null ) bundle . close () result The output is: Array(Array(3.019596), Array(3.9878292))","title":"3. Loading TensorFlow model on the driver end of spark (scala) project and debug it successfully."},{"location":"english/Chapter6/Chapter6-7/#4-loading-tensorflow-model-on-executor-of-spark-scala-project-through-rdd-and-debug-it-successfully","text":"Here we transfer the TensorFlow model loaded on the Driver end to each executor through broadcasting, and predict with distributed computing on all the executors. import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } val spark = SparkSession . builder () . appName ( \"TfRDD\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext // Loading model on Driver end val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) // Broadcasting the model to all the executors val broads = sc . broadcast ( bundle ) // Creating dataset val rdd_data = sc . makeRDD ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 6.0f , 7.0f ), Array ( 8.0f , 3.0f ))) // Predicting in batch by using the model through mapPartitions val rdd_result = rdd_data . mapPartitions ( iter => { val arr = iter . toArray val model = broads . value val sess = model . session () val x = tf . Tensor . create ( arr ) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) // Copy the prediction into the Array in type Float with the same shape val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) result . iterator }) rdd_result . take ( 5 ) bundle . close The output is: Array(Array(3.019596), Array(3.9264367), Array(7.8607616), Array(15.974984))","title":"4. Loading TensorFlow model on executor of spark (scala) project through RDD and debug it successfully"},{"location":"english/Chapter6/Chapter6-7/#5-loading-tensorflow-model-on-executor-of-spark-scala-project-through-data-and-debug-it-successfully","text":"The distributed prediction using TensorFlow model could also be implemented on DataFrame data, besides implementing on RDD data in Spark. It could be done through registering the method of prediction as a sparkSQL function. import org.apache.spark.sql.SparkSession import scala.collection.mutable.WrappedArray import org. { tensorflow => tf } object TfDataFrame extends Serializable { def main ( args : Array [ String ]) : Unit = { val spark = SparkSession . builder () . appName ( \"TfDataFrame\" ) . enableHiveSupport () . getOrCreate () val sc = spark . sparkContext import spark.implicits._ val bundle = tf . SavedModelBundle . load ( \"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\" , \"serve\" ) val broads = sc . broadcast ( bundle ) // Construct the prediction function and register it as udf of sparkSQL val tfpredict = ( features : WrappedArray [ Float ]) => { val bund = broads . value val sess = bund . session () val x = tf . Tensor . create ( Array ( features . toArray )) val y = sess . runner (). feed ( \"serving_default_inputs:0\" , x ) . fetch ( \"StatefulPartitionedCall:0\" ). run (). get ( 0 ) val result = Array . ofDim [ Float ]( y . shape ()( 0 ). toInt , y . shape ()( 1 ). toInt ) y . copyTo ( result ) val y_pred = result ( 0 )( 0 ) y_pred } spark . udf . register ( \"tfpredict\" , tfpredict ) // Creating DataFrame dataset, and put the features into one of the columns val dfdata = sc . parallelize ( List ( Array ( 1.0f , 2.0f ), Array ( 3.0f , 5.0f ), Array ( 7.0f , 8.0f ))). toDF ( \"features\" ) dfdata . show // Call the sparkSQL predicting function, add a new column as y_preds val dfresult = dfdata . selectExpr ( \"features\" , \"tfpredict(features) as y_preds\" ) dfresult . show bundle . close } } TfDataFrame . main ( Array ()) +----------+ | features| +----------+ |[1.0, 2.0]| |[3.0, 5.0]| |[7.0, 8.0]| +----------+ +----------+---------+ | features| y_preds| +----------+---------+ |[1.0, 2.0]| 3.019596| |[3.0, 5.0]|3.9264367| |[7.0, 8.0]| 8.828995| +----------+---------+ We implemented distributed prediction using a linear regression model (implemented by tf.keras ) using both RDD and DataFrame data structures in spark. It is also possible to use the trained neural networks for distributed prediction through spark with just a slight modifications on this demonstration. Actually the capability of TensorFlow is more than implementing neural networks, the low-level language of graph is able to express all kinds of numerical computation. We are able to implement any kind of machine learning model on TensorFlow 2.0 with these various low-level APIs. It is also possible to export the trained models as files and use it on the distributed system such as spark, which provides huge space of imagination for future applications. Please leave comments in the WeChat official account \"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available. You are also welcomed to join the group chat with the other readers through replying \u52a0\u7fa4 (join group) in the WeChat official account.","title":"5. Loading TensorFlow model on executor of spark (scala) project through Data and debug it successfully"}]}